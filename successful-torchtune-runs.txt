$ tune run --nproc_per_node 8 full_finetune_distributed --config llama3/8B_full compile=true
$ tune run --nproc_per_node 8 full_finetune_distributed --config mistral/7B_full batch_size=64
$ tune run --nproc_per_node 8 full_finetune_distributed --config gemma/2B_full batch_size=32
$ tune run --nproc_per_node 8 full_finetune_distributed --config phi3/mini_full batch_size=64
$ tune run --nproc_per_node 8 full_finetune_distributed --config gemma/7B_full batch_size=16
$ tune run --nproc_per_node 8 full_finetune_distributed --config gemma2/2B_full batch_size=32
$ tune run --nproc_per_node 8 full_finetune_distributed --config qwen2/7B_full batch_size=32
$ tune run --nproc_per_node 8 full_finetune_distributed --config gemma2/9B_full batch_size=8
$ tune run --nproc_per_node 8 full_finetune_distributed --config qwen2/0.5B_full batch_size=16
$ tune run --nproc_per_node 8 full_finetune_distributed --config qwen2/1.5B_full batch_size=8
$ tune run --nproc_per_node 8 full_finetune_distributed --config qwen2_5/0.5B_full batch_size=16
$ tune run --nproc_per_node 8 full_finetune_distributed --config qwen2_5/1.5B_full batch_size=8
$ tune run --nproc_per_node 8 full_finetune_distributed --config gemma2/27B_full batch_size=4
$ tune run --nproc_per_node 8 full_finetune_distributed --config qwen2_5/3B_full batch_size=32
$ tune run --nproc_per_node 8 lora_finetune_distributed --config gemma/2B_lora batch_size=32
$ tune run --nproc_per_node 8 full_finetune_distributed --config qwen2_5/7B_full batch_size=32
$ tune run --nproc_per_node 8 lora_finetune_distributed --config gemma/7B_lora batch_size=32