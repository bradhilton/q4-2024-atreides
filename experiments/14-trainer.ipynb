{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from lib.clue import Clue, DeductiveSolver\n",
    "from lib.rl.episode import Episode, EpisodeCompletion\n",
    "from lib.rl.trainer import Trainer\n",
    "import random\n",
    "import re\n",
    "\n",
    "\n",
    "def sample_random_episode() -> Episode:\n",
    "    game = Clue(\n",
    "        num_players=3,\n",
    "        elements={\n",
    "            \"suspect\": random.choices(Clue.suspects, k=3),\n",
    "            \"weapon\": random.choices(Clue.weapons, k=3),\n",
    "            \"room\": random.choices(Clue.rooms, k=3),\n",
    "            # \"motive\": random.choices(Clue.motives, k=3),\n",
    "            # \"time\": random.choices(Clue.get_times(\"21:00\", \"03:00\", \"1h\"), k=3),\n",
    "        },\n",
    "    )\n",
    "    game.play(\n",
    "        deductive_solver=DeductiveSolver(\n",
    "            # note_cards_in_hand=False,\n",
    "            # note_responses_to_suggestions=False,\n",
    "            # note_cards_that_players_do_not_have=False,\n",
    "            # check_unique_card_placement_constraints=False,\n",
    "            # check_player_hand_size_constraints=False,\n",
    "            check_solution_has_one_and_only_one_card_per_element=False,\n",
    "            check_one_of_constraints=False,\n",
    "            check_inverse_one_of_constraints=False,\n",
    "            merge_and_check_disjoint_inverse_one_of_constraints=False,\n",
    "            exhaustively_test_possible_assignments=False,\n",
    "        ),\n",
    "        cp_solver_max_solve_time_per_turn=0.01,\n",
    "        check_cp_solver_grid=False,\n",
    "        check_if_deductive_solver_and_cp_solver_grids_match=False,\n",
    "        print_playthrough=False,\n",
    "    )\n",
    "    prompt = game.get_prompt()\n",
    "    follow_up = \"Fill out your answer like this:\\n\" + \"\\n\".join(\n",
    "        f\"{element.capitalize()}: <#{element.upper()}#>\" for element in game.elements\n",
    "    )\n",
    "\n",
    "    async def reward_completion(completion: EpisodeCompletion) -> EpisodeCompletion:\n",
    "        if len(completion.messages) == 2:\n",
    "            follow_up_completion = await completion.follow_up(\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": follow_up},\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            follow_up_completion = completion\n",
    "        answer = follow_up_completion.last_assistant_message.get(\"content\")\n",
    "        assert isinstance(answer, str)\n",
    "        completion.reward = sum(\n",
    "            [\n",
    "                bool(\n",
    "                    re.search(\n",
    "                        f\"{element}: {solution}\",\n",
    "                        answer,\n",
    "                        re.IGNORECASE,\n",
    "                    )\n",
    "                )\n",
    "                for element, solution in game.solution.items()\n",
    "            ]\n",
    "        ) / len(game.solution)\n",
    "        return completion\n",
    "\n",
    "    async def on_sample(completions: list[EpisodeCompletion]) -> None:\n",
    "        for completion in await asyncio.gather(\n",
    "            *[reward_completion(completion) for completion in completions]\n",
    "        ):\n",
    "            completion.commit()\n",
    "\n",
    "    return Episode(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        on_sample=on_sample,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_episodes():\n",
    "    while True:\n",
    "        yield sample_random_episode()\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    base_model=\"NousResearch/Hermes-2-Theta-Llama-3-8B\",\n",
    "    samples_per_episode=32,\n",
    "    branch_factor=5,\n",
    "    train_episodes=train_episodes(),\n",
    "    episodes_per_iteration=128,\n",
    "    val_episodes=[sample_random_episode() for _ in range(64)],\n",
    "    tune_sequence_length=8192,\n",
    "    vllm_kwargs=dict(disable_log_requests=True, scheduling_policy=\"priority\"),\n",
    "    vllm_max_concurrent_requests=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score, episodes = await asyncio.gather(trainer.eval(\"val\", 0), trainer.explore(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm = await trainer.vllm()\n",
    "vllm.process.terminate()\n",
    "trainer._vllm_task, trainer._completion_sampler = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from torchtune.models.llama3_1 import llama3_1_8b\n",
    "from torchtune.training import cleanup_before_training\n",
    "from torchtune.training.metric_logging import DiskLogger\n",
    "from typing import Any\n",
    "\n",
    "from lib.recipes.rl import ComponentConfig, RLConfig, RLRecipe\n",
    "from lib.rl.pack import PackedDataset, packed_tensors\n",
    "from lib.rl.ppo import PPOLoss\n",
    "\n",
    "tensors = packed_tensors(\n",
    "    episodes,\n",
    "    model=trainer.model,\n",
    "    sequence_length=trainer.tune_sequence_length,\n",
    "    trajectories_per_episode=(\n",
    "        int(trainer.samples_per_episode * trainer.tune_episode_sample_fraction)\n",
    "        if trainer.tune_episode_sample_fraction < 1.0\n",
    "        else None\n",
    "    ),\n",
    "    tokenizer=trainer.tokenizer,\n",
    ")\n",
    "\n",
    "checkpoint_dir = subprocess.run(\n",
    "    f\"HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download {trainer.model}\",\n",
    "    shell=True,\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    ").stdout.strip()\n",
    "print(\"Checkpoint directory:\", checkpoint_dir)\n",
    "\n",
    "checkpoint_output_dir = \"/home/ubuntu/atreides/experiments/models/rl\"\n",
    "os.makedirs(checkpoint_output_dir, exist_ok=True)\n",
    "\n",
    "PLACEHOLDER: Any = None\n",
    "\n",
    "config = RLConfig(\n",
    "    # Dataset\n",
    "    dataset=ComponentConfig(PackedDataset, tensors=tensors),\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    # Model\n",
    "    model=ComponentConfig(llama3_1_8b),\n",
    "    num_output_chunks=4,\n",
    "    # Checkpointer\n",
    "    checkpointer=ComponentConfig(\n",
    "        \"torchtune.training.FullModelHFCheckpointer\",\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        checkpoint_files=[\n",
    "            \"model-00001-of-00004.safetensors\",\n",
    "            \"model-00002-of-00004.safetensors\",\n",
    "            \"model-00003-of-00004.safetensors\",\n",
    "            \"model-00004-of-00004.safetensors\",\n",
    "        ],\n",
    "        recipe_checkpoint=None,\n",
    "        output_dir=checkpoint_output_dir,\n",
    "        model_type=\"LLAMA3\",\n",
    "    ),\n",
    "    resume_from_checkpoint=False,\n",
    "    # Fine-tuning arguments\n",
    "    batch_size=4,\n",
    "    epochs=1,\n",
    "    optimizer=ComponentConfig(\n",
    "        # AdamW,\n",
    "        \"bitsandbytes.optim.PagedAdamW8bit\",\n",
    "        params=PLACEHOLDER,\n",
    "        lr=5e-6,\n",
    "        # fused=True,\n",
    "    ),\n",
    "    loss=ComponentConfig(\n",
    "        PPOLoss,\n",
    "        # clip_epsilon=0.3,\n",
    "        # entropy_coef=0.0,\n",
    "        # kl_coef=0.0,\n",
    "        clip_epsilon=0.3,\n",
    "        entropy_coef=0.025,\n",
    "        kl_coef=0.025,\n",
    "    ),\n",
    "    max_steps_per_epoch=None,\n",
    "    compile=False,\n",
    "    optimizer_in_bwd=False,\n",
    "    gradient_accumulation_steps=1,\n",
    "    # Training env\n",
    "    device=\"cuda\",\n",
    "    # Memory management\n",
    "    enable_activation_checkpointing=True,\n",
    "    enable_activation_offloading=False,\n",
    "    custom_sharded_layers=[\"tok_embeddings\", \"output\"],\n",
    "    # Reduced precision\n",
    "    dtype=\"bf16\",\n",
    "    # Logging\n",
    "    metric_logger=ComponentConfig(\n",
    "        DiskLogger, log_dir=\"/home/ubuntu/atreides/experiments/logs\"\n",
    "    ),\n",
    "    output_dir=\"/home/ubuntu/atreides/experiments/logs\",\n",
    "    log_every_n_steps=1,\n",
    "    log_peak_memory_stats=True,\n",
    ")\n",
    "\n",
    "recipe = RLRecipe(config)\n",
    "recipe.setup(config)\n",
    "recipe.train()\n",
    "recipe.cleanup()\n",
    "del recipe\n",
    "cleanup_before_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del recipe\n",
    "cleanup_before_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "def show(mask: torch.Tensor) -> None:\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(mask, cmap=\"inferno\")\n",
    "    plt.colorbar(label=\"Relative Position\")\n",
    "    plt.title(\"Relative Position Attention Mask\")\n",
    "    plt.xlabel(\"Target Position\")\n",
    "    plt.ylabel(\"Source Position\")\n",
    "    plt.show()\n",
    "\n",
    "i = 1\n",
    "\n",
    "show(\n",
    "    tensors[\"mask\"][i].cumsum(dim=1)\n",
    "    * (\n",
    "        tensors[\"mask\"][i]\n",
    "        & (\n",
    "            ~torch.isnan(tensors[\"advantages\"][i]).unsqueeze(0)\n",
    "            & ~torch.isnan(tensors[\"advantages\"][i]).unsqueeze(1)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\n",
    "    f'<div style=\"white-space: pre-wrap\">{list(episodes[2].completion.leaves())[0].html(30.0)}</div>'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_and_pos_ids(\n",
    "    ids: torch.Tensor, parent_ids: torch.Tensor\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Creates an attention mask and position IDs for hierarchical attention based on node IDs and their parent IDs.\n",
    "\n",
    "    Args:\n",
    "        ids: A tensor of shape (batch_size, sequence_length) containing node IDs\n",
    "        parent_ids: A tensor of shape (batch_size, sequence_length) containing parent IDs for each node\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - mask: A boolean tensor of shape (batch_size, sequence_length, sequence_length) where True indicates\n",
    "          allowed attention connections. Each position can attend to itself and any of its ancestors\n",
    "          in the hierarchy, but only for previous positions (due to causal masking).\n",
    "        - pos_ids: A tensor of shape (batch_size, sequence_length, sequence_length) containing relative\n",
    "          position IDs for each allowed attention connection, with -1 for masked positions.\n",
    "    \"\"\"\n",
    "    mask = ids.unsqueeze(1) == ids.unsqueeze(2)\n",
    "    _mask = mask | (ids.unsqueeze(1) == parent_ids.unsqueeze(2))\n",
    "    while torch.any(mask != _mask):\n",
    "        parent_ids = parent_ids.gather(\n",
    "            1, torch.argmax((parent_ids.unsqueeze(2) == ids.unsqueeze(1)).int(), dim=2)\n",
    "        )\n",
    "        mask = _mask\n",
    "        _mask = mask | (ids.unsqueeze(1) == parent_ids.unsqueeze(2))\n",
    "    mask &= torch.tril(torch.ones_like(mask, dtype=torch.bool, device=ids.device))\n",
    "    # mask = torch.linalg.matrix_power(mask.float(), mask.size(1) - 1) > 0\n",
    "    pos_ids = (torch.where(mask, mask.cumsum(2), 0) - 1).max(1).values\n",
    "    return mask, pos_ids\n",
    "\n",
    "\n",
    "def test_mask_and_pos_ids(\n",
    "    ids: list[int],\n",
    "    parent_ids: list[int],\n",
    "    expected_mask: list[list[int]],\n",
    "    expected_pos_ids: list[int],\n",
    "):\n",
    "    mask, pos_ids = mask_and_pos_ids(\n",
    "        ids=torch.tensor([ids]), parent_ids=torch.tensor([parent_ids])\n",
    "    )\n",
    "    assert torch.all(mask.int() == torch.tensor([expected_mask])), f\"\\n{mask.int()[0]}\"\n",
    "    assert torch.all(\n",
    "        pos_ids == torch.tensor([expected_pos_ids])\n",
    "    ), f\"{pos_ids[0].tolist()}\"\n",
    "\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1],\n",
    "    parent_ids=[0, 1],\n",
    "    expected_mask=[[1, 0], [0, 1]],\n",
    "    expected_pos_ids=[0, 0],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1, 1],\n",
    "    parent_ids=[0, 0, 0],\n",
    "    expected_mask=[[1, 0, 0], [1, 1, 0], [1, 1, 1]],\n",
    "    expected_pos_ids=[0, 1, 2],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1, 2, 3],\n",
    "    parent_ids=[0, 0, 1, 2],\n",
    "    expected_mask=[[1, 0, 0, 0], [1, 1, 0, 0], [1, 1, 1, 0], [1, 1, 1, 1]],\n",
    "    expected_pos_ids=[0, 1, 2, 3],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 0, 1, 1],\n",
    "    parent_ids=[0, 0, 1, 1],\n",
    "    expected_mask=[[1, 0, 0, 0], [1, 1, 0, 0], [0, 0, 1, 0], [0, 0, 1, 1]],\n",
    "    expected_pos_ids=[0, 1, 0, 1],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1, 2, 3],\n",
    "    parent_ids=[0, 1, 0, 1],\n",
    "    expected_mask=[[1, 0, 0, 0], [0, 1, 0, 0], [1, 0, 1, 0], [0, 1, 0, 1]],\n",
    "    expected_pos_ids=[0, 0, 1, 1],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1, 2, 2, 3, 3],\n",
    "    parent_ids=[0, 1, 0, 0, 1, 1],\n",
    "    expected_mask=[\n",
    "        [1, 0, 0, 0, 0, 0],\n",
    "        [0, 1, 0, 0, 0, 0],\n",
    "        [1, 0, 1, 0, 0, 0],\n",
    "        [1, 0, 1, 1, 0, 0],\n",
    "        [0, 1, 0, 0, 1, 0],\n",
    "        [0, 1, 0, 0, 1, 1],\n",
    "    ],\n",
    "    expected_pos_ids=[0, 0, 1, 2, 1, 2],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1, 2, 3, 4, 4, 5, 5],\n",
    "    parent_ids=[0, 0, 1, 1, 2, 2, 3, 3],\n",
    "    expected_mask=[\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 0, 1, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 0, 1, 0, 0, 0],\n",
    "        [1, 1, 1, 0, 1, 1, 0, 0],\n",
    "        [1, 1, 0, 1, 0, 0, 1, 0],\n",
    "        [1, 1, 0, 1, 0, 0, 1, 1],\n",
    "    ],\n",
    "    expected_pos_ids=[0, 1, 2, 2, 3, 4, 3, 4],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[2, 1, 0],\n",
    "    parent_ids=[2, 2, 0],\n",
    "    expected_mask=[\n",
    "        [1, 0, 0],\n",
    "        [1, 1, 0],\n",
    "        [0, 0, 1],\n",
    "    ],\n",
    "    expected_pos_ids=[0, 1, 0],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
