{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from lib.clue import Clue, DeductiveSolver\n",
    "from lib.rl.episode import Episode, EpisodeCompletion\n",
    "from lib.rl.trainer import Trainer\n",
    "import re\n",
    "\n",
    "\n",
    "def sample_random_episode() -> Episode:\n",
    "    game = Clue(\n",
    "        num_players=3,\n",
    "        elements={\n",
    "            \"suspect\": Clue.suspects[:3],\n",
    "            \"weapon\": Clue.weapons[:3],\n",
    "            \"room\": Clue.rooms[:3],\n",
    "            # \"motive\": Clue.motives[:6],\n",
    "            # \"time\": Clue.get_times(\"21:00\", \"03:00\", \"1h\"),\n",
    "        },\n",
    "    )\n",
    "    game.play(\n",
    "        deductive_solver=DeductiveSolver(\n",
    "            # note_cards_in_hand=False,\n",
    "            # note_responses_to_suggestions=False,\n",
    "            # note_cards_that_players_do_not_have=False,\n",
    "            # check_unique_card_placement_constraints=False,\n",
    "            # check_player_hand_size_constraints=False,\n",
    "            check_solution_has_one_and_only_one_card_per_element=False,\n",
    "            check_one_of_constraints=False,\n",
    "            check_inverse_one_of_constraints=False,\n",
    "            merge_and_check_disjoint_inverse_one_of_constraints=False,\n",
    "            exhaustively_test_possible_assignments=False,\n",
    "        ),\n",
    "        cp_solver_max_solve_time_per_turn=0.01,\n",
    "        check_cp_solver_grid=False,\n",
    "        check_if_deductive_solver_and_cp_solver_grids_match=False,\n",
    "        print_playthrough=False,\n",
    "    )\n",
    "    prompt = game.get_prompt()\n",
    "    follow_up = \"Fill out your answer like this:\\n\" + \"\\n\".join(\n",
    "        f\"{element.capitalize()}: <#{element.upper()}#>\" for element in game.elements\n",
    "    )\n",
    "\n",
    "    async def reward_completion(completion: EpisodeCompletion) -> EpisodeCompletion:\n",
    "        if len(completion.messages) == 2:\n",
    "            follow_up_completion = await completion.follow_up(\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": follow_up},\n",
    "                ]\n",
    "            )\n",
    "        answer = follow_up_completion.last_assistant_message.get(\"content\")\n",
    "        assert isinstance(answer, str)\n",
    "        completion.reward = sum(\n",
    "            [\n",
    "                bool(\n",
    "                    re.search(\n",
    "                        f\"{element}: {solution}\",\n",
    "                        answer,\n",
    "                        re.IGNORECASE,\n",
    "                    )\n",
    "                )\n",
    "                for element, solution in game.solution.items()\n",
    "            ]\n",
    "        ) / len(game.solution)\n",
    "        return completion\n",
    "\n",
    "    async def on_sample(completions: list[EpisodeCompletion]) -> None:\n",
    "        for completion in await asyncio.gather(\n",
    "            *[reward_completion(completion) for completion in completions]\n",
    "        ):\n",
    "            completion.commit()\n",
    "\n",
    "    return Episode(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        on_sample=on_sample,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_episodes():\n",
    "    while True:\n",
    "        yield sample_random_episode()\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    base_model=\"NousResearch/Hermes-2-Theta-Llama-3-8B\",\n",
    "    samples_per_episode=32,\n",
    "    branch_factor=5,\n",
    "    train_episodes=train_episodes(),\n",
    "    episodes_per_iteration=128,\n",
    "    val_episodes=[sample_random_episode() for _ in range(64)],\n",
    "    tune_sequence_length=8192,\n",
    "    vllm_kwargs=dict(disable_log_requests=True, scheduling_policy=\"priority\"),\n",
    "    vllm_max_concurrent_requests=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score, episodes = await asyncio.gather(trainer.eval(\"val\", 0), trainer.explore(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm = await trainer.vllm()\n",
    "vllm.process.terminate()\n",
    "trainer._vllm_task, trainer._completion_sampler = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from torchtune.models.llama3_1 import llama3_1_8b\n",
    "from torchtune.training import cleanup_before_training\n",
    "from torchtune.training.metric_logging import DiskLogger\n",
    "from typing import Any\n",
    "\n",
    "from lib.recipes.rl import ComponentConfig, RLConfig, RLRecipe\n",
    "from lib.rl.pack import PackedDataset, packed_tensors\n",
    "from lib.rl.ppo import PPOLoss\n",
    "\n",
    "tensors = packed_tensors(\n",
    "    episodes,\n",
    "    model=trainer.model,\n",
    "    sequence_length=trainer.tune_sequence_length,\n",
    "    trajectories_per_episode=(\n",
    "        int(trainer.samples_per_episode * trainer.tune_episode_sample_fraction)\n",
    "        if trainer.tune_episode_sample_fraction < 1.0\n",
    "        else None\n",
    "    ),\n",
    "    tokenizer=trainer.tokenizer,\n",
    ")\n",
    "\n",
    "checkpoint_dir = subprocess.run(\n",
    "    f\"HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download {trainer.model}\",\n",
    "    shell=True,\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    ").stdout.strip()\n",
    "print(\"Checkpoint directory:\", checkpoint_dir)\n",
    "\n",
    "checkpoint_output_dir = \"/home/ubuntu/atreides/experiments/models/rl\"\n",
    "os.makedirs(checkpoint_output_dir, exist_ok=True)\n",
    "\n",
    "PLACEHOLDER: Any = None\n",
    "\n",
    "config = RLConfig(\n",
    "    # Dataset\n",
    "    dataset=ComponentConfig(PackedDataset, tensors=tensors),\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    # Model\n",
    "    model=ComponentConfig(llama3_1_8b),\n",
    "    num_output_chunks=4,\n",
    "    # Checkpointer\n",
    "    checkpointer=ComponentConfig(\n",
    "        \"torchtune.training.FullModelHFCheckpointer\",\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        checkpoint_files=[\n",
    "            \"model-00001-of-00004.safetensors\",\n",
    "            \"model-00002-of-00004.safetensors\",\n",
    "            \"model-00003-of-00004.safetensors\",\n",
    "            \"model-00004-of-00004.safetensors\",\n",
    "        ],\n",
    "        recipe_checkpoint=None,\n",
    "        output_dir=checkpoint_output_dir,\n",
    "        model_type=\"LLAMA3\",\n",
    "    ),\n",
    "    resume_from_checkpoint=False,\n",
    "    # Fine-tuning arguments\n",
    "    batch_size=4,\n",
    "    epochs=1,\n",
    "    optimizer=ComponentConfig(\n",
    "        # AdamW,\n",
    "        \"bitsandbytes.optim.PagedAdamW8bit\",\n",
    "        params=PLACEHOLDER,\n",
    "        lr=5e-6,\n",
    "        # fused=True,\n",
    "    ),\n",
    "    loss=ComponentConfig(\n",
    "        PPOLoss,\n",
    "        # clip_epsilon=0.3,\n",
    "        # entropy_coef=0.0,\n",
    "        # kl_coef=0.0,\n",
    "        clip_epsilon=0.3,\n",
    "        entropy_coef=0.025,\n",
    "        kl_coef=0.025,\n",
    "    ),\n",
    "    max_steps_per_epoch=None,\n",
    "    compile=False,\n",
    "    optimizer_in_bwd=False,\n",
    "    gradient_accumulation_steps=1,\n",
    "    # Training env\n",
    "    device=\"cuda\",\n",
    "    # Memory management\n",
    "    enable_activation_checkpointing=True,\n",
    "    enable_activation_offloading=False,\n",
    "    custom_sharded_layers=[\"tok_embeddings\", \"output\"],\n",
    "    # Reduced precision\n",
    "    dtype=\"bf16\",\n",
    "    # Logging\n",
    "    metric_logger=ComponentConfig(\n",
    "        DiskLogger, log_dir=\"/home/ubuntu/atreides/experiments/logs\"\n",
    "    ),\n",
    "    output_dir=\"/home/ubuntu/atreides/experiments/logs\",\n",
    "    log_every_n_steps=1,\n",
    "    log_peak_memory_stats=True,\n",
    ")\n",
    "\n",
    "recipe = RLRecipe(config)\n",
    "recipe.setup(config)\n",
    "recipe.train()\n",
    "recipe.cleanup()\n",
    "del recipe\n",
    "cleanup_before_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del recipe\n",
    "cleanup_before_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors[\"tokens\"][0][tensors[\"mask\"][0][1405]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors2 = packed_tensors(\n",
    "    episodes,\n",
    "    model=trainer.model,\n",
    "    sequence_length=trainer.tune_sequence_length,\n",
    "    trajectories_per_episode=(\n",
    "        int(trainer.samples_per_episode * trainer.tune_episode_sample_fraction)\n",
    "        if trainer.tune_episode_sample_fraction < 1.0\n",
    "        else None\n",
    "    ),\n",
    "    tokenizer=trainer.tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors[\"advantages\"][0][1406]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors[\"input_pos\"][0][tensors[\"mask\"][0][1406]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.tokenizer.decode(tensors[\"tokens\"][0][tensors[\"mask\"][0][1405]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.tokenizer.decode(trainer.tokenizer.encode(next(episodes[0].completion.leaves()).all_message_params(), continue_final_message=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.tokenizer.decode(trainer.tokenizer.encode(next(episodes[0].completion.leaves()).all_message_params())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors[\"mask\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainer.tokenizer.decode(tensors[\"tokens\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_mask(ids: torch.Tensor, ancestor_ids: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Creates an attention mask for hierarchical attention based on node IDs and their ancestor IDs.\n",
    "\n",
    "    Args:\n",
    "        ids: A tensor of shape (batch_size, sequence_length) containing node IDs\n",
    "        ancestor_ids: A tensor of shape (batch_size, sequence_length, max_ancestors) containing ancestor IDs for each node\n",
    "            including itself, padded with zeros\n",
    "\n",
    "    Returns:\n",
    "        A boolean tensor of shape (batch_size, sequence_length, sequence_length) where True indicates\n",
    "        allowed attention connections. Each position can attend to itself and any of its ancestors\n",
    "        in the hierarchy, but only for previous positions (due to causal masking).\n",
    "    \"\"\"\n",
    "    # Compare each position against all ancestors of each other position\n",
    "    # Shape: (batch, seq, seq, max_ancestors)\n",
    "    mask = ids.unsqueeze(1).unsqueeze(3) == ancestor_ids.unsqueeze(2)\n",
    "    # Reduce over ancestors dimension to get final mask\n",
    "    # Shape: (batch, seq, seq)\n",
    "    mask = mask.any(dim=3)\n",
    "    # Apply causal mask\n",
    "    mask &= torch.tril(torch.ones_like(mask, dtype=torch.bool, device=ids.device))\n",
    "    return mask\n",
    "\n",
    "\n",
    "# mask = get_mask(tensors[\"ids\"], tensors[\"ancestor_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mask(\n",
    "    ids=torch.tensor([[0, 1, 2, 3, 3, 4, 4, 5, 5, 6]]),\n",
    "    ancestor_ids=torch.tensor(\n",
    "        [\n",
    "            [\n",
    "                [0, 0, 0],\n",
    "                [1, 0, 0],\n",
    "                [2, 1, 0],\n",
    "                [3, 1, 0],\n",
    "                [3, 1, 0],\n",
    "                [4, 0, 0],\n",
    "                [4, 0, 0],\n",
    "                [5, 4, 0],\n",
    "                [5, 4, 0],\n",
    "                [6, 6, 6],\n",
    "            ]\n",
    "        ]\n",
    "    ),\n",
    ").int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(~torch.isnan(tensors[\"advantages\"][0]).unsqueeze(0) & ~torch.isnan(tensors[\"advantages\"][0]).unsqueeze(1)).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "def show(mask: torch.Tensor) -> None:\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(mask, cmap=\"inferno\")\n",
    "    plt.colorbar(label=\"Relative Position\")\n",
    "    plt.title(\"Relative Position Attention Mask\")\n",
    "    plt.xlabel(\"Target Position\")\n",
    "    plt.ylabel(\"Source Position\")\n",
    "    plt.show()\n",
    "\n",
    "i = 1\n",
    "\n",
    "show(\n",
    "    tensors[\"mask\"][i].cumsum(dim=1)\n",
    "    * (\n",
    "        tensors[\"mask\"][i]\n",
    "        & (\n",
    "            ~torch.isnan(tensors[\"advantages\"][i]).unsqueeze(0)\n",
    "            & ~torch.isnan(tensors[\"advantages\"][i]).unsqueeze(1)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.isnan(tensors[\"advantages\"][i]).unsqueeze(0)\n",
    "            & ~torch.isnan(tensors[\"advantages\"][i]).unsqueeze(1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show((~torch.isnan(tensors[\"advantages\"][0]).unsqueeze(0) & ~torch.isnan(tensors[\"advantages\"][0]).unsqueeze(1)).int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "tensors = await trainer.tune(episodes[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await trainer.eval(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = await trainer.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\n",
    "    f'<div style=\"white-space: pre-wrap\">{list(episodes[2].completion.leaves())[0].html(30.0)}</div>'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes: list[Episode] = trainer.eval_episodes[\"val\"]  # type: ignore\n",
    "divisor = max(\n",
    "    sum(\n",
    "        1\n",
    "        for episode in episodes\n",
    "        if any(child.model == trainer.model for child in episode.completion.children)\n",
    "    ),\n",
    "    1,\n",
    ")\n",
    "score = (\n",
    "    sum(episode.completion.value(model=trainer.model) for episode in episodes) / divisor\n",
    ")\n",
    "score, divisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(list(episode.completion.descendants())) for episode in episodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(list(episodes[0].completion.children)[0].children)[0].message_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[episode.completion.value(model=trainer.model) for episode in episodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(\n",
    "    sum(child.model == trainer.model for child in episode.completion.children)\n",
    "    for episode in episodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.eval_scores[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_mask(ids: torch.Tensor, parent_ids: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Creates a causal attention mask based on token group IDs and their parent relationships.\n",
    "\n",
    "    Each token can attend to:\n",
    "    1. All preceding tokens in its own group (tokens with same ID)\n",
    "    2. All tokens in any ancestor group (following parent_ids chain up)\n",
    "    The mask enforces causality - tokens cannot attend to future positions.\n",
    "\n",
    "    Args:\n",
    "        ids: 1D tensor of token group IDs. Shape: [sequence_length]\n",
    "        parent_ids: 1D tensor of parent group IDs. Shape: [sequence_length]\n",
    "            Any integer value is valid - if a parent ID is not found in ids,\n",
    "            that group is treated as a root node.\n",
    "            Each ID must have a corresponding parent ID at the same index.\n",
    "\n",
    "    Returns:\n",
    "        2D boolean tensor of shape [sequence_length, sequence_length] where\n",
    "        mask[i,j] = True means position i can attend to position j.\n",
    "        False means position i cannot attend to position j.\n",
    "\n",
    "    Example:\n",
    "        ids = torch.tensor([0, 0, 1, 1])\n",
    "        parent_ids = torch.tensor([100, 100, 0, 0])\n",
    "        # Group 1 tokens can attend to group 0 tokens since 0 is their parent\n",
    "        # Group 0's parent (100) is not in ids so it's treated as root\n",
    "    \"\"\"\n",
    "    # Create mask of shape [seq_len, seq_len] initialized to False\n",
    "    seq_len = len(ids)\n",
    "    mask = torch.zeros((seq_len, seq_len), dtype=torch.bool)\n",
    "\n",
    "    # For each target position\n",
    "    for i in range(seq_len):\n",
    "        # Get current id and parent id\n",
    "        curr_id = ids[i]\n",
    "        curr_parent = parent_ids[i]\n",
    "\n",
    "        # For each source position up to and including target\n",
    "        for j in range(i + 1):\n",
    "            # Token can attend to itself and earlier tokens in same group\n",
    "            if ids[j] == curr_id:\n",
    "                mask[i, j] = True\n",
    "\n",
    "            # Token can attend to tokens in ancestor groups\n",
    "            ancestor_id = curr_parent\n",
    "            while ancestor_id in ids:  # Only follow chain while ancestor exists in ids\n",
    "                if ids[j] == ancestor_id:\n",
    "                    mask[i, j] = True\n",
    "                # Move up to next ancestor\n",
    "                # Find first occurrence of current ancestor to get its parent\n",
    "                ancestor_idx = torch.where(ids == ancestor_id)[0][0]\n",
    "                ancestor_id = parent_ids[ancestor_idx]\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_fast_mask(ids: torch.Tensor, parent_ids: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Faster implementation of get_mask using vectorized operations\"\"\"\n",
    "    seq_len = len(ids)\n",
    "\n",
    "    # Get unique group IDs and map them to indices\n",
    "    unique_ids = torch.unique(ids)\n",
    "    group_id_list = unique_ids.tolist()  # Converts tensor to list of Python numbers\n",
    "    group_id_to_index = {group_id: idx for idx, group_id in enumerate(group_id_list)}\n",
    "    num_groups = len(unique_ids)\n",
    "\n",
    "    # Build group_id_to_parent_id mapping\n",
    "    group_parents = {}\n",
    "    for group_id in group_id_list:\n",
    "        indices = (ids == group_id).nonzero(as_tuple=True)[0]\n",
    "        idx = indices[0].item()  # Select the first occurrence\n",
    "        parent_id = parent_ids[idx].item()\n",
    "        group_parents[group_id] = parent_id\n",
    "\n",
    "    # For each group, compute its ancestors\n",
    "    group_ancestors = {}\n",
    "    for group_id in group_id_list:\n",
    "        ancestors = set()\n",
    "        parent_id = group_parents.get(group_id, None)\n",
    "        while parent_id in group_id_list and parent_id not in ancestors:\n",
    "            ancestors.add(parent_id)\n",
    "            parent_id = group_parents.get(parent_id, None)\n",
    "        group_ancestors[group_id] = ancestors\n",
    "\n",
    "    # Create allowed_groups per group index\n",
    "    allowed_groups = torch.zeros((num_groups, num_groups), dtype=torch.bool)\n",
    "    for i, group_id in enumerate(group_id_list):\n",
    "        # Each group can attend to itself\n",
    "        allowed_groups[i, i] = True\n",
    "        # And its ancestors\n",
    "        for ancestor_id in group_ancestors[group_id]:\n",
    "            ancestor_idx = group_id_to_index[ancestor_id]\n",
    "            allowed_groups[i, ancestor_idx] = True\n",
    "\n",
    "    # Map positions to group indices\n",
    "    group_indices = torch.tensor(\n",
    "        [group_id_to_index[group_id.item()] for group_id in ids], dtype=torch.long\n",
    "    )\n",
    "\n",
    "    # Get allowed groups per position\n",
    "    allowed_groups_per_position = allowed_groups[\n",
    "        group_indices\n",
    "    ]  # Shape: [seq_len, num_groups]\n",
    "\n",
    "    # Create group indices matrix for source positions\n",
    "    group_indices_source = group_indices.unsqueeze(0).expand(\n",
    "        seq_len, seq_len\n",
    "    )  # Shape: [seq_len, seq_len]\n",
    "\n",
    "    # Compute mask by checking if source group is allowed for target position\n",
    "    mask = allowed_groups_per_position.gather(1, group_indices_source)\n",
    "\n",
    "    # Enforce causality (tokens cannot attend to future positions)\n",
    "    causal_mask = torch.tril(torch.ones(seq_len, seq_len, dtype=torch.bool))\n",
    "    mask = mask & causal_mask\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "ids = torch.tensor([0, 0, 0, 1, 1, 2, 2, 3, 4, 4, 4, 5, 5] * 2)\n",
    "parent_ids = torch.tensor([-1, -1, -1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2] * 2)\n",
    "mask = get_mask(ids, parent_ids)\n",
    "fast_mask = get_fast_mask(ids, parent_ids)\n",
    "assert torch.all(mask == fast_mask), \"Fast implementation does not match original\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(fast_mask, cmap=\"binary\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Attention Mask\")\n",
    "plt.xlabel(\"Source Position\")\n",
    "plt.ylabel(\"Target Position\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faster_mask(ids: torch.Tensor, parent_ids: torch.Tensor) -> torch.Tensor:\n",
    "    mask = ids.unsqueeze(0) == ids.unsqueeze(1)\n",
    "    _mask = mask | (ids.unsqueeze(0) == parent_ids.unsqueeze(1))\n",
    "    parent_ids = parent_ids[ids]\n",
    "    while torch.any(mask != _mask):\n",
    "        mask = _mask\n",
    "        _mask = mask | (ids.unsqueeze(0) == parent_ids.unsqueeze(1))\n",
    "        parent_ids = parent_ids[parent_ids]\n",
    "    mask &= torch.tril(torch.ones_like(mask))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "get_faster_mask(ids, parent_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, id: int, parent: \"Node | None\" = None, size: int = 1):\n",
    "        self.id = id\n",
    "        self.parent = parent\n",
    "        self.size = size\n",
    "\n",
    "\n",
    "nodes = [Node(id=0, size=random.randint(1, 1)), Node(id=1, size=random.randint(1, 1))]\n",
    "for i in range(2, 8):\n",
    "    parent = random.choice(nodes)\n",
    "    size = random.randint(1, 2)\n",
    "    node = Node(id=i, parent=parent, size=size)\n",
    "    nodes.append(node)\n",
    "ids = torch.tensor([node.id for node in nodes for _ in range(node.size)])\n",
    "parent_ids = torch.tensor(\n",
    "    [\n",
    "        node.parent.id if node.parent else node.id\n",
    "        for node in nodes\n",
    "        for _ in range(node.size)\n",
    "    ]\n",
    ")\n",
    "# mask = get_mask(ids, parent_ids)\n",
    "# faster_mask = get_faster_mask(ids, parent_ids)\n",
    "torch.stack([ids, parent_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_and_pos_ids(\n",
    "    ids: torch.Tensor, parent_ids: torch.Tensor\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Creates an attention mask and position IDs for hierarchical attention based on node IDs and their parent IDs.\n",
    "\n",
    "    Args:\n",
    "        ids: A tensor of shape (batch_size, sequence_length) containing node IDs\n",
    "        parent_ids: A tensor of shape (batch_size, sequence_length) containing parent IDs for each node\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - mask: A boolean tensor of shape (batch_size, sequence_length, sequence_length) where True indicates\n",
    "          allowed attention connections. Each position can attend to itself and any of its ancestors\n",
    "          in the hierarchy, but only for previous positions (due to causal masking).\n",
    "        - pos_ids: A tensor of shape (batch_size, sequence_length, sequence_length) containing relative\n",
    "          position IDs for each allowed attention connection, with -1 for masked positions.\n",
    "    \"\"\"\n",
    "    mask = ids.unsqueeze(1) == ids.unsqueeze(2)\n",
    "    _mask = mask | (ids.unsqueeze(1) == parent_ids.unsqueeze(2))\n",
    "    while torch.any(mask != _mask):\n",
    "        parent_ids = parent_ids.gather(\n",
    "            1, torch.argmax((parent_ids.unsqueeze(2) == ids.unsqueeze(1)).int(), dim=2)\n",
    "        )\n",
    "        mask = _mask\n",
    "        _mask = mask | (ids.unsqueeze(1) == parent_ids.unsqueeze(2))\n",
    "    mask &= torch.tril(torch.ones_like(mask, dtype=torch.bool, device=ids.device))\n",
    "    # mask = torch.linalg.matrix_power(mask.float(), mask.size(1) - 1) > 0\n",
    "    pos_ids = (torch.where(mask, mask.cumsum(2), 0) - 1).max(1).values\n",
    "    return mask, pos_ids\n",
    "\n",
    "\n",
    "def test_mask_and_pos_ids(\n",
    "    ids: list[int],\n",
    "    parent_ids: list[int],\n",
    "    expected_mask: list[list[int]],\n",
    "    expected_pos_ids: list[int],\n",
    "):\n",
    "    mask, pos_ids = mask_and_pos_ids(\n",
    "        ids=torch.tensor([ids]), parent_ids=torch.tensor([parent_ids])\n",
    "    )\n",
    "    assert torch.all(mask.int() == torch.tensor([expected_mask])), f\"\\n{mask.int()[0]}\"\n",
    "    assert torch.all(\n",
    "        pos_ids == torch.tensor([expected_pos_ids])\n",
    "    ), f\"{pos_ids[0].tolist()}\"\n",
    "\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1],\n",
    "    parent_ids=[0, 1],\n",
    "    expected_mask=[[1, 0], [0, 1]],\n",
    "    expected_pos_ids=[0, 0],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1, 1],\n",
    "    parent_ids=[0, 0, 0],\n",
    "    expected_mask=[[1, 0, 0], [1, 1, 0], [1, 1, 1]],\n",
    "    expected_pos_ids=[0, 1, 2],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1, 2, 3],\n",
    "    parent_ids=[0, 0, 1, 2],\n",
    "    expected_mask=[[1, 0, 0, 0], [1, 1, 0, 0], [1, 1, 1, 0], [1, 1, 1, 1]],\n",
    "    expected_pos_ids=[0, 1, 2, 3],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 0, 1, 1],\n",
    "    parent_ids=[0, 0, 1, 1],\n",
    "    expected_mask=[[1, 0, 0, 0], [1, 1, 0, 0], [0, 0, 1, 0], [0, 0, 1, 1]],\n",
    "    expected_pos_ids=[0, 1, 0, 1],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1, 2, 3],\n",
    "    parent_ids=[0, 1, 0, 1],\n",
    "    expected_mask=[[1, 0, 0, 0], [0, 1, 0, 0], [1, 0, 1, 0], [0, 1, 0, 1]],\n",
    "    expected_pos_ids=[0, 0, 1, 1],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1, 2, 2, 3, 3],\n",
    "    parent_ids=[0, 1, 0, 0, 1, 1],\n",
    "    expected_mask=[\n",
    "        [1, 0, 0, 0, 0, 0],\n",
    "        [0, 1, 0, 0, 0, 0],\n",
    "        [1, 0, 1, 0, 0, 0],\n",
    "        [1, 0, 1, 1, 0, 0],\n",
    "        [0, 1, 0, 0, 1, 0],\n",
    "        [0, 1, 0, 0, 1, 1],\n",
    "    ],\n",
    "    expected_pos_ids=[0, 0, 1, 2, 1, 2],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1, 2, 3, 4, 4, 5, 5],\n",
    "    parent_ids=[0, 0, 1, 1, 2, 2, 3, 3],\n",
    "    expected_mask=[\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 0, 1, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 0, 1, 0, 0, 0],\n",
    "        [1, 1, 1, 0, 1, 1, 0, 0],\n",
    "        [1, 1, 0, 1, 0, 0, 1, 0],\n",
    "        [1, 1, 0, 1, 0, 0, 1, 1],\n",
    "    ],\n",
    "    expected_pos_ids=[0, 1, 2, 2, 3, 4, 3, 4],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[2, 1, 0],\n",
    "    parent_ids=[2, 2, 0],\n",
    "    expected_mask=[\n",
    "        [1, 0, 0],\n",
    "        [1, 1, 0],\n",
    "        [0, 0, 1],\n",
    "    ],\n",
    "    expected_pos_ids=[0, 1, 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def compute_reachability_matrix(adj_matrix):\n",
    "    # Number of nodes\n",
    "    num_nodes = adj_matrix.size(0)\n",
    "\n",
    "    # Start with the adjacency matrix as reachability\n",
    "    reachability = adj_matrix.clone()\n",
    "\n",
    "    # Add paths of length 2 to N-1\n",
    "    for _ in range(num_nodes - 1):\n",
    "        # Update reachability with additional paths\n",
    "        reachability = reachability + torch.mm(reachability, adj_matrix)\n",
    "\n",
    "    # Convert to binary (reachable or not)\n",
    "    reachability = (reachability > 0).float()\n",
    "\n",
    "    return reachability\n",
    "\n",
    "\n",
    "# Example adjacency matrix\n",
    "adj_matrix = torch.tensor(\n",
    "    [[1, 0, 0, 0], [1, 1, 0, 0], [0, 1, 1, 0], [0, 0, 0, 1]], dtype=torch.float32\n",
    ")\n",
    "\n",
    "reachability_matrix = compute_reachability_matrix(adj_matrix)\n",
    "print(reachability_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_reachability_matrix_one_swoop(adj_matrix):\n",
    "    num_nodes = adj_matrix.size(0)\n",
    "\n",
    "    # Compute the series sum: (I + A + A^2 + ... + A^(N-1))\n",
    "    reachability = torch.matrix_power(adj_matrix, num_nodes - 1)\n",
    "\n",
    "    # Binarize the result\n",
    "    reachability = (reachability > 0).float()\n",
    "\n",
    "    return reachability\n",
    "\n",
    "\n",
    "reachability_matrix = compute_reachability_matrix_one_swoop(adj_matrix)\n",
    "print(reachability_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, id: int, parent: \"Node | None\" = None, size: int = 1):\n",
    "        self.id = id\n",
    "        self.parent = parent\n",
    "        self.size = size\n",
    "\n",
    "\n",
    "nodes = [Node(id=0, size=random.randint(1, 1)), Node(id=1, size=random.randint(1, 1))]\n",
    "for i in range(2, 128):\n",
    "    parent = random.choice(nodes)\n",
    "    size = random.randint(1, 128)\n",
    "    node = Node(id=i, parent=parent, size=size)\n",
    "    nodes.append(node)\n",
    "ids = torch.tensor([node.id for node in nodes for _ in range(node.size)])\n",
    "parent_ids = torch.tensor(\n",
    "    [\n",
    "        node.parent.id if node.parent else node.id\n",
    "        for node in nodes\n",
    "        for _ in range(node.size)\n",
    "    ]\n",
    ")\n",
    "# mask = get_mask(ids, parent_ids)\n",
    "# faster_mask = get_faster_mask(ids, parent_ids)\n",
    "torch.stack([ids, parent_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "_ = mask_and_pos_ids(torch.stack([ids, ids]), torch.stack([parent_ids, parent_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(mask):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(mask, cmap=\"binary\")\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Attention Mask\")\n",
    "    plt.xlabel(\"Source Position\")\n",
    "    plt.ylabel(\"Target Position\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "process = await asyncio.create_subprocess_exec(\n",
    "    \"vllm\",\n",
    "    \"serve\",\n",
    "    \"NousResearch/Hermes-2-Theta-Llama-3-8B\",\n",
    "    stdout=asyncio.subprocess.PIPE,\n",
    "    stderr=asyncio.subprocess.PIPE,\n",
    ")\n",
    "while True:\n",
    "    print((await process.stdout.readline()).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.vllm import start_vllm_server, vllm_server_metrics\n",
    "import os\n",
    "\n",
    "model = \"NousResearch/Hermes-2-Theta-Llama-3-8B\"\n",
    "\n",
    "os.environ[\"VLLM_ALLOW_LONG_MAX_MODEL_LEN\"] = \"1\"\n",
    "shutdown_server, client = await start_vllm_server(\n",
    "    disable_log_requests=True,\n",
    "    max_model_len=16384,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from lib.rl.episode import Episode\n",
    "from typing import AsyncIterable, Literal\n",
    "\n",
    "Split = Literal[\"train\", \"val\", \"test\"]\n",
    "\n",
    "\n",
    "async def episodes(split: Split) -> AsyncIterable[Episode]:\n",
    "    for _ in range(10):\n",
    "        await asyncio.sleep(1)\n",
    "        yield Episode()  # type: ignore\n",
    "\n",
    "\n",
    "async for episode in episodes(split=\"val\"):\n",
    "    print(episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.rl.trainer import Trainer\n",
    "\n",
    "episode = Episode()\n",
    "\n",
    "Trainer(\n",
    "    base_model=model,\n",
    "    episodes={\n",
    "        \"train\": [episode],\n",
    "        \"val\": [episode],\n",
    "        \"test\": [episode],\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
