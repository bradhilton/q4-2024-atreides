{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.vllm import start_vllm\n",
    "\n",
    "vllm = await start_vllm(\n",
    "    \"NousResearch/Hermes-2-Theta-Llama-3-8B\",\n",
    "    env={\"VLLM_ALLOW_LONG_MAX_MODEL_LEN\": \"1\"},\n",
    "    block_size=32,\n",
    "    disable_log_requests=True,\n",
    "    # enable_prefix_caching=True,\n",
    "    enforce_eager=True,\n",
    "    gpu_memory_utilization=0.999,\n",
    "    max_model_len=16384,\n",
    "    max_num_seqs=4096,\n",
    "    max_num_batched_tokens=16384 * 8,\n",
    "    swap_space=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm.process.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await vllm.client.completions.create(\n",
    "    model=\"NousResearch/Hermes-2-Theta-Llama-3-8B\",\n",
    "    # prompt=\"<|begin_of_text|><|im_start|>user\\n\",\n",
    "    prompt=[128000, 128002, 882],\n",
    "    max_tokens=1,\n",
    "    extra_body={\n",
    "        \"prompt_logprobs\": 1,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from lib.clue import Clue, DeductiveSolver\n",
    "from lib.rl.episode import Episode, EpisodeCompletion\n",
    "from lib.rl.ppo import PPOLoss\n",
    "from lib.rl.recipe import ComponentConfig, TuneRecipeConfig\n",
    "from lib.rl.trainer import Trainer\n",
    "from lib.utils import return_exception\n",
    "import torch\n",
    "from torchtune.models.llama3_1 import llama3_1_8b\n",
    "import random\n",
    "import re\n",
    "\n",
    "\n",
    "@return_exception\n",
    "def sample_random_episode() -> Episode:\n",
    "    game = Clue(\n",
    "        num_players=3,\n",
    "        elements={\n",
    "            \"suspect\": random.sample(Clue.suspects, k=3),\n",
    "            \"weapon\": random.sample(Clue.weapons, k=3),\n",
    "            \"room\": random.sample(Clue.rooms, k=3),\n",
    "            # \"motive\": random.sample(Clue.motives, k=3),\n",
    "            # \"time\": Clue.get_times(\"21:00\", \"03:00\", \"1h\"),\n",
    "        },\n",
    "    )\n",
    "    game.play(\n",
    "        deductive_solver=DeductiveSolver(\n",
    "            # note_cards_in_hand=False,\n",
    "            # note_responses_to_suggestions=False,\n",
    "            # note_cards_that_players_do_not_have=False,\n",
    "            # check_unique_card_placement_constraints=False,\n",
    "            # check_player_hand_size_constraints=False,\n",
    "            check_solution_has_one_and_only_one_card_per_element=False,\n",
    "            check_one_of_constraints=False,\n",
    "            check_inverse_one_of_constraints=False,\n",
    "            merge_and_check_disjoint_inverse_one_of_constraints=False,\n",
    "            exhaustively_test_possible_assignments=False,\n",
    "        ),\n",
    "        cp_solver_max_solve_time_per_turn=0.01,\n",
    "        check_cp_solver_grid=False,\n",
    "        check_if_deductive_solver_and_cp_solver_grids_match=False,\n",
    "        print_playthrough=False,\n",
    "    )\n",
    "    prompt, follow_up, solution = game.get_prompt_and_follow_up_and_solution()\n",
    "\n",
    "    async def reward_completion(completion: EpisodeCompletion) -> EpisodeCompletion:\n",
    "        if len(completion.messages) == 2:\n",
    "            follow_up_completion = await completion.follow_up(\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": follow_up},\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            follow_up_completion = completion\n",
    "        answer = follow_up_completion.last_assistant_message.get(\"content\")\n",
    "        assert isinstance(answer, str)\n",
    "        completion.reward = sum(\n",
    "            [\n",
    "                bool(\n",
    "                    re.search(\n",
    "                        f\"{key}: {value}\",\n",
    "                        answer,\n",
    "                        re.IGNORECASE,\n",
    "                    )\n",
    "                )\n",
    "                for key, value in solution.items()\n",
    "            ]\n",
    "        ) / len(solution)\n",
    "        return completion\n",
    "\n",
    "    async def on_sample(completions: list[EpisodeCompletion]) -> None:\n",
    "        for completion in await asyncio.gather(\n",
    "            *[reward_completion(completion) for completion in completions]\n",
    "        ):\n",
    "            completion.commit()\n",
    "\n",
    "    return Episode(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        on_sample=on_sample,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_episodes():\n",
    "    while True:\n",
    "        yield sample_random_episode()\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    base_model=\"NousResearch/Hermes-2-Theta-Llama-3-8B\",\n",
    "    output_dir=\"./models/rl2\",\n",
    "    samples_per_episode=27,\n",
    "    branch_factor=3,\n",
    "    sample_probability_power=1 / 3,\n",
    "    train_episodes=train_episodes(),\n",
    "    episodes_per_iteration=128 * torch.cuda.device_count(),\n",
    "    patience_per_sample=1 / 27,\n",
    "    sampling_kwargs={\n",
    "        \"max_tokens\": 4096,\n",
    "    },\n",
    "    max_mask_sequence_batch_size=1,\n",
    "    val_episodes=(\n",
    "        sample_random_episode() for _ in range(32 * torch.cuda.device_count())\n",
    "    ),\n",
    "    val_samples_per_episode=3,\n",
    "    torchrun_kwargs=dict(nnodes=1, nproc_per_node=torch.cuda.device_count()),\n",
    "    tune_model=llama3_1_8b,\n",
    "    tune_model_type=\"LLAMA3\",\n",
    "    tune_recipe_config=TuneRecipeConfig(\n",
    "        seed=42,\n",
    "        shuffle=False,\n",
    "        num_output_chunks=4,\n",
    "        resume_from_checkpoint=False,\n",
    "        batch_size=2,\n",
    "        epochs=2,\n",
    "        optimizer=ComponentConfig(\n",
    "            \"torch.optim.AdamW\",\n",
    "            # \"bitsandbytes.optim.PagedAdamW8bit\",\n",
    "            # \"bitsandbytes.optim.AdamW\",\n",
    "            # params=PLACEHOLDER,\n",
    "            lr=5e-6,\n",
    "            fused=True,\n",
    "        ),\n",
    "        loss=ComponentConfig(\n",
    "            PPOLoss,\n",
    "            policy_coef=1.0,\n",
    "            clip_epsilon=0.2,\n",
    "            entropy_coef=0.0,\n",
    "            kl_coef=0.0,\n",
    "            weighted_ce_coef=0.0,\n",
    "            weighted_entropy_coef=0.0,\n",
    "            weighted_kl_coef=0.0,\n",
    "            normalize_values=False,\n",
    "            normalize_advantages=False,\n",
    "        ),\n",
    "        compile=False,\n",
    "        optimizer_in_bwd=False,\n",
    "        gradient_accumulation_steps=2,\n",
    "        enable_activation_checkpointing=True,\n",
    "        enable_activation_offloading=False,\n",
    "        custom_sharded_layers=[\"tok_embeddings\", \"output\"],\n",
    "        log_every_n_steps=1,\n",
    "        log_peak_memory_stats=True,\n",
    "    ),\n",
    "    tune_sequence_length=16384,\n",
    "    vllm_env={\"VLLM_ALLOW_LONG_MAX_MODEL_LEN\": \"1\"},\n",
    "    vllm_kwargs=dict(\n",
    "        block_size=32,\n",
    "        disable_log_requests=True,\n",
    "        enable_prefix_caching=True,\n",
    "        enforce_eager=True,\n",
    "        gpu_memory_utilization=0.999,\n",
    "        max_model_len=16384,\n",
    "        max_num_seqs=4096,\n",
    "        max_num_batched_tokens=16384 * 8,\n",
    "        swap_space=8,\n",
    "        # scheduling_policy=\"priority\",\n",
    "        # tensor_parallel_size=torch.cuda.device_count() // 8,\n",
    "    ),\n",
    "    vllm_max_concurrent_samples=4096,\n",
    "    vllm_min_time_between_requests=0.0,\n",
    "    vllm_num=torch.cuda.device_count(),\n",
    "    vllm_timeout=120,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_result = await trainer.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "completion_sampler = await trainer.get_completion_sampler()\n",
    "client: AsyncOpenAI = completion_sampler.samplers[0].client  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm.client.chat.completions.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "episode = explore_result.episodes[0]\n",
    "completion = next(iter(episode.completion.leaves()))\n",
    "tokens = completion.all_tokens(trainer.tokenizer, cache=True).tolist()\n",
    "plain_completion = await vllm.client.completions.create(\n",
    "    model=trainer.model,\n",
    "    prompt=tokens,\n",
    "    max_tokens=1,\n",
    "    extra_body={\n",
    "        \"prompt_logprobs\": True,\n",
    "    },\n",
    ")\n",
    "prompt_logprobs: list[dict[str, dict[str, Any]]] = plain_completion.choices[0].prompt_logprobs  # type: ignore\n",
    "prompt_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(prompt_logprobs) == len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_logprobs = [\n",
    "    prompt_logprob[str(token)][\"logprob\"] if prompt_logprob else torch.nan\n",
    "    for token, prompt_logprob in zip(tokens, prompt_logprobs)\n",
    "]\n",
    "for c in completion.ancestors(including_self=True, reverse=True):\n",
    "    count = c.token_count(trainer.tokenizer, cache=True)\n",
    "    c.reference_logprobs, reference_logprobs = (\n",
    "        torch.tensor(reference_logprobs[:count]),\n",
    "        reference_logprobs[count:],\n",
    "    )\n",
    "\n",
    "completion.reference_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(c._reference_logprobs.shape[0] for c in completion.ancestors(including_self=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(\n",
    "    [\n",
    "        prompt_logprob[str(token)][\"logprob\"] if prompt_logprob else torch.nan\n",
    "        for token, prompt_logprob in zip(tokens, prompt_logprobs)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prompt_logprobs), len(completion.all_tokens(trainer.tokenizer, cache=True).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"/tmp/err_execute_model_input_20241201-005319.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(plain_completion, \"prompt_logprobs\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_completion.choices[0].prompt_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion.all_tokens(trainer.tokenizer, cache=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.patience_per_val_sample = 1.0\n",
    "trainer.patience_per_test_sample = 1.0\n",
    "trainer.tune_recipe_config.optimizer.lr = 8e-6\n",
    "trainer.tune_recipe_config.loss.clip_epsilon = 0.1\n",
    "trainer.tune_recipe_config.loss.weighted_ce_coef = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await trainer.train(iterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.eval_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.rl.pack import packed_tensors_from_dir\n",
    "\n",
    "tensors = packed_tensors_from_dir(dir=\"./models/rl/tensors\", num_sequences=50, sequence_length=16384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors[\"mask\"][0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.max_mask_sequence_batch_size = 16\n",
    "# (eval_score, eval_exceptions), \n",
    "result, = await asyncio.gather(\n",
    "    # trainer.eval(\"val\", 0, return_exceptions=True),\n",
    "    trainer.explore(1, return_exceptions=True),\n",
    ")\n",
    "# print(f\"Eval score: {eval_score:.2%}\")\n",
    "print(\n",
    "    f\"Generated {sum(completion.num_token_logprobs() for episode in result.episodes for completion in episode.completion.descendants()):,} tokens\"\n",
    ")\n",
    "tensors = trainer.tensors(result.episodes)\n",
    "(tensors[\"mask\"] == result.tensors()[\"mask\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = trainer.tensors(result.episodes)\n",
    "(tensors[\"mask\"] == result.tensors()[\"mask\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(tensors[\"advantages\"].shape).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "def show(mask: torch.Tensor) -> None:\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(mask, cmap=\"inferno\")\n",
    "    plt.colorbar(label=\"Relative Position\")\n",
    "    plt.title(\"Relative Position Attention Mask\")\n",
    "    plt.xlabel(\"Target Position\")\n",
    "    plt.ylabel(\"Source Position\")\n",
    "    plt.show()\n",
    "\n",
    "i = 1\n",
    "_tensors = tensors\n",
    "key = \"input_pos\"\n",
    "\n",
    "show(\n",
    "    _tensors[\"mask\"][i].cumsum(dim=1)\n",
    "    * (\n",
    "        _tensors[\"mask\"][i]\n",
    "        & (\n",
    "            ~torch.isnan(_tensors[key][i]).unsqueeze(0)\n",
    "            & ~torch.isnan(_tensors[key][i]).unsqueeze(1)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.tensors()[\"mask\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tensors[\"mask\"] == result.tensors()[\"mask\"]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(127):\n",
    "    for j in range(127):\n",
    "        if (tensors[\"mask\"][i] == result.tensors()[\"mask\"][j]).all():\n",
    "            print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"advantages\"\n",
    "torch.isclose(tensors[key], result.tensors()[key], rtol=1e-5, atol=1e-8, equal_nan=True).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.all((tensors[\"weights\"] == result.tensors()[\"weights\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise result.exceptions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2_033_717 / 4.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2_064_056 / 6.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2_064_056 / 10.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2_071_601 / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2_071_601 / 11.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4_119_041 / 16.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await trainer.train(iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_score, episodes = await asyncio.gather(trainer.eval(\"val\", 0), trainer.explore(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtune.models.llama3_1 import llama3_1_8b\n",
    "from torchtune.training import cleanup_before_training\n",
    "from torchtune.training.metric_logging import DiskLogger\n",
    "from typing import Any\n",
    "\n",
    "from lib.recipes.rl import ComponentConfig, RLConfig, RLRecipe\n",
    "from lib.rl.pack import PackedDataset, packed_tensors_to_dir\n",
    "from lib.rl.ppo import PPOLoss\n",
    "\n",
    "\n",
    "tensors, checkpoint_dir, checkpoint_files = await trainer.tune_resources(episodes)\n",
    "\n",
    "PLACEHOLDER: Any = None\n",
    "\n",
    "config = RLConfig(\n",
    "    # Dataset\n",
    "    dataset=ComponentConfig(\n",
    "        PackedDataset, **packed_tensors_to_dir(tensors, trainer.output_dir + \"/tensors\")\n",
    "    ),\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    # Model\n",
    "    model=ComponentConfig(llama3_1_8b),\n",
    "    num_output_chunks=4,\n",
    "    # Checkpointer\n",
    "    checkpointer=ComponentConfig(\n",
    "        \"torchtune.training.FullModelHFCheckpointer\",\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        checkpoint_files=checkpoint_files,\n",
    "        recipe_checkpoint=None,\n",
    "        output_dir=trainer.output_dir,\n",
    "        model_type=\"LLAMA3\",\n",
    "    ),\n",
    "    resume_from_checkpoint=False,\n",
    "    # Fine-tuning arguments\n",
    "    batch_size=4,\n",
    "    epochs=1,\n",
    "    optimizer=ComponentConfig(\n",
    "        \"torch.optim.AdamW\",\n",
    "        # \"bitsandbytes.optim.PagedAdamW8bit\",\n",
    "        # \"bitsandbytes.optim.AdamW\",\n",
    "        # params=PLACEHOLDER,\n",
    "        lr=5e-6,\n",
    "        fused=True,\n",
    "    ),\n",
    "    loss=ComponentConfig(\n",
    "        PPOLoss,\n",
    "        # clip_epsilon=0.3,\n",
    "        # entropy_coef=0.0,\n",
    "        # kl_coef=0.0,\n",
    "        clip_epsilon=0.3,\n",
    "        entropy_coef=0.025,\n",
    "        kl_coef=0.025,\n",
    "        normalize_advantages=False,\n",
    "    ),\n",
    "    max_steps_per_epoch=None,\n",
    "    compile=False,\n",
    "    optimizer_in_bwd=False,\n",
    "    gradient_accumulation_steps=1,\n",
    "    # Training env\n",
    "    device=\"cuda\",\n",
    "    # Memory management\n",
    "    enable_activation_checkpointing=True,\n",
    "    enable_activation_offloading=False,\n",
    "    custom_sharded_layers=[\"tok_embeddings\", \"output\"],\n",
    "    # Reduced precision\n",
    "    dtype=\"bf16\",\n",
    "    # Logging\n",
    "    metric_logger=ComponentConfig(\n",
    "        DiskLogger, log_dir=\"/home/ubuntu/atreides/experiments/logs\"\n",
    "    ),\n",
    "    log_every_n_steps=1,\n",
    "    log_peak_memory_stats=True,\n",
    ")\n",
    "\n",
    "# recipe = RLRecipe(config)\n",
    "# recipe.setup(config)\n",
    "# recipe.train()\n",
    "# recipe.cleanup()\n",
    "# del tensors, recipe\n",
    "# cleanup_before_training()\n",
    "# trainer.save(base_checkpoint_dir=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "dict_config = config.dict_config()\n",
    "OmegaConf.save(dict_config, trainer.output_dir + \"/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import IO\n",
    "\n",
    "torchrun_kwargs = {\"nnodes\": 1, \"nproc_per_node\": 2}\n",
    "kwargs = {}\n",
    "env = {\"CUDA_LAUNCH_BLOCKING\": \"1\"}\n",
    "\n",
    "args = [\n",
    "    \"tune\",\n",
    "    \"run\",\n",
    "    *[\n",
    "        f\"--{key.replace('_', '-')}{f'={value}' if value is not True else ''}\"\n",
    "        for key, value in torchrun_kwargs.items()\n",
    "    ],\n",
    "    \"lib.recipes.rl.RLRecipe\",\n",
    "    \"--config\",\n",
    "    trainer.output_dir + \"/config.yaml\",\n",
    "    *[\n",
    "        f\"--{key.replace('_', '-')}{f'={value}' if value != True else ''}\"\n",
    "        for key, value in kwargs.items()\n",
    "    ],\n",
    "]\n",
    "print(f\"$ {' '.join(args)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = await asyncio.create_subprocess_exec(\n",
    "    *args,\n",
    "    stdout=asyncio.subprocess.PIPE,\n",
    "    stderr=asyncio.subprocess.PIPE,\n",
    "    env={\n",
    "        **os.environ,\n",
    "        **(env or {}),\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "async def log_output(stream: asyncio.StreamReader, io: IO[str]) -> None:\n",
    "    while True:\n",
    "        line = await stream.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        decoded_line = line.decode()\n",
    "        io.write(decoded_line)\n",
    "        io.flush()\n",
    "\n",
    "\n",
    "tasks = []\n",
    "if process.stdout:\n",
    "    tasks.append(asyncio.create_task(log_output(process.stdout, sys.stdout)))\n",
    "if process.stderr:\n",
    "    tasks.append(asyncio.create_task(log_output(process.stderr, sys.stderr)))\n",
    "_ = await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.recipes.rl import recipe_main\n",
    "import os\n",
    "from torch import distributed as dist\n",
    "from torchtune.training import is_distributed\n",
    "\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "\n",
    "\n",
    "recipe_main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import DictConfig, OmegaConf\n",
    "dict_config = config.dict_config()\n",
    "OmegaConf.save(dict_config, trainer.output_dir + \"/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.rl.completion import Completion\n",
    "\n",
    "\n",
    "OmegaConf.create(OmegaConf.to_yaml(DictConfig(dict(name=f\"{Completion.__module__}.{Completion.__name__}\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import sys\n",
    "\n",
    "traceback.clear_frames(sys.exc_info()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_before_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save(base_checkpoint_dir=checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "def show(mask: torch.Tensor) -> None:\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(mask, cmap=\"inferno\")\n",
    "    plt.colorbar(label=\"Relative Position\")\n",
    "    plt.title(\"Relative Position Attention Mask\")\n",
    "    plt.xlabel(\"Target Position\")\n",
    "    plt.ylabel(\"Source Position\")\n",
    "    plt.show()\n",
    "\n",
    "i = 1\n",
    "\n",
    "show(\n",
    "    tensors[\"mask\"][i].cumsum(dim=1)\n",
    "    * (\n",
    "        tensors[\"mask\"][i]\n",
    "        & (\n",
    "            ~torch.isnan(tensors[\"advantages\"][i]).unsqueeze(0)\n",
    "            & ~torch.isnan(tensors[\"advantages\"][i]).unsqueeze(1)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\n",
    "    f'<div style=\"white-space: pre-wrap\">{list(episodes[2].completion.leaves())[0].html(30.0)}</div>'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_and_pos_ids(\n",
    "    ids: torch.Tensor, parent_ids: torch.Tensor\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Creates an attention mask and position IDs for hierarchical attention based on node IDs and their parent IDs.\n",
    "\n",
    "    Args:\n",
    "        ids: A tensor of shape (batch_size, sequence_length) containing node IDs\n",
    "        parent_ids: A tensor of shape (batch_size, sequence_length) containing parent IDs for each node\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - mask: A boolean tensor of shape (batch_size, sequence_length, sequence_length) where True indicates\n",
    "          allowed attention connections. Each position can attend to itself and any of its ancestors\n",
    "          in the hierarchy, but only for previous positions (due to causal masking).\n",
    "        - pos_ids: A tensor of shape (batch_size, sequence_length, sequence_length) containing relative\n",
    "          position IDs for each allowed attention connection, with -1 for masked positions.\n",
    "    \"\"\"\n",
    "    mask = ids.unsqueeze(1) == ids.unsqueeze(2)\n",
    "    _mask = mask | (ids.unsqueeze(1) == parent_ids.unsqueeze(2))\n",
    "    while torch.any(mask != _mask):\n",
    "        parent_ids = parent_ids.gather(\n",
    "            1, torch.argmax((parent_ids.unsqueeze(2) == ids.unsqueeze(1)).int(), dim=2)\n",
    "        )\n",
    "        mask = _mask\n",
    "        _mask = mask | (ids.unsqueeze(1) == parent_ids.unsqueeze(2))\n",
    "    mask &= torch.tril(torch.ones_like(mask, dtype=torch.bool, device=ids.device))\n",
    "    # mask = torch.linalg.matrix_power(mask.float(), mask.size(1) - 1) > 0\n",
    "    pos_ids = (torch.where(mask, mask.cumsum(2), 0) - 1).max(1).values\n",
    "    return mask, pos_ids\n",
    "\n",
    "\n",
    "def test_mask_and_pos_ids(\n",
    "    ids: list[int],\n",
    "    parent_ids: list[int],\n",
    "    expected_mask: list[list[int]],\n",
    "    expected_pos_ids: list[int],\n",
    "):\n",
    "    mask, pos_ids = mask_and_pos_ids(\n",
    "        ids=torch.tensor([ids]), parent_ids=torch.tensor([parent_ids])\n",
    "    )\n",
    "    assert torch.all(mask.int() == torch.tensor([expected_mask])), f\"\\n{mask.int()[0]}\"\n",
    "    assert torch.all(\n",
    "        pos_ids == torch.tensor([expected_pos_ids])\n",
    "    ), f\"{pos_ids[0].tolist()}\"\n",
    "\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1],\n",
    "    parent_ids=[0, 1],\n",
    "    expected_mask=[[1, 0], [0, 1]],\n",
    "    expected_pos_ids=[0, 0],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1, 1],\n",
    "    parent_ids=[0, 0, 0],\n",
    "    expected_mask=[[1, 0, 0], [1, 1, 0], [1, 1, 1]],\n",
    "    expected_pos_ids=[0, 1, 2],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1, 2, 3],\n",
    "    parent_ids=[0, 0, 1, 2],\n",
    "    expected_mask=[[1, 0, 0, 0], [1, 1, 0, 0], [1, 1, 1, 0], [1, 1, 1, 1]],\n",
    "    expected_pos_ids=[0, 1, 2, 3],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 0, 1, 1],\n",
    "    parent_ids=[0, 0, 1, 1],\n",
    "    expected_mask=[[1, 0, 0, 0], [1, 1, 0, 0], [0, 0, 1, 0], [0, 0, 1, 1]],\n",
    "    expected_pos_ids=[0, 1, 0, 1],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1, 2, 3],\n",
    "    parent_ids=[0, 1, 0, 1],\n",
    "    expected_mask=[[1, 0, 0, 0], [0, 1, 0, 0], [1, 0, 1, 0], [0, 1, 0, 1]],\n",
    "    expected_pos_ids=[0, 0, 1, 1],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1, 2, 2, 3, 3],\n",
    "    parent_ids=[0, 1, 0, 0, 1, 1],\n",
    "    expected_mask=[\n",
    "        [1, 0, 0, 0, 0, 0],\n",
    "        [0, 1, 0, 0, 0, 0],\n",
    "        [1, 0, 1, 0, 0, 0],\n",
    "        [1, 0, 1, 1, 0, 0],\n",
    "        [0, 1, 0, 0, 1, 0],\n",
    "        [0, 1, 0, 0, 1, 1],\n",
    "    ],\n",
    "    expected_pos_ids=[0, 0, 1, 2, 1, 2],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[0, 1, 2, 3, 4, 4, 5, 5],\n",
    "    parent_ids=[0, 0, 1, 1, 2, 2, 3, 3],\n",
    "    expected_mask=[\n",
    "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 0, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 0, 0, 0, 0, 0],\n",
    "        [1, 1, 0, 1, 0, 0, 0, 0],\n",
    "        [1, 1, 1, 0, 1, 0, 0, 0],\n",
    "        [1, 1, 1, 0, 1, 1, 0, 0],\n",
    "        [1, 1, 0, 1, 0, 0, 1, 0],\n",
    "        [1, 1, 0, 1, 0, 0, 1, 1],\n",
    "    ],\n",
    "    expected_pos_ids=[0, 1, 2, 2, 3, 4, 3, 4],\n",
    ")\n",
    "\n",
    "test_mask_and_pos_ids(\n",
    "    ids=[2, 1, 0],\n",
    "    parent_ids=[2, 2, 0],\n",
    "    expected_mask=[\n",
    "        [1, 0, 0],\n",
    "        [1, 1, 0],\n",
    "        [0, 0, 1],\n",
    "    ],\n",
    "    expected_pos_ids=[0, 1, 0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
