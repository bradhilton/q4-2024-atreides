import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import glob
import subprocess
import contextlib
from dataclasses import dataclass

import torch
torch.empty(1, device='cuda', requires_grad=True).backward()
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G, steps):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    if G.size(0) > G.size(1):
        X = X.T

    # Ensure spectral norm is at most 1
    X = X / (X.norm() + 1e-7)
    # Perform the NS iterations
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(0) > G.size(1):
        X = X.T
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Instead of skipping orth steps, we reduce their cost early on by using fewer
    Newton–Schulz iterations. Later, we switch to the full iteration count.

    Arguments:
        init_ns_steps: fewer Newton–Schulz steps early in training (speedup).
        final_ns_steps: more steps later in training (better accuracy).
        switchover_frac: fraction of total steps at which we move from init_ns_steps
                         to final_ns_steps.
        ...
    """
    def __init__(self, 
                 params, 
                 lr=0.02, 
                 momentum=0.95, 
                 nesterov=True,
                 init_ns_steps=2,
                 final_ns_steps=5,
                 switchover_frac=0.5,
                 init_orth_every=1,
                 final_orth_every=1):
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.rank = int(os.environ['RANK'])
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov)
        super().__init__([{'params': list(params)}], defaults)
        self._step_count = 0

        # store user hyperparameters
        self.init_ns_steps = init_ns_steps
        self.final_ns_steps = final_ns_steps
        self.switchover_frac = switchover_frac
        self.init_orth_every = init_orth_every
        self.final_orth_every = final_orth_every

        # Set up memory buffers as before
        sizes = {p.numel() for p in params}
        self.param_groups = [
            dict(
                params=[p for p in params if p.numel() == size],
                update_buffer=[torch.empty(size, device='cuda', dtype=torch.bfloat16) for _ in range(self.world_size)],
                **defaults
            )
            for size in sizes
        ]

    def _current_ns_steps(self, total_steps):
        fraction_done = self._step_count / max(1, total_steps)
        if fraction_done < self.switchover_frac:
            return self.init_ns_steps
        else:
            return self.final_ns_steps

    def _current_orth_every(self, total_steps):
        fraction_done = self._step_count / max(1, total_steps)
        if fraction_done < self.switchover_frac:
            return self.init_orth_every
        else:
            return self.final_orth_every

    def step(self, total_steps=None):
        assert total_steps is not None, "Pass total_steps to step() so we can decide steps for Newton–Schulz."
        self._step_count += 1

        # for the first param_group
        group = self.param_groups[0]
        lr = group['lr']
        momentum = group['momentum']
        nesterov = group['nesterov']
        update_buffers = group['update_buffer']
        params = group['params']

        # pick how many NS steps to do at this point in training
        ns_steps = self._current_ns_steps(total_steps)
        orth_every = self._current_orth_every(total_steps)

        handle = None
        params_world = None

        def update_prev():
            if params_world is None:
                return
            handle.wait()
            # apply the updates from update_buffers
            for p_world, g_world in zip(params_world, update_buffers):
                p_world.data.add_(
                    g_world.view_as(p_world),
                    alpha = -lr * max(1, p_world.size(0) / p_world.size(1))**0.5,
                )

        # Main loop
        for base_i in range(len(params))[::self.world_size]:
            if base_i + self.rank < len(params):
                p = params[base_i + self.rank]
                g = p.grad
                assert g is not None

                # basic momentum
                state = self.state[p]
                if 'momentum_buffer' not in state:
                    state['momentum_buffer'] = torch.zeros_like(g)
                buf = state['momentum_buffer']
                buf.lerp_(g, 1 - momentum)
                g = g.lerp_(buf, momentum) if nesterov else buf

                # run Newton–Schulz only if needed
                if (self._step_count % orth_every) == 0:
                    g = zeropower_via_newtonschulz5(g, steps=ns_steps).flatten()
                else:
                    g = g.flatten()

                # ensure g is the same dtype as update_buffers
                g = g.to(update_buffers[self.rank].dtype)
            else:
                # no param on this rank for that chunk
                g = update_buffers[self.rank]

            update_prev()
            handle = dist.all_gather(update_buffers, g, async_op=True)
            params_world = params[base_i : base_i + self.world_size]

        update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

def norm(x):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):

    def __init__(self, in_features, out_features):
        super().__init__(in_features, out_features, bias=False)

    def forward(self, x):
        return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):

    def __init__(self, dim, max_seq_len=65536):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum('i,j -> ij', t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x):
        cos, sin = self.cos[None, :x.size(-3), None, :], self.sin[None, :x.size(-3), None, :]
        x1, x2 = x.float().chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, dim, num_heads):
        super().__init__()
        assert dim % num_heads == 0
        self.num_heads = num_heads
        self.c_q = CastedLinear(dim, dim)
        self.c_k = CastedLinear(dim, dim)
        self.c_v = CastedLinear(dim, dim)
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(dim // num_heads) # dim // num_heads = head_dim
        self.c_proj = CastedLinear(dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x, ve, block_mask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, 'Must use batch size = 1 for FlexAttention'
        q = self.c_q(x).view(B, T, self.num_heads, -1)
        k = self.c_k(x).view(B, T, self.num_heads, -1)
        v = self.c_v(x).view(B, T, self.num_heads, -1)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, dim):
        super().__init__()
        self.c_fc = CastedLinear(dim, 4 * dim)
        self.c_proj = CastedLinear(4 * dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, model_dim, num_heads, use_attn=True):
        super().__init__()
        self.attn = CausalSelfAttention(model_dim, num_heads) if use_attn else None
        self.mlp = MLP(model_dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, ve, x0, block_mask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

class ValueEmbedding(nn.Module):
    def __init__(self, vocab_size, model_dim):
        super().__init__()
        self.embed = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])

    def forward(self, inputs):
        ve = [emb(inputs).bfloat16() for emb in self.embed]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2], None, None, None, None, None, None, ve[0], ve[1], ve[2]]
        return ve

# -----------------------------------------------------------------------------
# The main GPT-2 model

class GPT(nn.Module):

    def __init__(self, vocab_size, num_layers, num_heads, model_dim):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, use_attn=(i != 7))
                                     for i in range(num_layers)])
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual learning
        # U-net structure on token value embeddings by @leloykun
        self.value_embeds = ValueEmbedding(vocab_size, model_dim)
        self.lm_head = CastedLinear(model_dim, vocab_size)
        self.lm_head.weight.data.zero_() # @Grad62304977
        # U-net design by @brendanh0gan
        self.num_encoder_layers = num_layers // 2 # Half of the layers for encoder
        self.num_decoder_layers = num_layers - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

    def forward(self, inputs, targets, sliding_window_num_blocks):
        BLOCK_SIZE = 128
        seq_len = len(inputs)
        assert seq_len % BLOCK_SIZE == 0
        total_num_blocks = seq_len // BLOCK_SIZE
        assert inputs.ndim == 1
        docs = (inputs == 50256).cumsum(0)
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_mask):
            num_blocks = dense_mask.sum(dim=-1, dtype=torch.int32)
            indices = dense_mask.argsort(dim=-1, descending=True, stable=True).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        def create_doc_swc_block_mask(sliding_window_num_blocks):
            kv_idx = block_idx = torch.arange(total_num_blocks, dtype=torch.int32, device='cuda')
            q_idx = block_idx[:, None]
            causal_bm = q_idx >= kv_idx
            causal_full_bm = q_idx > kv_idx
            window_bm = q_idx - kv_idx < sliding_window_num_blocks
            window_full_bm = window_bm # block-wise sliding window by @YouJiacheng
            # document_bm = (docs_low[q_idx] <= docs_high[kv_idx]) & (docs_low[kv_idx] <= docs_high[q_idx])
            document_bm = (docs_low[:, None] <= docs_high) & (docs_low <= docs_high[:, None])
            document_full_bm = (docs_low[:, None] == docs_high) & (docs_low == docs_high[:, None])
            nonzero_bm = causal_bm & window_bm & document_bm
            full_bm  = causal_full_bm & window_full_bm & document_full_bm
            kv_num_blocks, kv_indices = dense_to_ordered(nonzero_bm & ~full_bm)
            full_kv_num_blocks, full_kv_indices = dense_to_ordered(full_bm)
            return BlockMask.from_kv_blocks(
                kv_num_blocks,
                kv_indices,
                full_kv_num_blocks,
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )

        block_mask = create_doc_swc_block_mask(sliding_window_num_blocks)

        x0 = norm(self.embed(inputs[None]).bfloat16()) # use of norm here by @Grad62304977
        x = x0
        ve = self.value_embeds(inputs)
        assert len(ve) == len(self.blocks)
        ve_enc, ve_dec = ve[:self.num_encoder_layers], ve[self.num_encoder_layers:]

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        for i in range(self.num_encoder_layers):
            x = self.blocks[i](x, ve_enc[i], x0, block_mask)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        for i in range(self.num_decoder_layers):
            x = x + self.skip_weights[i] * skip_connections.pop()
            # U-net structure on token value embeddings by @leloykun
            x = self.blocks[self.num_encoder_layers + i](x, ve_dec[i], x0, block_mask)

        x = norm(x)
        logits = self.lm_head(x)
        logits = 15 * torch.tanh(logits / 15) # @Grad62304977 added tanh softcapping, @KoszarskyB reduced it from 30 to 15
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets)
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(path):
    # only reads the header, returns header data
    # header is 256 int32
    header = torch.from_file(path, False, 256, dtype=torch.int32)
    assert header[0] == 20240520, 'magic number mismatch in the data .bin file'
    assert header[1] == 1, 'unsupported version'
    num_tokens = int(header[2]) # number of tokens (claimed)
    with open(path, 'rb', buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, 'number of tokens read does not match header'
    return tokens

class DistributedDataLoader:

    def __init__(self, filename_pattern):
        self.rank = int(os.environ['RANK'])
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.files = sorted(glob.glob(filename_pattern))
        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self):
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = 0
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self, batch_size):
        assert batch_size % self.world_size == 0
        device_batch_size = batch_size // self.world_size
        # load next shard if necessary
        if self.current_position + batch_size + 1 >= len(self.tokens):
            self.advance()
        pos = self.current_position + self.rank * device_batch_size
        device_batch_tokens = self.tokens[pos:pos+device_batch_size+1]
        # advance current position
        self.current_position += batch_size
        inputs = device_batch_tokens[:-1].to(device='cuda', dtype=torch.int32, non_blocking=True)
        targets = device_batch_tokens[1:].to(device='cuda', dtype=torch.int64, non_blocking=True)
        return inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    val_files = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # optimization
    batch_size = 8*64*1024 # batch size in tokens
    num_iterations = 1390 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    bf16_embeds = True
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    # implementation
    max_device_batch_size = 64*1024 # batch size per device in tokens
    save_checkpoint = False
args = Hyperparameters()

micro_bs = args.max_device_batch_size

# set up DDP (distributed data parallel). torchrun sets this env variable
rank = int(os.environ['RANK'])
local_rank = int(os.environ['LOCAL_RANK'])
world_size = int(os.environ['WORLD_SIZE'])
assert torch.cuda.is_available()
torch.cuda.set_device(local_rank)
dist.init_process_group(backend='nccl', device_id=torch.device(local_rank))
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs('logs', exist_ok=True)
    logfile = f'logs/{run_id}.txt'
    print(logfile)

def print0(s, console=False):
    if master_process:
        with open(logfile, 'a') as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0('='*100)
# log information about the hardware/software environment this is running on
print0(f'Running Python {sys.version}')
print0(f'Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}')
print0(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout)
print0('='*100)

# load data
train_loader = DistributedDataLoader(args.train_files)
val_loader = DistributedDataLoader(args.val_files)
print0(f'Training dataloader files: {train_loader.files}')
print0(f'Validation dataloader files: {val_loader.files}')
print0('='*100)

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
model = GPT(vocab_size=50304, num_layers=12, num_heads=6, model_dim=768)
model = model.cuda()
if args.bf16_embeds:
    for m in model.modules():
        if isinstance(m, nn.Embedding):
            m.bfloat16()
model = torch.compile(model)
ddp_model = DDP(model, device_ids=[local_rank], broadcast_buffers=False, gradient_as_bucket_view=True)

# collect the parameters to optimize
hidden_matrix_params = [p for p in model.blocks.parameters() if p.ndim == 2]
embed_params = [model.embed.weight, *model.value_embeds.parameters()]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
optimizer1 = torch.optim.Adam([dict(params=embed_params, lr=0.6),
                               dict(params=head_params, lr=0.008),
                               dict(params=scalar_params, lr=0.04)],
                              betas=(0.8, 0.95), fused=True)
optimizer2 = Muon(
    hidden_matrix_params, 
    lr=0.05,
    momentum=0.95,
    init_ns_steps=2,   # cheaper early orth steps
    final_ns_steps=5,  # more precise near the end 
    switchover_frac=0.3,   # start switching earlier, or try 0.5
    init_orth_every=1, # run orth from the start for stability
    final_orth_every=1, # keep it frequent
)
optimizers = [optimizer1, optimizer2]

# learning rate schedule: stable then decay
def get_lr(it):
    t = 1 - it / args.num_iterations # time remaining in training
    assert 1 >= t > 0
    # 1) constant lr for first part of training
    if t >= args.cooldown_frac:
        return 1.0
    # 2) then linear cooldown
    else:
        return t / args.cooldown_frac
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# sliding window size schedule: linear increase over training in chunks of 128 from 128 -> 1792. By @fernbear.bsky.social
def get_sliding_window_blocks(it):
    x = it / args.num_iterations # training progress
    assert 0 <= x <= 1
    return int(((1 - x) * 128 + x * 1856) // 128)
sliding_window_num_blocks = torch.tensor(1, dtype=torch.int32, device='cuda')

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.perf_counter()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    sliding_window_num_blocks.copy_(get_sliding_window_blocks(step))

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        # calculate the number of steps to take in the val loop.
        val_batch_size = world_size * micro_bs
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        for _ in range(val_steps):
            with torch.no_grad():
                inputs_val, targets_val = val_loader.next_batch(val_batch_size)
                val_loss += ddp_model(inputs_val, targets_val, sliding_window_num_blocks)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # logging
        print0(f'step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms', console=True)
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f'logs/{run_id}', exist_ok=True)
            torch.save(log, f'logs/{run_id}/state_step{step:06d}.pt')
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    model.train()
    batch_size = args.batch_size
    assert batch_size % world_size == 0
    inputs_train, targets_train = train_loader.next_batch(batch_size)
    assert len(inputs_train) <= micro_bs or len(inputs_train) % micro_bs == 0
    for micro_inputs_train, micro_targets_train in zip(inputs_train.split(micro_bs), targets_train.split(micro_bs)):
        ddp_model(micro_inputs_train, micro_targets_train, sliding_window_num_blocks).backward()
    # momentum warmup for Muon
    frac = min(step/300, 1)
    for group in optimizer2.param_groups:
        group['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        if opt is optimizer2:
            opt.step(total_steps=train_steps)
        else:
            opt.step()
        if step != train_steps - 1:
            sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_time = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f'step:{step+1}/{train_steps} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms', console=True)

print0(f'peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB')
dist.destroy_process_group()

====================================================================================================
Running Python 3.12.7 (main, Jan  9 2025, 22:54:50) [GCC 13.2.0]
Running PyTorch 2.6.0.dev20241231+cu126 compiled for CUDA 12.6
Fri Jan 10 04:16:49 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:61:00.0 Off |                    0 |
| N/A   26C    P0            146W /  700W |    7746MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:62:00.0 Off |                    0 |
| N/A   30C    P0            123W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:63:00.0 Off |                    0 |
| N/A   30C    P0            116W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:64:00.0 Off |                    0 |
| N/A   29C    P0            119W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  |   00000000:6A:00.0 Off |                    0 |
| N/A   28C    P0            134W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  |   00000000:6B:00.0 Off |                    0 |
| N/A   30C    P0            118W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  |   00000000:6C:00.0 Off |                    0 |
| N/A   49C    P0            141W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  |   00000000:6D:00.0 Off |                    0 |
| N/A   27C    P0            125W /  700W |    3216MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
Training dataloader files: ['data/fineweb10B/fineweb_train_000001.bin', 'data/fineweb10B/fineweb_train_000002.bin', 'data/fineweb10B/fineweb_train_000003.bin', 'data/fineweb10B/fineweb_train_000004.bin', 'data/fineweb10B/fineweb_train_000005.bin', 'data/fineweb10B/fineweb_train_000006.bin', 'data/fineweb10B/fineweb_train_000007.bin', 'data/fineweb10B/fineweb_train_000008.bin', 'data/fineweb10B/fineweb_train_000009.bin', 'data/fineweb10B/fineweb_train_000010.bin']
Validation dataloader files: ['data/fineweb10B/fineweb_val_000000.bin']
====================================================================================================
step:0/1390 val_loss:10.8258 train_time:0ms step_avg:nanms
step:1/1390 train_time:238629ms step_avg:nanms
step:2/1390 train_time:238757ms step_avg:nanms
step:3/1390 train_time:238860ms step_avg:nanms
step:4/1390 train_time:238986ms step_avg:nanms
step:5/1390 train_time:239115ms step_avg:nanms
step:6/1390 train_time:239244ms step_avg:nanms
step:7/1390 train_time:239373ms step_avg:nanms
step:8/1390 train_time:239503ms step_avg:nanms
step:9/1390 train_time:239635ms step_avg:nanms
step:10/1390 train_time:239762ms step_avg:nanms
step:11/1390 train_time:128ms step_avg:nanms
step:12/1390 train_time:258ms step_avg:nanms
step:13/1390 train_time:387ms step_avg:129.08ms
step:14/1390 train_time:517ms step_avg:129.34ms
step:15/1390 train_time:653ms step_avg:130.68ms
step:16/1390 train_time:785ms step_avg:130.82ms
step:17/1390 train_time:906ms step_avg:129.45ms
step:18/1390 train_time:1035ms step_avg:129.34ms
step:19/1390 train_time:1164ms step_avg:129.37ms
step:20/1390 train_time:1293ms step_avg:129.33ms
step:21/1390 train_time:1423ms step_avg:129.33ms
step:22/1390 train_time:1553ms step_avg:129.43ms
step:23/1390 train_time:1691ms step_avg:130.08ms
step:24/1390 train_time:1817ms step_avg:129.79ms
step:25/1390 train_time:1947ms step_avg:129.79ms
step:26/1390 train_time:2076ms step_avg:129.75ms
step:27/1390 train_time:2203ms step_avg:129.60ms
step:28/1390 train_time:2333ms step_avg:129.62ms
step:29/1390 train_time:2462ms step_avg:129.58ms
step:30/1390 train_time:2592ms step_avg:129.62ms
step:31/1390 train_time:2720ms step_avg:129.52ms
step:32/1390 train_time:2849ms step_avg:129.50ms
step:33/1390 train_time:2979ms step_avg:129.53ms
step:34/1390 train_time:3108ms step_avg:129.52ms
step:35/1390 train_time:3238ms step_avg:129.50ms
step:36/1390 train_time:3367ms step_avg:129.50ms
step:37/1390 train_time:3500ms step_avg:129.63ms
step:38/1390 train_time:3632ms step_avg:129.71ms
step:39/1390 train_time:3757ms step_avg:129.55ms
step:40/1390 train_time:3886ms step_avg:129.52ms
step:41/1390 train_time:4014ms step_avg:129.48ms
step:42/1390 train_time:4143ms step_avg:129.48ms
step:43/1390 train_time:4273ms step_avg:129.47ms
step:44/1390 train_time:4402ms step_avg:129.47ms
step:45/1390 train_time:4531ms step_avg:129.46ms
step:46/1390 train_time:4665ms step_avg:129.57ms
step:47/1390 train_time:4790ms step_avg:129.47ms
step:48/1390 train_time:4920ms step_avg:129.47ms
step:49/1390 train_time:5050ms step_avg:129.48ms
step:50/1390 train_time:5179ms step_avg:129.49ms
step:51/1390 train_time:5308ms step_avg:129.47ms
step:52/1390 train_time:5437ms step_avg:129.46ms
step:53/1390 train_time:5572ms step_avg:129.58ms
step:54/1390 train_time:5698ms step_avg:129.50ms
step:55/1390 train_time:5827ms step_avg:129.49ms
step:56/1390 train_time:5956ms step_avg:129.49ms
step:57/1390 train_time:6085ms step_avg:129.46ms
step:58/1390 train_time:6214ms step_avg:129.46ms
step:59/1390 train_time:6343ms step_avg:129.45ms
step:60/1390 train_time:6472ms step_avg:129.44ms
step:61/1390 train_time:6600ms step_avg:129.42ms
step:62/1390 train_time:6730ms step_avg:129.42ms
step:63/1390 train_time:6859ms step_avg:129.41ms
step:64/1390 train_time:6988ms step_avg:129.41ms
step:65/1390 train_time:7117ms step_avg:129.39ms
step:66/1390 train_time:7248ms step_avg:129.43ms
step:67/1390 train_time:7375ms step_avg:129.39ms
step:68/1390 train_time:7504ms step_avg:129.38ms
step:69/1390 train_time:7634ms step_avg:129.38ms
step:70/1390 train_time:7763ms step_avg:129.39ms
step:71/1390 train_time:7892ms step_avg:129.38ms
step:72/1390 train_time:8022ms step_avg:129.38ms
step:73/1390 train_time:8150ms step_avg:129.37ms
step:74/1390 train_time:8280ms step_avg:129.38ms
step:75/1390 train_time:8409ms step_avg:129.36ms
step:76/1390 train_time:8537ms step_avg:129.35ms
step:77/1390 train_time:8667ms step_avg:129.36ms
step:78/1390 train_time:8795ms step_avg:129.33ms
step:79/1390 train_time:8930ms step_avg:129.42ms
step:80/1390 train_time:9057ms step_avg:129.39ms
step:81/1390 train_time:9183ms step_avg:129.34ms
step:82/1390 train_time:9316ms step_avg:129.39ms
step:83/1390 train_time:9441ms step_avg:129.33ms
step:84/1390 train_time:9574ms step_avg:129.38ms
step:85/1390 train_time:9701ms step_avg:129.35ms
step:86/1390 train_time:9830ms step_avg:129.34ms
step:87/1390 train_time:9960ms step_avg:129.35ms
step:88/1390 train_time:10089ms step_avg:129.34ms
step:89/1390 train_time:10222ms step_avg:129.40ms
step:90/1390 train_time:10347ms step_avg:129.34ms
step:91/1390 train_time:10476ms step_avg:129.33ms
step:92/1390 train_time:10605ms step_avg:129.33ms
step:93/1390 train_time:10734ms step_avg:129.32ms
step:94/1390 train_time:10864ms step_avg:129.34ms
step:95/1390 train_time:10995ms step_avg:129.35ms
step:96/1390 train_time:11122ms step_avg:129.33ms
step:97/1390 train_time:11252ms step_avg:129.33ms
step:98/1390 train_time:11381ms step_avg:129.33ms
step:99/1390 train_time:11511ms step_avg:129.33ms
step:100/1390 train_time:11639ms step_avg:129.33ms
step:101/1390 train_time:11769ms step_avg:129.33ms
step:102/1390 train_time:11898ms step_avg:129.33ms
step:103/1390 train_time:12027ms step_avg:129.32ms
step:104/1390 train_time:12157ms step_avg:129.33ms
step:105/1390 train_time:12289ms step_avg:129.36ms
step:106/1390 train_time:12426ms step_avg:129.43ms
step:107/1390 train_time:12554ms step_avg:129.42ms
step:108/1390 train_time:12685ms step_avg:129.44ms
step:109/1390 train_time:12817ms step_avg:129.46ms
step:110/1390 train_time:12950ms step_avg:129.50ms
step:111/1390 train_time:13083ms step_avg:129.54ms
step:112/1390 train_time:13215ms step_avg:129.56ms
step:113/1390 train_time:13348ms step_avg:129.60ms
step:114/1390 train_time:13482ms step_avg:129.63ms
step:115/1390 train_time:13614ms step_avg:129.66ms
step:116/1390 train_time:13747ms step_avg:129.69ms
step:117/1390 train_time:13879ms step_avg:129.71ms
step:118/1390 train_time:14012ms step_avg:129.74ms
step:119/1390 train_time:14149ms step_avg:129.81ms
step:120/1390 train_time:14278ms step_avg:129.80ms
step:121/1390 train_time:14409ms step_avg:129.81ms
step:122/1390 train_time:14546ms step_avg:129.88ms
step:123/1390 train_time:14675ms step_avg:129.87ms
step:124/1390 train_time:14810ms step_avg:129.91ms
step:125/1390 train_time:14941ms step_avg:129.92ms
step:125/1390 val_loss:4.8225 train_time:15044ms step_avg:130.82ms
step:126/1390 train_time:15085ms step_avg:130.05ms
step:127/1390 train_time:15219ms step_avg:130.07ms
step:128/1390 train_time:15351ms step_avg:130.09ms
step:129/1390 train_time:15484ms step_avg:130.12ms
step:130/1390 train_time:15616ms step_avg:130.13ms
step:131/1390 train_time:15750ms step_avg:130.17ms
step:132/1390 train_time:15881ms step_avg:130.17ms
step:133/1390 train_time:16014ms step_avg:130.19ms
step:134/1390 train_time:16147ms step_avg:130.22ms
step:135/1390 train_time:16279ms step_avg:130.23ms
step:136/1390 train_time:16412ms step_avg:130.25ms
step:137/1390 train_time:16545ms step_avg:130.27ms
step:138/1390 train_time:16684ms step_avg:130.35ms
step:139/1390 train_time:16814ms step_avg:130.34ms
step:140/1390 train_time:16943ms step_avg:130.33ms
step:141/1390 train_time:17081ms step_avg:130.39ms
step:142/1390 train_time:17222ms step_avg:130.47ms
step:143/1390 train_time:17342ms step_avg:130.39ms
step:144/1390 train_time:17475ms step_avg:130.41ms
step:145/1390 train_time:17609ms step_avg:130.44ms
step:146/1390 train_time:17742ms step_avg:130.45ms
step:147/1390 train_time:17874ms step_avg:130.47ms
step:148/1390 train_time:18009ms step_avg:130.50ms
step:149/1390 train_time:18145ms step_avg:130.54ms
step:150/1390 train_time:18273ms step_avg:130.52ms
step:151/1390 train_time:18408ms step_avg:130.55ms
step:152/1390 train_time:18542ms step_avg:130.58ms
step:153/1390 train_time:18671ms step_avg:130.57ms
step:154/1390 train_time:18803ms step_avg:130.58ms
step:155/1390 train_time:18939ms step_avg:130.61ms
step:156/1390 train_time:19071ms step_avg:130.62ms
step:157/1390 train_time:19202ms step_avg:130.63ms
step:158/1390 train_time:19336ms step_avg:130.65ms
step:159/1390 train_time:19487ms step_avg:130.79ms
step:160/1390 train_time:19611ms step_avg:130.74ms
step:161/1390 train_time:19739ms step_avg:130.72ms
step:162/1390 train_time:19873ms step_avg:130.74ms
step:163/1390 train_time:20004ms step_avg:130.74ms
step:164/1390 train_time:20137ms step_avg:130.76ms
step:165/1390 train_time:20270ms step_avg:130.78ms
step:166/1390 train_time:20403ms step_avg:130.79ms
step:167/1390 train_time:20537ms step_avg:130.81ms
step:168/1390 train_time:20670ms step_avg:130.82ms
step:169/1390 train_time:20803ms step_avg:130.84ms
step:170/1390 train_time:20937ms step_avg:130.86ms
step:171/1390 train_time:21070ms step_avg:130.87ms
step:172/1390 train_time:21203ms step_avg:130.88ms
step:173/1390 train_time:21335ms step_avg:130.89ms
step:174/1390 train_time:21476ms step_avg:130.95ms
step:175/1390 train_time:21603ms step_avg:130.93ms
step:176/1390 train_time:21737ms step_avg:130.95ms
step:177/1390 train_time:21870ms step_avg:130.96ms
step:178/1390 train_time:22002ms step_avg:130.97ms
step:179/1390 train_time:22137ms step_avg:130.99ms
step:180/1390 train_time:22270ms step_avg:131.00ms
step:181/1390 train_time:22402ms step_avg:131.01ms
step:182/1390 train_time:22535ms step_avg:131.02ms
step:183/1390 train_time:22668ms step_avg:131.03ms
step:184/1390 train_time:22801ms step_avg:131.04ms
step:185/1390 train_time:22935ms step_avg:131.06ms
step:186/1390 train_time:23069ms step_avg:131.07ms
step:187/1390 train_time:23201ms step_avg:131.08ms
step:188/1390 train_time:23335ms step_avg:131.09ms
step:189/1390 train_time:23468ms step_avg:131.11ms
step:190/1390 train_time:23601ms step_avg:131.11ms
step:191/1390 train_time:23787ms step_avg:131.42ms
step:192/1390 train_time:23917ms step_avg:131.41ms
step:193/1390 train_time:24051ms step_avg:131.43ms
step:194/1390 train_time:24182ms step_avg:131.43ms
step:195/1390 train_time:24316ms step_avg:131.44ms
step:196/1390 train_time:24450ms step_avg:131.45ms
step:197/1390 train_time:24586ms step_avg:131.48ms
step:198/1390 train_time:24718ms step_avg:131.48ms
step:199/1390 train_time:24852ms step_avg:131.49ms
step:200/1390 train_time:24988ms step_avg:131.51ms
step:201/1390 train_time:25120ms step_avg:131.52ms
step:202/1390 train_time:25255ms step_avg:131.54ms
step:203/1390 train_time:25388ms step_avg:131.54ms
step:204/1390 train_time:25524ms step_avg:131.57ms
step:205/1390 train_time:25656ms step_avg:131.57ms
step:206/1390 train_time:25789ms step_avg:131.58ms
step:207/1390 train_time:25925ms step_avg:131.60ms
step:208/1390 train_time:26059ms step_avg:131.61ms
step:209/1390 train_time:26193ms step_avg:131.62ms
step:210/1390 train_time:26329ms step_avg:131.64ms
step:211/1390 train_time:26465ms step_avg:131.67ms
step:212/1390 train_time:26600ms step_avg:131.68ms
step:213/1390 train_time:26736ms step_avg:131.70ms
step:214/1390 train_time:26871ms step_avg:131.72ms
step:215/1390 train_time:27007ms step_avg:131.74ms
step:216/1390 train_time:27144ms step_avg:131.77ms
step:217/1390 train_time:27280ms step_avg:131.79ms
step:218/1390 train_time:27416ms step_avg:131.81ms
step:219/1390 train_time:27552ms step_avg:131.83ms
step:220/1390 train_time:27688ms step_avg:131.85ms
step:221/1390 train_time:27824ms step_avg:131.86ms
step:222/1390 train_time:27960ms step_avg:131.89ms
step:223/1390 train_time:28096ms step_avg:131.91ms
step:224/1390 train_time:28231ms step_avg:131.92ms
step:225/1390 train_time:28367ms step_avg:131.94ms
step:226/1390 train_time:28503ms step_avg:131.96ms
step:227/1390 train_time:28640ms step_avg:131.98ms
step:228/1390 train_time:28775ms step_avg:132.00ms
step:229/1390 train_time:28911ms step_avg:132.01ms
step:230/1390 train_time:29048ms step_avg:132.03ms
step:231/1390 train_time:29185ms step_avg:132.06ms
step:232/1390 train_time:29320ms step_avg:132.07ms
step:233/1390 train_time:29456ms step_avg:132.09ms
step:234/1390 train_time:29593ms step_avg:132.11ms
step:235/1390 train_time:29728ms step_avg:132.13ms
step:236/1390 train_time:29864ms step_avg:132.14ms
step:237/1390 train_time:30000ms step_avg:132.16ms
step:238/1390 train_time:30137ms step_avg:132.18ms
step:239/1390 train_time:30278ms step_avg:132.22ms
step:240/1390 train_time:30408ms step_avg:132.21ms
step:241/1390 train_time:30544ms step_avg:132.22ms
step:242/1390 train_time:30679ms step_avg:132.24ms
step:243/1390 train_time:30815ms step_avg:132.25ms
step:244/1390 train_time:30955ms step_avg:132.29ms
step:245/1390 train_time:31090ms step_avg:132.30ms
step:246/1390 train_time:31224ms step_avg:132.30ms
step:247/1390 train_time:31360ms step_avg:132.32ms
step:248/1390 train_time:31496ms step_avg:132.34ms
step:249/1390 train_time:31633ms step_avg:132.35ms
step:250/1390 train_time:31778ms step_avg:132.41ms
step:250/1390 val_loss:4.3060 train_time:31875ms step_avg:132.81ms
step:251/1390 train_time:31911ms step_avg:132.41ms
step:252/1390 train_time:32047ms step_avg:132.43ms
step:253/1390 train_time:32185ms step_avg:132.45ms
step:254/1390 train_time:32320ms step_avg:132.46ms
step:255/1390 train_time:32455ms step_avg:132.47ms
step:256/1390 train_time:32591ms step_avg:132.48ms
step:257/1390 train_time:32727ms step_avg:132.50ms
step:258/1390 train_time:32863ms step_avg:132.51ms
step:259/1390 train_time:33000ms step_avg:132.53ms
step:260/1390 train_time:33136ms step_avg:132.55ms
step:261/1390 train_time:33273ms step_avg:132.56ms
step:262/1390 train_time:33409ms step_avg:132.57ms
step:263/1390 train_time:33545ms step_avg:132.59ms
step:264/1390 train_time:33682ms step_avg:132.60ms
step:265/1390 train_time:33817ms step_avg:132.62ms
step:266/1390 train_time:33955ms step_avg:132.64ms
step:267/1390 train_time:34089ms step_avg:132.64ms
step:268/1390 train_time:34225ms step_avg:132.65ms
step:269/1390 train_time:34361ms step_avg:132.67ms
step:270/1390 train_time:34497ms step_avg:132.68ms
step:271/1390 train_time:34633ms step_avg:132.69ms
step:272/1390 train_time:34770ms step_avg:132.71ms
step:273/1390 train_time:34909ms step_avg:132.73ms
step:274/1390 train_time:35042ms step_avg:132.74ms
step:275/1390 train_time:35180ms step_avg:132.75ms
step:276/1390 train_time:35315ms step_avg:132.76ms
step:277/1390 train_time:35450ms step_avg:132.77ms
step:278/1390 train_time:35590ms step_avg:132.80ms
step:279/1390 train_time:35730ms step_avg:132.83ms
step:280/1390 train_time:35860ms step_avg:132.82ms
step:281/1390 train_time:36000ms step_avg:132.84ms
step:282/1390 train_time:36133ms step_avg:132.84ms
step:283/1390 train_time:36269ms step_avg:132.85ms
step:284/1390 train_time:36404ms step_avg:132.86ms
step:285/1390 train_time:36541ms step_avg:132.88ms
step:286/1390 train_time:36677ms step_avg:132.89ms
step:287/1390 train_time:36813ms step_avg:132.90ms
step:288/1390 train_time:36950ms step_avg:132.92ms
step:289/1390 train_time:37086ms step_avg:132.93ms
step:290/1390 train_time:37222ms step_avg:132.94ms
step:291/1390 train_time:37359ms step_avg:132.95ms
step:292/1390 train_time:37496ms step_avg:132.96ms
step:293/1390 train_time:37630ms step_avg:132.97ms
step:294/1390 train_time:37766ms step_avg:132.98ms
step:295/1390 train_time:37902ms step_avg:132.99ms
step:296/1390 train_time:38039ms step_avg:133.00ms
step:297/1390 train_time:38176ms step_avg:133.02ms
step:298/1390 train_time:38312ms step_avg:133.03ms
step:299/1390 train_time:38448ms step_avg:133.04ms
step:300/1390 train_time:38585ms step_avg:133.05ms
step:301/1390 train_time:38721ms step_avg:133.06ms
step:302/1390 train_time:38858ms step_avg:133.07ms
step:303/1390 train_time:38997ms step_avg:133.10ms
step:304/1390 train_time:39132ms step_avg:133.10ms
step:305/1390 train_time:39267ms step_avg:133.11ms
step:306/1390 train_time:39403ms step_avg:133.12ms
step:307/1390 train_time:39539ms step_avg:133.13ms
step:308/1390 train_time:39675ms step_avg:133.14ms
step:309/1390 train_time:39811ms step_avg:133.15ms
step:310/1390 train_time:39948ms step_avg:133.16ms
step:311/1390 train_time:40086ms step_avg:133.18ms
step:312/1390 train_time:40224ms step_avg:133.19ms
step:313/1390 train_time:40366ms step_avg:133.22ms
step:314/1390 train_time:40503ms step_avg:133.23ms
step:315/1390 train_time:40641ms step_avg:133.25ms
step:316/1390 train_time:40779ms step_avg:133.27ms
step:317/1390 train_time:40919ms step_avg:133.29ms
step:318/1390 train_time:41056ms step_avg:133.30ms
step:319/1390 train_time:41193ms step_avg:133.31ms
step:320/1390 train_time:41339ms step_avg:133.35ms
step:321/1390 train_time:41471ms step_avg:133.35ms
step:322/1390 train_time:41614ms step_avg:133.38ms
step:323/1390 train_time:41748ms step_avg:133.38ms
step:324/1390 train_time:41886ms step_avg:133.39ms
step:325/1390 train_time:42023ms step_avg:133.41ms
step:326/1390 train_time:42163ms step_avg:133.43ms
step:327/1390 train_time:42300ms step_avg:133.44ms
step:328/1390 train_time:42439ms step_avg:133.46ms
step:329/1390 train_time:42578ms step_avg:133.47ms
step:330/1390 train_time:42715ms step_avg:133.48ms
step:331/1390 train_time:42854ms step_avg:133.50ms
step:332/1390 train_time:42992ms step_avg:133.52ms
step:333/1390 train_time:43132ms step_avg:133.54ms
step:334/1390 train_time:43273ms step_avg:133.56ms
step:335/1390 train_time:43408ms step_avg:133.56ms
step:336/1390 train_time:43546ms step_avg:133.58ms
step:337/1390 train_time:43684ms step_avg:133.59ms
step:338/1390 train_time:43822ms step_avg:133.60ms
step:339/1390 train_time:43961ms step_avg:133.62ms
step:340/1390 train_time:44100ms step_avg:133.64ms
step:341/1390 train_time:44237ms step_avg:133.65ms
step:342/1390 train_time:44375ms step_avg:133.66ms
step:343/1390 train_time:44513ms step_avg:133.67ms
step:344/1390 train_time:44651ms step_avg:133.69ms
step:345/1390 train_time:44790ms step_avg:133.70ms
step:346/1390 train_time:44929ms step_avg:133.72ms
step:347/1390 train_time:45067ms step_avg:133.73ms
step:348/1390 train_time:45206ms step_avg:133.74ms
step:349/1390 train_time:45350ms step_avg:133.78ms
step:350/1390 train_time:45483ms step_avg:133.77ms
step:351/1390 train_time:45621ms step_avg:133.79ms
step:352/1390 train_time:45760ms step_avg:133.80ms
step:353/1390 train_time:45898ms step_avg:133.81ms
step:354/1390 train_time:46036ms step_avg:133.82ms
step:355/1390 train_time:46175ms step_avg:133.84ms
step:356/1390 train_time:46315ms step_avg:133.86ms
step:357/1390 train_time:46454ms step_avg:133.87ms
step:358/1390 train_time:46588ms step_avg:133.87ms
step:359/1390 train_time:46726ms step_avg:133.89ms
step:360/1390 train_time:46866ms step_avg:133.90ms
step:361/1390 train_time:47004ms step_avg:133.91ms
step:362/1390 train_time:47142ms step_avg:133.93ms
step:363/1390 train_time:47281ms step_avg:133.94ms
step:364/1390 train_time:47418ms step_avg:133.95ms
step:365/1390 train_time:47556ms step_avg:133.96ms
step:366/1390 train_time:47698ms step_avg:133.98ms
step:367/1390 train_time:47833ms step_avg:133.99ms
step:368/1390 train_time:47971ms step_avg:134.00ms
step:369/1390 train_time:48109ms step_avg:134.01ms
step:370/1390 train_time:48247ms step_avg:134.02ms
step:371/1390 train_time:48386ms step_avg:134.03ms
step:372/1390 train_time:48524ms step_avg:134.04ms
step:373/1390 train_time:48663ms step_avg:134.06ms
step:374/1390 train_time:48802ms step_avg:134.07ms
step:375/1390 train_time:48942ms step_avg:134.09ms
step:375/1390 val_loss:4.1103 train_time:49048ms step_avg:134.38ms
step:376/1390 train_time:49083ms step_avg:134.11ms
step:377/1390 train_time:49222ms step_avg:134.12ms
step:378/1390 train_time:49360ms step_avg:134.13ms
step:379/1390 train_time:49499ms step_avg:134.14ms
step:380/1390 train_time:49637ms step_avg:134.15ms
step:381/1390 train_time:49825ms step_avg:134.30ms
step:382/1390 train_time:49961ms step_avg:134.30ms
step:383/1390 train_time:50099ms step_avg:134.31ms
step:384/1390 train_time:50239ms step_avg:134.33ms
step:385/1390 train_time:50374ms step_avg:134.33ms
step:386/1390 train_time:50513ms step_avg:134.34ms
step:387/1390 train_time:50651ms step_avg:134.35ms
step:388/1390 train_time:50791ms step_avg:134.37ms
step:389/1390 train_time:50930ms step_avg:134.38ms
step:390/1390 train_time:51069ms step_avg:134.39ms
step:391/1390 train_time:51208ms step_avg:134.40ms
step:392/1390 train_time:51346ms step_avg:134.41ms
step:393/1390 train_time:51484ms step_avg:134.42ms
step:394/1390 train_time:51623ms step_avg:134.43ms
step:395/1390 train_time:51761ms step_avg:134.44ms
step:396/1390 train_time:51899ms step_avg:134.45ms
step:397/1390 train_time:52038ms step_avg:134.46ms
step:398/1390 train_time:52176ms step_avg:134.47ms
step:399/1390 train_time:52315ms step_avg:134.48ms
step:400/1390 train_time:52452ms step_avg:134.49ms
step:401/1390 train_time:52591ms step_avg:134.50ms
step:402/1390 train_time:52731ms step_avg:134.52ms
step:403/1390 train_time:52869ms step_avg:134.53ms
step:404/1390 train_time:53008ms step_avg:134.54ms
step:405/1390 train_time:53145ms step_avg:134.54ms
step:406/1390 train_time:53284ms step_avg:134.55ms
step:407/1390 train_time:53430ms step_avg:134.58ms
step:408/1390 train_time:53560ms step_avg:134.57ms
step:409/1390 train_time:53699ms step_avg:134.58ms
step:410/1390 train_time:53837ms step_avg:134.59ms
step:411/1390 train_time:53974ms step_avg:134.60ms
step:412/1390 train_time:54114ms step_avg:134.61ms
step:413/1390 train_time:54251ms step_avg:134.62ms
step:414/1390 train_time:54391ms step_avg:134.63ms
step:415/1390 train_time:54532ms step_avg:134.65ms
step:416/1390 train_time:54672ms step_avg:134.66ms
step:417/1390 train_time:55410ms step_avg:136.14ms
step:418/1390 train_time:55796ms step_avg:136.75ms
step:419/1390 train_time:55934ms step_avg:136.76ms
step:420/1390 train_time:56074ms step_avg:136.77ms
step:421/1390 train_time:56216ms step_avg:136.78ms
step:422/1390 train_time:56356ms step_avg:136.79ms
step:423/1390 train_time:56496ms step_avg:136.79ms
step:424/1390 train_time:56635ms step_avg:136.80ms
step:425/1390 train_time:56776ms step_avg:136.81ms
step:426/1390 train_time:56917ms step_avg:136.82ms
step:427/1390 train_time:57057ms step_avg:136.83ms
step:428/1390 train_time:57198ms step_avg:136.84ms
step:429/1390 train_time:57343ms step_avg:136.86ms
step:430/1390 train_time:57480ms step_avg:136.86ms
step:431/1390 train_time:57621ms step_avg:136.87ms
step:432/1390 train_time:57761ms step_avg:136.87ms
step:433/1390 train_time:57901ms step_avg:136.88ms
step:434/1390 train_time:58043ms step_avg:136.89ms
step:435/1390 train_time:58183ms step_avg:136.90ms
step:436/1390 train_time:58323ms step_avg:136.91ms
step:437/1390 train_time:58463ms step_avg:136.92ms
step:438/1390 train_time:58603ms step_avg:136.92ms
step:439/1390 train_time:58742ms step_avg:136.93ms
step:440/1390 train_time:58883ms step_avg:136.94ms
step:441/1390 train_time:59024ms step_avg:136.95ms
step:442/1390 train_time:59165ms step_avg:136.96ms
step:443/1390 train_time:59306ms step_avg:136.97ms
step:444/1390 train_time:59445ms step_avg:136.97ms
step:445/1390 train_time:59586ms step_avg:136.98ms
step:446/1390 train_time:59727ms step_avg:136.99ms
step:447/1390 train_time:59868ms step_avg:137.00ms
step:448/1390 train_time:60008ms step_avg:137.00ms
step:449/1390 train_time:60148ms step_avg:137.01ms
step:450/1390 train_time:60288ms step_avg:137.02ms
step:451/1390 train_time:60428ms step_avg:137.03ms
step:452/1390 train_time:60569ms step_avg:137.03ms
step:453/1390 train_time:60710ms step_avg:137.04ms
step:454/1390 train_time:60850ms step_avg:137.05ms
step:455/1390 train_time:60991ms step_avg:137.06ms
step:456/1390 train_time:61130ms step_avg:137.06ms
step:457/1390 train_time:61271ms step_avg:137.07ms
step:458/1390 train_time:61412ms step_avg:137.08ms
step:459/1390 train_time:61552ms step_avg:137.09ms
step:460/1390 train_time:61693ms step_avg:137.10ms
step:461/1390 train_time:61836ms step_avg:137.11ms
step:462/1390 train_time:61975ms step_avg:137.11ms
step:463/1390 train_time:62116ms step_avg:137.12ms
step:464/1390 train_time:62256ms step_avg:137.13ms
step:465/1390 train_time:62396ms step_avg:137.14ms
step:466/1390 train_time:62537ms step_avg:137.14ms
step:467/1390 train_time:62677ms step_avg:137.15ms
step:468/1390 train_time:62820ms step_avg:137.16ms
step:469/1390 train_time:62958ms step_avg:137.16ms
step:470/1390 train_time:63100ms step_avg:137.17ms
step:471/1390 train_time:63238ms step_avg:137.18ms
step:472/1390 train_time:63378ms step_avg:137.18ms
step:473/1390 train_time:63519ms step_avg:137.19ms
step:474/1390 train_time:63663ms step_avg:137.20ms
step:475/1390 train_time:63801ms step_avg:137.21ms
step:476/1390 train_time:63940ms step_avg:137.21ms
step:477/1390 train_time:64081ms step_avg:137.22ms
step:478/1390 train_time:64222ms step_avg:137.23ms
step:479/1390 train_time:64363ms step_avg:137.23ms
step:480/1390 train_time:64504ms step_avg:137.24ms
step:481/1390 train_time:64645ms step_avg:137.25ms
step:482/1390 train_time:64785ms step_avg:137.26ms
step:483/1390 train_time:64926ms step_avg:137.26ms
step:484/1390 train_time:65066ms step_avg:137.27ms
step:485/1390 train_time:65207ms step_avg:137.28ms
step:486/1390 train_time:65347ms step_avg:137.28ms
step:487/1390 train_time:65488ms step_avg:137.29ms
step:488/1390 train_time:65628ms step_avg:137.30ms
step:489/1390 train_time:65769ms step_avg:137.30ms
step:490/1390 train_time:65909ms step_avg:137.31ms
step:491/1390 train_time:66049ms step_avg:137.32ms
step:492/1390 train_time:66191ms step_avg:137.32ms
step:493/1390 train_time:66330ms step_avg:137.33ms
step:494/1390 train_time:66474ms step_avg:137.34ms
step:495/1390 train_time:66614ms step_avg:137.35ms
step:496/1390 train_time:66753ms step_avg:137.35ms
step:497/1390 train_time:66894ms step_avg:137.36ms
step:498/1390 train_time:67036ms step_avg:137.37ms
step:499/1390 train_time:67177ms step_avg:137.38ms
step:500/1390 train_time:67317ms step_avg:137.38ms
step:500/1390 val_loss:3.9944 train_time:67423ms step_avg:137.60ms
step:501/1390 train_time:67460ms step_avg:137.39ms
step:502/1390 train_time:67612ms step_avg:137.42ms
step:503/1390 train_time:67747ms step_avg:137.42ms
step:504/1390 train_time:67886ms step_avg:137.42ms
step:505/1390 train_time:68024ms step_avg:137.42ms
step:506/1390 train_time:68164ms step_avg:137.43ms
step:507/1390 train_time:68305ms step_avg:137.43ms
step:508/1390 train_time:68446ms step_avg:137.44ms
step:509/1390 train_time:68586ms step_avg:137.45ms
step:510/1390 train_time:68727ms step_avg:137.45ms
step:511/1390 train_time:68868ms step_avg:137.46ms
step:512/1390 train_time:69010ms step_avg:137.47ms
step:513/1390 train_time:69150ms step_avg:137.48ms
step:514/1390 train_time:69291ms step_avg:137.48ms
step:515/1390 train_time:69431ms step_avg:137.49ms
step:516/1390 train_time:69574ms step_avg:137.50ms
step:517/1390 train_time:69715ms step_avg:137.50ms
step:518/1390 train_time:69857ms step_avg:137.51ms
step:519/1390 train_time:69998ms step_avg:137.52ms
step:520/1390 train_time:70142ms step_avg:137.53ms
step:521/1390 train_time:70284ms step_avg:137.54ms
step:522/1390 train_time:70425ms step_avg:137.55ms
step:523/1390 train_time:70567ms step_avg:137.56ms
step:524/1390 train_time:70710ms step_avg:137.57ms
step:525/1390 train_time:70854ms step_avg:137.58ms
step:526/1390 train_time:70996ms step_avg:137.59ms
step:527/1390 train_time:71139ms step_avg:137.60ms
step:528/1390 train_time:71280ms step_avg:137.61ms
step:529/1390 train_time:71423ms step_avg:137.62ms
step:530/1390 train_time:71564ms step_avg:137.62ms
step:531/1390 train_time:71713ms step_avg:137.64ms
step:532/1390 train_time:71850ms step_avg:137.64ms
step:533/1390 train_time:71996ms step_avg:137.66ms
step:534/1390 train_time:72138ms step_avg:137.67ms
step:535/1390 train_time:72281ms step_avg:137.68ms
step:536/1390 train_time:72423ms step_avg:137.69ms
step:537/1390 train_time:72565ms step_avg:137.70ms
step:538/1390 train_time:72709ms step_avg:137.71ms
step:539/1390 train_time:72850ms step_avg:137.71ms
step:540/1390 train_time:72993ms step_avg:137.72ms
step:541/1390 train_time:73136ms step_avg:137.73ms
step:542/1390 train_time:73279ms step_avg:137.74ms
step:543/1390 train_time:73422ms step_avg:137.75ms
step:544/1390 train_time:73566ms step_avg:137.76ms
step:545/1390 train_time:73705ms step_avg:137.77ms
step:546/1390 train_time:73847ms step_avg:137.77ms
step:547/1390 train_time:73989ms step_avg:137.78ms
step:548/1390 train_time:74133ms step_avg:137.79ms
step:549/1390 train_time:74274ms step_avg:137.80ms
step:550/1390 train_time:74417ms step_avg:137.81ms
step:551/1390 train_time:74559ms step_avg:137.82ms
step:552/1390 train_time:74702ms step_avg:137.83ms
step:553/1390 train_time:74845ms step_avg:137.84ms
step:554/1390 train_time:74987ms step_avg:137.84ms
step:555/1390 train_time:75129ms step_avg:137.85ms
step:556/1390 train_time:75273ms step_avg:137.86ms
step:557/1390 train_time:75414ms step_avg:137.87ms
step:558/1390 train_time:75556ms step_avg:137.88ms
step:559/1390 train_time:75697ms step_avg:137.88ms
step:560/1390 train_time:75840ms step_avg:137.89ms
step:561/1390 train_time:75983ms step_avg:137.90ms
step:562/1390 train_time:76126ms step_avg:137.91ms
step:563/1390 train_time:76275ms step_avg:137.93ms
step:564/1390 train_time:76410ms step_avg:137.92ms
step:565/1390 train_time:76553ms step_avg:137.93ms
step:566/1390 train_time:76696ms step_avg:137.94ms
step:567/1390 train_time:76837ms step_avg:137.95ms
step:568/1390 train_time:76980ms step_avg:137.96ms
step:569/1390 train_time:77122ms step_avg:137.96ms
step:570/1390 train_time:77265ms step_avg:137.97ms
step:571/1390 train_time:77457ms step_avg:138.07ms
step:572/1390 train_time:77596ms step_avg:138.07ms
step:573/1390 train_time:77738ms step_avg:138.08ms
step:574/1390 train_time:77881ms step_avg:138.09ms
step:575/1390 train_time:78023ms step_avg:138.09ms
step:576/1390 train_time:78165ms step_avg:138.10ms
step:577/1390 train_time:78307ms step_avg:138.11ms
step:578/1390 train_time:78450ms step_avg:138.12ms
step:579/1390 train_time:78593ms step_avg:138.13ms
step:580/1390 train_time:78736ms step_avg:138.13ms
step:581/1390 train_time:78879ms step_avg:138.14ms
step:582/1390 train_time:79022ms step_avg:138.15ms
step:583/1390 train_time:79167ms step_avg:138.16ms
step:584/1390 train_time:79314ms step_avg:138.18ms
step:585/1390 train_time:79449ms step_avg:138.17ms
step:586/1390 train_time:79592ms step_avg:138.18ms
step:587/1390 train_time:79735ms step_avg:138.19ms
step:588/1390 train_time:79876ms step_avg:138.19ms
step:589/1390 train_time:80020ms step_avg:138.20ms
step:590/1390 train_time:80162ms step_avg:138.21ms
step:591/1390 train_time:80305ms step_avg:138.22ms
step:592/1390 train_time:80447ms step_avg:138.23ms
step:593/1390 train_time:80595ms step_avg:138.24ms
step:594/1390 train_time:80736ms step_avg:138.25ms
step:595/1390 train_time:80877ms step_avg:138.25ms
step:596/1390 train_time:81021ms step_avg:138.26ms
step:597/1390 train_time:81163ms step_avg:138.27ms
step:598/1390 train_time:81305ms step_avg:138.27ms
step:599/1390 train_time:81447ms step_avg:138.28ms
step:600/1390 train_time:81589ms step_avg:138.29ms
step:601/1390 train_time:81733ms step_avg:138.30ms
step:602/1390 train_time:81874ms step_avg:138.30ms
step:603/1390 train_time:82018ms step_avg:138.31ms
step:604/1390 train_time:82159ms step_avg:138.32ms
step:605/1390 train_time:82302ms step_avg:138.32ms
step:606/1390 train_time:82443ms step_avg:138.33ms
step:607/1390 train_time:82585ms step_avg:138.33ms
step:608/1390 train_time:82729ms step_avg:138.34ms
step:609/1390 train_time:82870ms step_avg:138.35ms
step:610/1390 train_time:83012ms step_avg:138.35ms
step:611/1390 train_time:83157ms step_avg:138.36ms
step:612/1390 train_time:83298ms step_avg:138.37ms
step:613/1390 train_time:83440ms step_avg:138.37ms
step:614/1390 train_time:83582ms step_avg:138.38ms
step:615/1390 train_time:83725ms step_avg:138.39ms
step:616/1390 train_time:83866ms step_avg:138.39ms
step:617/1390 train_time:84008ms step_avg:138.40ms
step:618/1390 train_time:84151ms step_avg:138.41ms
step:619/1390 train_time:84297ms step_avg:138.42ms
step:620/1390 train_time:84450ms step_avg:138.44ms
step:621/1390 train_time:84586ms step_avg:138.44ms
step:622/1390 train_time:84727ms step_avg:138.44ms
step:623/1390 train_time:84869ms step_avg:138.45ms
step:624/1390 train_time:85017ms step_avg:138.46ms
step:625/1390 train_time:85158ms step_avg:138.47ms
step:625/1390 val_loss:3.8853 train_time:85269ms step_avg:138.65ms
step:626/1390 train_time:85305ms step_avg:138.48ms
step:627/1390 train_time:85453ms step_avg:138.50ms
step:628/1390 train_time:85603ms step_avg:138.52ms
step:629/1390 train_time:85739ms step_avg:138.51ms
step:630/1390 train_time:85882ms step_avg:138.52ms
step:631/1390 train_time:86026ms step_avg:138.53ms
step:632/1390 train_time:86168ms step_avg:138.53ms
step:633/1390 train_time:86311ms step_avg:138.54ms
step:634/1390 train_time:86456ms step_avg:138.55ms
step:635/1390 train_time:86600ms step_avg:138.56ms
step:636/1390 train_time:86745ms step_avg:138.57ms
step:637/1390 train_time:86887ms step_avg:138.58ms
step:638/1390 train_time:87031ms step_avg:138.58ms
step:639/1390 train_time:87173ms step_avg:138.59ms
step:640/1390 train_time:87318ms step_avg:138.60ms
step:641/1390 train_time:87461ms step_avg:138.61ms
step:642/1390 train_time:87605ms step_avg:138.62ms
step:643/1390 train_time:87748ms step_avg:138.62ms
step:644/1390 train_time:87893ms step_avg:138.63ms
step:645/1390 train_time:88036ms step_avg:138.64ms
step:646/1390 train_time:88178ms step_avg:138.65ms
step:647/1390 train_time:88322ms step_avg:138.65ms
step:648/1390 train_time:88467ms step_avg:138.66ms
step:649/1390 train_time:88612ms step_avg:138.67ms
step:650/1390 train_time:88756ms step_avg:138.68ms
step:651/1390 train_time:88900ms step_avg:138.69ms
step:652/1390 train_time:89045ms step_avg:138.70ms
step:653/1390 train_time:89192ms step_avg:138.71ms
step:654/1390 train_time:89335ms step_avg:138.72ms
step:655/1390 train_time:89478ms step_avg:138.73ms
step:656/1390 train_time:89621ms step_avg:138.73ms
step:657/1390 train_time:89765ms step_avg:138.74ms
step:658/1390 train_time:89908ms step_avg:138.75ms
step:659/1390 train_time:90053ms step_avg:138.76ms
step:660/1390 train_time:90197ms step_avg:138.76ms
step:661/1390 train_time:90341ms step_avg:138.77ms
step:662/1390 train_time:90485ms step_avg:138.78ms
step:663/1390 train_time:90628ms step_avg:138.79ms
step:664/1390 train_time:90772ms step_avg:138.79ms
step:665/1390 train_time:90915ms step_avg:138.80ms
step:666/1390 train_time:91059ms step_avg:138.81ms
step:667/1390 train_time:91202ms step_avg:138.82ms
step:668/1390 train_time:91348ms step_avg:138.83ms
step:669/1390 train_time:91490ms step_avg:138.83ms
step:670/1390 train_time:91636ms step_avg:138.84ms
step:671/1390 train_time:91780ms step_avg:138.85ms
step:672/1390 train_time:91925ms step_avg:138.86ms
step:673/1390 train_time:92068ms step_avg:138.87ms
step:674/1390 train_time:92212ms step_avg:138.87ms
step:675/1390 train_time:92358ms step_avg:138.88ms
step:676/1390 train_time:92503ms step_avg:138.89ms
step:677/1390 train_time:92646ms step_avg:138.90ms
step:678/1390 train_time:92789ms step_avg:138.91ms
step:679/1390 train_time:92933ms step_avg:138.91ms
step:680/1390 train_time:93077ms step_avg:138.92ms
step:681/1390 train_time:93222ms step_avg:138.93ms
step:682/1390 train_time:93365ms step_avg:138.94ms
step:683/1390 train_time:93508ms step_avg:138.94ms
step:684/1390 train_time:93654ms step_avg:138.95ms
step:685/1390 train_time:93798ms step_avg:138.96ms
step:686/1390 train_time:93942ms step_avg:138.97ms
step:687/1390 train_time:94086ms step_avg:138.97ms
step:688/1390 train_time:94230ms step_avg:138.98ms
step:689/1390 train_time:94374ms step_avg:138.99ms
step:690/1390 train_time:94519ms step_avg:139.00ms
step:691/1390 train_time:94662ms step_avg:139.01ms
step:692/1390 train_time:94807ms step_avg:139.01ms
step:693/1390 train_time:94950ms step_avg:139.02ms
step:694/1390 train_time:95097ms step_avg:139.03ms
step:695/1390 train_time:95240ms step_avg:139.04ms
step:696/1390 train_time:95382ms step_avg:139.04ms
step:697/1390 train_time:95526ms step_avg:139.05ms
step:698/1390 train_time:95669ms step_avg:139.05ms
step:699/1390 train_time:95813ms step_avg:139.06ms
step:700/1390 train_time:95957ms step_avg:139.07ms
step:701/1390 train_time:96101ms step_avg:139.08ms
step:702/1390 train_time:96246ms step_avg:139.08ms
step:703/1390 train_time:96388ms step_avg:139.09ms
step:704/1390 train_time:96533ms step_avg:139.10ms
step:705/1390 train_time:96677ms step_avg:139.10ms
step:706/1390 train_time:96825ms step_avg:139.12ms
step:707/1390 train_time:96967ms step_avg:139.12ms
step:708/1390 train_time:97116ms step_avg:139.13ms
step:709/1390 train_time:97259ms step_avg:139.14ms
step:710/1390 train_time:97403ms step_avg:139.15ms
step:711/1390 train_time:97553ms step_avg:139.16ms
step:712/1390 train_time:97694ms step_avg:139.16ms
step:713/1390 train_time:97839ms step_avg:139.17ms
step:714/1390 train_time:97982ms step_avg:139.18ms
step:715/1390 train_time:98126ms step_avg:139.19ms
step:716/1390 train_time:98271ms step_avg:139.19ms
step:717/1390 train_time:98415ms step_avg:139.20ms
step:718/1390 train_time:98559ms step_avg:139.21ms
step:719/1390 train_time:98701ms step_avg:139.21ms
step:720/1390 train_time:98846ms step_avg:139.22ms
step:721/1390 train_time:98989ms step_avg:139.23ms
step:722/1390 train_time:99134ms step_avg:139.23ms
step:723/1390 train_time:99279ms step_avg:139.24ms
step:724/1390 train_time:99425ms step_avg:139.25ms
step:725/1390 train_time:99571ms step_avg:139.26ms
step:726/1390 train_time:99718ms step_avg:139.27ms
step:727/1390 train_time:99864ms step_avg:139.28ms
step:728/1390 train_time:100008ms step_avg:139.29ms
step:729/1390 train_time:100154ms step_avg:139.30ms
step:730/1390 train_time:100300ms step_avg:139.31ms
step:731/1390 train_time:100446ms step_avg:139.31ms
step:732/1390 train_time:100591ms step_avg:139.32ms
step:733/1390 train_time:100739ms step_avg:139.34ms
step:734/1390 train_time:100881ms step_avg:139.34ms
step:735/1390 train_time:101027ms step_avg:139.35ms
step:736/1390 train_time:101171ms step_avg:139.35ms
step:737/1390 train_time:101319ms step_avg:139.37ms
step:738/1390 train_time:101463ms step_avg:139.37ms
step:739/1390 train_time:101609ms step_avg:139.38ms
step:740/1390 train_time:101755ms step_avg:139.39ms
step:741/1390 train_time:101904ms step_avg:139.40ms
step:742/1390 train_time:102048ms step_avg:139.41ms
step:743/1390 train_time:102194ms step_avg:139.42ms
step:744/1390 train_time:102341ms step_avg:139.43ms
step:745/1390 train_time:102488ms step_avg:139.44ms
step:746/1390 train_time:102634ms step_avg:139.45ms
step:747/1390 train_time:102782ms step_avg:139.46ms
step:748/1390 train_time:102925ms step_avg:139.46ms
step:749/1390 train_time:103071ms step_avg:139.47ms
step:750/1390 train_time:103220ms step_avg:139.49ms
step:750/1390 val_loss:3.8195 train_time:103334ms step_avg:139.64ms
step:751/1390 train_time:103370ms step_avg:139.50ms
step:752/1390 train_time:103518ms step_avg:139.51ms
step:753/1390 train_time:103662ms step_avg:139.52ms
step:754/1390 train_time:103808ms step_avg:139.53ms
step:755/1390 train_time:103952ms step_avg:139.53ms
step:756/1390 train_time:104096ms step_avg:139.54ms
step:757/1390 train_time:104243ms step_avg:139.55ms
step:758/1390 train_time:104388ms step_avg:139.56ms
step:759/1390 train_time:104533ms step_avg:139.56ms
step:760/1390 train_time:104678ms step_avg:139.57ms
step:761/1390 train_time:104874ms step_avg:139.65ms
step:762/1390 train_time:105016ms step_avg:139.65ms
step:763/1390 train_time:105160ms step_avg:139.65ms
step:764/1390 train_time:105316ms step_avg:139.68ms
step:765/1390 train_time:105451ms step_avg:139.67ms
step:766/1390 train_time:105597ms step_avg:139.68ms
step:767/1390 train_time:105743ms step_avg:139.69ms
step:768/1390 train_time:105889ms step_avg:139.70ms
step:769/1390 train_time:106035ms step_avg:139.70ms
step:770/1390 train_time:106180ms step_avg:139.71ms
step:771/1390 train_time:106325ms step_avg:139.72ms
step:772/1390 train_time:106470ms step_avg:139.72ms
step:773/1390 train_time:106617ms step_avg:139.73ms
step:774/1390 train_time:106761ms step_avg:139.74ms
step:775/1390 train_time:106906ms step_avg:139.75ms
step:776/1390 train_time:107050ms step_avg:139.75ms
step:777/1390 train_time:107195ms step_avg:139.76ms
step:778/1390 train_time:107343ms step_avg:139.77ms
step:779/1390 train_time:107485ms step_avg:139.77ms
step:780/1390 train_time:107631ms step_avg:139.78ms
step:781/1390 train_time:107779ms step_avg:139.79ms
step:782/1390 train_time:107923ms step_avg:139.80ms
step:783/1390 train_time:108069ms step_avg:139.80ms
step:784/1390 train_time:108215ms step_avg:139.81ms
step:785/1390 train_time:108359ms step_avg:139.82ms
step:786/1390 train_time:108505ms step_avg:139.83ms
step:787/1390 train_time:108650ms step_avg:139.83ms
step:788/1390 train_time:108796ms step_avg:139.84ms
step:789/1390 train_time:108941ms step_avg:139.85ms
step:790/1390 train_time:109087ms step_avg:139.86ms
step:791/1390 train_time:109231ms step_avg:139.86ms
step:792/1390 train_time:109378ms step_avg:139.87ms
step:793/1390 train_time:109524ms step_avg:139.88ms
step:794/1390 train_time:109670ms step_avg:139.89ms
step:795/1390 train_time:109819ms step_avg:139.90ms
step:796/1390 train_time:109964ms step_avg:139.90ms
step:797/1390 train_time:110110ms step_avg:139.91ms
step:798/1390 train_time:110255ms step_avg:139.92ms
step:799/1390 train_time:110401ms step_avg:139.93ms
step:800/1390 train_time:110546ms step_avg:139.93ms
step:801/1390 train_time:110693ms step_avg:139.94ms
step:802/1390 train_time:110839ms step_avg:139.95ms
step:803/1390 train_time:110982ms step_avg:139.95ms
step:804/1390 train_time:111127ms step_avg:139.96ms
step:805/1390 train_time:111274ms step_avg:139.97ms
step:806/1390 train_time:111418ms step_avg:139.97ms
step:807/1390 train_time:111561ms step_avg:139.98ms
step:808/1390 train_time:111708ms step_avg:139.98ms
step:809/1390 train_time:111854ms step_avg:139.99ms
step:810/1390 train_time:111999ms step_avg:140.00ms
step:811/1390 train_time:112146ms step_avg:140.01ms
step:812/1390 train_time:112291ms step_avg:140.01ms
step:813/1390 train_time:112436ms step_avg:140.02ms
step:814/1390 train_time:112580ms step_avg:140.03ms
step:815/1390 train_time:112727ms step_avg:140.03ms
step:816/1390 train_time:112876ms step_avg:140.05ms
step:817/1390 train_time:113020ms step_avg:140.05ms
step:818/1390 train_time:113162ms step_avg:140.05ms
step:819/1390 train_time:113309ms step_avg:140.06ms
step:820/1390 train_time:113454ms step_avg:140.07ms
step:821/1390 train_time:113599ms step_avg:140.07ms
step:822/1390 train_time:113749ms step_avg:140.08ms
step:823/1390 train_time:113890ms step_avg:140.09ms
step:824/1390 train_time:114035ms step_avg:140.09ms
step:825/1390 train_time:114180ms step_avg:140.10ms
step:826/1390 train_time:114328ms step_avg:140.11ms
step:827/1390 train_time:114476ms step_avg:140.12ms
step:828/1390 train_time:114623ms step_avg:140.13ms
step:829/1390 train_time:114769ms step_avg:140.13ms
step:830/1390 train_time:114915ms step_avg:140.14ms
step:831/1390 train_time:115061ms step_avg:140.15ms
step:832/1390 train_time:115208ms step_avg:140.16ms
step:833/1390 train_time:115354ms step_avg:140.16ms
step:834/1390 train_time:115502ms step_avg:140.17ms
step:835/1390 train_time:115649ms step_avg:140.18ms
step:836/1390 train_time:115798ms step_avg:140.19ms
step:837/1390 train_time:115946ms step_avg:140.20ms
step:838/1390 train_time:116093ms step_avg:140.21ms
step:839/1390 train_time:116239ms step_avg:140.22ms
step:840/1390 train_time:116385ms step_avg:140.22ms
step:841/1390 train_time:116532ms step_avg:140.23ms
step:842/1390 train_time:116678ms step_avg:140.24ms
step:843/1390 train_time:116825ms step_avg:140.25ms
step:844/1390 train_time:116972ms step_avg:140.25ms
step:845/1390 train_time:117117ms step_avg:140.26ms
step:846/1390 train_time:117265ms step_avg:140.27ms
step:847/1390 train_time:117413ms step_avg:140.28ms
step:848/1390 train_time:117558ms step_avg:140.28ms
step:849/1390 train_time:117705ms step_avg:140.29ms
step:850/1390 train_time:117852ms step_avg:140.30ms
step:851/1390 train_time:117999ms step_avg:140.31ms
step:852/1390 train_time:118146ms step_avg:140.32ms
step:853/1390 train_time:118294ms step_avg:140.32ms
step:854/1390 train_time:118438ms step_avg:140.33ms
step:855/1390 train_time:118584ms step_avg:140.34ms
step:856/1390 train_time:118729ms step_avg:140.34ms
step:857/1390 train_time:118876ms step_avg:140.35ms
step:858/1390 train_time:119025ms step_avg:140.36ms
step:859/1390 train_time:119172ms step_avg:140.37ms
step:860/1390 train_time:119319ms step_avg:140.38ms
step:861/1390 train_time:119464ms step_avg:140.38ms
step:862/1390 train_time:119612ms step_avg:140.39ms
step:863/1390 train_time:119761ms step_avg:140.40ms
step:864/1390 train_time:119908ms step_avg:140.41ms
step:865/1390 train_time:120053ms step_avg:140.41ms
step:866/1390 train_time:120204ms step_avg:140.43ms
step:867/1390 train_time:120353ms step_avg:140.44ms
step:868/1390 train_time:120499ms step_avg:140.44ms
step:869/1390 train_time:120645ms step_avg:140.45ms
step:870/1390 train_time:120794ms step_avg:140.46ms
step:871/1390 train_time:120941ms step_avg:140.47ms
step:872/1390 train_time:121086ms step_avg:140.47ms
step:873/1390 train_time:121232ms step_avg:140.48ms
step:874/1390 train_time:121377ms step_avg:140.48ms
step:875/1390 train_time:121526ms step_avg:140.49ms
step:875/1390 val_loss:3.7637 train_time:121640ms step_avg:140.62ms
step:876/1390 train_time:121676ms step_avg:140.50ms
step:877/1390 train_time:121825ms step_avg:140.51ms
step:878/1390 train_time:121971ms step_avg:140.52ms
step:879/1390 train_time:122118ms step_avg:140.53ms
step:880/1390 train_time:122264ms step_avg:140.53ms
step:881/1390 train_time:122410ms step_avg:140.54ms
step:882/1390 train_time:122558ms step_avg:140.55ms
step:883/1390 train_time:122703ms step_avg:140.55ms
step:884/1390 train_time:122850ms step_avg:140.56ms
step:885/1390 train_time:122997ms step_avg:140.57ms
step:886/1390 train_time:123144ms step_avg:140.58ms
step:887/1390 train_time:123293ms step_avg:140.58ms
step:888/1390 train_time:123439ms step_avg:140.59ms
step:889/1390 train_time:123589ms step_avg:140.60ms
step:890/1390 train_time:123733ms step_avg:140.61ms
step:891/1390 train_time:123879ms step_avg:140.61ms
step:892/1390 train_time:124025ms step_avg:140.62ms
step:893/1390 train_time:124171ms step_avg:140.62ms
step:894/1390 train_time:124324ms step_avg:140.64ms
step:895/1390 train_time:124465ms step_avg:140.64ms
step:896/1390 train_time:124612ms step_avg:140.65ms
step:897/1390 train_time:124758ms step_avg:140.65ms
step:898/1390 train_time:124906ms step_avg:140.66ms
step:899/1390 train_time:125056ms step_avg:140.67ms
step:900/1390 train_time:125203ms step_avg:140.68ms
step:901/1390 train_time:125350ms step_avg:140.68ms
step:902/1390 train_time:125494ms step_avg:140.69ms
step:903/1390 train_time:125642ms step_avg:140.70ms
step:904/1390 train_time:125789ms step_avg:140.70ms
step:905/1390 train_time:125935ms step_avg:140.71ms
step:906/1390 train_time:126080ms step_avg:140.71ms
step:907/1390 train_time:126229ms step_avg:140.72ms
step:908/1390 train_time:126375ms step_avg:140.73ms
step:909/1390 train_time:126521ms step_avg:140.74ms
step:910/1390 train_time:126671ms step_avg:140.75ms
step:911/1390 train_time:126818ms step_avg:140.75ms
step:912/1390 train_time:126962ms step_avg:140.76ms
step:913/1390 train_time:127109ms step_avg:140.76ms
step:914/1390 train_time:127257ms step_avg:140.77ms
step:915/1390 train_time:127403ms step_avg:140.78ms
step:916/1390 train_time:127551ms step_avg:140.78ms
step:917/1390 train_time:127699ms step_avg:140.79ms
step:918/1390 train_time:127849ms step_avg:140.80ms
step:919/1390 train_time:127997ms step_avg:140.81ms
step:920/1390 train_time:128145ms step_avg:140.82ms
step:921/1390 train_time:128293ms step_avg:140.83ms
step:922/1390 train_time:128446ms step_avg:140.84ms
step:923/1390 train_time:128587ms step_avg:140.84ms
step:924/1390 train_time:128734ms step_avg:140.85ms
step:925/1390 train_time:128883ms step_avg:140.86ms
step:926/1390 train_time:129028ms step_avg:140.86ms
step:927/1390 train_time:129175ms step_avg:140.87ms
step:928/1390 train_time:129326ms step_avg:140.88ms
step:929/1390 train_time:129472ms step_avg:140.88ms
step:930/1390 train_time:129619ms step_avg:140.89ms
step:931/1390 train_time:129766ms step_avg:140.90ms
step:932/1390 train_time:129914ms step_avg:140.90ms
step:933/1390 train_time:130063ms step_avg:140.91ms
step:934/1390 train_time:130211ms step_avg:140.92ms
step:935/1390 train_time:130362ms step_avg:140.93ms
step:936/1390 train_time:130511ms step_avg:140.94ms
step:937/1390 train_time:130663ms step_avg:140.95ms
step:938/1390 train_time:130814ms step_avg:140.96ms
step:939/1390 train_time:130961ms step_avg:140.97ms
step:940/1390 train_time:131112ms step_avg:140.98ms
step:941/1390 train_time:131258ms step_avg:140.99ms
step:942/1390 train_time:131406ms step_avg:140.99ms
step:943/1390 train_time:131557ms step_avg:141.00ms
step:944/1390 train_time:131708ms step_avg:141.02ms
step:945/1390 train_time:131858ms step_avg:141.02ms
step:946/1390 train_time:132007ms step_avg:141.03ms
step:947/1390 train_time:132158ms step_avg:141.04ms
step:948/1390 train_time:132305ms step_avg:141.05ms
step:949/1390 train_time:132453ms step_avg:141.06ms
step:950/1390 train_time:132601ms step_avg:141.06ms
step:951/1390 train_time:132799ms step_avg:141.13ms
step:952/1390 train_time:132942ms step_avg:141.13ms
step:953/1390 train_time:133092ms step_avg:141.14ms
step:954/1390 train_time:133238ms step_avg:141.14ms
step:955/1390 train_time:133386ms step_avg:141.15ms
step:956/1390 train_time:133537ms step_avg:141.16ms
step:957/1390 train_time:133685ms step_avg:141.17ms
step:958/1390 train_time:133834ms step_avg:141.18ms
step:959/1390 train_time:133983ms step_avg:141.18ms
step:960/1390 train_time:134132ms step_avg:141.19ms
step:961/1390 train_time:134278ms step_avg:141.20ms
step:962/1390 train_time:134427ms step_avg:141.20ms
step:963/1390 train_time:134582ms step_avg:141.22ms
step:964/1390 train_time:134727ms step_avg:141.22ms
step:965/1390 train_time:134876ms step_avg:141.23ms
step:966/1390 train_time:135023ms step_avg:141.24ms
step:967/1390 train_time:135173ms step_avg:141.25ms
step:968/1390 train_time:135319ms step_avg:141.25ms
step:969/1390 train_time:135468ms step_avg:141.26ms
step:970/1390 train_time:135615ms step_avg:141.27ms
step:971/1390 train_time:135763ms step_avg:141.27ms
step:972/1390 train_time:135910ms step_avg:141.28ms
step:973/1390 train_time:136059ms step_avg:141.29ms
step:974/1390 train_time:136208ms step_avg:141.30ms
step:975/1390 train_time:136356ms step_avg:141.30ms
step:976/1390 train_time:136503ms step_avg:141.31ms
step:977/1390 train_time:136651ms step_avg:141.31ms
step:978/1390 train_time:136798ms step_avg:141.32ms
step:979/1390 train_time:136945ms step_avg:141.33ms
step:980/1390 train_time:137092ms step_avg:141.33ms
step:981/1390 train_time:137237ms step_avg:141.34ms
step:982/1390 train_time:137384ms step_avg:141.34ms
step:983/1390 train_time:137532ms step_avg:141.35ms
step:984/1390 train_time:137679ms step_avg:141.35ms
step:985/1390 train_time:137830ms step_avg:141.36ms
step:986/1390 train_time:137982ms step_avg:141.38ms
step:987/1390 train_time:138129ms step_avg:141.38ms
step:988/1390 train_time:138278ms step_avg:141.39ms
step:989/1390 train_time:138427ms step_avg:141.40ms
step:990/1390 train_time:138576ms step_avg:141.40ms
step:991/1390 train_time:138724ms step_avg:141.41ms
step:992/1390 train_time:138876ms step_avg:141.42ms
step:993/1390 train_time:139030ms step_avg:141.43ms
step:994/1390 train_time:139177ms step_avg:141.44ms
step:995/1390 train_time:139328ms step_avg:141.45ms
step:996/1390 train_time:139472ms step_avg:141.45ms
step:997/1390 train_time:139618ms step_avg:141.46ms
step:998/1390 train_time:139766ms step_avg:141.46ms
step:999/1390 train_time:139913ms step_avg:141.47ms
step:1000/1390 train_time:140061ms step_avg:141.48ms
step:1000/1390 val_loss:3.6986 train_time:140175ms step_avg:141.59ms
step:1001/1390 train_time:140211ms step_avg:141.48ms
step:1002/1390 train_time:140361ms step_avg:141.49ms
step:1003/1390 train_time:140510ms step_avg:141.50ms
step:1004/1390 train_time:140658ms step_avg:141.51ms
step:1005/1390 train_time:140807ms step_avg:141.51ms
step:1006/1390 train_time:140954ms step_avg:141.52ms
step:1007/1390 train_time:141100ms step_avg:141.52ms
step:1008/1390 train_time:141249ms step_avg:141.53ms
step:1009/1390 train_time:141401ms step_avg:141.54ms
step:1010/1390 train_time:141549ms step_avg:141.55ms
step:1011/1390 train_time:141700ms step_avg:141.56ms
step:1012/1390 train_time:141847ms step_avg:141.56ms
step:1013/1390 train_time:141996ms step_avg:141.57ms
step:1014/1390 train_time:142144ms step_avg:141.58ms
step:1015/1390 train_time:142290ms step_avg:141.58ms
step:1016/1390 train_time:142438ms step_avg:141.59ms
step:1017/1390 train_time:142587ms step_avg:141.60ms
step:1018/1390 train_time:142739ms step_avg:141.61ms
step:1019/1390 train_time:142886ms step_avg:141.61ms
step:1020/1390 train_time:143035ms step_avg:141.62ms
step:1021/1390 train_time:143182ms step_avg:141.62ms
step:1022/1390 train_time:143329ms step_avg:141.63ms
step:1023/1390 train_time:143478ms step_avg:141.64ms
step:1024/1390 train_time:143630ms step_avg:141.65ms
step:1025/1390 train_time:143779ms step_avg:141.65ms
step:1026/1390 train_time:143927ms step_avg:141.66ms
step:1027/1390 train_time:144076ms step_avg:141.67ms
step:1028/1390 train_time:144226ms step_avg:141.68ms
step:1029/1390 train_time:144378ms step_avg:141.69ms
step:1030/1390 train_time:144529ms step_avg:141.69ms
step:1031/1390 train_time:144673ms step_avg:141.70ms
step:1032/1390 train_time:144819ms step_avg:141.70ms
step:1033/1390 train_time:144967ms step_avg:141.71ms
step:1034/1390 train_time:145117ms step_avg:141.72ms
step:1035/1390 train_time:145267ms step_avg:141.72ms
step:1036/1390 train_time:145417ms step_avg:141.73ms
step:1037/1390 train_time:145569ms step_avg:141.74ms
step:1038/1390 train_time:145720ms step_avg:141.75ms
step:1039/1390 train_time:145867ms step_avg:141.76ms
step:1040/1390 train_time:146015ms step_avg:141.76ms
step:1041/1390 train_time:146165ms step_avg:141.77ms
step:1042/1390 train_time:146313ms step_avg:141.78ms
step:1043/1390 train_time:146463ms step_avg:141.78ms
step:1044/1390 train_time:146616ms step_avg:141.79ms
step:1045/1390 train_time:146767ms step_avg:141.80ms
step:1046/1390 train_time:146916ms step_avg:141.81ms
step:1047/1390 train_time:147065ms step_avg:141.82ms
step:1048/1390 train_time:147212ms step_avg:141.82ms
step:1049/1390 train_time:147361ms step_avg:141.83ms
step:1050/1390 train_time:147510ms step_avg:141.84ms
step:1051/1390 train_time:147663ms step_avg:141.85ms
step:1052/1390 train_time:147810ms step_avg:141.85ms
step:1053/1390 train_time:147958ms step_avg:141.86ms
step:1054/1390 train_time:148106ms step_avg:141.86ms
step:1055/1390 train_time:148257ms step_avg:141.87ms
step:1056/1390 train_time:148401ms step_avg:141.88ms
step:1057/1390 train_time:148550ms step_avg:141.88ms
step:1058/1390 train_time:148700ms step_avg:141.89ms
step:1059/1390 train_time:148850ms step_avg:141.90ms
step:1060/1390 train_time:149009ms step_avg:141.91ms
step:1061/1390 train_time:149150ms step_avg:141.91ms
step:1062/1390 train_time:149301ms step_avg:141.92ms
step:1063/1390 train_time:149448ms step_avg:141.93ms
step:1064/1390 train_time:149598ms step_avg:141.93ms
step:1065/1390 train_time:149748ms step_avg:141.94ms
step:1066/1390 train_time:149900ms step_avg:141.95ms
step:1067/1390 train_time:150051ms step_avg:141.96ms
step:1068/1390 train_time:150198ms step_avg:141.96ms
step:1069/1390 train_time:150354ms step_avg:141.98ms
step:1070/1390 train_time:150499ms step_avg:141.98ms
step:1071/1390 train_time:150651ms step_avg:141.99ms
step:1072/1390 train_time:150799ms step_avg:142.00ms
step:1073/1390 train_time:150948ms step_avg:142.00ms
step:1074/1390 train_time:151095ms step_avg:142.01ms
step:1075/1390 train_time:151247ms step_avg:142.02ms
step:1076/1390 train_time:151395ms step_avg:142.02ms
step:1077/1390 train_time:151545ms step_avg:142.03ms
step:1078/1390 train_time:151693ms step_avg:142.03ms
step:1079/1390 train_time:151852ms step_avg:142.05ms
step:1080/1390 train_time:152000ms step_avg:142.06ms
step:1081/1390 train_time:152151ms step_avg:142.06ms
step:1082/1390 train_time:152296ms step_avg:142.07ms
step:1083/1390 train_time:152446ms step_avg:142.07ms
step:1084/1390 train_time:152598ms step_avg:142.08ms
step:1085/1390 train_time:152749ms step_avg:142.09ms
step:1086/1390 train_time:152896ms step_avg:142.10ms
step:1087/1390 train_time:153046ms step_avg:142.10ms
step:1088/1390 train_time:153195ms step_avg:142.11ms
step:1089/1390 train_time:153350ms step_avg:142.12ms
step:1090/1390 train_time:153507ms step_avg:142.14ms
step:1091/1390 train_time:153652ms step_avg:142.14ms
step:1092/1390 train_time:153800ms step_avg:142.14ms
step:1093/1390 train_time:153949ms step_avg:142.15ms
step:1094/1390 train_time:154097ms step_avg:142.16ms
step:1095/1390 train_time:154246ms step_avg:142.16ms
step:1096/1390 train_time:154397ms step_avg:142.17ms
step:1097/1390 train_time:154552ms step_avg:142.18ms
step:1098/1390 train_time:154698ms step_avg:142.19ms
step:1099/1390 train_time:154848ms step_avg:142.19ms
step:1100/1390 train_time:154997ms step_avg:142.20ms
step:1101/1390 train_time:155146ms step_avg:142.21ms
step:1102/1390 train_time:155296ms step_avg:142.21ms
step:1103/1390 train_time:155445ms step_avg:142.22ms
step:1104/1390 train_time:155599ms step_avg:142.23ms
step:1105/1390 train_time:155755ms step_avg:142.24ms
step:1106/1390 train_time:155899ms step_avg:142.24ms
step:1107/1390 train_time:156048ms step_avg:142.25ms
step:1108/1390 train_time:156204ms step_avg:142.26ms
step:1109/1390 train_time:156355ms step_avg:142.27ms
step:1110/1390 train_time:156502ms step_avg:142.27ms
step:1111/1390 train_time:156651ms step_avg:142.28ms
step:1112/1390 train_time:156799ms step_avg:142.29ms
step:1113/1390 train_time:156947ms step_avg:142.29ms
step:1114/1390 train_time:157098ms step_avg:142.30ms
step:1115/1390 train_time:157249ms step_avg:142.31ms
step:1116/1390 train_time:157397ms step_avg:142.31ms
step:1117/1390 train_time:157547ms step_avg:142.32ms
step:1118/1390 train_time:157702ms step_avg:142.33ms
step:1119/1390 train_time:157850ms step_avg:142.34ms
step:1120/1390 train_time:157998ms step_avg:142.34ms
step:1121/1390 train_time:158148ms step_avg:142.35ms
step:1122/1390 train_time:158297ms step_avg:142.35ms
step:1123/1390 train_time:158443ms step_avg:142.36ms
step:1124/1390 train_time:158594ms step_avg:142.36ms
step:1125/1390 train_time:158740ms step_avg:142.37ms
step:1125/1390 val_loss:3.6484 train_time:158860ms step_avg:142.48ms
step:1126/1390 train_time:158897ms step_avg:142.38ms
step:1127/1390 train_time:159047ms step_avg:142.39ms
step:1128/1390 train_time:159196ms step_avg:142.39ms
step:1129/1390 train_time:159348ms step_avg:142.40ms
step:1130/1390 train_time:159496ms step_avg:142.41ms
step:1131/1390 train_time:159648ms step_avg:142.42ms
step:1132/1390 train_time:159797ms step_avg:142.42ms
step:1133/1390 train_time:159945ms step_avg:142.43ms
step:1134/1390 train_time:160096ms step_avg:142.43ms
step:1135/1390 train_time:160247ms step_avg:142.44ms
step:1136/1390 train_time:160405ms step_avg:142.46ms
step:1137/1390 train_time:160555ms step_avg:142.46ms
step:1138/1390 train_time:160712ms step_avg:142.48ms
step:1139/1390 train_time:160857ms step_avg:142.48ms
step:1140/1390 train_time:161008ms step_avg:142.49ms
step:1141/1390 train_time:161211ms step_avg:142.54ms
step:1142/1390 train_time:161360ms step_avg:142.54ms
step:1143/1390 train_time:161514ms step_avg:142.55ms
step:1144/1390 train_time:161662ms step_avg:142.56ms
step:1145/1390 train_time:161811ms step_avg:142.56ms
step:1146/1390 train_time:161960ms step_avg:142.57ms
step:1147/1390 train_time:162113ms step_avg:142.58ms
step:1148/1390 train_time:162263ms step_avg:142.59ms
step:1149/1390 train_time:162413ms step_avg:142.59ms
step:1150/1390 train_time:162563ms step_avg:142.60ms
step:1151/1390 train_time:162717ms step_avg:142.61ms
step:1152/1390 train_time:162865ms step_avg:142.61ms
step:1153/1390 train_time:163019ms step_avg:142.62ms
step:1154/1390 train_time:163168ms step_avg:142.63ms
step:1155/1390 train_time:163318ms step_avg:142.64ms
step:1156/1390 train_time:163477ms step_avg:142.65ms
step:1157/1390 train_time:163628ms step_avg:142.66ms
step:1158/1390 train_time:163776ms step_avg:142.66ms
step:1159/1390 train_time:163925ms step_avg:142.67ms
step:1160/1390 train_time:164077ms step_avg:142.68ms
step:1161/1390 train_time:164226ms step_avg:142.68ms
step:1162/1390 train_time:164377ms step_avg:142.69ms
step:1163/1390 train_time:164524ms step_avg:142.69ms
step:1164/1390 train_time:164675ms step_avg:142.70ms
step:1165/1390 train_time:164823ms step_avg:142.70ms
step:1166/1390 train_time:164973ms step_avg:142.71ms
step:1167/1390 train_time:165122ms step_avg:142.72ms
step:1168/1390 train_time:165273ms step_avg:142.72ms
step:1169/1390 train_time:165422ms step_avg:142.73ms
step:1170/1390 train_time:165572ms step_avg:142.73ms
step:1171/1390 train_time:165723ms step_avg:142.74ms
step:1172/1390 train_time:165874ms step_avg:142.75ms
step:1173/1390 train_time:166024ms step_avg:142.75ms
step:1174/1390 train_time:166184ms step_avg:142.77ms
step:1175/1390 train_time:166335ms step_avg:142.78ms
step:1176/1390 train_time:166487ms step_avg:142.78ms
step:1177/1390 train_time:166645ms step_avg:142.80ms
step:1178/1390 train_time:166794ms step_avg:142.80ms
step:1179/1390 train_time:166942ms step_avg:142.81ms
step:1180/1390 train_time:167097ms step_avg:142.82ms
step:1181/1390 train_time:167249ms step_avg:142.83ms
step:1182/1390 train_time:167398ms step_avg:142.83ms
step:1183/1390 train_time:167551ms step_avg:142.84ms
step:1184/1390 train_time:167701ms step_avg:142.85ms
step:1185/1390 train_time:167853ms step_avg:142.85ms
step:1186/1390 train_time:168002ms step_avg:142.86ms
step:1187/1390 train_time:168164ms step_avg:142.88ms
step:1188/1390 train_time:168314ms step_avg:142.88ms
step:1189/1390 train_time:168467ms step_avg:142.89ms
step:1190/1390 train_time:168618ms step_avg:142.90ms
step:1191/1390 train_time:168768ms step_avg:142.90ms
step:1192/1390 train_time:168917ms step_avg:142.91ms
step:1193/1390 train_time:169066ms step_avg:142.91ms
step:1194/1390 train_time:169217ms step_avg:142.92ms
step:1195/1390 train_time:169368ms step_avg:142.93ms
step:1196/1390 train_time:169518ms step_avg:142.93ms
step:1197/1390 train_time:169669ms step_avg:142.94ms
step:1198/1390 train_time:169826ms step_avg:142.95ms
step:1199/1390 train_time:169976ms step_avg:142.96ms
step:1200/1390 train_time:170126ms step_avg:142.96ms
step:1201/1390 train_time:170274ms step_avg:142.97ms
step:1202/1390 train_time:170434ms step_avg:142.98ms
step:1203/1390 train_time:170593ms step_avg:143.00ms
step:1204/1390 train_time:170747ms step_avg:143.00ms
step:1205/1390 train_time:170900ms step_avg:143.01ms
step:1206/1390 train_time:171055ms step_avg:143.02ms
step:1207/1390 train_time:171204ms step_avg:143.03ms
step:1208/1390 train_time:171361ms step_avg:143.04ms
step:1209/1390 train_time:171510ms step_avg:143.04ms
step:1210/1390 train_time:171667ms step_avg:143.06ms
step:1211/1390 train_time:171817ms step_avg:143.06ms
step:1212/1390 train_time:171966ms step_avg:143.07ms
step:1213/1390 train_time:172115ms step_avg:143.07ms
step:1214/1390 train_time:172265ms step_avg:143.08ms
step:1215/1390 train_time:172422ms step_avg:143.09ms
step:1216/1390 train_time:172568ms step_avg:143.09ms
step:1217/1390 train_time:172723ms step_avg:143.10ms
step:1218/1390 train_time:172870ms step_avg:143.10ms
step:1219/1390 train_time:173016ms step_avg:143.11ms
step:1220/1390 train_time:173165ms step_avg:143.11ms
step:1221/1390 train_time:173315ms step_avg:143.12ms
step:1222/1390 train_time:173464ms step_avg:143.12ms
step:1223/1390 train_time:173614ms step_avg:143.13ms
step:1224/1390 train_time:173766ms step_avg:143.14ms
step:1225/1390 train_time:173922ms step_avg:143.15ms
step:1226/1390 train_time:174073ms step_avg:143.15ms
step:1227/1390 train_time:174222ms step_avg:143.16ms
step:1228/1390 train_time:174374ms step_avg:143.16ms
step:1229/1390 train_time:174522ms step_avg:143.17ms
step:1230/1390 train_time:174676ms step_avg:143.18ms
step:1231/1390 train_time:174827ms step_avg:143.18ms
step:1232/1390 train_time:174980ms step_avg:143.19ms
step:1233/1390 train_time:175131ms step_avg:143.20ms
step:1234/1390 train_time:175283ms step_avg:143.21ms
step:1235/1390 train_time:175430ms step_avg:143.21ms
step:1236/1390 train_time:175582ms step_avg:143.21ms
step:1237/1390 train_time:175732ms step_avg:143.22ms
step:1238/1390 train_time:175893ms step_avg:143.24ms
step:1239/1390 train_time:176043ms step_avg:143.24ms
step:1240/1390 train_time:176196ms step_avg:143.25ms
step:1241/1390 train_time:176353ms step_avg:143.26ms
step:1242/1390 train_time:176501ms step_avg:143.26ms
step:1243/1390 train_time:176655ms step_avg:143.27ms
step:1244/1390 train_time:176805ms step_avg:143.28ms
step:1245/1390 train_time:176958ms step_avg:143.29ms
step:1246/1390 train_time:177106ms step_avg:143.29ms
step:1247/1390 train_time:177260ms step_avg:143.30ms
step:1248/1390 train_time:177411ms step_avg:143.30ms
step:1249/1390 train_time:177561ms step_avg:143.31ms
step:1250/1390 train_time:177708ms step_avg:143.31ms
step:1250/1390 val_loss:3.6039 train_time:177829ms step_avg:143.41ms
step:1251/1390 train_time:177864ms step_avg:143.32ms
step:1252/1390 train_time:178019ms step_avg:143.33ms
step:1253/1390 train_time:178167ms step_avg:143.34ms
step:1254/1390 train_time:178315ms step_avg:143.34ms
step:1255/1390 train_time:178480ms step_avg:143.36ms
step:1256/1390 train_time:178639ms step_avg:143.37ms
step:1257/1390 train_time:178788ms step_avg:143.37ms
step:1258/1390 train_time:178933ms step_avg:143.38ms
step:1259/1390 train_time:179089ms step_avg:143.39ms
step:1260/1390 train_time:179237ms step_avg:143.39ms
step:1261/1390 train_time:179387ms step_avg:143.40ms
step:1262/1390 train_time:179541ms step_avg:143.40ms
step:1263/1390 train_time:179695ms step_avg:143.41ms
step:1264/1390 train_time:179846ms step_avg:143.42ms
step:1265/1390 train_time:179996ms step_avg:143.42ms
step:1266/1390 train_time:180148ms step_avg:143.43ms
step:1267/1390 train_time:180299ms step_avg:143.44ms
step:1268/1390 train_time:180451ms step_avg:143.44ms
step:1269/1390 train_time:180604ms step_avg:143.45ms
step:1270/1390 train_time:180756ms step_avg:143.46ms
step:1271/1390 train_time:180906ms step_avg:143.46ms
step:1272/1390 train_time:181055ms step_avg:143.47ms
step:1273/1390 train_time:181205ms step_avg:143.47ms
step:1274/1390 train_time:181357ms step_avg:143.48ms
step:1275/1390 train_time:181513ms step_avg:143.49ms
step:1276/1390 train_time:181664ms step_avg:143.49ms
step:1277/1390 train_time:181809ms step_avg:143.50ms
step:1278/1390 train_time:181960ms step_avg:143.50ms
step:1279/1390 train_time:182111ms step_avg:143.51ms
step:1280/1390 train_time:182271ms step_avg:143.52ms
step:1281/1390 train_time:182423ms step_avg:143.53ms
step:1282/1390 train_time:182571ms step_avg:143.53ms
step:1283/1390 train_time:182728ms step_avg:143.54ms
step:1284/1390 train_time:182875ms step_avg:143.54ms
step:1285/1390 train_time:183024ms step_avg:143.55ms
step:1286/1390 train_time:183177ms step_avg:143.56ms
step:1287/1390 train_time:183329ms step_avg:143.56ms
step:1288/1390 train_time:183479ms step_avg:143.57ms
step:1289/1390 train_time:183637ms step_avg:143.58ms
step:1290/1390 train_time:183791ms step_avg:143.59ms
step:1291/1390 train_time:183946ms step_avg:143.60ms
step:1292/1390 train_time:184097ms step_avg:143.60ms
step:1293/1390 train_time:184255ms step_avg:143.61ms
step:1294/1390 train_time:184406ms step_avg:143.62ms
step:1295/1390 train_time:184555ms step_avg:143.62ms
step:1296/1390 train_time:184713ms step_avg:143.63ms
step:1297/1390 train_time:184862ms step_avg:143.64ms
step:1298/1390 train_time:185011ms step_avg:143.64ms
step:1299/1390 train_time:185166ms step_avg:143.65ms
step:1300/1390 train_time:185314ms step_avg:143.65ms
step:1301/1390 train_time:185464ms step_avg:143.66ms
step:1302/1390 train_time:185615ms step_avg:143.66ms
step:1303/1390 train_time:185769ms step_avg:143.67ms
step:1304/1390 train_time:185921ms step_avg:143.68ms
step:1305/1390 train_time:186073ms step_avg:143.69ms
step:1306/1390 train_time:186224ms step_avg:143.69ms
step:1307/1390 train_time:186377ms step_avg:143.70ms
step:1308/1390 train_time:186531ms step_avg:143.71ms
step:1309/1390 train_time:186682ms step_avg:143.71ms
step:1310/1390 train_time:186833ms step_avg:143.72ms
step:1311/1390 train_time:186990ms step_avg:143.73ms
step:1312/1390 train_time:187132ms step_avg:143.73ms
step:1313/1390 train_time:187285ms step_avg:143.73ms
step:1314/1390 train_time:187434ms step_avg:143.74ms
step:1315/1390 train_time:187587ms step_avg:143.74ms
step:1316/1390 train_time:187736ms step_avg:143.75ms
step:1317/1390 train_time:187888ms step_avg:143.76ms
step:1318/1390 train_time:188042ms step_avg:143.76ms
step:1319/1390 train_time:188196ms step_avg:143.77ms
step:1320/1390 train_time:188348ms step_avg:143.78ms
step:1321/1390 train_time:188498ms step_avg:143.78ms
step:1322/1390 train_time:188655ms step_avg:143.79ms
step:1323/1390 train_time:188808ms step_avg:143.80ms
step:1324/1390 train_time:188956ms step_avg:143.80ms
step:1325/1390 train_time:189110ms step_avg:143.81ms
step:1326/1390 train_time:189268ms step_avg:143.82ms
step:1327/1390 train_time:189414ms step_avg:143.82ms
step:1328/1390 train_time:189562ms step_avg:143.83ms
step:1329/1390 train_time:189726ms step_avg:143.84ms
step:1330/1390 train_time:189879ms step_avg:143.85ms
step:1331/1390 train_time:190088ms step_avg:143.90ms
step:1332/1390 train_time:190243ms step_avg:143.91ms
step:1333/1390 train_time:190397ms step_avg:143.91ms
step:1334/1390 train_time:190548ms step_avg:143.92ms
step:1335/1390 train_time:190697ms step_avg:143.92ms
step:1336/1390 train_time:190856ms step_avg:143.93ms
step:1337/1390 train_time:191007ms step_avg:143.94ms
step:1338/1390 train_time:191158ms step_avg:143.94ms
step:1339/1390 train_time:191310ms step_avg:143.95ms
step:1340/1390 train_time:191467ms step_avg:143.96ms
step:1341/1390 train_time:191619ms step_avg:143.97ms
step:1342/1390 train_time:191770ms step_avg:143.97ms
step:1343/1390 train_time:191922ms step_avg:143.98ms
step:1344/1390 train_time:192073ms step_avg:143.98ms
step:1345/1390 train_time:192225ms step_avg:143.99ms
step:1346/1390 train_time:192375ms step_avg:143.99ms
step:1347/1390 train_time:192534ms step_avg:144.00ms
step:1348/1390 train_time:192680ms step_avg:144.01ms
step:1349/1390 train_time:192833ms step_avg:144.01ms
step:1350/1390 train_time:192981ms step_avg:144.02ms
step:1351/1390 train_time:193133ms step_avg:144.02ms
step:1352/1390 train_time:193294ms step_avg:144.03ms
step:1353/1390 train_time:193446ms step_avg:144.04ms
step:1354/1390 train_time:193600ms step_avg:144.05ms
step:1355/1390 train_time:193750ms step_avg:144.05ms
step:1356/1390 train_time:193899ms step_avg:144.06ms
step:1357/1390 train_time:194052ms step_avg:144.06ms
step:1358/1390 train_time:194204ms step_avg:144.07ms
step:1359/1390 train_time:194354ms step_avg:144.07ms
step:1360/1390 train_time:194508ms step_avg:144.08ms
step:1361/1390 train_time:194659ms step_avg:144.09ms
step:1362/1390 train_time:194817ms step_avg:144.10ms
step:1363/1390 train_time:194973ms step_avg:144.10ms
step:1364/1390 train_time:195127ms step_avg:144.11ms
step:1365/1390 train_time:195276ms step_avg:144.11ms
step:1366/1390 train_time:195428ms step_avg:144.12ms
step:1367/1390 train_time:195582ms step_avg:144.13ms
step:1368/1390 train_time:195735ms step_avg:144.13ms
step:1369/1390 train_time:195893ms step_avg:144.14ms
step:1370/1390 train_time:196055ms step_avg:144.16ms
step:1371/1390 train_time:196209ms step_avg:144.17ms
step:1372/1390 train_time:196367ms step_avg:144.18ms
step:1373/1390 train_time:196518ms step_avg:144.18ms
step:1374/1390 train_time:196676ms step_avg:144.19ms
step:1375/1390 train_time:196824ms step_avg:144.19ms
step:1375/1390 val_loss:3.5778 train_time:196943ms step_avg:144.28ms
step:1376/1390 train_time:196977ms step_avg:144.20ms
step:1377/1390 train_time:197128ms step_avg:144.20ms
step:1378/1390 train_time:197281ms step_avg:144.21ms
step:1379/1390 train_time:197429ms step_avg:144.21ms
step:1380/1390 train_time:197582ms step_avg:144.22ms
step:1381/1390 train_time:197738ms step_avg:144.23ms
step:1382/1390 train_time:197890ms step_avg:144.23ms
step:1383/1390 train_time:198042ms step_avg:144.24ms
step:1384/1390 train_time:198200ms step_avg:144.25ms
step:1385/1390 train_time:198352ms step_avg:144.26ms
step:1386/1390 train_time:198500ms step_avg:144.26ms
step:1387/1390 train_time:198654ms step_avg:144.27ms
step:1388/1390 train_time:198803ms step_avg:144.27ms
step:1389/1390 train_time:198954ms step_avg:144.27ms
step:1390/1390 train_time:199106ms step_avg:144.28ms
step:1390/1390 val_loss:3.5771 train_time:199225ms step_avg:144.37ms
peak memory consumption: 31537 MiB
