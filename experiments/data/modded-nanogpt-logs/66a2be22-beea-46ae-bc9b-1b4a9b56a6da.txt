import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import glob
import subprocess
import contextlib
from dataclasses import dataclass

import torch
torch.empty(1, device='cuda', requires_grad=True).backward()
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G, steps):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    # Convert to bfloat16 earlier and include the gradient tensor
    X = G.bfloat16()
    if G.size(0) > G.size(1):
        X = X.T

    # Ensure spectral norm is at most 1 (also in bfloat16)
    X = X / (X.norm().bfloat16() + 1e-7)
    # Perform the NS iterations
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A
        X = a * X + B @ X
    
    if G.size(0) > G.size(1):
        X = X.T
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5):
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.rank = int(os.environ['RANK'])
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        assert all(isinstance(p, torch.Tensor) for p in params)
        sizes = {p.numel() for p in params}
        param_groups = [dict(params=[p for p in params if p.numel() == size],
                             update_buffer=[torch.empty(size, device='cuda', dtype=torch.bfloat16) for _ in range(self.world_size)])
                        for size in sizes]
        super().__init__(param_groups, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            nesterov = group['nesterov']
            ns_steps = group['ns_steps']
            update_buffers = group['update_buffer']
            # generate weight updates in distributed fashion
            params = group['params']
            handle = None
            params_world = None
            def update_prev():
                if params_world is None:
                    return
                assert handle is not None
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffers):
                    p_world.data.add_(
                        g_world.view_as(p_world),
                        alpha=-lr * max(1, p_world.size(0) / p_world.size(1)) ** 0.5,
                    )
            for base_i in range(len(params))[::self.world_size]:
                if base_i + rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.lerp_(g, 1 - momentum)
                    g = g.lerp_(buf, momentum) if nesterov else buf
                    g = zeropower_via_newtonschulz5(g, steps=ns_steps).flatten()
                else:
                    g = update_buffers[rank]
                update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather(update_buffers, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

def norm(x):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):

    def __init__(self, in_features, out_features):
        super().__init__(in_features, out_features, bias=False)

    def forward(self, x):
        return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):

    def __init__(self, dim, max_seq_len=65536):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum('i,j -> ij', t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x):
        cos, sin = self.cos[None, :x.size(-3), None, :], self.sin[None, :x.size(-3), None, :]
        x1, x2 = x.float().chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, dim, num_heads):
        super().__init__()
        assert dim % num_heads == 0
        self.num_heads = num_heads
        self.c_q = CastedLinear(dim, dim)
        self.c_k = CastedLinear(dim, dim)
        self.c_v = CastedLinear(dim, dim)
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(dim // num_heads) # dim // num_heads = head_dim
        self.c_proj = CastedLinear(dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x, ve, block_mask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, 'Must use batch size = 1 for FlexAttention'
        q = self.c_q(x).view(B, T, self.num_heads, -1)
        k = self.c_k(x).view(B, T, self.num_heads, -1)
        v = self.c_v(x).view(B, T, self.num_heads, -1)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, dim):
        super().__init__()
        self.c_fc = CastedLinear(dim, 4 * dim)
        self.c_proj = CastedLinear(4 * dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, model_dim, num_heads, use_attn=True):
        super().__init__()
        self.attn = CausalSelfAttention(model_dim, num_heads) if use_attn else None
        self.mlp = MLP(model_dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, ve, x0, block_mask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

class ValueEmbedding(nn.Module):
    def __init__(self, vocab_size, model_dim):
        super().__init__()
        self.embed = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])

    def forward(self, inputs):
        ve = [emb(inputs).bfloat16() for emb in self.embed]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2], None, None, None, None, None, None, ve[0], ve[1], ve[2]]
        return ve

# -----------------------------------------------------------------------------
# The main GPT-2 model

class GPT(nn.Module):

    def __init__(self, vocab_size, num_layers, num_heads, model_dim):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, use_attn=(i != 7))
                                     for i in range(num_layers)])
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual learning
        # U-net structure on token value embeddings by @leloykun
        self.value_embeds = ValueEmbedding(vocab_size, model_dim)
        self.lm_head = CastedLinear(model_dim, vocab_size)
        self.lm_head.weight.data.zero_() # @Grad62304977
        # U-net design by @brendanh0gan
        self.num_encoder_layers = num_layers // 2 # Half of the layers for encoder
        self.num_decoder_layers = num_layers - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

    def forward(self, inputs, targets, sliding_window_num_blocks):
        BLOCK_SIZE = 128
        seq_len = len(inputs)
        assert seq_len % BLOCK_SIZE == 0
        total_num_blocks = seq_len // BLOCK_SIZE
        assert inputs.ndim == 1
        docs = (inputs == 50256).cumsum(0)
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_mask):
            num_blocks = dense_mask.sum(dim=-1, dtype=torch.int32)
            indices = dense_mask.argsort(dim=-1, descending=True, stable=True).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        def create_doc_swc_block_mask(sliding_window_num_blocks):
            kv_idx = block_idx = torch.arange(total_num_blocks, dtype=torch.int32, device='cuda')
            q_idx = block_idx[:, None]
            causal_bm = q_idx >= kv_idx
            causal_full_bm = q_idx > kv_idx
            window_bm = q_idx - kv_idx < sliding_window_num_blocks
            window_full_bm = window_bm # block-wise sliding window by @YouJiacheng
            # document_bm = (docs_low[q_idx] <= docs_high[kv_idx]) & (docs_low[kv_idx] <= docs_high[q_idx])
            document_bm = (docs_low[:, None] <= docs_high) & (docs_low <= docs_high[:, None])
            document_full_bm = (docs_low[:, None] == docs_high) & (docs_low == docs_high[:, None])
            nonzero_bm = causal_bm & window_bm & document_bm
            full_bm  = causal_full_bm & window_full_bm & document_full_bm
            kv_num_blocks, kv_indices = dense_to_ordered(nonzero_bm & ~full_bm)
            full_kv_num_blocks, full_kv_indices = dense_to_ordered(full_bm)
            return BlockMask.from_kv_blocks(
                kv_num_blocks,
                kv_indices,
                full_kv_num_blocks,
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )

        block_mask = create_doc_swc_block_mask(sliding_window_num_blocks)

        x0 = norm(self.embed(inputs[None]).bfloat16()) # use of norm here by @Grad62304977
        x = x0
        ve = self.value_embeds(inputs)
        assert len(ve) == len(self.blocks)
        ve_enc, ve_dec = ve[:self.num_encoder_layers], ve[self.num_encoder_layers:]

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        for i in range(self.num_encoder_layers):
            x = self.blocks[i](x, ve_enc[i], x0, block_mask)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        for i in range(self.num_decoder_layers):
            x = x + self.skip_weights[i] * skip_connections.pop()
            # U-net structure on token value embeddings by @leloykun
            x = self.blocks[self.num_encoder_layers + i](x, ve_dec[i], x0, block_mask)

        x = norm(x)
        logits = self.lm_head(x)
        logits = 15 * torch.tanh(logits / 15) # @Grad62304977 added tanh softcapping, @KoszarskyB reduced it from 30 to 15
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets)
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(path):
    # only reads the header, returns header data
    # header is 256 int32
    header = torch.from_file(path, False, 256, dtype=torch.int32)
    assert header[0] == 20240520, 'magic number mismatch in the data .bin file'
    assert header[1] == 1, 'unsupported version'
    num_tokens = int(header[2]) # number of tokens (claimed)
    with open(path, 'rb', buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, 'number of tokens read does not match header'
    return tokens

class DistributedDataLoader:

    def __init__(self, filename_pattern):
        self.rank = int(os.environ['RANK'])
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.files = sorted(glob.glob(filename_pattern))
        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self):
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = 0
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self, batch_size):
        assert batch_size % self.world_size == 0
        device_batch_size = batch_size // self.world_size
        # load next shard if necessary
        if self.current_position + batch_size + 1 >= len(self.tokens):
            self.advance()
        pos = self.current_position + self.rank * device_batch_size
        device_batch_tokens = self.tokens[pos:pos+device_batch_size+1]
        # advance current position
        self.current_position += batch_size
        inputs = device_batch_tokens[:-1].to(device='cuda', dtype=torch.int32, non_blocking=True)
        targets = device_batch_tokens[1:].to(device='cuda', dtype=torch.int64, non_blocking=True)
        return inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    val_files = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # optimization
    batch_size = 8*64*1024 # batch size in tokens
    num_iterations = 1390 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    bf16_embeds = True
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    # implementation
    max_device_batch_size = 64*1024 # batch size per device in tokens
    save_checkpoint = False
args = Hyperparameters()

micro_bs = args.max_device_batch_size

# set up DDP (distributed data parallel). torchrun sets this env variable
rank = int(os.environ['RANK'])
local_rank = int(os.environ['LOCAL_RANK'])
world_size = int(os.environ['WORLD_SIZE'])
assert torch.cuda.is_available()
torch.cuda.set_device(local_rank)
dist.init_process_group(backend='nccl', device_id=torch.device(local_rank))
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs('logs', exist_ok=True)
    logfile = f'logs/{run_id}.txt'
    print(logfile)

def print0(s, console=False):
    if master_process:
        with open(logfile, 'a') as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0('='*100)
# log information about the hardware/software environment this is running on
print0(f'Running Python {sys.version}')
print0(f'Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}')
print0(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout)
print0('='*100)

# load data
train_loader = DistributedDataLoader(args.train_files)
val_loader = DistributedDataLoader(args.val_files)
print0(f'Training dataloader files: {train_loader.files}')
print0(f'Validation dataloader files: {val_loader.files}')
print0('='*100)

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
model = GPT(vocab_size=50304, num_layers=12, num_heads=6, model_dim=768)
model = model.cuda()
if args.bf16_embeds:
    for m in model.modules():
        if isinstance(m, nn.Embedding):
            m.bfloat16()
model = torch.compile(model)
ddp_model = DDP(model, device_ids=[local_rank], broadcast_buffers=False, gradient_as_bucket_view=True)

# collect the parameters to optimize
hidden_matrix_params = [p for p in model.blocks.parameters() if p.ndim == 2]
embed_params = [model.embed.weight, *model.value_embeds.parameters()]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
optimizer1 = torch.optim.Adam([dict(params=embed_params, lr=0.6),
                               dict(params=head_params, lr=0.008),
                               dict(params=scalar_params, lr=0.04)],
                              betas=(0.8, 0.95), fused=True)
optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95)
optimizers = [optimizer1, optimizer2]

# learning rate schedule: stable then decay
def get_lr(it):
    t = 1 - it / args.num_iterations # time remaining in training
    assert 1 >= t > 0
    # 1) constant lr for first part of training
    if t >= args.cooldown_frac:
        return 1.0
    # 2) then linear cooldown
    else:
        return t / args.cooldown_frac
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# sliding window size schedule: linear increase over training in chunks of 128 from 128 -> 1792. By @fernbear.bsky.social
def get_sliding_window_blocks(it):
    x = it / args.num_iterations # training progress
    assert 0 <= x <= 1
    return int(((1 - x) * 128 + x * 1856) // 128)
sliding_window_num_blocks = torch.tensor(1, dtype=torch.int32, device='cuda')

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.perf_counter()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    sliding_window_num_blocks.copy_(get_sliding_window_blocks(step))

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        # calculate the number of steps to take in the val loop.
        val_batch_size = world_size * micro_bs
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        for _ in range(val_steps):
            with torch.no_grad():
                inputs_val, targets_val = val_loader.next_batch(val_batch_size)
                val_loss += ddp_model(inputs_val, targets_val, sliding_window_num_blocks)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # logging
        print0(f'step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms', console=True)
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f'logs/{run_id}', exist_ok=True)
            torch.save(log, f'logs/{run_id}/state_step{step:06d}.pt')
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    model.train()
    batch_size = args.batch_size
    assert batch_size % world_size == 0
    inputs_train, targets_train = train_loader.next_batch(batch_size)
    assert len(inputs_train) <= micro_bs or len(inputs_train) % micro_bs == 0
    for micro_inputs_train, micro_targets_train in zip(inputs_train.split(micro_bs), targets_train.split(micro_bs)):
        ddp_model(micro_inputs_train, micro_targets_train, sliding_window_num_blocks).backward()
    # momentum warmup for Muon
    frac = min(step/300, 1)
    for group in optimizer2.param_groups:
        group['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        if step != train_steps-1:
            sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_time = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f'step:{step+1}/{train_steps} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms', console=True)

print0(f'peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB')
dist.destroy_process_group()

====================================================================================================
Running Python 3.12.7 (main, Jan  9 2025, 22:54:50) [GCC 13.2.0]
Running PyTorch 2.6.0.dev20241231+cu126 compiled for CUDA 12.6
Fri Jan 10 00:30:33 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:61:00.0 Off |                    0 |
| N/A   25C    P0            131W /  700W |    7746MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:62:00.0 Off |                    0 |
| N/A   29C    P0            124W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:63:00.0 Off |                    0 |
| N/A   30C    P0            117W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:64:00.0 Off |                    0 |
| N/A   29C    P0            121W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  |   00000000:6A:00.0 Off |                    0 |
| N/A   27C    P0            122W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  |   00000000:6B:00.0 Off |                    0 |
| N/A   29C    P0            118W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  |   00000000:6C:00.0 Off |                    0 |
| N/A   48C    P0            136W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  |   00000000:6D:00.0 Off |                    0 |
| N/A   27C    P0            121W /  700W |    3216MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
Training dataloader files: ['data/fineweb10B/fineweb_train_000001.bin', 'data/fineweb10B/fineweb_train_000002.bin', 'data/fineweb10B/fineweb_train_000003.bin', 'data/fineweb10B/fineweb_train_000004.bin', 'data/fineweb10B/fineweb_train_000005.bin', 'data/fineweb10B/fineweb_train_000006.bin', 'data/fineweb10B/fineweb_train_000007.bin', 'data/fineweb10B/fineweb_train_000008.bin', 'data/fineweb10B/fineweb_train_000009.bin', 'data/fineweb10B/fineweb_train_000010.bin']
Validation dataloader files: ['data/fineweb10B/fineweb_val_000000.bin']
====================================================================================================
step:0/1390 val_loss:10.8258 train_time:0ms step_avg:nanms
step:1/1390 train_time:241476ms step_avg:nanms
step:2/1390 train_time:241563ms step_avg:nanms
step:3/1390 train_time:243013ms step_avg:nanms
step:4/1390 train_time:243143ms step_avg:nanms
step:5/1390 train_time:243278ms step_avg:nanms
step:6/1390 train_time:243410ms step_avg:nanms
step:7/1390 train_time:243542ms step_avg:nanms
step:8/1390 train_time:243675ms step_avg:nanms
step:9/1390 train_time:243808ms step_avg:nanms
step:10/1390 train_time:243947ms step_avg:nanms
step:11/1390 train_time:137ms step_avg:nanms
step:12/1390 train_time:271ms step_avg:nanms
step:13/1390 train_time:406ms step_avg:135.19ms
step:14/1390 train_time:539ms step_avg:134.77ms
step:15/1390 train_time:674ms step_avg:134.75ms
step:16/1390 train_time:807ms step_avg:134.51ms
step:17/1390 train_time:943ms step_avg:134.66ms
step:18/1390 train_time:1078ms step_avg:134.69ms
step:19/1390 train_time:1213ms step_avg:134.80ms
step:20/1390 train_time:1348ms step_avg:134.80ms
step:21/1390 train_time:1482ms step_avg:134.77ms
step:22/1390 train_time:1616ms step_avg:134.68ms
step:23/1390 train_time:1751ms step_avg:134.68ms
step:24/1390 train_time:1886ms step_avg:134.71ms
step:25/1390 train_time:2021ms step_avg:134.73ms
step:26/1390 train_time:2155ms step_avg:134.69ms
step:27/1390 train_time:2289ms step_avg:134.65ms
step:28/1390 train_time:2426ms step_avg:134.76ms
step:29/1390 train_time:2560ms step_avg:134.73ms
step:30/1390 train_time:2695ms step_avg:134.75ms
step:31/1390 train_time:2832ms step_avg:134.85ms
step:32/1390 train_time:2966ms step_avg:134.84ms
step:33/1390 train_time:3101ms step_avg:134.84ms
step:34/1390 train_time:3236ms step_avg:134.82ms
step:35/1390 train_time:3369ms step_avg:134.78ms
step:36/1390 train_time:3504ms step_avg:134.78ms
step:37/1390 train_time:3639ms step_avg:134.77ms
step:38/1390 train_time:3774ms step_avg:134.77ms
step:39/1390 train_time:3910ms step_avg:134.82ms
step:40/1390 train_time:4045ms step_avg:134.84ms
step:41/1390 train_time:4179ms step_avg:134.79ms
step:42/1390 train_time:4312ms step_avg:134.76ms
step:43/1390 train_time:4447ms step_avg:134.75ms
step:44/1390 train_time:4581ms step_avg:134.74ms
step:45/1390 train_time:4716ms step_avg:134.74ms
step:46/1390 train_time:4851ms step_avg:134.74ms
step:47/1390 train_time:4986ms step_avg:134.75ms
step:48/1390 train_time:5122ms step_avg:134.79ms
step:49/1390 train_time:5256ms step_avg:134.78ms
step:50/1390 train_time:5391ms step_avg:134.77ms
step:51/1390 train_time:5526ms step_avg:134.79ms
step:52/1390 train_time:5659ms step_avg:134.75ms
step:53/1390 train_time:5795ms step_avg:134.76ms
step:54/1390 train_time:5930ms step_avg:134.77ms
step:55/1390 train_time:6065ms step_avg:134.78ms
step:56/1390 train_time:6199ms step_avg:134.76ms
step:57/1390 train_time:6333ms step_avg:134.75ms
step:58/1390 train_time:6468ms step_avg:134.75ms
step:59/1390 train_time:6603ms step_avg:134.75ms
step:60/1390 train_time:6737ms step_avg:134.75ms
step:61/1390 train_time:6872ms step_avg:134.75ms
step:62/1390 train_time:7007ms step_avg:134.75ms
step:63/1390 train_time:7142ms step_avg:134.75ms
step:64/1390 train_time:7275ms step_avg:134.73ms
step:65/1390 train_time:7411ms step_avg:134.74ms
step:66/1390 train_time:7546ms step_avg:134.76ms
step:67/1390 train_time:7682ms step_avg:134.77ms
step:68/1390 train_time:7815ms step_avg:134.75ms
step:69/1390 train_time:7951ms step_avg:134.76ms
step:70/1390 train_time:8086ms step_avg:134.76ms
step:71/1390 train_time:8222ms step_avg:134.78ms
step:72/1390 train_time:8356ms step_avg:134.77ms
step:73/1390 train_time:8491ms step_avg:134.78ms
step:74/1390 train_time:8627ms step_avg:134.80ms
step:75/1390 train_time:8761ms step_avg:134.78ms
step:76/1390 train_time:8895ms step_avg:134.77ms
step:77/1390 train_time:9030ms step_avg:134.78ms
step:78/1390 train_time:9165ms step_avg:134.78ms
step:79/1390 train_time:9300ms step_avg:134.79ms
step:80/1390 train_time:9435ms step_avg:134.79ms
step:81/1390 train_time:9570ms step_avg:134.79ms
step:82/1390 train_time:9705ms step_avg:134.79ms
step:83/1390 train_time:9839ms step_avg:134.78ms
step:84/1390 train_time:9975ms step_avg:134.80ms
step:85/1390 train_time:10110ms step_avg:134.80ms
step:86/1390 train_time:10245ms step_avg:134.80ms
step:87/1390 train_time:10379ms step_avg:134.79ms
step:88/1390 train_time:10514ms step_avg:134.80ms
step:89/1390 train_time:10650ms step_avg:134.81ms
step:90/1390 train_time:10784ms step_avg:134.80ms
step:91/1390 train_time:10920ms step_avg:134.81ms
step:92/1390 train_time:11054ms step_avg:134.81ms
step:93/1390 train_time:11189ms step_avg:134.81ms
step:94/1390 train_time:11325ms step_avg:134.82ms
step:95/1390 train_time:11459ms step_avg:134.81ms
step:96/1390 train_time:11593ms step_avg:134.80ms
step:97/1390 train_time:11730ms step_avg:134.83ms
step:98/1390 train_time:11864ms step_avg:134.82ms
step:99/1390 train_time:11998ms step_avg:134.81ms
step:100/1390 train_time:12134ms step_avg:134.82ms
step:101/1390 train_time:12269ms step_avg:134.82ms
step:102/1390 train_time:12405ms step_avg:134.83ms
step:103/1390 train_time:12538ms step_avg:134.82ms
step:104/1390 train_time:12675ms step_avg:134.84ms
step:105/1390 train_time:12814ms step_avg:134.88ms
step:106/1390 train_time:12953ms step_avg:134.93ms
step:107/1390 train_time:13091ms step_avg:134.96ms
step:108/1390 train_time:13230ms step_avg:135.00ms
step:109/1390 train_time:13368ms step_avg:135.03ms
step:110/1390 train_time:13507ms step_avg:135.07ms
step:111/1390 train_time:13645ms step_avg:135.10ms
step:112/1390 train_time:13782ms step_avg:135.12ms
step:113/1390 train_time:13920ms step_avg:135.15ms
step:114/1390 train_time:14059ms step_avg:135.18ms
step:115/1390 train_time:14196ms step_avg:135.20ms
step:116/1390 train_time:14336ms step_avg:135.24ms
step:117/1390 train_time:14474ms step_avg:135.27ms
step:118/1390 train_time:14611ms step_avg:135.28ms
step:119/1390 train_time:14748ms step_avg:135.31ms
step:120/1390 train_time:14887ms step_avg:135.33ms
step:121/1390 train_time:15026ms step_avg:135.37ms
step:122/1390 train_time:15163ms step_avg:135.38ms
step:123/1390 train_time:15301ms step_avg:135.41ms
step:124/1390 train_time:15438ms step_avg:135.42ms
step:125/1390 train_time:15576ms step_avg:135.45ms
step:125/1390 val_loss:4.3813 train_time:15644ms step_avg:136.04ms
step:126/1390 train_time:15722ms step_avg:135.53ms
step:127/1390 train_time:15862ms step_avg:135.57ms
step:128/1390 train_time:16001ms step_avg:135.60ms
step:129/1390 train_time:16138ms step_avg:135.61ms
step:130/1390 train_time:16276ms step_avg:135.63ms
step:131/1390 train_time:16412ms step_avg:135.64ms
step:132/1390 train_time:16549ms step_avg:135.64ms
step:133/1390 train_time:16686ms step_avg:135.66ms
step:134/1390 train_time:16826ms step_avg:135.69ms
step:135/1390 train_time:16967ms step_avg:135.73ms
step:136/1390 train_time:17105ms step_avg:135.76ms
step:137/1390 train_time:17243ms step_avg:135.77ms
step:138/1390 train_time:17380ms step_avg:135.78ms
step:139/1390 train_time:17518ms step_avg:135.80ms
step:140/1390 train_time:17656ms step_avg:135.81ms
step:141/1390 train_time:17794ms step_avg:135.83ms
step:142/1390 train_time:17933ms step_avg:135.86ms
step:143/1390 train_time:18073ms step_avg:135.89ms
step:144/1390 train_time:18211ms step_avg:135.90ms
step:145/1390 train_time:18348ms step_avg:135.91ms
step:146/1390 train_time:18485ms step_avg:135.92ms
step:147/1390 train_time:18623ms step_avg:135.94ms
step:148/1390 train_time:18761ms step_avg:135.95ms
step:149/1390 train_time:18899ms step_avg:135.97ms
step:150/1390 train_time:19037ms step_avg:135.98ms
step:151/1390 train_time:19178ms step_avg:136.01ms
step:152/1390 train_time:19317ms step_avg:136.04ms
step:153/1390 train_time:19455ms step_avg:136.05ms
step:154/1390 train_time:19593ms step_avg:136.06ms
step:155/1390 train_time:19732ms step_avg:136.08ms
step:156/1390 train_time:19870ms step_avg:136.10ms
step:157/1390 train_time:20008ms step_avg:136.11ms
step:158/1390 train_time:20148ms step_avg:136.13ms
step:159/1390 train_time:20286ms step_avg:136.15ms
step:160/1390 train_time:20425ms step_avg:136.17ms
step:161/1390 train_time:20563ms step_avg:136.18ms
step:162/1390 train_time:20702ms step_avg:136.20ms
step:163/1390 train_time:20840ms step_avg:136.21ms
step:164/1390 train_time:20979ms step_avg:136.23ms
step:165/1390 train_time:21118ms step_avg:136.24ms
step:166/1390 train_time:21256ms step_avg:136.26ms
step:167/1390 train_time:21396ms step_avg:136.28ms
step:168/1390 train_time:21534ms step_avg:136.29ms
step:169/1390 train_time:21673ms step_avg:136.31ms
step:170/1390 train_time:21812ms step_avg:136.32ms
step:171/1390 train_time:21950ms step_avg:136.33ms
step:172/1390 train_time:22089ms step_avg:136.35ms
step:173/1390 train_time:22228ms step_avg:136.37ms
step:174/1390 train_time:22368ms step_avg:136.39ms
step:175/1390 train_time:22507ms step_avg:136.41ms
step:176/1390 train_time:22645ms step_avg:136.42ms
step:177/1390 train_time:22783ms step_avg:136.43ms
step:178/1390 train_time:22922ms step_avg:136.44ms
step:179/1390 train_time:23061ms step_avg:136.46ms
step:180/1390 train_time:23199ms step_avg:136.47ms
step:181/1390 train_time:23338ms step_avg:136.48ms
step:182/1390 train_time:23478ms step_avg:136.50ms
step:183/1390 train_time:23617ms step_avg:136.51ms
step:184/1390 train_time:23756ms step_avg:136.53ms
step:185/1390 train_time:23893ms step_avg:136.53ms
step:186/1390 train_time:24032ms step_avg:136.55ms
step:187/1390 train_time:24170ms step_avg:136.55ms
step:188/1390 train_time:24309ms step_avg:136.57ms
step:189/1390 train_time:24448ms step_avg:136.58ms
step:190/1390 train_time:24586ms step_avg:136.59ms
step:191/1390 train_time:24772ms step_avg:136.86ms
step:192/1390 train_time:24909ms step_avg:136.86ms
step:193/1390 train_time:25046ms step_avg:136.86ms
step:194/1390 train_time:25183ms step_avg:136.87ms
step:195/1390 train_time:25321ms step_avg:136.87ms
step:196/1390 train_time:25459ms step_avg:136.88ms
step:197/1390 train_time:25597ms step_avg:136.88ms
step:198/1390 train_time:25739ms step_avg:136.91ms
step:199/1390 train_time:25881ms step_avg:136.93ms
step:200/1390 train_time:26019ms step_avg:136.94ms
step:201/1390 train_time:26158ms step_avg:136.95ms
step:202/1390 train_time:26297ms step_avg:136.96ms
step:203/1390 train_time:26434ms step_avg:136.97ms
step:204/1390 train_time:26573ms step_avg:136.98ms
step:205/1390 train_time:26713ms step_avg:136.99ms
step:206/1390 train_time:26853ms step_avg:137.01ms
step:207/1390 train_time:26993ms step_avg:137.02ms
step:208/1390 train_time:27135ms step_avg:137.04ms
step:209/1390 train_time:27277ms step_avg:137.07ms
step:210/1390 train_time:27418ms step_avg:137.09ms
step:211/1390 train_time:27560ms step_avg:137.11ms
step:212/1390 train_time:27702ms step_avg:137.14ms
step:213/1390 train_time:27843ms step_avg:137.16ms
step:214/1390 train_time:27985ms step_avg:137.18ms
step:215/1390 train_time:28126ms step_avg:137.20ms
step:216/1390 train_time:28267ms step_avg:137.22ms
step:217/1390 train_time:28408ms step_avg:137.23ms
step:218/1390 train_time:28549ms step_avg:137.25ms
step:219/1390 train_time:28690ms step_avg:137.27ms
step:220/1390 train_time:28832ms step_avg:137.30ms
step:221/1390 train_time:28974ms step_avg:137.32ms
step:222/1390 train_time:29116ms step_avg:137.34ms
step:223/1390 train_time:29257ms step_avg:137.36ms
step:224/1390 train_time:29399ms step_avg:137.38ms
step:225/1390 train_time:29540ms step_avg:137.40ms
step:226/1390 train_time:29680ms step_avg:137.41ms
step:227/1390 train_time:29822ms step_avg:137.43ms
step:228/1390 train_time:29962ms step_avg:137.44ms
step:229/1390 train_time:30103ms step_avg:137.46ms
step:230/1390 train_time:30244ms step_avg:137.47ms
step:231/1390 train_time:30385ms step_avg:137.49ms
step:232/1390 train_time:30527ms step_avg:137.51ms
step:233/1390 train_time:30669ms step_avg:137.53ms
step:234/1390 train_time:30810ms step_avg:137.54ms
step:235/1390 train_time:30952ms step_avg:137.56ms
step:236/1390 train_time:31093ms step_avg:137.58ms
step:237/1390 train_time:31234ms step_avg:137.60ms
step:238/1390 train_time:31376ms step_avg:137.62ms
step:239/1390 train_time:31518ms step_avg:137.63ms
step:240/1390 train_time:31659ms step_avg:137.65ms
step:241/1390 train_time:31800ms step_avg:137.66ms
step:242/1390 train_time:31941ms step_avg:137.68ms
step:243/1390 train_time:32082ms step_avg:137.69ms
step:244/1390 train_time:32224ms step_avg:137.71ms
step:245/1390 train_time:32365ms step_avg:137.72ms
step:246/1390 train_time:32506ms step_avg:137.74ms
step:247/1390 train_time:32648ms step_avg:137.76ms
step:248/1390 train_time:32790ms step_avg:137.77ms
step:249/1390 train_time:32932ms step_avg:137.79ms
step:250/1390 train_time:33073ms step_avg:137.81ms
step:250/1390 val_loss:3.9511 train_time:33141ms step_avg:138.09ms
step:251/1390 train_time:33218ms step_avg:137.83ms
step:252/1390 train_time:33360ms step_avg:137.85ms
step:253/1390 train_time:33502ms step_avg:137.87ms
step:254/1390 train_time:33642ms step_avg:137.88ms
step:255/1390 train_time:33783ms step_avg:137.89ms
step:256/1390 train_time:33923ms step_avg:137.90ms
step:257/1390 train_time:34064ms step_avg:137.91ms
step:258/1390 train_time:34206ms step_avg:137.93ms
step:259/1390 train_time:34350ms step_avg:137.95ms
step:260/1390 train_time:34492ms step_avg:137.97ms
step:261/1390 train_time:34633ms step_avg:137.98ms
step:262/1390 train_time:34774ms step_avg:137.99ms
step:263/1390 train_time:34917ms step_avg:138.01ms
step:264/1390 train_time:35058ms step_avg:138.02ms
step:265/1390 train_time:35200ms step_avg:138.04ms
step:266/1390 train_time:35341ms step_avg:138.05ms
step:267/1390 train_time:35482ms step_avg:138.06ms
step:268/1390 train_time:35623ms step_avg:138.07ms
step:269/1390 train_time:35765ms step_avg:138.09ms
step:270/1390 train_time:35905ms step_avg:138.10ms
step:271/1390 train_time:36047ms step_avg:138.11ms
step:272/1390 train_time:36188ms step_avg:138.12ms
step:273/1390 train_time:36329ms step_avg:138.13ms
step:274/1390 train_time:36470ms step_avg:138.14ms
step:275/1390 train_time:36611ms step_avg:138.15ms
step:276/1390 train_time:36752ms step_avg:138.17ms
step:277/1390 train_time:36894ms step_avg:138.18ms
step:278/1390 train_time:37036ms step_avg:138.20ms
step:279/1390 train_time:37178ms step_avg:138.21ms
step:280/1390 train_time:37319ms step_avg:138.22ms
step:281/1390 train_time:37461ms step_avg:138.23ms
step:282/1390 train_time:37604ms step_avg:138.25ms
step:283/1390 train_time:37745ms step_avg:138.26ms
step:284/1390 train_time:37886ms step_avg:138.27ms
step:285/1390 train_time:38028ms step_avg:138.28ms
step:286/1390 train_time:38167ms step_avg:138.29ms
step:287/1390 train_time:38309ms step_avg:138.30ms
step:288/1390 train_time:38450ms step_avg:138.31ms
step:289/1390 train_time:38593ms step_avg:138.33ms
step:290/1390 train_time:38736ms step_avg:138.34ms
step:291/1390 train_time:38877ms step_avg:138.35ms
step:292/1390 train_time:39019ms step_avg:138.37ms
step:293/1390 train_time:39160ms step_avg:138.37ms
step:294/1390 train_time:39302ms step_avg:138.39ms
step:295/1390 train_time:39443ms step_avg:138.40ms
step:296/1390 train_time:39584ms step_avg:138.41ms
step:297/1390 train_time:39725ms step_avg:138.41ms
step:298/1390 train_time:39867ms step_avg:138.43ms
step:299/1390 train_time:40007ms step_avg:138.43ms
step:300/1390 train_time:40150ms step_avg:138.45ms
step:301/1390 train_time:40292ms step_avg:138.46ms
step:302/1390 train_time:40433ms step_avg:138.47ms
step:303/1390 train_time:40574ms step_avg:138.48ms
step:304/1390 train_time:40717ms step_avg:138.49ms
step:305/1390 train_time:40858ms step_avg:138.50ms
step:306/1390 train_time:41001ms step_avg:138.52ms
step:307/1390 train_time:41142ms step_avg:138.52ms
step:308/1390 train_time:41284ms step_avg:138.54ms
step:309/1390 train_time:41425ms step_avg:138.54ms
step:310/1390 train_time:41566ms step_avg:138.55ms
step:311/1390 train_time:41711ms step_avg:138.58ms
step:312/1390 train_time:41854ms step_avg:138.59ms
step:313/1390 train_time:41998ms step_avg:138.61ms
step:314/1390 train_time:42141ms step_avg:138.62ms
step:315/1390 train_time:42282ms step_avg:138.63ms
step:316/1390 train_time:42427ms step_avg:138.65ms
step:317/1390 train_time:42571ms step_avg:138.67ms
step:318/1390 train_time:42715ms step_avg:138.69ms
step:319/1390 train_time:42858ms step_avg:138.70ms
step:320/1390 train_time:43001ms step_avg:138.71ms
step:321/1390 train_time:43145ms step_avg:138.73ms
step:322/1390 train_time:43289ms step_avg:138.75ms
step:323/1390 train_time:43433ms step_avg:138.76ms
step:324/1390 train_time:43577ms step_avg:138.78ms
step:325/1390 train_time:43720ms step_avg:138.79ms
step:326/1390 train_time:43863ms step_avg:138.81ms
step:327/1390 train_time:44006ms step_avg:138.82ms
step:328/1390 train_time:44151ms step_avg:138.84ms
step:329/1390 train_time:44294ms step_avg:138.85ms
step:330/1390 train_time:44437ms step_avg:138.87ms
step:331/1390 train_time:44580ms step_avg:138.88ms
step:332/1390 train_time:44722ms step_avg:138.89ms
step:333/1390 train_time:44866ms step_avg:138.90ms
step:334/1390 train_time:45009ms step_avg:138.92ms
step:335/1390 train_time:45153ms step_avg:138.93ms
step:336/1390 train_time:45297ms step_avg:138.95ms
step:337/1390 train_time:45440ms step_avg:138.96ms
step:338/1390 train_time:45585ms step_avg:138.98ms
step:339/1390 train_time:45729ms step_avg:138.99ms
step:340/1390 train_time:45874ms step_avg:139.01ms
step:341/1390 train_time:46017ms step_avg:139.03ms
step:342/1390 train_time:46161ms step_avg:139.04ms
step:343/1390 train_time:46304ms step_avg:139.05ms
step:344/1390 train_time:46447ms step_avg:139.06ms
step:345/1390 train_time:46592ms step_avg:139.08ms
step:346/1390 train_time:46734ms step_avg:139.09ms
step:347/1390 train_time:46879ms step_avg:139.11ms
step:348/1390 train_time:47021ms step_avg:139.12ms
step:349/1390 train_time:47165ms step_avg:139.13ms
step:350/1390 train_time:47309ms step_avg:139.14ms
step:351/1390 train_time:47454ms step_avg:139.16ms
step:352/1390 train_time:47598ms step_avg:139.17ms
step:353/1390 train_time:47741ms step_avg:139.19ms
step:354/1390 train_time:47883ms step_avg:139.19ms
step:355/1390 train_time:48028ms step_avg:139.21ms
step:356/1390 train_time:48173ms step_avg:139.23ms
step:357/1390 train_time:48318ms step_avg:139.25ms
step:358/1390 train_time:48461ms step_avg:139.26ms
step:359/1390 train_time:48606ms step_avg:139.27ms
step:360/1390 train_time:48751ms step_avg:139.29ms
step:361/1390 train_time:48895ms step_avg:139.30ms
step:362/1390 train_time:49038ms step_avg:139.31ms
step:363/1390 train_time:49181ms step_avg:139.32ms
step:364/1390 train_time:49325ms step_avg:139.34ms
step:365/1390 train_time:49469ms step_avg:139.35ms
step:366/1390 train_time:49613ms step_avg:139.36ms
step:367/1390 train_time:49756ms step_avg:139.37ms
step:368/1390 train_time:49900ms step_avg:139.38ms
step:369/1390 train_time:50042ms step_avg:139.39ms
step:370/1390 train_time:50186ms step_avg:139.41ms
step:371/1390 train_time:50330ms step_avg:139.42ms
step:372/1390 train_time:50475ms step_avg:139.43ms
step:373/1390 train_time:50618ms step_avg:139.44ms
step:374/1390 train_time:50761ms step_avg:139.45ms
step:375/1390 train_time:50903ms step_avg:139.46ms
step:375/1390 val_loss:3.7676 train_time:50974ms step_avg:139.65ms
step:376/1390 train_time:51050ms step_avg:139.48ms
step:377/1390 train_time:51195ms step_avg:139.50ms
step:378/1390 train_time:51338ms step_avg:139.50ms
step:379/1390 train_time:51481ms step_avg:139.51ms
step:380/1390 train_time:51623ms step_avg:139.52ms
step:381/1390 train_time:51808ms step_avg:139.64ms
step:382/1390 train_time:51949ms step_avg:139.65ms
step:383/1390 train_time:52093ms step_avg:139.66ms
step:384/1390 train_time:52236ms step_avg:139.67ms
step:385/1390 train_time:52378ms step_avg:139.67ms
step:386/1390 train_time:52522ms step_avg:139.69ms
step:387/1390 train_time:52665ms step_avg:139.70ms
step:388/1390 train_time:52812ms step_avg:139.71ms
step:389/1390 train_time:52955ms step_avg:139.72ms
step:390/1390 train_time:53099ms step_avg:139.73ms
step:391/1390 train_time:53242ms step_avg:139.74ms
step:392/1390 train_time:53385ms step_avg:139.75ms
step:393/1390 train_time:53527ms step_avg:139.76ms
step:394/1390 train_time:53672ms step_avg:139.77ms
step:395/1390 train_time:53817ms step_avg:139.78ms
step:396/1390 train_time:53961ms step_avg:139.79ms
step:397/1390 train_time:54104ms step_avg:139.80ms
step:398/1390 train_time:54247ms step_avg:139.81ms
step:399/1390 train_time:54389ms step_avg:139.82ms
step:400/1390 train_time:54532ms step_avg:139.83ms
step:401/1390 train_time:54676ms step_avg:139.84ms
step:402/1390 train_time:54821ms step_avg:139.85ms
step:403/1390 train_time:54965ms step_avg:139.86ms
step:404/1390 train_time:55108ms step_avg:139.87ms
step:405/1390 train_time:55252ms step_avg:139.88ms
step:406/1390 train_time:55396ms step_avg:139.89ms
step:407/1390 train_time:55539ms step_avg:139.90ms
step:408/1390 train_time:55681ms step_avg:139.90ms
step:409/1390 train_time:55826ms step_avg:139.91ms
step:410/1390 train_time:55971ms step_avg:139.93ms
step:411/1390 train_time:56114ms step_avg:139.94ms
step:412/1390 train_time:56257ms step_avg:139.94ms
step:413/1390 train_time:56402ms step_avg:139.95ms
step:414/1390 train_time:56546ms step_avg:139.97ms
step:415/1390 train_time:56691ms step_avg:139.98ms
step:416/1390 train_time:56837ms step_avg:139.99ms
step:417/1390 train_time:56984ms step_avg:140.01ms
step:418/1390 train_time:57130ms step_avg:140.02ms
step:419/1390 train_time:57275ms step_avg:140.04ms
step:420/1390 train_time:57422ms step_avg:140.05ms
step:421/1390 train_time:57566ms step_avg:140.06ms
step:422/1390 train_time:57712ms step_avg:140.08ms
step:423/1390 train_time:57858ms step_avg:140.09ms
step:424/1390 train_time:58004ms step_avg:140.11ms
step:425/1390 train_time:58148ms step_avg:140.12ms
step:426/1390 train_time:58295ms step_avg:140.13ms
step:427/1390 train_time:58440ms step_avg:140.14ms
step:428/1390 train_time:58586ms step_avg:140.16ms
step:429/1390 train_time:58732ms step_avg:140.17ms
step:430/1390 train_time:58878ms step_avg:140.19ms
step:431/1390 train_time:59024ms step_avg:140.20ms
step:432/1390 train_time:59169ms step_avg:140.21ms
step:433/1390 train_time:59315ms step_avg:140.23ms
step:434/1390 train_time:59460ms step_avg:140.24ms
step:435/1390 train_time:59606ms step_avg:140.25ms
step:436/1390 train_time:59750ms step_avg:140.26ms
step:437/1390 train_time:59896ms step_avg:140.27ms
step:438/1390 train_time:60041ms step_avg:140.28ms
step:439/1390 train_time:60186ms step_avg:140.29ms
step:440/1390 train_time:60334ms step_avg:140.31ms
step:441/1390 train_time:60480ms step_avg:140.32ms
step:442/1390 train_time:60625ms step_avg:140.34ms
step:443/1390 train_time:60771ms step_avg:140.35ms
step:444/1390 train_time:60918ms step_avg:140.36ms
step:445/1390 train_time:61063ms step_avg:140.37ms
step:446/1390 train_time:61208ms step_avg:140.39ms
step:447/1390 train_time:61352ms step_avg:140.39ms
step:448/1390 train_time:61498ms step_avg:140.41ms
step:449/1390 train_time:61644ms step_avg:140.42ms
step:450/1390 train_time:61787ms step_avg:140.43ms
step:451/1390 train_time:61933ms step_avg:140.44ms
step:452/1390 train_time:62078ms step_avg:140.45ms
step:453/1390 train_time:62224ms step_avg:140.46ms
step:454/1390 train_time:62370ms step_avg:140.47ms
step:455/1390 train_time:62515ms step_avg:140.48ms
step:456/1390 train_time:62660ms step_avg:140.49ms
step:457/1390 train_time:62806ms step_avg:140.51ms
step:458/1390 train_time:62950ms step_avg:140.51ms
step:459/1390 train_time:63097ms step_avg:140.53ms
step:460/1390 train_time:63243ms step_avg:140.54ms
step:461/1390 train_time:63387ms step_avg:140.55ms
step:462/1390 train_time:63533ms step_avg:140.56ms
step:463/1390 train_time:63679ms step_avg:140.57ms
step:464/1390 train_time:63825ms step_avg:140.58ms
step:465/1390 train_time:63969ms step_avg:140.59ms
step:466/1390 train_time:64117ms step_avg:140.61ms
step:467/1390 train_time:64263ms step_avg:140.62ms
step:468/1390 train_time:64407ms step_avg:140.63ms
step:469/1390 train_time:64552ms step_avg:140.64ms
step:470/1390 train_time:64698ms step_avg:140.65ms
step:471/1390 train_time:64843ms step_avg:140.66ms
step:472/1390 train_time:64989ms step_avg:140.67ms
step:473/1390 train_time:65136ms step_avg:140.68ms
step:474/1390 train_time:65282ms step_avg:140.69ms
step:475/1390 train_time:65427ms step_avg:140.70ms
step:476/1390 train_time:65573ms step_avg:140.71ms
step:477/1390 train_time:65718ms step_avg:140.72ms
step:478/1390 train_time:65863ms step_avg:140.73ms
step:479/1390 train_time:66009ms step_avg:140.74ms
step:480/1390 train_time:66154ms step_avg:140.75ms
step:481/1390 train_time:66301ms step_avg:140.77ms
step:482/1390 train_time:66446ms step_avg:140.78ms
step:483/1390 train_time:66593ms step_avg:140.79ms
step:484/1390 train_time:66738ms step_avg:140.80ms
step:485/1390 train_time:66884ms step_avg:140.81ms
step:486/1390 train_time:67028ms step_avg:140.82ms
step:487/1390 train_time:67175ms step_avg:140.83ms
step:488/1390 train_time:67321ms step_avg:140.84ms
step:489/1390 train_time:67465ms step_avg:140.85ms
step:490/1390 train_time:67611ms step_avg:140.86ms
step:491/1390 train_time:67758ms step_avg:140.87ms
step:492/1390 train_time:67903ms step_avg:140.88ms
step:493/1390 train_time:68047ms step_avg:140.88ms
step:494/1390 train_time:68195ms step_avg:140.90ms
step:495/1390 train_time:68341ms step_avg:140.91ms
step:496/1390 train_time:68487ms step_avg:140.92ms
step:497/1390 train_time:68633ms step_avg:140.93ms
step:498/1390 train_time:68779ms step_avg:140.94ms
step:499/1390 train_time:68923ms step_avg:140.95ms
step:500/1390 train_time:69068ms step_avg:140.96ms
step:500/1390 val_loss:3.6520 train_time:69140ms step_avg:141.10ms
step:501/1390 train_time:69216ms step_avg:140.97ms
step:502/1390 train_time:69365ms step_avg:140.99ms
step:503/1390 train_time:69511ms step_avg:141.00ms
step:504/1390 train_time:69656ms step_avg:141.00ms
step:505/1390 train_time:69802ms step_avg:141.01ms
step:506/1390 train_time:69947ms step_avg:141.02ms
step:507/1390 train_time:70092ms step_avg:141.03ms
step:508/1390 train_time:70238ms step_avg:141.04ms
step:509/1390 train_time:70386ms step_avg:141.05ms
step:510/1390 train_time:70533ms step_avg:141.07ms
step:511/1390 train_time:70678ms step_avg:141.07ms
step:512/1390 train_time:70823ms step_avg:141.08ms
step:513/1390 train_time:70969ms step_avg:141.09ms
step:514/1390 train_time:71115ms step_avg:141.10ms
step:515/1390 train_time:71260ms step_avg:141.11ms
step:516/1390 train_time:71409ms step_avg:141.12ms
step:517/1390 train_time:71554ms step_avg:141.13ms
step:518/1390 train_time:71701ms step_avg:141.14ms
step:519/1390 train_time:71848ms step_avg:141.15ms
step:520/1390 train_time:71995ms step_avg:141.17ms
step:521/1390 train_time:72141ms step_avg:141.18ms
step:522/1390 train_time:72289ms step_avg:141.19ms
step:523/1390 train_time:72435ms step_avg:141.20ms
step:524/1390 train_time:72585ms step_avg:141.22ms
step:525/1390 train_time:72732ms step_avg:141.23ms
step:526/1390 train_time:72878ms step_avg:141.24ms
step:527/1390 train_time:73027ms step_avg:141.25ms
step:528/1390 train_time:73173ms step_avg:141.26ms
step:529/1390 train_time:73321ms step_avg:141.27ms
step:530/1390 train_time:73470ms step_avg:141.29ms
step:531/1390 train_time:73616ms step_avg:141.30ms
step:532/1390 train_time:73762ms step_avg:141.31ms
step:533/1390 train_time:73913ms step_avg:141.33ms
step:534/1390 train_time:74059ms step_avg:141.33ms
step:535/1390 train_time:74208ms step_avg:141.35ms
step:536/1390 train_time:74356ms step_avg:141.36ms
step:537/1390 train_time:74502ms step_avg:141.37ms
step:538/1390 train_time:74650ms step_avg:141.38ms
step:539/1390 train_time:74798ms step_avg:141.40ms
step:540/1390 train_time:74945ms step_avg:141.41ms
step:541/1390 train_time:75093ms step_avg:141.42ms
step:542/1390 train_time:75239ms step_avg:141.43ms
step:543/1390 train_time:75388ms step_avg:141.44ms
step:544/1390 train_time:75535ms step_avg:141.45ms
step:545/1390 train_time:75680ms step_avg:141.46ms
step:546/1390 train_time:75829ms step_avg:141.47ms
step:547/1390 train_time:75976ms step_avg:141.48ms
step:548/1390 train_time:76124ms step_avg:141.49ms
step:549/1390 train_time:76270ms step_avg:141.50ms
step:550/1390 train_time:76418ms step_avg:141.52ms
step:551/1390 train_time:76565ms step_avg:141.52ms
step:552/1390 train_time:76712ms step_avg:141.54ms
step:553/1390 train_time:76858ms step_avg:141.54ms
step:554/1390 train_time:77005ms step_avg:141.55ms
step:555/1390 train_time:77152ms step_avg:141.56ms
step:556/1390 train_time:77299ms step_avg:141.57ms
step:557/1390 train_time:77449ms step_avg:141.59ms
step:558/1390 train_time:77596ms step_avg:141.60ms
step:559/1390 train_time:77742ms step_avg:141.61ms
step:560/1390 train_time:77890ms step_avg:141.62ms
step:561/1390 train_time:78036ms step_avg:141.63ms
step:562/1390 train_time:78182ms step_avg:141.63ms
step:563/1390 train_time:78330ms step_avg:141.65ms
step:564/1390 train_time:78476ms step_avg:141.65ms
step:565/1390 train_time:78624ms step_avg:141.67ms
step:566/1390 train_time:78772ms step_avg:141.68ms
step:567/1390 train_time:78917ms step_avg:141.68ms
step:568/1390 train_time:79064ms step_avg:141.69ms
step:569/1390 train_time:79211ms step_avg:141.70ms
step:570/1390 train_time:79357ms step_avg:141.71ms
step:571/1390 train_time:79549ms step_avg:141.80ms
step:572/1390 train_time:79693ms step_avg:141.80ms
step:573/1390 train_time:79839ms step_avg:141.81ms
step:574/1390 train_time:79988ms step_avg:141.82ms
step:575/1390 train_time:80134ms step_avg:141.83ms
step:576/1390 train_time:80279ms step_avg:141.84ms
step:577/1390 train_time:80427ms step_avg:141.85ms
step:578/1390 train_time:80575ms step_avg:141.86ms
step:579/1390 train_time:80722ms step_avg:141.87ms
step:580/1390 train_time:80869ms step_avg:141.88ms
step:581/1390 train_time:81016ms step_avg:141.88ms
step:582/1390 train_time:81162ms step_avg:141.89ms
step:583/1390 train_time:81311ms step_avg:141.90ms
step:584/1390 train_time:81458ms step_avg:141.91ms
step:585/1390 train_time:81605ms step_avg:141.92ms
step:586/1390 train_time:81753ms step_avg:141.93ms
step:587/1390 train_time:81899ms step_avg:141.94ms
step:588/1390 train_time:82045ms step_avg:141.95ms
step:589/1390 train_time:82193ms step_avg:141.96ms
step:590/1390 train_time:82339ms step_avg:141.96ms
step:591/1390 train_time:82488ms step_avg:141.98ms
step:592/1390 train_time:82635ms step_avg:141.99ms
step:593/1390 train_time:82784ms step_avg:142.00ms
step:594/1390 train_time:82931ms step_avg:142.01ms
step:595/1390 train_time:83077ms step_avg:142.01ms
step:596/1390 train_time:83224ms step_avg:142.02ms
step:597/1390 train_time:83372ms step_avg:142.03ms
step:598/1390 train_time:83518ms step_avg:142.04ms
step:599/1390 train_time:83666ms step_avg:142.05ms
step:600/1390 train_time:83815ms step_avg:142.06ms
step:601/1390 train_time:83961ms step_avg:142.07ms
step:602/1390 train_time:84108ms step_avg:142.08ms
step:603/1390 train_time:84254ms step_avg:142.08ms
step:604/1390 train_time:84402ms step_avg:142.09ms
step:605/1390 train_time:84550ms step_avg:142.10ms
step:606/1390 train_time:84698ms step_avg:142.11ms
step:607/1390 train_time:84846ms step_avg:142.12ms
step:608/1390 train_time:84994ms step_avg:142.13ms
step:609/1390 train_time:85140ms step_avg:142.14ms
step:610/1390 train_time:85288ms step_avg:142.15ms
step:611/1390 train_time:85435ms step_avg:142.15ms
step:612/1390 train_time:85582ms step_avg:142.16ms
step:613/1390 train_time:85731ms step_avg:142.17ms
step:614/1390 train_time:85877ms step_avg:142.18ms
step:615/1390 train_time:86023ms step_avg:142.19ms
step:616/1390 train_time:86170ms step_avg:142.19ms
step:617/1390 train_time:86317ms step_avg:142.20ms
step:618/1390 train_time:86463ms step_avg:142.21ms
step:619/1390 train_time:86612ms step_avg:142.22ms
step:620/1390 train_time:86761ms step_avg:142.23ms
step:621/1390 train_time:86910ms step_avg:142.24ms
step:622/1390 train_time:87058ms step_avg:142.25ms
step:623/1390 train_time:87207ms step_avg:142.26ms
step:624/1390 train_time:87355ms step_avg:142.27ms
step:625/1390 train_time:87505ms step_avg:142.28ms
step:625/1390 val_loss:3.5716 train_time:87579ms step_avg:142.40ms
step:626/1390 train_time:87655ms step_avg:142.30ms
step:627/1390 train_time:87807ms step_avg:142.31ms
step:628/1390 train_time:87954ms step_avg:142.32ms
step:629/1390 train_time:88101ms step_avg:142.33ms
step:630/1390 train_time:88250ms step_avg:142.34ms
step:631/1390 train_time:88395ms step_avg:142.34ms
step:632/1390 train_time:88544ms step_avg:142.35ms
step:633/1390 train_time:88693ms step_avg:142.36ms
step:634/1390 train_time:88842ms step_avg:142.38ms
step:635/1390 train_time:88992ms step_avg:142.39ms
step:636/1390 train_time:89140ms step_avg:142.40ms
step:637/1390 train_time:89290ms step_avg:142.41ms
step:638/1390 train_time:89436ms step_avg:142.41ms
step:639/1390 train_time:89584ms step_avg:142.42ms
step:640/1390 train_time:89732ms step_avg:142.43ms
step:641/1390 train_time:89880ms step_avg:142.44ms
step:642/1390 train_time:90028ms step_avg:142.45ms
step:643/1390 train_time:90177ms step_avg:142.46ms
step:644/1390 train_time:90326ms step_avg:142.47ms
step:645/1390 train_time:90475ms step_avg:142.48ms
step:646/1390 train_time:90623ms step_avg:142.49ms
step:647/1390 train_time:90771ms step_avg:142.50ms
step:648/1390 train_time:90920ms step_avg:142.51ms
step:649/1390 train_time:91069ms step_avg:142.52ms
step:650/1390 train_time:91218ms step_avg:142.53ms
step:651/1390 train_time:91368ms step_avg:142.54ms
step:652/1390 train_time:91516ms step_avg:142.55ms
step:653/1390 train_time:91666ms step_avg:142.56ms
step:654/1390 train_time:91815ms step_avg:142.57ms
step:655/1390 train_time:91964ms step_avg:142.58ms
step:656/1390 train_time:92112ms step_avg:142.59ms
step:657/1390 train_time:92261ms step_avg:142.60ms
step:658/1390 train_time:92409ms step_avg:142.61ms
step:659/1390 train_time:92556ms step_avg:142.61ms
step:660/1390 train_time:92705ms step_avg:142.62ms
step:661/1390 train_time:92855ms step_avg:142.63ms
step:662/1390 train_time:93004ms step_avg:142.64ms
step:663/1390 train_time:93152ms step_avg:142.65ms
step:664/1390 train_time:93300ms step_avg:142.66ms
step:665/1390 train_time:93450ms step_avg:142.67ms
step:666/1390 train_time:93597ms step_avg:142.68ms
step:667/1390 train_time:93747ms step_avg:142.69ms
step:668/1390 train_time:93895ms step_avg:142.70ms
step:669/1390 train_time:94046ms step_avg:142.71ms
step:670/1390 train_time:94194ms step_avg:142.72ms
step:671/1390 train_time:94342ms step_avg:142.73ms
step:672/1390 train_time:94492ms step_avg:142.74ms
step:673/1390 train_time:94639ms step_avg:142.74ms
step:674/1390 train_time:94790ms step_avg:142.76ms
step:675/1390 train_time:94938ms step_avg:142.76ms
step:676/1390 train_time:95088ms step_avg:142.78ms
step:677/1390 train_time:95235ms step_avg:142.78ms
step:678/1390 train_time:95383ms step_avg:142.79ms
step:679/1390 train_time:95533ms step_avg:142.80ms
step:680/1390 train_time:95682ms step_avg:142.81ms
step:681/1390 train_time:95832ms step_avg:142.82ms
step:682/1390 train_time:95979ms step_avg:142.83ms
step:683/1390 train_time:96129ms step_avg:142.84ms
step:684/1390 train_time:96277ms step_avg:142.84ms
step:685/1390 train_time:96428ms step_avg:142.86ms
step:686/1390 train_time:96576ms step_avg:142.86ms
step:687/1390 train_time:96724ms step_avg:142.87ms
step:688/1390 train_time:96874ms step_avg:142.88ms
step:689/1390 train_time:97022ms step_avg:142.89ms
step:690/1390 train_time:97172ms step_avg:142.90ms
step:691/1390 train_time:97319ms step_avg:142.91ms
step:692/1390 train_time:97469ms step_avg:142.92ms
step:693/1390 train_time:97616ms step_avg:142.92ms
step:694/1390 train_time:97764ms step_avg:142.93ms
step:695/1390 train_time:97911ms step_avg:142.94ms
step:696/1390 train_time:98058ms step_avg:142.94ms
step:697/1390 train_time:98209ms step_avg:142.95ms
step:698/1390 train_time:98356ms step_avg:142.96ms
step:699/1390 train_time:98506ms step_avg:142.97ms
step:700/1390 train_time:98655ms step_avg:142.98ms
step:701/1390 train_time:98804ms step_avg:142.99ms
step:702/1390 train_time:98952ms step_avg:142.99ms
step:703/1390 train_time:99100ms step_avg:143.00ms
step:704/1390 train_time:99249ms step_avg:143.01ms
step:705/1390 train_time:99397ms step_avg:143.02ms
step:706/1390 train_time:99548ms step_avg:143.03ms
step:707/1390 train_time:99695ms step_avg:143.03ms
step:708/1390 train_time:99846ms step_avg:143.05ms
step:709/1390 train_time:99996ms step_avg:143.06ms
step:710/1390 train_time:100146ms step_avg:143.07ms
step:711/1390 train_time:100295ms step_avg:143.07ms
step:712/1390 train_time:100445ms step_avg:143.08ms
step:713/1390 train_time:100594ms step_avg:143.09ms
step:714/1390 train_time:100741ms step_avg:143.10ms
step:715/1390 train_time:100891ms step_avg:143.11ms
step:716/1390 train_time:101038ms step_avg:143.11ms
step:717/1390 train_time:101190ms step_avg:143.13ms
step:718/1390 train_time:101338ms step_avg:143.13ms
step:719/1390 train_time:101488ms step_avg:143.14ms
step:720/1390 train_time:101637ms step_avg:143.15ms
step:721/1390 train_time:101785ms step_avg:143.16ms
step:722/1390 train_time:101934ms step_avg:143.17ms
step:723/1390 train_time:102083ms step_avg:143.17ms
step:724/1390 train_time:102232ms step_avg:143.18ms
step:725/1390 train_time:102385ms step_avg:143.20ms
step:726/1390 train_time:102536ms step_avg:143.21ms
step:727/1390 train_time:102689ms step_avg:143.22ms
step:728/1390 train_time:102837ms step_avg:143.23ms
step:729/1390 train_time:102987ms step_avg:143.24ms
step:730/1390 train_time:103138ms step_avg:143.25ms
step:731/1390 train_time:103290ms step_avg:143.26ms
step:732/1390 train_time:103438ms step_avg:143.27ms
step:733/1390 train_time:103589ms step_avg:143.28ms
step:734/1390 train_time:103737ms step_avg:143.28ms
step:735/1390 train_time:103889ms step_avg:143.30ms
step:736/1390 train_time:104038ms step_avg:143.30ms
step:737/1390 train_time:104190ms step_avg:143.31ms
step:738/1390 train_time:104339ms step_avg:143.32ms
step:739/1390 train_time:104489ms step_avg:143.33ms
step:740/1390 train_time:104639ms step_avg:143.34ms
step:741/1390 train_time:104792ms step_avg:143.35ms
step:742/1390 train_time:104940ms step_avg:143.36ms
step:743/1390 train_time:105091ms step_avg:143.37ms
step:744/1390 train_time:105240ms step_avg:143.38ms
step:745/1390 train_time:105393ms step_avg:143.39ms
step:746/1390 train_time:105540ms step_avg:143.40ms
step:747/1390 train_time:105690ms step_avg:143.41ms
step:748/1390 train_time:105841ms step_avg:143.42ms
step:749/1390 train_time:105993ms step_avg:143.43ms
step:750/1390 train_time:106144ms step_avg:143.44ms
step:750/1390 val_loss:3.5181 train_time:106220ms step_avg:143.54ms
step:751/1390 train_time:106298ms step_avg:143.45ms
step:752/1390 train_time:106448ms step_avg:143.46ms
step:753/1390 train_time:106599ms step_avg:143.47ms
step:754/1390 train_time:106747ms step_avg:143.48ms
step:755/1390 train_time:106896ms step_avg:143.48ms
step:756/1390 train_time:107044ms step_avg:143.49ms
step:757/1390 train_time:107196ms step_avg:143.50ms
step:758/1390 train_time:107348ms step_avg:143.51ms
step:759/1390 train_time:107501ms step_avg:143.53ms
step:760/1390 train_time:107648ms step_avg:143.53ms
step:761/1390 train_time:107843ms step_avg:143.60ms
step:762/1390 train_time:107990ms step_avg:143.60ms
step:763/1390 train_time:108139ms step_avg:143.61ms
step:764/1390 train_time:108288ms step_avg:143.62ms
step:765/1390 train_time:108437ms step_avg:143.63ms
step:766/1390 train_time:108587ms step_avg:143.63ms
step:767/1390 train_time:108739ms step_avg:143.64ms
step:768/1390 train_time:108890ms step_avg:143.65ms
step:769/1390 train_time:109041ms step_avg:143.66ms
step:770/1390 train_time:109190ms step_avg:143.67ms
step:771/1390 train_time:109340ms step_avg:143.68ms
step:772/1390 train_time:109488ms step_avg:143.69ms
step:773/1390 train_time:109639ms step_avg:143.70ms
step:774/1390 train_time:109789ms step_avg:143.70ms
step:775/1390 train_time:109941ms step_avg:143.71ms
step:776/1390 train_time:110092ms step_avg:143.72ms
step:777/1390 train_time:110241ms step_avg:143.73ms
step:778/1390 train_time:110389ms step_avg:143.74ms
step:779/1390 train_time:110540ms step_avg:143.74ms
step:780/1390 train_time:110688ms step_avg:143.75ms
step:781/1390 train_time:110840ms step_avg:143.76ms
step:782/1390 train_time:110989ms step_avg:143.77ms
step:783/1390 train_time:111140ms step_avg:143.78ms
step:784/1390 train_time:111289ms step_avg:143.78ms
step:785/1390 train_time:111439ms step_avg:143.79ms
step:786/1390 train_time:111589ms step_avg:143.80ms
step:787/1390 train_time:111739ms step_avg:143.81ms
step:788/1390 train_time:111888ms step_avg:143.81ms
step:789/1390 train_time:112038ms step_avg:143.82ms
step:790/1390 train_time:112186ms step_avg:143.83ms
step:791/1390 train_time:112338ms step_avg:143.84ms
step:792/1390 train_time:112487ms step_avg:143.85ms
step:793/1390 train_time:112640ms step_avg:143.86ms
step:794/1390 train_time:112789ms step_avg:143.86ms
step:795/1390 train_time:112943ms step_avg:143.88ms
step:796/1390 train_time:113093ms step_avg:143.88ms
step:797/1390 train_time:113244ms step_avg:143.89ms
step:798/1390 train_time:113393ms step_avg:143.90ms
step:799/1390 train_time:113545ms step_avg:143.91ms
step:800/1390 train_time:113695ms step_avg:143.92ms
step:801/1390 train_time:113843ms step_avg:143.92ms
step:802/1390 train_time:113995ms step_avg:143.93ms
step:803/1390 train_time:114143ms step_avg:143.94ms
step:804/1390 train_time:114293ms step_avg:143.95ms
step:805/1390 train_time:114443ms step_avg:143.95ms
step:806/1390 train_time:114593ms step_avg:143.96ms
step:807/1390 train_time:114741ms step_avg:143.97ms
step:808/1390 train_time:114891ms step_avg:143.97ms
step:809/1390 train_time:115041ms step_avg:143.98ms
step:810/1390 train_time:115190ms step_avg:143.99ms
step:811/1390 train_time:115341ms step_avg:144.00ms
step:812/1390 train_time:115491ms step_avg:144.00ms
step:813/1390 train_time:115640ms step_avg:144.01ms
step:814/1390 train_time:115789ms step_avg:144.02ms
step:815/1390 train_time:115939ms step_avg:144.02ms
step:816/1390 train_time:116090ms step_avg:144.03ms
step:817/1390 train_time:116240ms step_avg:144.04ms
step:818/1390 train_time:116388ms step_avg:144.04ms
step:819/1390 train_time:116539ms step_avg:144.05ms
step:820/1390 train_time:116688ms step_avg:144.06ms
step:821/1390 train_time:116839ms step_avg:144.07ms
step:822/1390 train_time:116987ms step_avg:144.07ms
step:823/1390 train_time:117139ms step_avg:144.08ms
step:824/1390 train_time:117287ms step_avg:144.09ms
step:825/1390 train_time:117439ms step_avg:144.10ms
step:826/1390 train_time:117593ms step_avg:144.11ms
step:827/1390 train_time:117744ms step_avg:144.12ms
step:828/1390 train_time:117896ms step_avg:144.13ms
step:829/1390 train_time:118046ms step_avg:144.13ms
step:830/1390 train_time:118198ms step_avg:144.14ms
step:831/1390 train_time:118349ms step_avg:144.15ms
step:832/1390 train_time:118501ms step_avg:144.16ms
step:833/1390 train_time:118652ms step_avg:144.17ms
step:834/1390 train_time:118803ms step_avg:144.18ms
step:835/1390 train_time:118954ms step_avg:144.19ms
step:836/1390 train_time:119107ms step_avg:144.20ms
step:837/1390 train_time:119261ms step_avg:144.21ms
step:838/1390 train_time:119412ms step_avg:144.22ms
step:839/1390 train_time:119563ms step_avg:144.23ms
step:840/1390 train_time:119713ms step_avg:144.23ms
step:841/1390 train_time:119864ms step_avg:144.24ms
step:842/1390 train_time:120015ms step_avg:144.25ms
step:843/1390 train_time:120165ms step_avg:144.26ms
step:844/1390 train_time:120318ms step_avg:144.27ms
step:845/1390 train_time:120468ms step_avg:144.27ms
step:846/1390 train_time:120622ms step_avg:144.28ms
step:847/1390 train_time:120773ms step_avg:144.29ms
step:848/1390 train_time:120922ms step_avg:144.30ms
step:849/1390 train_time:121073ms step_avg:144.31ms
step:850/1390 train_time:121225ms step_avg:144.32ms
step:851/1390 train_time:121379ms step_avg:144.33ms
step:852/1390 train_time:121529ms step_avg:144.33ms
step:853/1390 train_time:121679ms step_avg:144.34ms
step:854/1390 train_time:121829ms step_avg:144.35ms
step:855/1390 train_time:121980ms step_avg:144.35ms
step:856/1390 train_time:122130ms step_avg:144.36ms
step:857/1390 train_time:122283ms step_avg:144.37ms
step:858/1390 train_time:122437ms step_avg:144.38ms
step:859/1390 train_time:122587ms step_avg:144.39ms
step:860/1390 train_time:122739ms step_avg:144.40ms
step:861/1390 train_time:122891ms step_avg:144.41ms
step:862/1390 train_time:123043ms step_avg:144.42ms
step:863/1390 train_time:123197ms step_avg:144.43ms
step:864/1390 train_time:123348ms step_avg:144.44ms
step:865/1390 train_time:123498ms step_avg:144.44ms
step:866/1390 train_time:123656ms step_avg:144.46ms
step:867/1390 train_time:123807ms step_avg:144.46ms
step:868/1390 train_time:123957ms step_avg:144.47ms
step:869/1390 train_time:124106ms step_avg:144.48ms
step:870/1390 train_time:124260ms step_avg:144.49ms
step:871/1390 train_time:124410ms step_avg:144.49ms
step:872/1390 train_time:124561ms step_avg:144.50ms
step:873/1390 train_time:124711ms step_avg:144.51ms
step:874/1390 train_time:124862ms step_avg:144.52ms
step:875/1390 train_time:125014ms step_avg:144.53ms
step:875/1390 val_loss:3.4700 train_time:125089ms step_avg:144.61ms
step:876/1390 train_time:125167ms step_avg:144.54ms
step:877/1390 train_time:125321ms step_avg:144.55ms
step:878/1390 train_time:125474ms step_avg:144.56ms
step:879/1390 train_time:125625ms step_avg:144.56ms
step:880/1390 train_time:125776ms step_avg:144.57ms
step:881/1390 train_time:125927ms step_avg:144.58ms
step:882/1390 train_time:126078ms step_avg:144.58ms
step:883/1390 train_time:126229ms step_avg:144.59ms
step:884/1390 train_time:126381ms step_avg:144.60ms
step:885/1390 train_time:126532ms step_avg:144.61ms
step:886/1390 train_time:126684ms step_avg:144.62ms
step:887/1390 train_time:126837ms step_avg:144.63ms
step:888/1390 train_time:126989ms step_avg:144.63ms
step:889/1390 train_time:127143ms step_avg:144.64ms
step:890/1390 train_time:127294ms step_avg:144.65ms
step:891/1390 train_time:127445ms step_avg:144.66ms
step:892/1390 train_time:127597ms step_avg:144.67ms
step:893/1390 train_time:127746ms step_avg:144.67ms
step:894/1390 train_time:127899ms step_avg:144.68ms
step:895/1390 train_time:128049ms step_avg:144.69ms
step:896/1390 train_time:128201ms step_avg:144.70ms
step:897/1390 train_time:128352ms step_avg:144.70ms
step:898/1390 train_time:128504ms step_avg:144.71ms
step:899/1390 train_time:128656ms step_avg:144.72ms
step:900/1390 train_time:128807ms step_avg:144.73ms
step:901/1390 train_time:128959ms step_avg:144.73ms
step:902/1390 train_time:129108ms step_avg:144.74ms
step:903/1390 train_time:129264ms step_avg:144.75ms
step:904/1390 train_time:129415ms step_avg:144.76ms
step:905/1390 train_time:129565ms step_avg:144.77ms
step:906/1390 train_time:129719ms step_avg:144.78ms
step:907/1390 train_time:129873ms step_avg:144.79ms
step:908/1390 train_time:130024ms step_avg:144.79ms
step:909/1390 train_time:130177ms step_avg:144.80ms
step:910/1390 train_time:130332ms step_avg:144.81ms
step:911/1390 train_time:130483ms step_avg:144.82ms
step:912/1390 train_time:130634ms step_avg:144.83ms
step:913/1390 train_time:130785ms step_avg:144.83ms
step:914/1390 train_time:130937ms step_avg:144.84ms
step:915/1390 train_time:131088ms step_avg:144.85ms
step:916/1390 train_time:131242ms step_avg:144.86ms
step:917/1390 train_time:131394ms step_avg:144.87ms
step:918/1390 train_time:131544ms step_avg:144.87ms
step:919/1390 train_time:131703ms step_avg:144.89ms
step:920/1390 train_time:131854ms step_avg:144.89ms
step:921/1390 train_time:132005ms step_avg:144.90ms
step:922/1390 train_time:132159ms step_avg:144.91ms
step:923/1390 train_time:132308ms step_avg:144.92ms
step:924/1390 train_time:132460ms step_avg:144.92ms
step:925/1390 train_time:132614ms step_avg:144.93ms
step:926/1390 train_time:132764ms step_avg:144.94ms
step:927/1390 train_time:132917ms step_avg:144.95ms
step:928/1390 train_time:133069ms step_avg:144.95ms
step:929/1390 train_time:133221ms step_avg:144.96ms
step:930/1390 train_time:133373ms step_avg:144.97ms
step:931/1390 train_time:133523ms step_avg:144.98ms
step:932/1390 train_time:133678ms step_avg:144.99ms
step:933/1390 train_time:133832ms step_avg:145.00ms
step:934/1390 train_time:133984ms step_avg:145.00ms
step:935/1390 train_time:134141ms step_avg:145.02ms
step:936/1390 train_time:134296ms step_avg:145.03ms
step:937/1390 train_time:134452ms step_avg:145.04ms
step:938/1390 train_time:134609ms step_avg:145.05ms
step:939/1390 train_time:134763ms step_avg:145.06ms
step:940/1390 train_time:134915ms step_avg:145.07ms
step:941/1390 train_time:135065ms step_avg:145.07ms
step:942/1390 train_time:135218ms step_avg:145.08ms
step:943/1390 train_time:135374ms step_avg:145.10ms
step:944/1390 train_time:135533ms step_avg:145.11ms
step:945/1390 train_time:135685ms step_avg:145.12ms
step:946/1390 train_time:135838ms step_avg:145.13ms
step:947/1390 train_time:135990ms step_avg:145.13ms
step:948/1390 train_time:136143ms step_avg:145.14ms
step:949/1390 train_time:136299ms step_avg:145.15ms
step:950/1390 train_time:136451ms step_avg:145.16ms
step:951/1390 train_time:136649ms step_avg:145.22ms
step:952/1390 train_time:136800ms step_avg:145.22ms
step:953/1390 train_time:136951ms step_avg:145.23ms
step:954/1390 train_time:137103ms step_avg:145.24ms
step:955/1390 train_time:137254ms step_avg:145.24ms
step:956/1390 train_time:137409ms step_avg:145.25ms
step:957/1390 train_time:137562ms step_avg:145.26ms
step:958/1390 train_time:137717ms step_avg:145.27ms
step:959/1390 train_time:137873ms step_avg:145.28ms
step:960/1390 train_time:138027ms step_avg:145.29ms
step:961/1390 train_time:138180ms step_avg:145.30ms
step:962/1390 train_time:138331ms step_avg:145.31ms
step:963/1390 train_time:138488ms step_avg:145.32ms
step:964/1390 train_time:138642ms step_avg:145.33ms
step:965/1390 train_time:138794ms step_avg:145.33ms
step:966/1390 train_time:138944ms step_avg:145.34ms
step:967/1390 train_time:139102ms step_avg:145.35ms
step:968/1390 train_time:139252ms step_avg:145.36ms
step:969/1390 train_time:139405ms step_avg:145.37ms
step:970/1390 train_time:139557ms step_avg:145.37ms
step:971/1390 train_time:139709ms step_avg:145.38ms
step:972/1390 train_time:139861ms step_avg:145.39ms
step:973/1390 train_time:140013ms step_avg:145.39ms
step:974/1390 train_time:140167ms step_avg:145.40ms
step:975/1390 train_time:140320ms step_avg:145.41ms
step:976/1390 train_time:140472ms step_avg:145.42ms
step:977/1390 train_time:140623ms step_avg:145.42ms
step:978/1390 train_time:140777ms step_avg:145.43ms
step:979/1390 train_time:140928ms step_avg:145.44ms
step:980/1390 train_time:141080ms step_avg:145.44ms
step:981/1390 train_time:141230ms step_avg:145.45ms
step:982/1390 train_time:141382ms step_avg:145.46ms
step:983/1390 train_time:141536ms step_avg:145.46ms
step:984/1390 train_time:141686ms step_avg:145.47ms
step:985/1390 train_time:141842ms step_avg:145.48ms
step:986/1390 train_time:141999ms step_avg:145.49ms
step:987/1390 train_time:142151ms step_avg:145.50ms
step:988/1390 train_time:142304ms step_avg:145.51ms
step:989/1390 train_time:142457ms step_avg:145.51ms
step:990/1390 train_time:142611ms step_avg:145.52ms
step:991/1390 train_time:142762ms step_avg:145.53ms
step:992/1390 train_time:142919ms step_avg:145.54ms
step:993/1390 train_time:143078ms step_avg:145.55ms
step:994/1390 train_time:143228ms step_avg:145.56ms
step:995/1390 train_time:143380ms step_avg:145.56ms
step:996/1390 train_time:143531ms step_avg:145.57ms
step:997/1390 train_time:143683ms step_avg:145.58ms
step:998/1390 train_time:143834ms step_avg:145.58ms
step:999/1390 train_time:143987ms step_avg:145.59ms
step:1000/1390 train_time:144141ms step_avg:145.60ms
step:1000/1390 val_loss:3.4050 train_time:144216ms step_avg:145.67ms
step:1001/1390 train_time:144294ms step_avg:145.60ms
step:1002/1390 train_time:144446ms step_avg:145.61ms
step:1003/1390 train_time:144601ms step_avg:145.62ms
step:1004/1390 train_time:144754ms step_avg:145.63ms
step:1005/1390 train_time:144907ms step_avg:145.64ms
step:1006/1390 train_time:145059ms step_avg:145.64ms
step:1007/1390 train_time:145211ms step_avg:145.65ms
step:1008/1390 train_time:145365ms step_avg:145.66ms
step:1009/1390 train_time:145522ms step_avg:145.67ms
step:1010/1390 train_time:145672ms step_avg:145.67ms
step:1011/1390 train_time:145829ms step_avg:145.68ms
step:1012/1390 train_time:145980ms step_avg:145.69ms
step:1013/1390 train_time:146135ms step_avg:145.70ms
step:1014/1390 train_time:146287ms step_avg:145.70ms
step:1015/1390 train_time:146440ms step_avg:145.71ms
step:1016/1390 train_time:146593ms step_avg:145.72ms
step:1017/1390 train_time:146749ms step_avg:145.73ms
step:1018/1390 train_time:146902ms step_avg:145.74ms
step:1019/1390 train_time:147054ms step_avg:145.74ms
step:1020/1390 train_time:147210ms step_avg:145.75ms
step:1021/1390 train_time:147360ms step_avg:145.76ms
step:1022/1390 train_time:147512ms step_avg:145.76ms
step:1023/1390 train_time:147666ms step_avg:145.77ms
step:1024/1390 train_time:147821ms step_avg:145.78ms
step:1025/1390 train_time:147975ms step_avg:145.79ms
step:1026/1390 train_time:148130ms step_avg:145.80ms
step:1027/1390 train_time:148280ms step_avg:145.80ms
step:1028/1390 train_time:148436ms step_avg:145.81ms
step:1029/1390 train_time:148593ms step_avg:145.82ms
step:1030/1390 train_time:148747ms step_avg:145.83ms
step:1031/1390 train_time:148898ms step_avg:145.84ms
step:1032/1390 train_time:149051ms step_avg:145.84ms
step:1033/1390 train_time:149203ms step_avg:145.85ms
step:1034/1390 train_time:149356ms step_avg:145.86ms
step:1035/1390 train_time:149511ms step_avg:145.86ms
step:1036/1390 train_time:149665ms step_avg:145.87ms
step:1037/1390 train_time:149820ms step_avg:145.88ms
step:1038/1390 train_time:149975ms step_avg:145.89ms
step:1039/1390 train_time:150128ms step_avg:145.90ms
step:1040/1390 train_time:150280ms step_avg:145.90ms
step:1041/1390 train_time:150434ms step_avg:145.91ms
step:1042/1390 train_time:150588ms step_avg:145.92ms
step:1043/1390 train_time:150741ms step_avg:145.93ms
step:1044/1390 train_time:150900ms step_avg:145.94ms
step:1045/1390 train_time:151055ms step_avg:145.95ms
step:1046/1390 train_time:151210ms step_avg:145.96ms
step:1047/1390 train_time:151363ms step_avg:145.96ms
step:1048/1390 train_time:151515ms step_avg:145.97ms
step:1049/1390 train_time:151668ms step_avg:145.98ms
step:1050/1390 train_time:151823ms step_avg:145.98ms
step:1051/1390 train_time:151979ms step_avg:145.99ms
step:1052/1390 train_time:152134ms step_avg:146.00ms
step:1053/1390 train_time:152286ms step_avg:146.01ms
step:1054/1390 train_time:152439ms step_avg:146.01ms
step:1055/1390 train_time:152592ms step_avg:146.02ms
step:1056/1390 train_time:152744ms step_avg:146.03ms
step:1057/1390 train_time:152896ms step_avg:146.03ms
step:1058/1390 train_time:153053ms step_avg:146.04ms
step:1059/1390 train_time:153210ms step_avg:146.05ms
step:1060/1390 train_time:153366ms step_avg:146.06ms
step:1061/1390 train_time:153515ms step_avg:146.07ms
step:1062/1390 train_time:153672ms step_avg:146.08ms
step:1063/1390 train_time:153824ms step_avg:146.08ms
step:1064/1390 train_time:153978ms step_avg:146.09ms
step:1065/1390 train_time:154133ms step_avg:146.10ms
step:1066/1390 train_time:154288ms step_avg:146.11ms
step:1067/1390 train_time:154443ms step_avg:146.11ms
step:1068/1390 train_time:154595ms step_avg:146.12ms
step:1069/1390 train_time:154751ms step_avg:146.13ms
step:1070/1390 train_time:154902ms step_avg:146.13ms
step:1071/1390 train_time:155061ms step_avg:146.15ms
step:1072/1390 train_time:155213ms step_avg:146.15ms
step:1073/1390 train_time:155364ms step_avg:146.16ms
step:1074/1390 train_time:155517ms step_avg:146.16ms
step:1075/1390 train_time:155674ms step_avg:146.17ms
step:1076/1390 train_time:155829ms step_avg:146.18ms
step:1077/1390 train_time:155981ms step_avg:146.19ms
step:1078/1390 train_time:156140ms step_avg:146.20ms
step:1079/1390 train_time:156297ms step_avg:146.21ms
step:1080/1390 train_time:156452ms step_avg:146.22ms
step:1081/1390 train_time:156604ms step_avg:146.22ms
step:1082/1390 train_time:156756ms step_avg:146.23ms
step:1083/1390 train_time:156910ms step_avg:146.24ms
step:1084/1390 train_time:157069ms step_avg:146.25ms
step:1085/1390 train_time:157222ms step_avg:146.25ms
step:1086/1390 train_time:157376ms step_avg:146.26ms
step:1087/1390 train_time:157530ms step_avg:146.27ms
step:1088/1390 train_time:157685ms step_avg:146.28ms
step:1089/1390 train_time:157842ms step_avg:146.29ms
step:1090/1390 train_time:157999ms step_avg:146.30ms
step:1091/1390 train_time:158155ms step_avg:146.30ms
step:1092/1390 train_time:158307ms step_avg:146.31ms
step:1093/1390 train_time:158462ms step_avg:146.32ms
step:1094/1390 train_time:158615ms step_avg:146.32ms
step:1095/1390 train_time:158767ms step_avg:146.33ms
step:1096/1390 train_time:158922ms step_avg:146.34ms
step:1097/1390 train_time:159077ms step_avg:146.35ms
step:1098/1390 train_time:159232ms step_avg:146.35ms
step:1099/1390 train_time:159387ms step_avg:146.36ms
step:1100/1390 train_time:159537ms step_avg:146.36ms
step:1101/1390 train_time:159692ms step_avg:146.37ms
step:1102/1390 train_time:159848ms step_avg:146.38ms
step:1103/1390 train_time:160002ms step_avg:146.39ms
step:1104/1390 train_time:160154ms step_avg:146.39ms
step:1105/1390 train_time:160313ms step_avg:146.40ms
step:1106/1390 train_time:160468ms step_avg:146.41ms
step:1107/1390 train_time:160621ms step_avg:146.42ms
step:1108/1390 train_time:160781ms step_avg:146.43ms
step:1109/1390 train_time:160933ms step_avg:146.44ms
step:1110/1390 train_time:161090ms step_avg:146.45ms
step:1111/1390 train_time:161242ms step_avg:146.45ms
step:1112/1390 train_time:161394ms step_avg:146.46ms
step:1113/1390 train_time:161546ms step_avg:146.46ms
step:1114/1390 train_time:161702ms step_avg:146.47ms
step:1115/1390 train_time:161858ms step_avg:146.48ms
step:1116/1390 train_time:162013ms step_avg:146.49ms
step:1117/1390 train_time:162169ms step_avg:146.49ms
step:1118/1390 train_time:162328ms step_avg:146.51ms
step:1119/1390 train_time:162478ms step_avg:146.51ms
step:1120/1390 train_time:162631ms step_avg:146.51ms
step:1121/1390 train_time:162785ms step_avg:146.52ms
step:1122/1390 train_time:162938ms step_avg:146.53ms
step:1123/1390 train_time:163091ms step_avg:146.53ms
step:1124/1390 train_time:163245ms step_avg:146.54ms
step:1125/1390 train_time:163398ms step_avg:146.55ms
step:1125/1390 val_loss:3.3522 train_time:163478ms step_avg:146.62ms
step:1126/1390 train_time:163556ms step_avg:146.56ms
step:1127/1390 train_time:163711ms step_avg:146.56ms
step:1128/1390 train_time:163865ms step_avg:146.57ms
step:1129/1390 train_time:164021ms step_avg:146.58ms
step:1130/1390 train_time:164174ms step_avg:146.58ms
step:1131/1390 train_time:164329ms step_avg:146.59ms
step:1132/1390 train_time:164481ms step_avg:146.60ms
step:1133/1390 train_time:164635ms step_avg:146.60ms
step:1134/1390 train_time:164789ms step_avg:146.61ms
step:1135/1390 train_time:164942ms step_avg:146.62ms
step:1136/1390 train_time:165105ms step_avg:146.63ms
step:1137/1390 train_time:165261ms step_avg:146.64ms
step:1138/1390 train_time:165419ms step_avg:146.65ms
step:1139/1390 train_time:165574ms step_avg:146.66ms
step:1140/1390 train_time:165730ms step_avg:146.66ms
step:1141/1390 train_time:165928ms step_avg:146.71ms
step:1142/1390 train_time:166080ms step_avg:146.71ms
step:1143/1390 train_time:166237ms step_avg:146.72ms
step:1144/1390 train_time:166393ms step_avg:146.73ms
step:1145/1390 train_time:166544ms step_avg:146.73ms
step:1146/1390 train_time:166700ms step_avg:146.74ms
step:1147/1390 train_time:166855ms step_avg:146.75ms
step:1148/1390 train_time:167011ms step_avg:146.76ms
step:1149/1390 train_time:167167ms step_avg:146.77ms
step:1150/1390 train_time:167320ms step_avg:146.77ms
step:1151/1390 train_time:167478ms step_avg:146.78ms
step:1152/1390 train_time:167635ms step_avg:146.79ms
step:1153/1390 train_time:167793ms step_avg:146.80ms
step:1154/1390 train_time:167944ms step_avg:146.80ms
step:1155/1390 train_time:168100ms step_avg:146.81ms
step:1156/1390 train_time:168265ms step_avg:146.83ms
step:1157/1390 train_time:168419ms step_avg:146.83ms
step:1158/1390 train_time:168574ms step_avg:146.84ms
step:1159/1390 train_time:168727ms step_avg:146.85ms
step:1160/1390 train_time:168879ms step_avg:146.85ms
step:1161/1390 train_time:169036ms step_avg:146.86ms
step:1162/1390 train_time:169191ms step_avg:146.87ms
step:1163/1390 train_time:169347ms step_avg:146.87ms
step:1164/1390 train_time:169500ms step_avg:146.88ms
step:1165/1390 train_time:169652ms step_avg:146.89ms
step:1166/1390 train_time:169807ms step_avg:146.89ms
step:1167/1390 train_time:169961ms step_avg:146.90ms
step:1168/1390 train_time:170117ms step_avg:146.91ms
step:1169/1390 train_time:170274ms step_avg:146.91ms
step:1170/1390 train_time:170428ms step_avg:146.92ms
step:1171/1390 train_time:170582ms step_avg:146.93ms
step:1172/1390 train_time:170736ms step_avg:146.93ms
step:1173/1390 train_time:170891ms step_avg:146.94ms
step:1174/1390 train_time:171055ms step_avg:146.95ms
step:1175/1390 train_time:171212ms step_avg:146.96ms
step:1176/1390 train_time:171368ms step_avg:146.97ms
step:1177/1390 train_time:171530ms step_avg:146.98ms
step:1178/1390 train_time:171685ms step_avg:146.99ms
step:1179/1390 train_time:171837ms step_avg:146.99ms
step:1180/1390 train_time:171999ms step_avg:147.01ms
step:1181/1390 train_time:172153ms step_avg:147.01ms
step:1182/1390 train_time:172306ms step_avg:147.02ms
step:1183/1390 train_time:172464ms step_avg:147.03ms
step:1184/1390 train_time:172617ms step_avg:147.03ms
step:1185/1390 train_time:172773ms step_avg:147.04ms
step:1186/1390 train_time:172929ms step_avg:147.05ms
step:1187/1390 train_time:173096ms step_avg:147.07ms
step:1188/1390 train_time:173249ms step_avg:147.07ms
step:1189/1390 train_time:173407ms step_avg:147.08ms
step:1190/1390 train_time:173561ms step_avg:147.09ms
step:1191/1390 train_time:173716ms step_avg:147.09ms
step:1192/1390 train_time:173870ms step_avg:147.10ms
step:1193/1390 train_time:174022ms step_avg:147.10ms
step:1194/1390 train_time:174177ms step_avg:147.11ms
step:1195/1390 train_time:174336ms step_avg:147.12ms
step:1196/1390 train_time:174494ms step_avg:147.13ms
step:1197/1390 train_time:174649ms step_avg:147.13ms
step:1198/1390 train_time:174812ms step_avg:147.15ms
step:1199/1390 train_time:174965ms step_avg:147.15ms
step:1200/1390 train_time:175117ms step_avg:147.16ms
step:1201/1390 train_time:175273ms step_avg:147.16ms
step:1202/1390 train_time:175439ms step_avg:147.18ms
step:1203/1390 train_time:175599ms step_avg:147.19ms
step:1204/1390 train_time:175757ms step_avg:147.20ms
step:1205/1390 train_time:175915ms step_avg:147.21ms
step:1206/1390 train_time:176073ms step_avg:147.22ms
step:1207/1390 train_time:176227ms step_avg:147.22ms
step:1208/1390 train_time:176384ms step_avg:147.23ms
step:1209/1390 train_time:176539ms step_avg:147.24ms
step:1210/1390 train_time:176696ms step_avg:147.25ms
step:1211/1390 train_time:176854ms step_avg:147.26ms
step:1212/1390 train_time:177010ms step_avg:147.26ms
step:1213/1390 train_time:177164ms step_avg:147.27ms
step:1214/1390 train_time:177320ms step_avg:147.28ms
step:1215/1390 train_time:177477ms step_avg:147.28ms
step:1216/1390 train_time:177633ms step_avg:147.29ms
step:1217/1390 train_time:177791ms step_avg:147.30ms
step:1218/1390 train_time:177942ms step_avg:147.30ms
step:1219/1390 train_time:178096ms step_avg:147.31ms
step:1220/1390 train_time:178248ms step_avg:147.31ms
step:1221/1390 train_time:178402ms step_avg:147.32ms
step:1222/1390 train_time:178555ms step_avg:147.32ms
step:1223/1390 train_time:178711ms step_avg:147.33ms
step:1224/1390 train_time:178871ms step_avg:147.34ms
step:1225/1390 train_time:179027ms step_avg:147.35ms
step:1226/1390 train_time:179180ms step_avg:147.35ms
step:1227/1390 train_time:179335ms step_avg:147.36ms
step:1228/1390 train_time:179487ms step_avg:147.36ms
step:1229/1390 train_time:179640ms step_avg:147.37ms
step:1230/1390 train_time:179800ms step_avg:147.38ms
step:1231/1390 train_time:179958ms step_avg:147.39ms
step:1232/1390 train_time:180116ms step_avg:147.39ms
step:1233/1390 train_time:180270ms step_avg:147.40ms
step:1234/1390 train_time:180422ms step_avg:147.40ms
step:1235/1390 train_time:180578ms step_avg:147.41ms
step:1236/1390 train_time:180735ms step_avg:147.42ms
step:1237/1390 train_time:180890ms step_avg:147.42ms
step:1238/1390 train_time:181056ms step_avg:147.44ms
step:1239/1390 train_time:181212ms step_avg:147.45ms
step:1240/1390 train_time:181370ms step_avg:147.46ms
step:1241/1390 train_time:181531ms step_avg:147.47ms
step:1242/1390 train_time:181686ms step_avg:147.47ms
step:1243/1390 train_time:181846ms step_avg:147.48ms
step:1244/1390 train_time:181998ms step_avg:147.49ms
step:1245/1390 train_time:182154ms step_avg:147.49ms
step:1246/1390 train_time:182310ms step_avg:147.50ms
step:1247/1390 train_time:182466ms step_avg:147.51ms
step:1248/1390 train_time:182622ms step_avg:147.51ms
step:1249/1390 train_time:182775ms step_avg:147.52ms
step:1250/1390 train_time:182932ms step_avg:147.53ms
step:1250/1390 val_loss:3.3063 train_time:183011ms step_avg:147.59ms
step:1251/1390 train_time:183092ms step_avg:147.54ms
step:1252/1390 train_time:183248ms step_avg:147.54ms
step:1253/1390 train_time:183402ms step_avg:147.55ms
step:1254/1390 train_time:183554ms step_avg:147.55ms
step:1255/1390 train_time:183722ms step_avg:147.57ms
step:1256/1390 train_time:183878ms step_avg:147.57ms
step:1257/1390 train_time:184034ms step_avg:147.58ms
step:1258/1390 train_time:184193ms step_avg:147.59ms
step:1259/1390 train_time:184349ms step_avg:147.60ms
step:1260/1390 train_time:184504ms step_avg:147.60ms
step:1261/1390 train_time:184660ms step_avg:147.61ms
step:1262/1390 train_time:184822ms step_avg:147.62ms
step:1263/1390 train_time:184979ms step_avg:147.63ms
step:1264/1390 train_time:185134ms step_avg:147.64ms
step:1265/1390 train_time:185289ms step_avg:147.64ms
step:1266/1390 train_time:185448ms step_avg:147.65ms
step:1267/1390 train_time:185604ms step_avg:147.66ms
step:1268/1390 train_time:185763ms step_avg:147.67ms
step:1269/1390 train_time:185924ms step_avg:147.68ms
step:1270/1390 train_time:186079ms step_avg:147.68ms
step:1271/1390 train_time:186235ms step_avg:147.69ms
step:1272/1390 train_time:186388ms step_avg:147.69ms
step:1273/1390 train_time:186543ms step_avg:147.70ms
step:1274/1390 train_time:186698ms step_avg:147.70ms
step:1275/1390 train_time:186857ms step_avg:147.71ms
step:1276/1390 train_time:187010ms step_avg:147.72ms
step:1277/1390 train_time:187167ms step_avg:147.72ms
step:1278/1390 train_time:187321ms step_avg:147.73ms
step:1279/1390 train_time:187477ms step_avg:147.74ms
step:1280/1390 train_time:187641ms step_avg:147.75ms
step:1281/1390 train_time:187795ms step_avg:147.75ms
step:1282/1390 train_time:187948ms step_avg:147.76ms
step:1283/1390 train_time:188105ms step_avg:147.77ms
step:1284/1390 train_time:188260ms step_avg:147.77ms
step:1285/1390 train_time:188413ms step_avg:147.78ms
step:1286/1390 train_time:188569ms step_avg:147.78ms
step:1287/1390 train_time:188726ms step_avg:147.79ms
step:1288/1390 train_time:188881ms step_avg:147.79ms
step:1289/1390 train_time:189045ms step_avg:147.81ms
step:1290/1390 train_time:189206ms step_avg:147.82ms
step:1291/1390 train_time:189362ms step_avg:147.82ms
step:1292/1390 train_time:189519ms step_avg:147.83ms
step:1293/1390 train_time:189679ms step_avg:147.84ms
step:1294/1390 train_time:189834ms step_avg:147.85ms
step:1295/1390 train_time:189989ms step_avg:147.85ms
step:1296/1390 train_time:190147ms step_avg:147.86ms
step:1297/1390 train_time:190304ms step_avg:147.87ms
step:1298/1390 train_time:190457ms step_avg:147.87ms
step:1299/1390 train_time:190613ms step_avg:147.88ms
step:1300/1390 train_time:190767ms step_avg:147.88ms
step:1301/1390 train_time:190921ms step_avg:147.89ms
step:1302/1390 train_time:191077ms step_avg:147.89ms
step:1303/1390 train_time:191235ms step_avg:147.90ms
step:1304/1390 train_time:191393ms step_avg:147.91ms
step:1305/1390 train_time:191545ms step_avg:147.91ms
step:1306/1390 train_time:191704ms step_avg:147.92ms
step:1307/1390 train_time:191859ms step_avg:147.92ms
step:1308/1390 train_time:192017ms step_avg:147.93ms
step:1309/1390 train_time:192174ms step_avg:147.94ms
step:1310/1390 train_time:192330ms step_avg:147.95ms
step:1311/1390 train_time:192484ms step_avg:147.95ms
step:1312/1390 train_time:192637ms step_avg:147.95ms
step:1313/1390 train_time:192791ms step_avg:147.96ms
step:1314/1390 train_time:192950ms step_avg:147.97ms
step:1315/1390 train_time:193104ms step_avg:147.97ms
step:1316/1390 train_time:193257ms step_avg:147.98ms
step:1317/1390 train_time:193412ms step_avg:147.98ms
step:1318/1390 train_time:193572ms step_avg:147.99ms
step:1319/1390 train_time:193728ms step_avg:148.00ms
step:1320/1390 train_time:193884ms step_avg:148.00ms
step:1321/1390 train_time:194039ms step_avg:148.01ms
step:1322/1390 train_time:194200ms step_avg:148.02ms
step:1323/1390 train_time:194355ms step_avg:148.02ms
step:1324/1390 train_time:194513ms step_avg:148.03ms
step:1325/1390 train_time:194671ms step_avg:148.04ms
step:1326/1390 train_time:194831ms step_avg:148.05ms
step:1327/1390 train_time:194987ms step_avg:148.05ms
step:1328/1390 train_time:195139ms step_avg:148.06ms
step:1329/1390 train_time:195309ms step_avg:148.07ms
step:1330/1390 train_time:195466ms step_avg:148.08ms
step:1331/1390 train_time:195669ms step_avg:148.12ms
step:1332/1390 train_time:195832ms step_avg:148.13ms
step:1333/1390 train_time:195990ms step_avg:148.14ms
step:1334/1390 train_time:196146ms step_avg:148.15ms
step:1335/1390 train_time:196297ms step_avg:148.15ms
step:1336/1390 train_time:196459ms step_avg:148.16ms
step:1337/1390 train_time:196621ms step_avg:148.17ms
step:1338/1390 train_time:196778ms step_avg:148.18ms
step:1339/1390 train_time:196933ms step_avg:148.18ms
step:1340/1390 train_time:197093ms step_avg:148.19ms
step:1341/1390 train_time:197248ms step_avg:148.20ms
step:1342/1390 train_time:197406ms step_avg:148.20ms
step:1343/1390 train_time:197562ms step_avg:148.21ms
step:1344/1390 train_time:197717ms step_avg:148.21ms
step:1345/1390 train_time:197872ms step_avg:148.22ms
step:1346/1390 train_time:198029ms step_avg:148.23ms
step:1347/1390 train_time:198187ms step_avg:148.23ms
step:1348/1390 train_time:198342ms step_avg:148.24ms
step:1349/1390 train_time:198498ms step_avg:148.24ms
step:1350/1390 train_time:198651ms step_avg:148.25ms
step:1351/1390 train_time:198809ms step_avg:148.25ms
step:1352/1390 train_time:198972ms step_avg:148.26ms
step:1353/1390 train_time:199130ms step_avg:148.27ms
step:1354/1390 train_time:199286ms step_avg:148.28ms
step:1355/1390 train_time:199441ms step_avg:148.28ms
step:1356/1390 train_time:199595ms step_avg:148.29ms
step:1357/1390 train_time:199753ms step_avg:148.29ms
step:1358/1390 train_time:199910ms step_avg:148.30ms
step:1359/1390 train_time:200068ms step_avg:148.31ms
step:1360/1390 train_time:200227ms step_avg:148.32ms
step:1361/1390 train_time:200385ms step_avg:148.32ms
step:1362/1390 train_time:200541ms step_avg:148.33ms
step:1363/1390 train_time:200707ms step_avg:148.34ms
step:1364/1390 train_time:200863ms step_avg:148.35ms
step:1365/1390 train_time:201014ms step_avg:148.35ms
step:1366/1390 train_time:201172ms step_avg:148.36ms
step:1367/1390 train_time:201329ms step_avg:148.36ms
step:1368/1390 train_time:201487ms step_avg:148.37ms
step:1369/1390 train_time:201654ms step_avg:148.38ms
step:1370/1390 train_time:201816ms step_avg:148.39ms
step:1371/1390 train_time:201974ms step_avg:148.40ms
step:1372/1390 train_time:202134ms step_avg:148.41ms
step:1373/1390 train_time:202288ms step_avg:148.41ms
step:1374/1390 train_time:202448ms step_avg:148.42ms
step:1375/1390 train_time:202604ms step_avg:148.43ms
step:1375/1390 val_loss:3.2779 train_time:202680ms step_avg:148.48ms
step:1376/1390 train_time:202760ms step_avg:148.43ms
step:1377/1390 train_time:202917ms step_avg:148.44ms
step:1378/1390 train_time:203073ms step_avg:148.45ms
step:1379/1390 train_time:203228ms step_avg:148.45ms
step:1380/1390 train_time:203383ms step_avg:148.45ms
step:1381/1390 train_time:203545ms step_avg:148.46ms
step:1382/1390 train_time:203702ms step_avg:148.47ms
step:1383/1390 train_time:203858ms step_avg:148.48ms
step:1384/1390 train_time:204019ms step_avg:148.49ms
step:1385/1390 train_time:204173ms step_avg:148.49ms
step:1386/1390 train_time:204329ms step_avg:148.49ms
step:1387/1390 train_time:204487ms step_avg:148.50ms
step:1388/1390 train_time:204642ms step_avg:148.51ms
step:1389/1390 train_time:204798ms step_avg:148.51ms
step:1390/1390 train_time:204955ms step_avg:148.52ms
step:1390/1390 val_loss:3.2771 train_time:205033ms step_avg:148.57ms
peak memory consumption: 31563 MiB
