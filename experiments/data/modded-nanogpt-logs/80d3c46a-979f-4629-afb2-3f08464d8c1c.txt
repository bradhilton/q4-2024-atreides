import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import glob
import subprocess
import contextlib
from dataclasses import dataclass

import torch
torch.empty(1, device='cuda', requires_grad=True).backward()
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G, steps):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    if G.size(0) > G.size(1):
        X = X.T

    # Ensure spectral norm is at most 1
    X = X / (X.norm() + 1e-7)
    # Perform the NS iterations
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(0) > G.size(1):
        X = X.T
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5):
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.rank = int(os.environ['RANK'])
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        assert all(isinstance(p, torch.Tensor) for p in params)
        sizes = {p.numel() for p in params}
        param_groups = [dict(params=[p for p in params if p.numel() == size],
                             update_buffer=[torch.empty(size, device='cuda', dtype=torch.bfloat16) for _ in range(self.world_size)])
                        for size in sizes]
        super().__init__(param_groups, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            nesterov = group['nesterov']
            ns_steps = group['ns_steps']
            update_buffers = group['update_buffer']
            # generate weight updates in distributed fashion
            params = group['params']
            handle = None
            params_world = None
            def update_prev():
                if params_world is None:
                    return
                assert handle is not None
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffers):
                    p_world.data.add_(
                        g_world.view_as(p_world),
                        alpha=-lr * max(1, p_world.size(0) / p_world.size(1)) ** 0.5,
                    )
            for base_i in range(len(params))[::self.world_size]:
                if base_i + rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.lerp_(g, 1 - momentum)
                    g = g.lerp_(buf, momentum) if nesterov else buf
                    g = zeropower_via_newtonschulz5(g, steps=ns_steps).flatten()
                else:
                    g = update_buffers[rank]
                update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather(update_buffers, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

def norm(x):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):

    def __init__(self, in_features, out_features):
        super().__init__(in_features, out_features, bias=False)

    def forward(self, x):
        return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):

    def __init__(self, dim, max_seq_len=65536):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum('i,j -> ij', t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x):
        cos, sin = self.cos[None, :x.size(-3), None, :], self.sin[None, :x.size(-3), None, :]
        x1, x2 = x.float().chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, dim, num_heads):
        super().__init__()
        assert dim % num_heads == 0
        self.num_heads = num_heads
        self.c_q = CastedLinear(dim, dim)
        self.c_k = CastedLinear(dim, dim)
        self.c_v = CastedLinear(dim, dim)
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(dim // num_heads) # dim // num_heads = head_dim
        self.c_proj = CastedLinear(dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x, ve, block_mask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, 'Must use batch size = 1 for FlexAttention'
        q = self.c_q(x).view(B, T, self.num_heads, -1)
        k = self.c_k(x).view(B, T, self.num_heads, -1)
        v = self.c_v(x).view(B, T, self.num_heads, -1)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, dim):
        super().__init__()
        self.c_fc = CastedLinear(dim, 4 * dim)
        self.c_proj = CastedLinear(4 * dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, model_dim, num_heads, use_attn=True):
        super().__init__()
        self.attn = CausalSelfAttention(model_dim, num_heads) if use_attn else None
        self.mlp = MLP(model_dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, ve, x0, block_mask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

class ValueEmbedding(nn.Module):
    def __init__(self, vocab_size, model_dim):
        super().__init__()
        self.embed = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])

    def forward(self, inputs):
        ve = [emb(inputs).bfloat16() for emb in self.embed]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2], None, None, None, None, None, None, ve[0], ve[1], ve[2]]
        return ve

# -----------------------------------------------------------------------------
# The main GPT-2 model

class GPT(nn.Module):

    def __init__(self, vocab_size, num_layers, num_heads, model_dim):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, use_attn=(i != 7))
                                     for i in range(num_layers)])
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual learning
        # U-net structure on token value embeddings by @leloykun
        self.value_embeds = ValueEmbedding(vocab_size, model_dim)
        self.lm_head = CastedLinear(model_dim, vocab_size)
        self.lm_head.weight.data.zero_() # @Grad62304977
        # U-net design by @brendanh0gan
        self.num_encoder_layers = num_layers // 2 # Half of the layers for encoder
        self.num_decoder_layers = num_layers - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

    def forward(self, inputs, targets, sliding_window_num_blocks):
        BLOCK_SIZE = 128
        seq_len = len(inputs)
        assert seq_len % BLOCK_SIZE == 0
        total_num_blocks = seq_len // BLOCK_SIZE
        assert inputs.ndim == 1
        docs = (inputs == 50256).cumsum(0)
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_mask):
            num_blocks = dense_mask.sum(dim=-1, dtype=torch.int32)
            indices = dense_mask.argsort(dim=-1, descending=True, stable=True).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        def create_doc_swc_block_mask(sliding_window_num_blocks):
            kv_idx = block_idx = torch.arange(total_num_blocks, dtype=torch.int32, device='cuda')
            q_idx = block_idx[:, None]
            causal_bm = q_idx >= kv_idx
            causal_full_bm = q_idx > kv_idx
            window_bm = q_idx - kv_idx < sliding_window_num_blocks
            window_full_bm = window_bm # block-wise sliding window by @YouJiacheng
            # document_bm = (docs_low[q_idx] <= docs_high[kv_idx]) & (docs_low[kv_idx] <= docs_high[q_idx])
            document_bm = (docs_low[:, None] <= docs_high) & (docs_low <= docs_high[:, None])
            document_full_bm = (docs_low[:, None] == docs_high) & (docs_low == docs_high[:, None])
            nonzero_bm = causal_bm & window_bm & document_bm
            full_bm  = causal_full_bm & window_full_bm & document_full_bm
            kv_num_blocks, kv_indices = dense_to_ordered(nonzero_bm & ~full_bm)
            full_kv_num_blocks, full_kv_indices = dense_to_ordered(full_bm)
            return BlockMask.from_kv_blocks(
                kv_num_blocks,
                kv_indices,
                full_kv_num_blocks,
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )

        block_mask = create_doc_swc_block_mask(sliding_window_num_blocks)

        x0 = norm(self.embed(inputs[None]).bfloat16()) # use of norm here by @Grad62304977
        x = x0
        ve = self.value_embeds(inputs)
        assert len(ve) == len(self.blocks)
        ve_enc, ve_dec = ve[:self.num_encoder_layers], ve[self.num_encoder_layers:]

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        for i in range(self.num_encoder_layers):
            x = self.blocks[i](x, ve_enc[i], x0, block_mask)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        for i in range(self.num_decoder_layers):
            x = x + self.skip_weights[i] * skip_connections.pop()
            # U-net structure on token value embeddings by @leloykun
            x = self.blocks[self.num_encoder_layers + i](x, ve_dec[i], x0, block_mask)

        x = norm(x)
        logits = self.lm_head(x)
        logits = 15 * torch.tanh(logits / 15) # @Grad62304977 added tanh softcapping, @KoszarskyB reduced it from 30 to 15
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets)
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(path):
    # only reads the header, returns header data
    # header is 256 int32
    header = torch.from_file(path, False, 256, dtype=torch.int32)
    assert header[0] == 20240520, 'magic number mismatch in the data .bin file'
    assert header[1] == 1, 'unsupported version'
    num_tokens = int(header[2]) # number of tokens (claimed)
    with open(path, 'rb', buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, 'number of tokens read does not match header'
    return tokens

class DistributedDataLoader:

    def __init__(self, filename_pattern):
        self.rank = int(os.environ['RANK'])
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.files = sorted(glob.glob(filename_pattern))
        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self):
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = 0
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self, batch_size):
        assert batch_size % self.world_size == 0
        device_batch_size = batch_size // self.world_size
        # load next shard if necessary
        if self.current_position + batch_size + 1 >= len(self.tokens):
            self.advance()
        pos = self.current_position + self.rank * device_batch_size
        device_batch_tokens = self.tokens[pos:pos+device_batch_size+1]
        # advance current position
        self.current_position += batch_size
        inputs = device_batch_tokens[:-1].to(device='cuda', dtype=torch.int32, non_blocking=True)
        targets = device_batch_tokens[1:].to(device='cuda', dtype=torch.int64, non_blocking=True)
        return inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    val_files = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # optimization
    batch_size = 8*64*1024 # batch size in tokens
    num_iterations = 1390 # number of iterations to run
    cooldown_frac = 0.2 # fraction of training spent cooling down the learning rate
    bf16_embeds = True
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    # implementation
    max_device_batch_size = 64*1024 # batch size per device in tokens
    save_checkpoint = False
args = Hyperparameters()

micro_bs = args.max_device_batch_size

# set up DDP (distributed data parallel). torchrun sets this env variable
rank = int(os.environ['RANK'])
local_rank = int(os.environ['LOCAL_RANK'])
world_size = int(os.environ['WORLD_SIZE'])
assert torch.cuda.is_available()
torch.cuda.set_device(local_rank)
dist.init_process_group(backend='nccl', device_id=torch.device(local_rank))
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs('logs', exist_ok=True)
    logfile = f'logs/{run_id}.txt'
    print(logfile)

def print0(s, console=False):
    if master_process:
        with open(logfile, 'a') as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0('='*100)
# log information about the hardware/software environment this is running on
print0(f'Running Python {sys.version}')
print0(f'Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}')
print0(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout)
print0('='*100)

# load data
train_loader = DistributedDataLoader(args.train_files)
val_loader = DistributedDataLoader(args.val_files)
print0(f'Training dataloader files: {train_loader.files}')
print0(f'Validation dataloader files: {val_loader.files}')
print0('='*100)

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
model = GPT(vocab_size=50304, num_layers=12, num_heads=6, model_dim=768)
model = model.cuda()
if args.bf16_embeds:
    for m in model.modules():
        if isinstance(m, nn.Embedding):
            m.bfloat16()
model = torch.compile(model)
ddp_model = DDP(model, device_ids=[local_rank], broadcast_buffers=False, gradient_as_bucket_view=True)

# collect the parameters to optimize
hidden_matrix_params = [p for p in model.blocks.parameters() if p.ndim == 2]
embed_params = [model.embed.weight, *model.value_embeds.parameters()]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
optimizer1 = torch.optim.Adam([dict(params=embed_params, lr=0.6),
                               dict(params=head_params, lr=0.008),
                               dict(params=scalar_params, lr=0.04)],
                              betas=(0.8, 0.95), fused=True)
optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95)
optimizers = [optimizer1, optimizer2]

# learning rate schedule: stable then decay
def get_lr(it):
    t = 1 - it / args.num_iterations # time remaining in training
    assert 1 >= t > 0
    # 1) constant lr for first part of training
    if t >= args.cooldown_frac:
        return 1.0
    # 2) then linear cooldown
    else:
        return t / args.cooldown_frac
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# sliding window size schedule: linear increase over training in chunks of 128 from 128 -> 1792. By @fernbear.bsky.social
def get_sliding_window_blocks(it):
    x = it / args.num_iterations # training progress
    assert 0 <= x <= 1
    return int(((1 - x) * 128 + x * 1856) // 128)
sliding_window_num_blocks = torch.tensor(1, dtype=torch.int32, device='cuda')

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.perf_counter()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    sliding_window_num_blocks.copy_(get_sliding_window_blocks(step))

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        # calculate the number of steps to take in the val loop.
        val_batch_size = world_size * micro_bs
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        for _ in range(val_steps):
            with torch.no_grad():
                inputs_val, targets_val = val_loader.next_batch(val_batch_size)
                val_loss += ddp_model(inputs_val, targets_val, sliding_window_num_blocks)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # logging
        print0(f'step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms', console=True)
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f'logs/{run_id}', exist_ok=True)
            torch.save(log, f'logs/{run_id}/state_step{step:06d}.pt')
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    model.train()
    batch_size = args.batch_size
    assert batch_size % world_size == 0
    inputs_train, targets_train = train_loader.next_batch(batch_size)
    assert len(inputs_train) <= micro_bs or len(inputs_train) % micro_bs == 0
    for micro_inputs_train, micro_targets_train in zip(inputs_train.split(micro_bs), targets_train.split(micro_bs)):
        ddp_model(micro_inputs_train, micro_targets_train, sliding_window_num_blocks).backward()
    # momentum warmup for Muon
    frac = min(step/300, 1)
    for group in optimizer2.param_groups:
        group['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        if step != train_steps-1:
            sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_time = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f'step:{step+1}/{train_steps} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms', console=True)

print0(f'peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB')
dist.destroy_process_group()

====================================================================================================
Running Python 3.12.7 (main, Jan  9 2025, 22:54:50) [GCC 13.2.0]
Running PyTorch 2.6.0.dev20241231+cu126 compiled for CUDA 12.6
Fri Jan 10 04:34:21 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:61:00.0 Off |                    0 |
| N/A   26C    P0            145W /  700W |    7746MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:62:00.0 Off |                    0 |
| N/A   30C    P0            125W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:63:00.0 Off |                    0 |
| N/A   30C    P0            118W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:64:00.0 Off |                    0 |
| N/A   29C    P0            122W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  |   00000000:6A:00.0 Off |                    0 |
| N/A   28C    P0            135W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  |   00000000:6B:00.0 Off |                    0 |
| N/A   30C    P0            118W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  |   00000000:6C:00.0 Off |                    0 |
| N/A   49C    P0            143W /  700W |    3456MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  |   00000000:6D:00.0 Off |                    0 |
| N/A   27C    P0            125W /  700W |    3216MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
Training dataloader files: ['data/fineweb10B/fineweb_train_000001.bin', 'data/fineweb10B/fineweb_train_000002.bin', 'data/fineweb10B/fineweb_train_000003.bin', 'data/fineweb10B/fineweb_train_000004.bin', 'data/fineweb10B/fineweb_train_000005.bin', 'data/fineweb10B/fineweb_train_000006.bin', 'data/fineweb10B/fineweb_train_000007.bin', 'data/fineweb10B/fineweb_train_000008.bin', 'data/fineweb10B/fineweb_train_000009.bin', 'data/fineweb10B/fineweb_train_000010.bin']
Validation dataloader files: ['data/fineweb10B/fineweb_val_000000.bin']
====================================================================================================
step:0/1390 val_loss:10.8258 train_time:0ms step_avg:nanms
step:1/1390 train_time:248754ms step_avg:nanms
step:2/1390 train_time:248829ms step_avg:nanms
step:3/1390 train_time:250284ms step_avg:nanms
step:4/1390 train_time:250416ms step_avg:nanms
step:5/1390 train_time:250550ms step_avg:nanms
step:6/1390 train_time:250682ms step_avg:nanms
step:7/1390 train_time:250815ms step_avg:nanms
step:8/1390 train_time:250949ms step_avg:nanms
step:9/1390 train_time:251083ms step_avg:nanms
step:10/1390 train_time:251218ms step_avg:nanms
step:11/1390 train_time:136ms step_avg:nanms
step:12/1390 train_time:270ms step_avg:nanms
step:13/1390 train_time:405ms step_avg:135.07ms
step:14/1390 train_time:539ms step_avg:134.69ms
step:15/1390 train_time:673ms step_avg:134.56ms
step:16/1390 train_time:806ms step_avg:134.33ms
step:17/1390 train_time:941ms step_avg:134.45ms
step:18/1390 train_time:1075ms step_avg:134.42ms
step:19/1390 train_time:1211ms step_avg:134.59ms
step:20/1390 train_time:1346ms step_avg:134.59ms
step:21/1390 train_time:1480ms step_avg:134.53ms
step:22/1390 train_time:1614ms step_avg:134.50ms
step:23/1390 train_time:1748ms step_avg:134.43ms
step:24/1390 train_time:1882ms step_avg:134.46ms
step:25/1390 train_time:2017ms step_avg:134.49ms
step:26/1390 train_time:2152ms step_avg:134.50ms
step:27/1390 train_time:2288ms step_avg:134.61ms
step:28/1390 train_time:2423ms step_avg:134.61ms
step:29/1390 train_time:2556ms step_avg:134.54ms
step:30/1390 train_time:2690ms step_avg:134.52ms
step:31/1390 train_time:2825ms step_avg:134.53ms
step:32/1390 train_time:2958ms step_avg:134.46ms
step:33/1390 train_time:3094ms step_avg:134.51ms
step:34/1390 train_time:3230ms step_avg:134.57ms
step:35/1390 train_time:3365ms step_avg:134.58ms
step:36/1390 train_time:3499ms step_avg:134.57ms
step:37/1390 train_time:3634ms step_avg:134.59ms
step:38/1390 train_time:3768ms step_avg:134.59ms
step:39/1390 train_time:3903ms step_avg:134.59ms
step:40/1390 train_time:4037ms step_avg:134.57ms
step:41/1390 train_time:4173ms step_avg:134.60ms
step:42/1390 train_time:4307ms step_avg:134.60ms
step:43/1390 train_time:4442ms step_avg:134.62ms
step:44/1390 train_time:4577ms step_avg:134.62ms
step:45/1390 train_time:4712ms step_avg:134.64ms
step:46/1390 train_time:4848ms step_avg:134.66ms
step:47/1390 train_time:4983ms step_avg:134.69ms
step:48/1390 train_time:5118ms step_avg:134.68ms
step:49/1390 train_time:5253ms step_avg:134.68ms
step:50/1390 train_time:5387ms step_avg:134.68ms
step:51/1390 train_time:5521ms step_avg:134.67ms
step:52/1390 train_time:5654ms step_avg:134.63ms
step:53/1390 train_time:5790ms step_avg:134.66ms
step:54/1390 train_time:5926ms step_avg:134.67ms
step:55/1390 train_time:6059ms step_avg:134.63ms
step:56/1390 train_time:6193ms step_avg:134.63ms
step:57/1390 train_time:6328ms step_avg:134.64ms
step:58/1390 train_time:6461ms step_avg:134.61ms
step:59/1390 train_time:6596ms step_avg:134.62ms
step:60/1390 train_time:6732ms step_avg:134.63ms
step:61/1390 train_time:6867ms step_avg:134.65ms
step:62/1390 train_time:7002ms step_avg:134.66ms
step:63/1390 train_time:7136ms step_avg:134.65ms
step:64/1390 train_time:7271ms step_avg:134.64ms
step:65/1390 train_time:7405ms step_avg:134.64ms
step:66/1390 train_time:7539ms step_avg:134.63ms
step:67/1390 train_time:7675ms step_avg:134.64ms
step:68/1390 train_time:7809ms step_avg:134.64ms
step:69/1390 train_time:7945ms step_avg:134.66ms
step:70/1390 train_time:8079ms step_avg:134.64ms
step:71/1390 train_time:8213ms step_avg:134.63ms
step:72/1390 train_time:8347ms step_avg:134.63ms
step:73/1390 train_time:8482ms step_avg:134.63ms
step:74/1390 train_time:8616ms step_avg:134.63ms
step:75/1390 train_time:8751ms step_avg:134.64ms
step:76/1390 train_time:8886ms step_avg:134.64ms
step:77/1390 train_time:9021ms step_avg:134.63ms
step:78/1390 train_time:9154ms step_avg:134.62ms
step:79/1390 train_time:9290ms step_avg:134.64ms
step:80/1390 train_time:9426ms step_avg:134.66ms
step:81/1390 train_time:9560ms step_avg:134.64ms
step:82/1390 train_time:9695ms step_avg:134.65ms
step:83/1390 train_time:9831ms step_avg:134.67ms
step:84/1390 train_time:9965ms step_avg:134.66ms
step:85/1390 train_time:10099ms step_avg:134.66ms
step:86/1390 train_time:10235ms step_avg:134.67ms
step:87/1390 train_time:10370ms step_avg:134.67ms
step:88/1390 train_time:10506ms step_avg:134.69ms
step:89/1390 train_time:10640ms step_avg:134.68ms
step:90/1390 train_time:10775ms step_avg:134.69ms
step:91/1390 train_time:10910ms step_avg:134.70ms
step:92/1390 train_time:11045ms step_avg:134.69ms
step:93/1390 train_time:11179ms step_avg:134.69ms
step:94/1390 train_time:11314ms step_avg:134.69ms
step:95/1390 train_time:11450ms step_avg:134.70ms
step:96/1390 train_time:11585ms step_avg:134.71ms
step:97/1390 train_time:11720ms step_avg:134.71ms
step:98/1390 train_time:11854ms step_avg:134.70ms
step:99/1390 train_time:11989ms step_avg:134.71ms
step:100/1390 train_time:12124ms step_avg:134.72ms
step:101/1390 train_time:12258ms step_avg:134.70ms
step:102/1390 train_time:12393ms step_avg:134.71ms
step:103/1390 train_time:12530ms step_avg:134.73ms
step:104/1390 train_time:12667ms step_avg:134.75ms
step:105/1390 train_time:12804ms step_avg:134.78ms
step:106/1390 train_time:12944ms step_avg:134.84ms
step:107/1390 train_time:13080ms step_avg:134.85ms
step:108/1390 train_time:13219ms step_avg:134.89ms
step:109/1390 train_time:13358ms step_avg:134.93ms
step:110/1390 train_time:13497ms step_avg:134.97ms
step:111/1390 train_time:13634ms step_avg:134.99ms
step:112/1390 train_time:13771ms step_avg:135.01ms
step:113/1390 train_time:13909ms step_avg:135.03ms
step:114/1390 train_time:14047ms step_avg:135.06ms
step:115/1390 train_time:14185ms step_avg:135.09ms
step:116/1390 train_time:14324ms step_avg:135.13ms
step:117/1390 train_time:14461ms step_avg:135.15ms
step:118/1390 train_time:14599ms step_avg:135.18ms
step:119/1390 train_time:14737ms step_avg:135.20ms
step:120/1390 train_time:14876ms step_avg:135.24ms
step:121/1390 train_time:15014ms step_avg:135.26ms
step:122/1390 train_time:15152ms step_avg:135.29ms
step:123/1390 train_time:15290ms step_avg:135.31ms
step:124/1390 train_time:15427ms step_avg:135.32ms
step:125/1390 train_time:15566ms step_avg:135.36ms
step:125/1390 val_loss:4.3758 train_time:15632ms step_avg:135.93ms
step:126/1390 train_time:15708ms step_avg:135.41ms
step:127/1390 train_time:15847ms step_avg:135.45ms
step:128/1390 train_time:15987ms step_avg:135.48ms
step:129/1390 train_time:16123ms step_avg:135.48ms
step:130/1390 train_time:16260ms step_avg:135.50ms
step:131/1390 train_time:16397ms step_avg:135.52ms
step:132/1390 train_time:16535ms step_avg:135.53ms
step:133/1390 train_time:16674ms step_avg:135.56ms
step:134/1390 train_time:16813ms step_avg:135.59ms
step:135/1390 train_time:16950ms step_avg:135.60ms
step:136/1390 train_time:17090ms step_avg:135.64ms
step:137/1390 train_time:17228ms step_avg:135.65ms
step:138/1390 train_time:17367ms step_avg:135.68ms
step:139/1390 train_time:17504ms step_avg:135.69ms
step:140/1390 train_time:17642ms step_avg:135.71ms
step:141/1390 train_time:17780ms step_avg:135.72ms
step:142/1390 train_time:17918ms step_avg:135.74ms
step:143/1390 train_time:18057ms step_avg:135.77ms
step:144/1390 train_time:18195ms step_avg:135.79ms
step:145/1390 train_time:18334ms step_avg:135.81ms
step:146/1390 train_time:18473ms step_avg:135.83ms
step:147/1390 train_time:18610ms step_avg:135.84ms
step:148/1390 train_time:18749ms step_avg:135.86ms
step:149/1390 train_time:18888ms step_avg:135.89ms
step:150/1390 train_time:19029ms step_avg:135.92ms
step:151/1390 train_time:19166ms step_avg:135.93ms
step:152/1390 train_time:19304ms step_avg:135.94ms
step:153/1390 train_time:19442ms step_avg:135.96ms
step:154/1390 train_time:19581ms step_avg:135.98ms
step:155/1390 train_time:19719ms step_avg:135.99ms
step:156/1390 train_time:19858ms step_avg:136.01ms
step:157/1390 train_time:19997ms step_avg:136.03ms
step:158/1390 train_time:20136ms step_avg:136.06ms
step:159/1390 train_time:20276ms step_avg:136.08ms
step:160/1390 train_time:20414ms step_avg:136.09ms
step:161/1390 train_time:20552ms step_avg:136.10ms
step:162/1390 train_time:20691ms step_avg:136.13ms
step:163/1390 train_time:20829ms step_avg:136.14ms
step:164/1390 train_time:20967ms step_avg:136.15ms
step:165/1390 train_time:21105ms step_avg:136.16ms
step:166/1390 train_time:21243ms step_avg:136.18ms
step:167/1390 train_time:21383ms step_avg:136.20ms
step:168/1390 train_time:21520ms step_avg:136.21ms
step:169/1390 train_time:21659ms step_avg:136.22ms
step:170/1390 train_time:21798ms step_avg:136.24ms
step:171/1390 train_time:21937ms step_avg:136.26ms
step:172/1390 train_time:22076ms step_avg:136.27ms
step:173/1390 train_time:22214ms step_avg:136.28ms
step:174/1390 train_time:22353ms step_avg:136.30ms
step:175/1390 train_time:22493ms step_avg:136.32ms
step:176/1390 train_time:22632ms step_avg:136.34ms
step:177/1390 train_time:22772ms step_avg:136.36ms
step:178/1390 train_time:22910ms step_avg:136.37ms
step:179/1390 train_time:23047ms step_avg:136.38ms
step:180/1390 train_time:23187ms step_avg:136.40ms
step:181/1390 train_time:23324ms step_avg:136.40ms
step:182/1390 train_time:23463ms step_avg:136.41ms
step:183/1390 train_time:23602ms step_avg:136.43ms
step:184/1390 train_time:23741ms step_avg:136.44ms
step:185/1390 train_time:23879ms step_avg:136.45ms
step:186/1390 train_time:24017ms step_avg:136.46ms
step:187/1390 train_time:24155ms step_avg:136.47ms
step:188/1390 train_time:24294ms step_avg:136.48ms
step:189/1390 train_time:24432ms step_avg:136.49ms
step:190/1390 train_time:24571ms step_avg:136.50ms
step:191/1390 train_time:24754ms step_avg:136.76ms
step:192/1390 train_time:24892ms step_avg:136.77ms
step:193/1390 train_time:25029ms step_avg:136.77ms
step:194/1390 train_time:25167ms step_avg:136.78ms
step:195/1390 train_time:25304ms step_avg:136.78ms
step:196/1390 train_time:25442ms step_avg:136.78ms
step:197/1390 train_time:25580ms step_avg:136.79ms
step:198/1390 train_time:25721ms step_avg:136.82ms
step:199/1390 train_time:25862ms step_avg:136.83ms
step:200/1390 train_time:26000ms step_avg:136.84ms
step:201/1390 train_time:26138ms step_avg:136.85ms
step:202/1390 train_time:26277ms step_avg:136.86ms
step:203/1390 train_time:26415ms step_avg:136.86ms
step:204/1390 train_time:26553ms step_avg:136.87ms
step:205/1390 train_time:26694ms step_avg:136.89ms
step:206/1390 train_time:26834ms step_avg:136.91ms
step:207/1390 train_time:26974ms step_avg:136.92ms
step:208/1390 train_time:27116ms step_avg:136.95ms
step:209/1390 train_time:27257ms step_avg:136.97ms
step:210/1390 train_time:27398ms step_avg:136.99ms
step:211/1390 train_time:27540ms step_avg:137.01ms
step:212/1390 train_time:27681ms step_avg:137.04ms
step:213/1390 train_time:27822ms step_avg:137.06ms
step:214/1390 train_time:27964ms step_avg:137.08ms
step:215/1390 train_time:28105ms step_avg:137.10ms
step:216/1390 train_time:28246ms step_avg:137.12ms
step:217/1390 train_time:28388ms step_avg:137.14ms
step:218/1390 train_time:28531ms step_avg:137.17ms
step:219/1390 train_time:28672ms step_avg:137.19ms
step:220/1390 train_time:28813ms step_avg:137.20ms
step:221/1390 train_time:28953ms step_avg:137.22ms
step:222/1390 train_time:29095ms step_avg:137.24ms
step:223/1390 train_time:29236ms step_avg:137.26ms
step:224/1390 train_time:29376ms step_avg:137.27ms
step:225/1390 train_time:29516ms step_avg:137.29ms
step:226/1390 train_time:29659ms step_avg:137.31ms
step:227/1390 train_time:29802ms step_avg:137.33ms
step:228/1390 train_time:29943ms step_avg:137.35ms
step:229/1390 train_time:30086ms step_avg:137.38ms
step:230/1390 train_time:30227ms step_avg:137.40ms
step:231/1390 train_time:30370ms step_avg:137.42ms
step:232/1390 train_time:30512ms step_avg:137.44ms
step:233/1390 train_time:30653ms step_avg:137.46ms
step:234/1390 train_time:30795ms step_avg:137.48ms
step:235/1390 train_time:30936ms step_avg:137.49ms
step:236/1390 train_time:31077ms step_avg:137.51ms
step:237/1390 train_time:31219ms step_avg:137.53ms
step:238/1390 train_time:31360ms step_avg:137.54ms
step:239/1390 train_time:31501ms step_avg:137.56ms
step:240/1390 train_time:31644ms step_avg:137.58ms
step:241/1390 train_time:31785ms step_avg:137.60ms
step:242/1390 train_time:31926ms step_avg:137.61ms
step:243/1390 train_time:32066ms step_avg:137.62ms
step:244/1390 train_time:32207ms step_avg:137.64ms
step:245/1390 train_time:32348ms step_avg:137.65ms
step:246/1390 train_time:32491ms step_avg:137.67ms
step:247/1390 train_time:32633ms step_avg:137.69ms
step:248/1390 train_time:32775ms step_avg:137.71ms
step:249/1390 train_time:32915ms step_avg:137.72ms
step:250/1390 train_time:33055ms step_avg:137.73ms
step:250/1390 val_loss:3.9549 train_time:33123ms step_avg:138.01ms
step:251/1390 train_time:33201ms step_avg:137.76ms
step:252/1390 train_time:33343ms step_avg:137.78ms
step:253/1390 train_time:33485ms step_avg:137.80ms
step:254/1390 train_time:33625ms step_avg:137.81ms
step:255/1390 train_time:33764ms step_avg:137.81ms
step:256/1390 train_time:33905ms step_avg:137.82ms
step:257/1390 train_time:34045ms step_avg:137.84ms
step:258/1390 train_time:34189ms step_avg:137.86ms
step:259/1390 train_time:34332ms step_avg:137.88ms
step:260/1390 train_time:34475ms step_avg:137.90ms
step:261/1390 train_time:34616ms step_avg:137.91ms
step:262/1390 train_time:34756ms step_avg:137.92ms
step:263/1390 train_time:34897ms step_avg:137.93ms
step:264/1390 train_time:35038ms step_avg:137.94ms
step:265/1390 train_time:35179ms step_avg:137.96ms
step:266/1390 train_time:35320ms step_avg:137.97ms
step:267/1390 train_time:35462ms step_avg:137.98ms
step:268/1390 train_time:35605ms step_avg:138.00ms
step:269/1390 train_time:35746ms step_avg:138.02ms
step:270/1390 train_time:35887ms step_avg:138.03ms
step:271/1390 train_time:36028ms step_avg:138.04ms
step:272/1390 train_time:36168ms step_avg:138.05ms
step:273/1390 train_time:36310ms step_avg:138.06ms
step:274/1390 train_time:36453ms step_avg:138.08ms
step:275/1390 train_time:36597ms step_avg:138.10ms
step:276/1390 train_time:36737ms step_avg:138.11ms
step:277/1390 train_time:36880ms step_avg:138.13ms
step:278/1390 train_time:37021ms step_avg:138.14ms
step:279/1390 train_time:37161ms step_avg:138.15ms
step:280/1390 train_time:37303ms step_avg:138.16ms
step:281/1390 train_time:37446ms step_avg:138.18ms
step:282/1390 train_time:37588ms step_avg:138.19ms
step:283/1390 train_time:37730ms step_avg:138.20ms
step:284/1390 train_time:37871ms step_avg:138.22ms
step:285/1390 train_time:38013ms step_avg:138.23ms
step:286/1390 train_time:38154ms step_avg:138.24ms
step:287/1390 train_time:38297ms step_avg:138.26ms
step:288/1390 train_time:38438ms step_avg:138.27ms
step:289/1390 train_time:38580ms step_avg:138.28ms
step:290/1390 train_time:38724ms step_avg:138.30ms
step:291/1390 train_time:38866ms step_avg:138.31ms
step:292/1390 train_time:39008ms step_avg:138.33ms
step:293/1390 train_time:39148ms step_avg:138.33ms
step:294/1390 train_time:39290ms step_avg:138.35ms
step:295/1390 train_time:39430ms step_avg:138.35ms
step:296/1390 train_time:39572ms step_avg:138.36ms
step:297/1390 train_time:39713ms step_avg:138.37ms
step:298/1390 train_time:39856ms step_avg:138.39ms
step:299/1390 train_time:39998ms step_avg:138.40ms
step:300/1390 train_time:40138ms step_avg:138.41ms
step:301/1390 train_time:40281ms step_avg:138.42ms
step:302/1390 train_time:40423ms step_avg:138.44ms
step:303/1390 train_time:40564ms step_avg:138.44ms
step:304/1390 train_time:40706ms step_avg:138.46ms
step:305/1390 train_time:40846ms step_avg:138.46ms
step:306/1390 train_time:40989ms step_avg:138.48ms
step:307/1390 train_time:41129ms step_avg:138.48ms
step:308/1390 train_time:41270ms step_avg:138.49ms
step:309/1390 train_time:41412ms step_avg:138.50ms
step:310/1390 train_time:41555ms step_avg:138.52ms
step:311/1390 train_time:41699ms step_avg:138.53ms
step:312/1390 train_time:41842ms step_avg:138.55ms
step:313/1390 train_time:41985ms step_avg:138.57ms
step:314/1390 train_time:42127ms step_avg:138.58ms
step:315/1390 train_time:42271ms step_avg:138.59ms
step:316/1390 train_time:42416ms step_avg:138.61ms
step:317/1390 train_time:42560ms step_avg:138.63ms
step:318/1390 train_time:42703ms step_avg:138.65ms
step:319/1390 train_time:42845ms step_avg:138.66ms
step:320/1390 train_time:42988ms step_avg:138.67ms
step:321/1390 train_time:43131ms step_avg:138.69ms
step:322/1390 train_time:43276ms step_avg:138.70ms
step:323/1390 train_time:43420ms step_avg:138.72ms
step:324/1390 train_time:43562ms step_avg:138.73ms
step:325/1390 train_time:43706ms step_avg:138.75ms
step:326/1390 train_time:43848ms step_avg:138.76ms
step:327/1390 train_time:43991ms step_avg:138.77ms
step:328/1390 train_time:44135ms step_avg:138.79ms
step:329/1390 train_time:44279ms step_avg:138.81ms
step:330/1390 train_time:44422ms step_avg:138.82ms
step:331/1390 train_time:44567ms step_avg:138.84ms
step:332/1390 train_time:44712ms step_avg:138.86ms
step:333/1390 train_time:44856ms step_avg:138.87ms
step:334/1390 train_time:45000ms step_avg:138.89ms
step:335/1390 train_time:45144ms step_avg:138.90ms
step:336/1390 train_time:45286ms step_avg:138.91ms
step:337/1390 train_time:45428ms step_avg:138.92ms
step:338/1390 train_time:45573ms step_avg:138.94ms
step:339/1390 train_time:45718ms step_avg:138.96ms
step:340/1390 train_time:45861ms step_avg:138.97ms
step:341/1390 train_time:46004ms step_avg:138.99ms
step:342/1390 train_time:46148ms step_avg:139.00ms
step:343/1390 train_time:46292ms step_avg:139.02ms
step:344/1390 train_time:46435ms step_avg:139.03ms
step:345/1390 train_time:46580ms step_avg:139.05ms
step:346/1390 train_time:46724ms step_avg:139.06ms
step:347/1390 train_time:46869ms step_avg:139.08ms
step:348/1390 train_time:47013ms step_avg:139.09ms
step:349/1390 train_time:47156ms step_avg:139.10ms
step:350/1390 train_time:47301ms step_avg:139.12ms
step:351/1390 train_time:47444ms step_avg:139.13ms
step:352/1390 train_time:47587ms step_avg:139.14ms
step:353/1390 train_time:47729ms step_avg:139.15ms
step:354/1390 train_time:47875ms step_avg:139.17ms
step:355/1390 train_time:48018ms step_avg:139.18ms
step:356/1390 train_time:48161ms step_avg:139.19ms
step:357/1390 train_time:48304ms step_avg:139.21ms
step:358/1390 train_time:48447ms step_avg:139.22ms
step:359/1390 train_time:48592ms step_avg:139.23ms
step:360/1390 train_time:48736ms step_avg:139.25ms
step:361/1390 train_time:48880ms step_avg:139.26ms
step:362/1390 train_time:49025ms step_avg:139.27ms
step:363/1390 train_time:49167ms step_avg:139.28ms
step:364/1390 train_time:49309ms step_avg:139.29ms
step:365/1390 train_time:49453ms step_avg:139.30ms
step:366/1390 train_time:49597ms step_avg:139.32ms
step:367/1390 train_time:49740ms step_avg:139.33ms
step:368/1390 train_time:49884ms step_avg:139.34ms
step:369/1390 train_time:50028ms step_avg:139.35ms
step:370/1390 train_time:50172ms step_avg:139.37ms
step:371/1390 train_time:50316ms step_avg:139.38ms
step:372/1390 train_time:50460ms step_avg:139.39ms
step:373/1390 train_time:50603ms step_avg:139.40ms
step:374/1390 train_time:50745ms step_avg:139.41ms
step:375/1390 train_time:50888ms step_avg:139.42ms
step:375/1390 val_loss:3.7731 train_time:50958ms step_avg:139.61ms
step:376/1390 train_time:51035ms step_avg:139.44ms
step:377/1390 train_time:51183ms step_avg:139.46ms
step:378/1390 train_time:51326ms step_avg:139.47ms
step:379/1390 train_time:51467ms step_avg:139.48ms
step:380/1390 train_time:51610ms step_avg:139.49ms
step:381/1390 train_time:51800ms step_avg:139.62ms
step:382/1390 train_time:51942ms step_avg:139.63ms
step:383/1390 train_time:52085ms step_avg:139.64ms
step:384/1390 train_time:52227ms step_avg:139.64ms
step:385/1390 train_time:52370ms step_avg:139.65ms
step:386/1390 train_time:52513ms step_avg:139.66ms
step:387/1390 train_time:52657ms step_avg:139.67ms
step:388/1390 train_time:52803ms step_avg:139.69ms
step:389/1390 train_time:52946ms step_avg:139.70ms
step:390/1390 train_time:53089ms step_avg:139.71ms
step:391/1390 train_time:53232ms step_avg:139.72ms
step:392/1390 train_time:53376ms step_avg:139.73ms
step:393/1390 train_time:53519ms step_avg:139.74ms
step:394/1390 train_time:53662ms step_avg:139.75ms
step:395/1390 train_time:53807ms step_avg:139.76ms
step:396/1390 train_time:53952ms step_avg:139.77ms
step:397/1390 train_time:54097ms step_avg:139.78ms
step:398/1390 train_time:54240ms step_avg:139.79ms
step:399/1390 train_time:54383ms step_avg:139.80ms
step:400/1390 train_time:54526ms step_avg:139.81ms
step:401/1390 train_time:54669ms step_avg:139.82ms
step:402/1390 train_time:54813ms step_avg:139.83ms
step:403/1390 train_time:54958ms step_avg:139.84ms
step:404/1390 train_time:55103ms step_avg:139.86ms
step:405/1390 train_time:55245ms step_avg:139.86ms
step:406/1390 train_time:55389ms step_avg:139.87ms
step:407/1390 train_time:55530ms step_avg:139.88ms
step:408/1390 train_time:55674ms step_avg:139.88ms
step:409/1390 train_time:55817ms step_avg:139.89ms
step:410/1390 train_time:55961ms step_avg:139.90ms
step:411/1390 train_time:56105ms step_avg:139.91ms
step:412/1390 train_time:56246ms step_avg:139.92ms
step:413/1390 train_time:56390ms step_avg:139.93ms
step:414/1390 train_time:56534ms step_avg:139.94ms
step:415/1390 train_time:56681ms step_avg:139.95ms
step:416/1390 train_time:56825ms step_avg:139.96ms
step:417/1390 train_time:56971ms step_avg:139.98ms
step:418/1390 train_time:57118ms step_avg:140.00ms
step:419/1390 train_time:57263ms step_avg:140.01ms
step:420/1390 train_time:57407ms step_avg:140.02ms
step:421/1390 train_time:57552ms step_avg:140.03ms
step:422/1390 train_time:57699ms step_avg:140.05ms
step:423/1390 train_time:57844ms step_avg:140.06ms
step:424/1390 train_time:57989ms step_avg:140.07ms
step:425/1390 train_time:58133ms step_avg:140.08ms
step:426/1390 train_time:58280ms step_avg:140.10ms
step:427/1390 train_time:58424ms step_avg:140.11ms
step:428/1390 train_time:58570ms step_avg:140.12ms
step:429/1390 train_time:58718ms step_avg:140.14ms
step:430/1390 train_time:58862ms step_avg:140.15ms
step:431/1390 train_time:59008ms step_avg:140.16ms
step:432/1390 train_time:59153ms step_avg:140.17ms
step:433/1390 train_time:59300ms step_avg:140.19ms
step:434/1390 train_time:59445ms step_avg:140.20ms
step:435/1390 train_time:59590ms step_avg:140.21ms
step:436/1390 train_time:59737ms step_avg:140.23ms
step:437/1390 train_time:59883ms step_avg:140.24ms
step:438/1390 train_time:60026ms step_avg:140.25ms
step:439/1390 train_time:60171ms step_avg:140.26ms
step:440/1390 train_time:60318ms step_avg:140.27ms
step:441/1390 train_time:60463ms step_avg:140.28ms
step:442/1390 train_time:60608ms step_avg:140.30ms
step:443/1390 train_time:60753ms step_avg:140.31ms
step:444/1390 train_time:60899ms step_avg:140.32ms
step:445/1390 train_time:61044ms step_avg:140.33ms
step:446/1390 train_time:61189ms step_avg:140.34ms
step:447/1390 train_time:61334ms step_avg:140.35ms
step:448/1390 train_time:61481ms step_avg:140.37ms
step:449/1390 train_time:61626ms step_avg:140.38ms
step:450/1390 train_time:61770ms step_avg:140.39ms
step:451/1390 train_time:61918ms step_avg:140.40ms
step:452/1390 train_time:62063ms step_avg:140.41ms
step:453/1390 train_time:62208ms step_avg:140.43ms
step:454/1390 train_time:62355ms step_avg:140.44ms
step:455/1390 train_time:62502ms step_avg:140.45ms
step:456/1390 train_time:62646ms step_avg:140.46ms
step:457/1390 train_time:62792ms step_avg:140.47ms
step:458/1390 train_time:62937ms step_avg:140.48ms
step:459/1390 train_time:63084ms step_avg:140.50ms
step:460/1390 train_time:63227ms step_avg:140.50ms
step:461/1390 train_time:63373ms step_avg:140.52ms
step:462/1390 train_time:63519ms step_avg:140.53ms
step:463/1390 train_time:63663ms step_avg:140.54ms
step:464/1390 train_time:63809ms step_avg:140.55ms
step:465/1390 train_time:63955ms step_avg:140.56ms
step:466/1390 train_time:64100ms step_avg:140.57ms
step:467/1390 train_time:64245ms step_avg:140.58ms
step:468/1390 train_time:64390ms step_avg:140.59ms
step:469/1390 train_time:64536ms step_avg:140.60ms
step:470/1390 train_time:64681ms step_avg:140.61ms
step:471/1390 train_time:64826ms step_avg:140.62ms
step:472/1390 train_time:64971ms step_avg:140.63ms
step:473/1390 train_time:65118ms step_avg:140.64ms
step:474/1390 train_time:65262ms step_avg:140.65ms
step:475/1390 train_time:65408ms step_avg:140.66ms
step:476/1390 train_time:65553ms step_avg:140.67ms
step:477/1390 train_time:65700ms step_avg:140.69ms
step:478/1390 train_time:65845ms step_avg:140.69ms
step:479/1390 train_time:65988ms step_avg:140.70ms
step:480/1390 train_time:66133ms step_avg:140.71ms
step:481/1390 train_time:66279ms step_avg:140.72ms
step:482/1390 train_time:66424ms step_avg:140.73ms
step:483/1390 train_time:66570ms step_avg:140.74ms
step:484/1390 train_time:66718ms step_avg:140.75ms
step:485/1390 train_time:66862ms step_avg:140.76ms
step:486/1390 train_time:67007ms step_avg:140.77ms
step:487/1390 train_time:67152ms step_avg:140.78ms
step:488/1390 train_time:67298ms step_avg:140.79ms
step:489/1390 train_time:67443ms step_avg:140.80ms
step:490/1390 train_time:67587ms step_avg:140.81ms
step:491/1390 train_time:67732ms step_avg:140.81ms
step:492/1390 train_time:67878ms step_avg:140.83ms
step:493/1390 train_time:68023ms step_avg:140.83ms
step:494/1390 train_time:68167ms step_avg:140.84ms
step:495/1390 train_time:68313ms step_avg:140.85ms
step:496/1390 train_time:68459ms step_avg:140.86ms
step:497/1390 train_time:68605ms step_avg:140.87ms
step:498/1390 train_time:68749ms step_avg:140.88ms
step:499/1390 train_time:68894ms step_avg:140.89ms
step:500/1390 train_time:69040ms step_avg:140.90ms
step:500/1390 val_loss:3.6558 train_time:69109ms step_avg:141.04ms
step:501/1390 train_time:69186ms step_avg:140.91ms
step:502/1390 train_time:69332ms step_avg:140.92ms
step:503/1390 train_time:69476ms step_avg:140.92ms
step:504/1390 train_time:69619ms step_avg:140.93ms
step:505/1390 train_time:69765ms step_avg:140.94ms
step:506/1390 train_time:69910ms step_avg:140.95ms
step:507/1390 train_time:70055ms step_avg:140.95ms
step:508/1390 train_time:70203ms step_avg:140.97ms
step:509/1390 train_time:70351ms step_avg:140.98ms
step:510/1390 train_time:70498ms step_avg:141.00ms
step:511/1390 train_time:70642ms step_avg:141.00ms
step:512/1390 train_time:70788ms step_avg:141.01ms
step:513/1390 train_time:70934ms step_avg:141.02ms
step:514/1390 train_time:71077ms step_avg:141.03ms
step:515/1390 train_time:71224ms step_avg:141.04ms
step:516/1390 train_time:71372ms step_avg:141.05ms
step:517/1390 train_time:71517ms step_avg:141.06ms
step:518/1390 train_time:71666ms step_avg:141.07ms
step:519/1390 train_time:71812ms step_avg:141.09ms
step:520/1390 train_time:71958ms step_avg:141.09ms
step:521/1390 train_time:72104ms step_avg:141.10ms
step:522/1390 train_time:72252ms step_avg:141.12ms
step:523/1390 train_time:72398ms step_avg:141.13ms
step:524/1390 train_time:72547ms step_avg:141.14ms
step:525/1390 train_time:72694ms step_avg:141.15ms
step:526/1390 train_time:72841ms step_avg:141.17ms
step:527/1390 train_time:72990ms step_avg:141.18ms
step:528/1390 train_time:73136ms step_avg:141.19ms
step:529/1390 train_time:73283ms step_avg:141.20ms
step:530/1390 train_time:73431ms step_avg:141.21ms
step:531/1390 train_time:73577ms step_avg:141.22ms
step:532/1390 train_time:73723ms step_avg:141.23ms
step:533/1390 train_time:73874ms step_avg:141.25ms
step:534/1390 train_time:74019ms step_avg:141.26ms
step:535/1390 train_time:74168ms step_avg:141.27ms
step:536/1390 train_time:74314ms step_avg:141.28ms
step:537/1390 train_time:74459ms step_avg:141.29ms
step:538/1390 train_time:74608ms step_avg:141.30ms
step:539/1390 train_time:74754ms step_avg:141.31ms
step:540/1390 train_time:74901ms step_avg:141.32ms
step:541/1390 train_time:75050ms step_avg:141.34ms
step:542/1390 train_time:75197ms step_avg:141.35ms
step:543/1390 train_time:75344ms step_avg:141.36ms
step:544/1390 train_time:75492ms step_avg:141.37ms
step:545/1390 train_time:75638ms step_avg:141.38ms
step:546/1390 train_time:75785ms step_avg:141.39ms
step:547/1390 train_time:75932ms step_avg:141.40ms
step:548/1390 train_time:76081ms step_avg:141.41ms
step:549/1390 train_time:76229ms step_avg:141.43ms
step:550/1390 train_time:76375ms step_avg:141.44ms
step:551/1390 train_time:76520ms step_avg:141.44ms
step:552/1390 train_time:76670ms step_avg:141.46ms
step:553/1390 train_time:76816ms step_avg:141.47ms
step:554/1390 train_time:76963ms step_avg:141.48ms
step:555/1390 train_time:77111ms step_avg:141.49ms
step:556/1390 train_time:77256ms step_avg:141.50ms
step:557/1390 train_time:77404ms step_avg:141.51ms
step:558/1390 train_time:77551ms step_avg:141.52ms
step:559/1390 train_time:77696ms step_avg:141.52ms
step:560/1390 train_time:77843ms step_avg:141.53ms
step:561/1390 train_time:77992ms step_avg:141.55ms
step:562/1390 train_time:78137ms step_avg:141.55ms
step:563/1390 train_time:78284ms step_avg:141.56ms
step:564/1390 train_time:78433ms step_avg:141.58ms
step:565/1390 train_time:78579ms step_avg:141.58ms
step:566/1390 train_time:78726ms step_avg:141.59ms
step:567/1390 train_time:78872ms step_avg:141.60ms
step:568/1390 train_time:79017ms step_avg:141.61ms
step:569/1390 train_time:79166ms step_avg:141.62ms
step:570/1390 train_time:79314ms step_avg:141.63ms
step:571/1390 train_time:79504ms step_avg:141.72ms
step:572/1390 train_time:79650ms step_avg:141.73ms
step:573/1390 train_time:79796ms step_avg:141.73ms
step:574/1390 train_time:79944ms step_avg:141.74ms
step:575/1390 train_time:80092ms step_avg:141.76ms
step:576/1390 train_time:80237ms step_avg:141.76ms
step:577/1390 train_time:80384ms step_avg:141.77ms
step:578/1390 train_time:80533ms step_avg:141.78ms
step:579/1390 train_time:80679ms step_avg:141.79ms
step:580/1390 train_time:80827ms step_avg:141.80ms
step:581/1390 train_time:80974ms step_avg:141.81ms
step:582/1390 train_time:81119ms step_avg:141.82ms
step:583/1390 train_time:81267ms step_avg:141.83ms
step:584/1390 train_time:81414ms step_avg:141.84ms
step:585/1390 train_time:81561ms step_avg:141.84ms
step:586/1390 train_time:81711ms step_avg:141.86ms
step:587/1390 train_time:81857ms step_avg:141.87ms
step:588/1390 train_time:82003ms step_avg:141.87ms
step:589/1390 train_time:82149ms step_avg:141.88ms
step:590/1390 train_time:82296ms step_avg:141.89ms
step:591/1390 train_time:82444ms step_avg:141.90ms
step:592/1390 train_time:82593ms step_avg:141.91ms
step:593/1390 train_time:82739ms step_avg:141.92ms
step:594/1390 train_time:82888ms step_avg:141.93ms
step:595/1390 train_time:83035ms step_avg:141.94ms
step:596/1390 train_time:83182ms step_avg:141.95ms
step:597/1390 train_time:83329ms step_avg:141.96ms
step:598/1390 train_time:83475ms step_avg:141.97ms
step:599/1390 train_time:83621ms step_avg:141.97ms
step:600/1390 train_time:83771ms step_avg:141.98ms
step:601/1390 train_time:83917ms step_avg:141.99ms
step:602/1390 train_time:84063ms step_avg:142.00ms
step:603/1390 train_time:84211ms step_avg:142.01ms
step:604/1390 train_time:84356ms step_avg:142.01ms
step:605/1390 train_time:84505ms step_avg:142.02ms
step:606/1390 train_time:84653ms step_avg:142.03ms
step:607/1390 train_time:84800ms step_avg:142.04ms
step:608/1390 train_time:84950ms step_avg:142.06ms
step:609/1390 train_time:85096ms step_avg:142.06ms
step:610/1390 train_time:85241ms step_avg:142.07ms
step:611/1390 train_time:85390ms step_avg:142.08ms
step:612/1390 train_time:85536ms step_avg:142.09ms
step:613/1390 train_time:85684ms step_avg:142.10ms
step:614/1390 train_time:85832ms step_avg:142.11ms
step:615/1390 train_time:85978ms step_avg:142.11ms
step:616/1390 train_time:86124ms step_avg:142.12ms
step:617/1390 train_time:86271ms step_avg:142.13ms
step:618/1390 train_time:86416ms step_avg:142.13ms
step:619/1390 train_time:86567ms step_avg:142.15ms
step:620/1390 train_time:86715ms step_avg:142.16ms
step:621/1390 train_time:86864ms step_avg:142.17ms
step:622/1390 train_time:87013ms step_avg:142.18ms
step:623/1390 train_time:87161ms step_avg:142.19ms
step:624/1390 train_time:87312ms step_avg:142.20ms
step:625/1390 train_time:87460ms step_avg:142.21ms
step:625/1390 val_loss:3.5738 train_time:87535ms step_avg:142.33ms
step:626/1390 train_time:87612ms step_avg:142.23ms
step:627/1390 train_time:87764ms step_avg:142.24ms
step:628/1390 train_time:87911ms step_avg:142.25ms
step:629/1390 train_time:88059ms step_avg:142.26ms
step:630/1390 train_time:88206ms step_avg:142.27ms
step:631/1390 train_time:88353ms step_avg:142.28ms
step:632/1390 train_time:88501ms step_avg:142.28ms
step:633/1390 train_time:88650ms step_avg:142.30ms
step:634/1390 train_time:88798ms step_avg:142.30ms
step:635/1390 train_time:88951ms step_avg:142.32ms
step:636/1390 train_time:89098ms step_avg:142.33ms
step:637/1390 train_time:89247ms step_avg:142.34ms
step:638/1390 train_time:89393ms step_avg:142.35ms
step:639/1390 train_time:89541ms step_avg:142.36ms
step:640/1390 train_time:89690ms step_avg:142.36ms
step:641/1390 train_time:89837ms step_avg:142.37ms
step:642/1390 train_time:89985ms step_avg:142.38ms
step:643/1390 train_time:90133ms step_avg:142.39ms
step:644/1390 train_time:90283ms step_avg:142.40ms
step:645/1390 train_time:90431ms step_avg:142.41ms
step:646/1390 train_time:90581ms step_avg:142.42ms
step:647/1390 train_time:90729ms step_avg:142.43ms
step:648/1390 train_time:90879ms step_avg:142.44ms
step:649/1390 train_time:91028ms step_avg:142.45ms
step:650/1390 train_time:91176ms step_avg:142.46ms
step:651/1390 train_time:91326ms step_avg:142.47ms
step:652/1390 train_time:91473ms step_avg:142.48ms
step:653/1390 train_time:91623ms step_avg:142.49ms
step:654/1390 train_time:91772ms step_avg:142.50ms
step:655/1390 train_time:91920ms step_avg:142.51ms
step:656/1390 train_time:92069ms step_avg:142.52ms
step:657/1390 train_time:92216ms step_avg:142.53ms
step:658/1390 train_time:92365ms step_avg:142.54ms
step:659/1390 train_time:92512ms step_avg:142.55ms
step:660/1390 train_time:92663ms step_avg:142.56ms
step:661/1390 train_time:92812ms step_avg:142.57ms
step:662/1390 train_time:92960ms step_avg:142.58ms
step:663/1390 train_time:93109ms step_avg:142.59ms
step:664/1390 train_time:93257ms step_avg:142.59ms
step:665/1390 train_time:93407ms step_avg:142.61ms
step:666/1390 train_time:93554ms step_avg:142.61ms
step:667/1390 train_time:93704ms step_avg:142.62ms
step:668/1390 train_time:93852ms step_avg:142.63ms
step:669/1390 train_time:94001ms step_avg:142.64ms
step:670/1390 train_time:94150ms step_avg:142.65ms
step:671/1390 train_time:94297ms step_avg:142.66ms
step:672/1390 train_time:94448ms step_avg:142.67ms
step:673/1390 train_time:94594ms step_avg:142.68ms
step:674/1390 train_time:94744ms step_avg:142.69ms
step:675/1390 train_time:94893ms step_avg:142.70ms
step:676/1390 train_time:95043ms step_avg:142.71ms
step:677/1390 train_time:95190ms step_avg:142.71ms
step:678/1390 train_time:95338ms step_avg:142.72ms
step:679/1390 train_time:95487ms step_avg:142.73ms
step:680/1390 train_time:95635ms step_avg:142.74ms
step:681/1390 train_time:95787ms step_avg:142.75ms
step:682/1390 train_time:95934ms step_avg:142.76ms
step:683/1390 train_time:96084ms step_avg:142.77ms
step:684/1390 train_time:96232ms step_avg:142.78ms
step:685/1390 train_time:96382ms step_avg:142.79ms
step:686/1390 train_time:96530ms step_avg:142.80ms
step:687/1390 train_time:96677ms step_avg:142.80ms
step:688/1390 train_time:96828ms step_avg:142.81ms
step:689/1390 train_time:96976ms step_avg:142.82ms
step:690/1390 train_time:97127ms step_avg:142.83ms
step:691/1390 train_time:97273ms step_avg:142.84ms
step:692/1390 train_time:97422ms step_avg:142.85ms
step:693/1390 train_time:97571ms step_avg:142.86ms
step:694/1390 train_time:97719ms step_avg:142.86ms
step:695/1390 train_time:97868ms step_avg:142.87ms
step:696/1390 train_time:98014ms step_avg:142.88ms
step:697/1390 train_time:98166ms step_avg:142.89ms
step:698/1390 train_time:98313ms step_avg:142.90ms
step:699/1390 train_time:98461ms step_avg:142.90ms
step:700/1390 train_time:98610ms step_avg:142.91ms
step:701/1390 train_time:98757ms step_avg:142.92ms
step:702/1390 train_time:98907ms step_avg:142.93ms
step:703/1390 train_time:99054ms step_avg:142.94ms
step:704/1390 train_time:99205ms step_avg:142.95ms
step:705/1390 train_time:99353ms step_avg:142.95ms
step:706/1390 train_time:99506ms step_avg:142.97ms
step:707/1390 train_time:99653ms step_avg:142.97ms
step:708/1390 train_time:99802ms step_avg:142.98ms
step:709/1390 train_time:99951ms step_avg:142.99ms
step:710/1390 train_time:100099ms step_avg:143.00ms
step:711/1390 train_time:100249ms step_avg:143.01ms
step:712/1390 train_time:100399ms step_avg:143.02ms
step:713/1390 train_time:100549ms step_avg:143.03ms
step:714/1390 train_time:100696ms step_avg:143.03ms
step:715/1390 train_time:100848ms step_avg:143.05ms
step:716/1390 train_time:100995ms step_avg:143.05ms
step:717/1390 train_time:101146ms step_avg:143.06ms
step:718/1390 train_time:101293ms step_avg:143.07ms
step:719/1390 train_time:101442ms step_avg:143.08ms
step:720/1390 train_time:101590ms step_avg:143.08ms
step:721/1390 train_time:101738ms step_avg:143.09ms
step:722/1390 train_time:101889ms step_avg:143.10ms
step:723/1390 train_time:102036ms step_avg:143.11ms
step:724/1390 train_time:102187ms step_avg:143.12ms
step:725/1390 train_time:102336ms step_avg:143.13ms
step:726/1390 train_time:102488ms step_avg:143.14ms
step:727/1390 train_time:102639ms step_avg:143.15ms
step:728/1390 train_time:102789ms step_avg:143.16ms
step:729/1390 train_time:102936ms step_avg:143.17ms
step:730/1390 train_time:103089ms step_avg:143.18ms
step:731/1390 train_time:103238ms step_avg:143.19ms
step:732/1390 train_time:103389ms step_avg:143.20ms
step:733/1390 train_time:103537ms step_avg:143.20ms
step:734/1390 train_time:103688ms step_avg:143.22ms
step:735/1390 train_time:103835ms step_avg:143.22ms
step:736/1390 train_time:103987ms step_avg:143.23ms
step:737/1390 train_time:104135ms step_avg:143.24ms
step:738/1390 train_time:104286ms step_avg:143.25ms
step:739/1390 train_time:104435ms step_avg:143.26ms
step:740/1390 train_time:104587ms step_avg:143.27ms
step:741/1390 train_time:104737ms step_avg:143.28ms
step:742/1390 train_time:104889ms step_avg:143.29ms
step:743/1390 train_time:105036ms step_avg:143.30ms
step:744/1390 train_time:105189ms step_avg:143.31ms
step:745/1390 train_time:105341ms step_avg:143.32ms
step:746/1390 train_time:105490ms step_avg:143.33ms
step:747/1390 train_time:105637ms step_avg:143.33ms
step:748/1390 train_time:105789ms step_avg:143.35ms
step:749/1390 train_time:105939ms step_avg:143.35ms
step:750/1390 train_time:106090ms step_avg:143.37ms
step:750/1390 val_loss:3.5203 train_time:106167ms step_avg:143.47ms
step:751/1390 train_time:106245ms step_avg:143.38ms
step:752/1390 train_time:106397ms step_avg:143.39ms
step:753/1390 train_time:106548ms step_avg:143.40ms
step:754/1390 train_time:106696ms step_avg:143.41ms
step:755/1390 train_time:106844ms step_avg:143.42ms
step:756/1390 train_time:106993ms step_avg:143.42ms
step:757/1390 train_time:107142ms step_avg:143.43ms
step:758/1390 train_time:107296ms step_avg:143.44ms
step:759/1390 train_time:107449ms step_avg:143.46ms
step:760/1390 train_time:107598ms step_avg:143.46ms
step:761/1390 train_time:107793ms step_avg:143.53ms
step:762/1390 train_time:107941ms step_avg:143.54ms
step:763/1390 train_time:108090ms step_avg:143.55ms
step:764/1390 train_time:108241ms step_avg:143.56ms
step:765/1390 train_time:108391ms step_avg:143.56ms
step:766/1390 train_time:108542ms step_avg:143.57ms
step:767/1390 train_time:108693ms step_avg:143.58ms
step:768/1390 train_time:108846ms step_avg:143.60ms
step:769/1390 train_time:108997ms step_avg:143.61ms
step:770/1390 train_time:109148ms step_avg:143.62ms
step:771/1390 train_time:109297ms step_avg:143.62ms
step:772/1390 train_time:109446ms step_avg:143.63ms
step:773/1390 train_time:109596ms step_avg:143.64ms
step:774/1390 train_time:109745ms step_avg:143.65ms
step:775/1390 train_time:109895ms step_avg:143.65ms
step:776/1390 train_time:110047ms step_avg:143.66ms
step:777/1390 train_time:110197ms step_avg:143.67ms
step:778/1390 train_time:110347ms step_avg:143.68ms
step:779/1390 train_time:110495ms step_avg:143.69ms
step:780/1390 train_time:110645ms step_avg:143.70ms
step:781/1390 train_time:110795ms step_avg:143.70ms
step:782/1390 train_time:110944ms step_avg:143.71ms
step:783/1390 train_time:111094ms step_avg:143.72ms
step:784/1390 train_time:111244ms step_avg:143.73ms
step:785/1390 train_time:111394ms step_avg:143.73ms
step:786/1390 train_time:111544ms step_avg:143.74ms
step:787/1390 train_time:111695ms step_avg:143.75ms
step:788/1390 train_time:111844ms step_avg:143.76ms
step:789/1390 train_time:111994ms step_avg:143.77ms
step:790/1390 train_time:112142ms step_avg:143.77ms
step:791/1390 train_time:112294ms step_avg:143.78ms
step:792/1390 train_time:112443ms step_avg:143.79ms
step:793/1390 train_time:112594ms step_avg:143.80ms
step:794/1390 train_time:112743ms step_avg:143.80ms
step:795/1390 train_time:112898ms step_avg:143.82ms
step:796/1390 train_time:113049ms step_avg:143.83ms
step:797/1390 train_time:113199ms step_avg:143.84ms
step:798/1390 train_time:113349ms step_avg:143.84ms
step:799/1390 train_time:113502ms step_avg:143.86ms
step:800/1390 train_time:113654ms step_avg:143.87ms
step:801/1390 train_time:113801ms step_avg:143.87ms
step:802/1390 train_time:113954ms step_avg:143.88ms
step:803/1390 train_time:114101ms step_avg:143.88ms
step:804/1390 train_time:114250ms step_avg:143.89ms
step:805/1390 train_time:114401ms step_avg:143.90ms
step:806/1390 train_time:114552ms step_avg:143.91ms
step:807/1390 train_time:114699ms step_avg:143.91ms
step:808/1390 train_time:114852ms step_avg:143.92ms
step:809/1390 train_time:115000ms step_avg:143.93ms
step:810/1390 train_time:115152ms step_avg:143.94ms
step:811/1390 train_time:115301ms step_avg:143.95ms
step:812/1390 train_time:115454ms step_avg:143.96ms
step:813/1390 train_time:115601ms step_avg:143.96ms
step:814/1390 train_time:115753ms step_avg:143.97ms
step:815/1390 train_time:115902ms step_avg:143.98ms
step:816/1390 train_time:116055ms step_avg:143.99ms
step:817/1390 train_time:116203ms step_avg:143.99ms
step:818/1390 train_time:116354ms step_avg:144.00ms
step:819/1390 train_time:116504ms step_avg:144.01ms
step:820/1390 train_time:116655ms step_avg:144.02ms
step:821/1390 train_time:116803ms step_avg:144.02ms
step:822/1390 train_time:116954ms step_avg:144.03ms
step:823/1390 train_time:117104ms step_avg:144.04ms
step:824/1390 train_time:117255ms step_avg:144.05ms
step:825/1390 train_time:117405ms step_avg:144.06ms
step:826/1390 train_time:117558ms step_avg:144.07ms
step:827/1390 train_time:117710ms step_avg:144.08ms
step:828/1390 train_time:117861ms step_avg:144.08ms
step:829/1390 train_time:118014ms step_avg:144.10ms
step:830/1390 train_time:118165ms step_avg:144.10ms
step:831/1390 train_time:118317ms step_avg:144.11ms
step:832/1390 train_time:118469ms step_avg:144.12ms
step:833/1390 train_time:118619ms step_avg:144.13ms
step:834/1390 train_time:118770ms step_avg:144.14ms
step:835/1390 train_time:118922ms step_avg:144.15ms
step:836/1390 train_time:119076ms step_avg:144.16ms
step:837/1390 train_time:119227ms step_avg:144.17ms
step:838/1390 train_time:119379ms step_avg:144.18ms
step:839/1390 train_time:119531ms step_avg:144.19ms
step:840/1390 train_time:119681ms step_avg:144.19ms
step:841/1390 train_time:119831ms step_avg:144.20ms
step:842/1390 train_time:119983ms step_avg:144.21ms
step:843/1390 train_time:120136ms step_avg:144.22ms
step:844/1390 train_time:120286ms step_avg:144.23ms
step:845/1390 train_time:120437ms step_avg:144.24ms
step:846/1390 train_time:120589ms step_avg:144.25ms
step:847/1390 train_time:120741ms step_avg:144.25ms
step:848/1390 train_time:120891ms step_avg:144.26ms
step:849/1390 train_time:121043ms step_avg:144.27ms
step:850/1390 train_time:121195ms step_avg:144.28ms
step:851/1390 train_time:121345ms step_avg:144.29ms
step:852/1390 train_time:121496ms step_avg:144.29ms
step:853/1390 train_time:121645ms step_avg:144.30ms
step:854/1390 train_time:121796ms step_avg:144.31ms
step:855/1390 train_time:121947ms step_avg:144.32ms
step:856/1390 train_time:122097ms step_avg:144.32ms
step:857/1390 train_time:122249ms step_avg:144.33ms
step:858/1390 train_time:122404ms step_avg:144.34ms
step:859/1390 train_time:122557ms step_avg:144.35ms
step:860/1390 train_time:122706ms step_avg:144.36ms
step:861/1390 train_time:122858ms step_avg:144.37ms
step:862/1390 train_time:123011ms step_avg:144.38ms
step:863/1390 train_time:123165ms step_avg:144.39ms
step:864/1390 train_time:123318ms step_avg:144.40ms
step:865/1390 train_time:123466ms step_avg:144.41ms
step:866/1390 train_time:123624ms step_avg:144.42ms
step:867/1390 train_time:123776ms step_avg:144.43ms
step:868/1390 train_time:123925ms step_avg:144.43ms
step:869/1390 train_time:124077ms step_avg:144.44ms
step:870/1390 train_time:124230ms step_avg:144.45ms
step:871/1390 train_time:124381ms step_avg:144.46ms
step:872/1390 train_time:124533ms step_avg:144.47ms
step:873/1390 train_time:124683ms step_avg:144.48ms
step:874/1390 train_time:124836ms step_avg:144.49ms
step:875/1390 train_time:124986ms step_avg:144.49ms
step:875/1390 val_loss:3.4761 train_time:125063ms step_avg:144.58ms
step:876/1390 train_time:125140ms step_avg:144.50ms
step:877/1390 train_time:125296ms step_avg:144.52ms
step:878/1390 train_time:125448ms step_avg:144.53ms
step:879/1390 train_time:125598ms step_avg:144.53ms
step:880/1390 train_time:125750ms step_avg:144.54ms
step:881/1390 train_time:125900ms step_avg:144.55ms
step:882/1390 train_time:126051ms step_avg:144.55ms
step:883/1390 train_time:126203ms step_avg:144.56ms
step:884/1390 train_time:126355ms step_avg:144.57ms
step:885/1390 train_time:126504ms step_avg:144.58ms
step:886/1390 train_time:126657ms step_avg:144.59ms
step:887/1390 train_time:126808ms step_avg:144.59ms
step:888/1390 train_time:126960ms step_avg:144.60ms
step:889/1390 train_time:127112ms step_avg:144.61ms
step:890/1390 train_time:127262ms step_avg:144.62ms
step:891/1390 train_time:127414ms step_avg:144.62ms
step:892/1390 train_time:127565ms step_avg:144.63ms
step:893/1390 train_time:127716ms step_avg:144.64ms
step:894/1390 train_time:127865ms step_avg:144.64ms
step:895/1390 train_time:128018ms step_avg:144.65ms
step:896/1390 train_time:128172ms step_avg:144.66ms
step:897/1390 train_time:128321ms step_avg:144.67ms
step:898/1390 train_time:128476ms step_avg:144.68ms
step:899/1390 train_time:128627ms step_avg:144.69ms
step:900/1390 train_time:128779ms step_avg:144.70ms
step:901/1390 train_time:128930ms step_avg:144.70ms
step:902/1390 train_time:129080ms step_avg:144.71ms
step:903/1390 train_time:129235ms step_avg:144.72ms
step:904/1390 train_time:129386ms step_avg:144.73ms
step:905/1390 train_time:129537ms step_avg:144.73ms
step:906/1390 train_time:129690ms step_avg:144.74ms
step:907/1390 train_time:129842ms step_avg:144.75ms
step:908/1390 train_time:129993ms step_avg:144.76ms
step:909/1390 train_time:130145ms step_avg:144.77ms
step:910/1390 train_time:130303ms step_avg:144.78ms
step:911/1390 train_time:130453ms step_avg:144.79ms
step:912/1390 train_time:130603ms step_avg:144.79ms
step:913/1390 train_time:130755ms step_avg:144.80ms
step:914/1390 train_time:130906ms step_avg:144.81ms
step:915/1390 train_time:131058ms step_avg:144.82ms
step:916/1390 train_time:131214ms step_avg:144.83ms
step:917/1390 train_time:131367ms step_avg:144.84ms
step:918/1390 train_time:131517ms step_avg:144.84ms
step:919/1390 train_time:131675ms step_avg:144.86ms
step:920/1390 train_time:131825ms step_avg:144.86ms
step:921/1390 train_time:131977ms step_avg:144.87ms
step:922/1390 train_time:132132ms step_avg:144.88ms
step:923/1390 train_time:132281ms step_avg:144.89ms
step:924/1390 train_time:132433ms step_avg:144.89ms
step:925/1390 train_time:132583ms step_avg:144.90ms
step:926/1390 train_time:132736ms step_avg:144.91ms
step:927/1390 train_time:132888ms step_avg:144.92ms
step:928/1390 train_time:133039ms step_avg:144.92ms
step:929/1390 train_time:133193ms step_avg:144.93ms
step:930/1390 train_time:133343ms step_avg:144.94ms
step:931/1390 train_time:133496ms step_avg:144.95ms
step:932/1390 train_time:133647ms step_avg:144.95ms
step:933/1390 train_time:133800ms step_avg:144.96ms
step:934/1390 train_time:133953ms step_avg:144.97ms
step:935/1390 train_time:134108ms step_avg:144.98ms
step:936/1390 train_time:134260ms step_avg:144.99ms
step:937/1390 train_time:134418ms step_avg:145.00ms
step:938/1390 train_time:134573ms step_avg:145.01ms
step:939/1390 train_time:134726ms step_avg:145.02ms
step:940/1390 train_time:134879ms step_avg:145.03ms
step:941/1390 train_time:135030ms step_avg:145.04ms
step:942/1390 train_time:135181ms step_avg:145.04ms
step:943/1390 train_time:135337ms step_avg:145.06ms
step:944/1390 train_time:135496ms step_avg:145.07ms
step:945/1390 train_time:135648ms step_avg:145.08ms
step:946/1390 train_time:135802ms step_avg:145.09ms
step:947/1390 train_time:135955ms step_avg:145.10ms
step:948/1390 train_time:136105ms step_avg:145.10ms
step:949/1390 train_time:136260ms step_avg:145.11ms
step:950/1390 train_time:136413ms step_avg:145.12ms
step:951/1390 train_time:136613ms step_avg:145.18ms
step:952/1390 train_time:136762ms step_avg:145.18ms
step:953/1390 train_time:136916ms step_avg:145.19ms
step:954/1390 train_time:137067ms step_avg:145.20ms
step:955/1390 train_time:137217ms step_avg:145.20ms
step:956/1390 train_time:137375ms step_avg:145.22ms
step:957/1390 train_time:137525ms step_avg:145.22ms
step:958/1390 train_time:137682ms step_avg:145.23ms
step:959/1390 train_time:137837ms step_avg:145.24ms
step:960/1390 train_time:137990ms step_avg:145.25ms
step:961/1390 train_time:138142ms step_avg:145.26ms
step:962/1390 train_time:138296ms step_avg:145.27ms
step:963/1390 train_time:138453ms step_avg:145.28ms
step:964/1390 train_time:138604ms step_avg:145.29ms
step:965/1390 train_time:138755ms step_avg:145.29ms
step:966/1390 train_time:138908ms step_avg:145.30ms
step:967/1390 train_time:139062ms step_avg:145.31ms
step:968/1390 train_time:139215ms step_avg:145.32ms
step:969/1390 train_time:139367ms step_avg:145.33ms
step:970/1390 train_time:139518ms step_avg:145.33ms
step:971/1390 train_time:139671ms step_avg:145.34ms
step:972/1390 train_time:139823ms step_avg:145.35ms
step:973/1390 train_time:139977ms step_avg:145.35ms
step:974/1390 train_time:140130ms step_avg:145.36ms
step:975/1390 train_time:140281ms step_avg:145.37ms
step:976/1390 train_time:140434ms step_avg:145.38ms
step:977/1390 train_time:140584ms step_avg:145.38ms
step:978/1390 train_time:140738ms step_avg:145.39ms
step:979/1390 train_time:140891ms step_avg:145.40ms
step:980/1390 train_time:141042ms step_avg:145.40ms
step:981/1390 train_time:141194ms step_avg:145.41ms
step:982/1390 train_time:141344ms step_avg:145.42ms
step:983/1390 train_time:141496ms step_avg:145.42ms
step:984/1390 train_time:141647ms step_avg:145.43ms
step:985/1390 train_time:141800ms step_avg:145.44ms
step:986/1390 train_time:141959ms step_avg:145.45ms
step:987/1390 train_time:142110ms step_avg:145.46ms
step:988/1390 train_time:142262ms step_avg:145.46ms
step:989/1390 train_time:142417ms step_avg:145.47ms
step:990/1390 train_time:142572ms step_avg:145.48ms
step:991/1390 train_time:142721ms step_avg:145.49ms
step:992/1390 train_time:142878ms step_avg:145.50ms
step:993/1390 train_time:143037ms step_avg:145.51ms
step:994/1390 train_time:143187ms step_avg:145.52ms
step:995/1390 train_time:143339ms step_avg:145.52ms
step:996/1390 train_time:143492ms step_avg:145.53ms
step:997/1390 train_time:143642ms step_avg:145.53ms
step:998/1390 train_time:143793ms step_avg:145.54ms
step:999/1390 train_time:143943ms step_avg:145.54ms
step:1000/1390 train_time:144097ms step_avg:145.55ms
step:1000/1390 val_loss:3.4385 train_time:144175ms step_avg:145.63ms
step:1001/1390 train_time:144252ms step_avg:145.56ms
step:1002/1390 train_time:144408ms step_avg:145.57ms
step:1003/1390 train_time:144563ms step_avg:145.58ms
step:1004/1390 train_time:144715ms step_avg:145.59ms
step:1005/1390 train_time:144868ms step_avg:145.60ms
step:1006/1390 train_time:145021ms step_avg:145.60ms
step:1007/1390 train_time:145171ms step_avg:145.61ms
step:1008/1390 train_time:145327ms step_avg:145.62ms
step:1009/1390 train_time:145487ms step_avg:145.63ms
step:1010/1390 train_time:145638ms step_avg:145.64ms
step:1011/1390 train_time:145791ms step_avg:145.64ms
step:1012/1390 train_time:145945ms step_avg:145.65ms
step:1013/1390 train_time:146098ms step_avg:145.66ms
step:1014/1390 train_time:146249ms step_avg:145.67ms
step:1015/1390 train_time:146402ms step_avg:145.67ms
step:1016/1390 train_time:146556ms step_avg:145.68ms
step:1017/1390 train_time:146711ms step_avg:145.69ms
step:1018/1390 train_time:146864ms step_avg:145.70ms
step:1019/1390 train_time:147016ms step_avg:145.70ms
step:1020/1390 train_time:147171ms step_avg:145.71ms
step:1021/1390 train_time:147322ms step_avg:145.72ms
step:1022/1390 train_time:147472ms step_avg:145.72ms
step:1023/1390 train_time:147627ms step_avg:145.73ms
step:1024/1390 train_time:147781ms step_avg:145.74ms
step:1025/1390 train_time:147935ms step_avg:145.75ms
step:1026/1390 train_time:148088ms step_avg:145.76ms
step:1027/1390 train_time:148243ms step_avg:145.76ms
step:1028/1390 train_time:148395ms step_avg:145.77ms
step:1029/1390 train_time:148551ms step_avg:145.78ms
step:1030/1390 train_time:148706ms step_avg:145.79ms
step:1031/1390 train_time:148854ms step_avg:145.79ms
step:1032/1390 train_time:149007ms step_avg:145.80ms
step:1033/1390 train_time:149161ms step_avg:145.81ms
step:1034/1390 train_time:149315ms step_avg:145.82ms
step:1035/1390 train_time:149470ms step_avg:145.82ms
step:1036/1390 train_time:149625ms step_avg:145.83ms
step:1037/1390 train_time:149779ms step_avg:145.84ms
step:1038/1390 train_time:149933ms step_avg:145.85ms
step:1039/1390 train_time:150086ms step_avg:145.86ms
step:1040/1390 train_time:150240ms step_avg:145.86ms
step:1041/1390 train_time:150395ms step_avg:145.87ms
step:1042/1390 train_time:150549ms step_avg:145.88ms
step:1043/1390 train_time:150704ms step_avg:145.89ms
step:1044/1390 train_time:150865ms step_avg:145.90ms
step:1045/1390 train_time:151020ms step_avg:145.91ms
step:1046/1390 train_time:151172ms step_avg:145.92ms
step:1047/1390 train_time:151327ms step_avg:145.93ms
step:1048/1390 train_time:151480ms step_avg:145.93ms
step:1049/1390 train_time:151633ms step_avg:145.94ms
step:1050/1390 train_time:151788ms step_avg:145.95ms
step:1051/1390 train_time:151946ms step_avg:145.96ms
step:1052/1390 train_time:152100ms step_avg:145.97ms
step:1053/1390 train_time:152250ms step_avg:145.97ms
step:1054/1390 train_time:152403ms step_avg:145.98ms
step:1055/1390 train_time:152555ms step_avg:145.99ms
step:1056/1390 train_time:152707ms step_avg:145.99ms
step:1057/1390 train_time:152860ms step_avg:146.00ms
step:1058/1390 train_time:153016ms step_avg:146.01ms
step:1059/1390 train_time:153173ms step_avg:146.02ms
step:1060/1390 train_time:153327ms step_avg:146.03ms
step:1061/1390 train_time:153476ms step_avg:146.03ms
step:1062/1390 train_time:153630ms step_avg:146.04ms
step:1063/1390 train_time:153783ms step_avg:146.04ms
step:1064/1390 train_time:153935ms step_avg:146.05ms
step:1065/1390 train_time:154090ms step_avg:146.06ms
step:1066/1390 train_time:154247ms step_avg:146.07ms
step:1067/1390 train_time:154400ms step_avg:146.07ms
step:1068/1390 train_time:154551ms step_avg:146.08ms
step:1069/1390 train_time:154708ms step_avg:146.09ms
step:1070/1390 train_time:154858ms step_avg:146.09ms
step:1071/1390 train_time:155015ms step_avg:146.10ms
step:1072/1390 train_time:155169ms step_avg:146.11ms
step:1073/1390 train_time:155322ms step_avg:146.12ms
step:1074/1390 train_time:155472ms step_avg:146.12ms
step:1075/1390 train_time:155629ms step_avg:146.13ms
step:1076/1390 train_time:155782ms step_avg:146.14ms
step:1077/1390 train_time:155934ms step_avg:146.14ms
step:1078/1390 train_time:156090ms step_avg:146.15ms
step:1079/1390 train_time:156248ms step_avg:146.16ms
step:1080/1390 train_time:156401ms step_avg:146.17ms
step:1081/1390 train_time:156554ms step_avg:146.18ms
step:1082/1390 train_time:156707ms step_avg:146.18ms
step:1083/1390 train_time:156859ms step_avg:146.19ms
step:1084/1390 train_time:157015ms step_avg:146.20ms
step:1085/1390 train_time:157169ms step_avg:146.20ms
step:1086/1390 train_time:157324ms step_avg:146.21ms
step:1087/1390 train_time:157476ms step_avg:146.22ms
step:1088/1390 train_time:157630ms step_avg:146.22ms
step:1089/1390 train_time:157787ms step_avg:146.23ms
step:1090/1390 train_time:157944ms step_avg:146.24ms
step:1091/1390 train_time:158096ms step_avg:146.25ms
step:1092/1390 train_time:158248ms step_avg:146.26ms
step:1093/1390 train_time:158404ms step_avg:146.26ms
step:1094/1390 train_time:158556ms step_avg:146.27ms
step:1095/1390 train_time:158709ms step_avg:146.28ms
step:1096/1390 train_time:158864ms step_avg:146.28ms
step:1097/1390 train_time:159018ms step_avg:146.29ms
step:1098/1390 train_time:159172ms step_avg:146.30ms
step:1099/1390 train_time:159327ms step_avg:146.31ms
step:1100/1390 train_time:159479ms step_avg:146.31ms
step:1101/1390 train_time:159634ms step_avg:146.32ms
step:1102/1390 train_time:159789ms step_avg:146.33ms
step:1103/1390 train_time:159944ms step_avg:146.34ms
step:1104/1390 train_time:160095ms step_avg:146.34ms
step:1105/1390 train_time:160254ms step_avg:146.35ms
step:1106/1390 train_time:160408ms step_avg:146.36ms
step:1107/1390 train_time:160562ms step_avg:146.36ms
step:1108/1390 train_time:160720ms step_avg:146.38ms
step:1109/1390 train_time:160872ms step_avg:146.38ms
step:1110/1390 train_time:161028ms step_avg:146.39ms
step:1111/1390 train_time:161181ms step_avg:146.39ms
step:1112/1390 train_time:161333ms step_avg:146.40ms
step:1113/1390 train_time:161485ms step_avg:146.41ms
step:1114/1390 train_time:161642ms step_avg:146.42ms
step:1115/1390 train_time:161795ms step_avg:146.42ms
step:1116/1390 train_time:161948ms step_avg:146.43ms
step:1117/1390 train_time:162103ms step_avg:146.43ms
step:1118/1390 train_time:162263ms step_avg:146.45ms
step:1119/1390 train_time:162415ms step_avg:146.45ms
step:1120/1390 train_time:162569ms step_avg:146.46ms
step:1121/1390 train_time:162724ms step_avg:146.47ms
step:1122/1390 train_time:162875ms step_avg:146.47ms
step:1123/1390 train_time:163028ms step_avg:146.48ms
step:1124/1390 train_time:163184ms step_avg:146.48ms
step:1125/1390 train_time:163334ms step_avg:146.49ms
step:1125/1390 val_loss:3.4119 train_time:163414ms step_avg:146.56ms
step:1126/1390 train_time:163493ms step_avg:146.50ms
step:1127/1390 train_time:163646ms step_avg:146.50ms
step:1128/1390 train_time:163800ms step_avg:146.51ms
step:1129/1390 train_time:163956ms step_avg:146.52ms
step:1130/1390 train_time:164109ms step_avg:146.53ms
step:1131/1390 train_time:164263ms step_avg:146.53ms
step:1132/1390 train_time:164417ms step_avg:146.54ms
step:1133/1390 train_time:164571ms step_avg:146.55ms
step:1134/1390 train_time:164724ms step_avg:146.55ms
step:1135/1390 train_time:164879ms step_avg:146.56ms
step:1136/1390 train_time:165042ms step_avg:146.57ms
step:1137/1390 train_time:165198ms step_avg:146.58ms
step:1138/1390 train_time:165353ms step_avg:146.59ms
step:1139/1390 train_time:165508ms step_avg:146.60ms
step:1140/1390 train_time:165662ms step_avg:146.60ms
step:1141/1390 train_time:165866ms step_avg:146.65ms
step:1142/1390 train_time:166017ms step_avg:146.66ms
step:1143/1390 train_time:166176ms step_avg:146.67ms
step:1144/1390 train_time:166329ms step_avg:146.67ms
step:1145/1390 train_time:166481ms step_avg:146.68ms
step:1146/1390 train_time:166636ms step_avg:146.69ms
step:1147/1390 train_time:166791ms step_avg:146.69ms
step:1148/1390 train_time:166947ms step_avg:146.70ms
step:1149/1390 train_time:167103ms step_avg:146.71ms
step:1150/1390 train_time:167259ms step_avg:146.72ms
step:1151/1390 train_time:167416ms step_avg:146.73ms
step:1152/1390 train_time:167572ms step_avg:146.74ms
step:1153/1390 train_time:167729ms step_avg:146.74ms
step:1154/1390 train_time:167881ms step_avg:146.75ms
step:1155/1390 train_time:168037ms step_avg:146.76ms
step:1156/1390 train_time:168199ms step_avg:146.77ms
step:1157/1390 train_time:168354ms step_avg:146.78ms
step:1158/1390 train_time:168507ms step_avg:146.78ms
step:1159/1390 train_time:168661ms step_avg:146.79ms
step:1160/1390 train_time:168815ms step_avg:146.80ms
step:1161/1390 train_time:168969ms step_avg:146.80ms
step:1162/1390 train_time:169123ms step_avg:146.81ms
step:1163/1390 train_time:169279ms step_avg:146.82ms
step:1164/1390 train_time:169434ms step_avg:146.82ms
step:1165/1390 train_time:169586ms step_avg:146.83ms
step:1166/1390 train_time:169741ms step_avg:146.83ms
step:1167/1390 train_time:169894ms step_avg:146.84ms
step:1168/1390 train_time:170048ms step_avg:146.85ms
step:1169/1390 train_time:170204ms step_avg:146.85ms
step:1170/1390 train_time:170360ms step_avg:146.86ms
step:1171/1390 train_time:170513ms step_avg:146.87ms
step:1172/1390 train_time:170666ms step_avg:146.87ms
step:1173/1390 train_time:170821ms step_avg:146.88ms
step:1174/1390 train_time:170986ms step_avg:146.90ms
step:1175/1390 train_time:171141ms step_avg:146.90ms
step:1176/1390 train_time:171298ms step_avg:146.91ms
step:1177/1390 train_time:171460ms step_avg:146.92ms
step:1178/1390 train_time:171613ms step_avg:146.93ms
step:1179/1390 train_time:171764ms step_avg:146.93ms
step:1180/1390 train_time:171927ms step_avg:146.95ms
step:1181/1390 train_time:172081ms step_avg:146.95ms
step:1182/1390 train_time:172236ms step_avg:146.96ms
step:1183/1390 train_time:172394ms step_avg:146.97ms
step:1184/1390 train_time:172548ms step_avg:146.97ms
step:1185/1390 train_time:172707ms step_avg:146.98ms
step:1186/1390 train_time:172861ms step_avg:146.99ms
step:1187/1390 train_time:173026ms step_avg:147.01ms
step:1188/1390 train_time:173180ms step_avg:147.01ms
step:1189/1390 train_time:173338ms step_avg:147.02ms
step:1190/1390 train_time:173493ms step_avg:147.03ms
step:1191/1390 train_time:173647ms step_avg:147.03ms
step:1192/1390 train_time:173799ms step_avg:147.04ms
step:1193/1390 train_time:173953ms step_avg:147.04ms
step:1194/1390 train_time:174107ms step_avg:147.05ms
step:1195/1390 train_time:174262ms step_avg:147.06ms
step:1196/1390 train_time:174419ms step_avg:147.06ms
step:1197/1390 train_time:174574ms step_avg:147.07ms
step:1198/1390 train_time:174734ms step_avg:147.08ms
step:1199/1390 train_time:174888ms step_avg:147.09ms
step:1200/1390 train_time:175042ms step_avg:147.09ms
step:1201/1390 train_time:175199ms step_avg:147.10ms
step:1202/1390 train_time:175365ms step_avg:147.12ms
step:1203/1390 train_time:175523ms step_avg:147.13ms
step:1204/1390 train_time:175682ms step_avg:147.14ms
step:1205/1390 train_time:175838ms step_avg:147.14ms
step:1206/1390 train_time:175997ms step_avg:147.15ms
step:1207/1390 train_time:176150ms step_avg:147.16ms
step:1208/1390 train_time:176307ms step_avg:147.17ms
step:1209/1390 train_time:176463ms step_avg:147.18ms
step:1210/1390 train_time:176620ms step_avg:147.18ms
step:1211/1390 train_time:176777ms step_avg:147.19ms
step:1212/1390 train_time:176933ms step_avg:147.20ms
step:1213/1390 train_time:177085ms step_avg:147.20ms
step:1214/1390 train_time:177241ms step_avg:147.21ms
step:1215/1390 train_time:177399ms step_avg:147.22ms
step:1216/1390 train_time:177552ms step_avg:147.22ms
step:1217/1390 train_time:177708ms step_avg:147.23ms
step:1218/1390 train_time:177860ms step_avg:147.24ms
step:1219/1390 train_time:178015ms step_avg:147.24ms
step:1220/1390 train_time:178169ms step_avg:147.25ms
step:1221/1390 train_time:178322ms step_avg:147.25ms
step:1222/1390 train_time:178476ms step_avg:147.26ms
step:1223/1390 train_time:178632ms step_avg:147.26ms
step:1224/1390 train_time:178789ms step_avg:147.27ms
step:1225/1390 train_time:178947ms step_avg:147.28ms
step:1226/1390 train_time:179102ms step_avg:147.29ms
step:1227/1390 train_time:179256ms step_avg:147.29ms
step:1228/1390 train_time:179408ms step_avg:147.30ms
step:1229/1390 train_time:179562ms step_avg:147.30ms
step:1230/1390 train_time:179724ms step_avg:147.31ms
step:1231/1390 train_time:179879ms step_avg:147.32ms
step:1232/1390 train_time:180036ms step_avg:147.33ms
step:1233/1390 train_time:180188ms step_avg:147.33ms
step:1234/1390 train_time:180340ms step_avg:147.34ms
step:1235/1390 train_time:180499ms step_avg:147.35ms
step:1236/1390 train_time:180656ms step_avg:147.35ms
step:1237/1390 train_time:180809ms step_avg:147.36ms
step:1238/1390 train_time:180976ms step_avg:147.37ms
step:1239/1390 train_time:181129ms step_avg:147.38ms
step:1240/1390 train_time:181287ms step_avg:147.39ms
step:1241/1390 train_time:181448ms step_avg:147.40ms
step:1242/1390 train_time:181602ms step_avg:147.40ms
step:1243/1390 train_time:181761ms step_avg:147.41ms
step:1244/1390 train_time:181915ms step_avg:147.42ms
step:1245/1390 train_time:182072ms step_avg:147.43ms
step:1246/1390 train_time:182225ms step_avg:147.43ms
step:1247/1390 train_time:182382ms step_avg:147.44ms
step:1248/1390 train_time:182537ms step_avg:147.44ms
step:1249/1390 train_time:182689ms step_avg:147.45ms
step:1250/1390 train_time:182843ms step_avg:147.45ms
step:1250/1390 val_loss:3.3380 train_time:182925ms step_avg:147.52ms
step:1251/1390 train_time:183009ms step_avg:147.47ms
step:1252/1390 train_time:183166ms step_avg:147.48ms
step:1253/1390 train_time:183319ms step_avg:147.48ms
step:1254/1390 train_time:183472ms step_avg:147.49ms
step:1255/1390 train_time:183639ms step_avg:147.50ms
step:1256/1390 train_time:183796ms step_avg:147.51ms
step:1257/1390 train_time:183951ms step_avg:147.51ms
step:1258/1390 train_time:184108ms step_avg:147.52ms
step:1259/1390 train_time:184264ms step_avg:147.53ms
step:1260/1390 train_time:184419ms step_avg:147.54ms
step:1261/1390 train_time:184576ms step_avg:147.54ms
step:1262/1390 train_time:184735ms step_avg:147.55ms
step:1263/1390 train_time:184892ms step_avg:147.56ms
step:1264/1390 train_time:185045ms step_avg:147.56ms
step:1265/1390 train_time:185198ms step_avg:147.57ms
step:1266/1390 train_time:185357ms step_avg:147.58ms
step:1267/1390 train_time:185513ms step_avg:147.58ms
step:1268/1390 train_time:185668ms step_avg:147.59ms
step:1269/1390 train_time:185829ms step_avg:147.60ms
step:1270/1390 train_time:185983ms step_avg:147.61ms
step:1271/1390 train_time:186139ms step_avg:147.61ms
step:1272/1390 train_time:186293ms step_avg:147.62ms
step:1273/1390 train_time:186450ms step_avg:147.62ms
step:1274/1390 train_time:186604ms step_avg:147.63ms
step:1275/1390 train_time:186762ms step_avg:147.64ms
step:1276/1390 train_time:186916ms step_avg:147.64ms
step:1277/1390 train_time:187071ms step_avg:147.65ms
step:1278/1390 train_time:187227ms step_avg:147.66ms
step:1279/1390 train_time:187384ms step_avg:147.66ms
step:1280/1390 train_time:187546ms step_avg:147.67ms
step:1281/1390 train_time:187702ms step_avg:147.68ms
step:1282/1390 train_time:187857ms step_avg:147.69ms
step:1283/1390 train_time:188013ms step_avg:147.69ms
step:1284/1390 train_time:188168ms step_avg:147.70ms
step:1285/1390 train_time:188323ms step_avg:147.70ms
step:1286/1390 train_time:188480ms step_avg:147.71ms
step:1287/1390 train_time:188638ms step_avg:147.72ms
step:1288/1390 train_time:188792ms step_avg:147.72ms
step:1289/1390 train_time:188955ms step_avg:147.74ms
step:1290/1390 train_time:189115ms step_avg:147.75ms
step:1291/1390 train_time:189272ms step_avg:147.75ms
step:1292/1390 train_time:189428ms step_avg:147.76ms
step:1293/1390 train_time:189590ms step_avg:147.77ms
step:1294/1390 train_time:189745ms step_avg:147.78ms
step:1295/1390 train_time:189901ms step_avg:147.78ms
step:1296/1390 train_time:190059ms step_avg:147.79ms
step:1297/1390 train_time:190218ms step_avg:147.80ms
step:1298/1390 train_time:190374ms step_avg:147.81ms
step:1299/1390 train_time:190530ms step_avg:147.81ms
step:1300/1390 train_time:190683ms step_avg:147.82ms
step:1301/1390 train_time:190838ms step_avg:147.82ms
step:1302/1390 train_time:190994ms step_avg:147.83ms
step:1303/1390 train_time:191153ms step_avg:147.84ms
step:1304/1390 train_time:191310ms step_avg:147.84ms
step:1305/1390 train_time:191464ms step_avg:147.85ms
step:1306/1390 train_time:191623ms step_avg:147.86ms
step:1307/1390 train_time:191779ms step_avg:147.86ms
step:1308/1390 train_time:191938ms step_avg:147.87ms
step:1309/1390 train_time:192095ms step_avg:147.88ms
step:1310/1390 train_time:192252ms step_avg:147.89ms
step:1311/1390 train_time:192403ms step_avg:147.89ms
step:1312/1390 train_time:192559ms step_avg:147.89ms
step:1313/1390 train_time:192714ms step_avg:147.90ms
step:1314/1390 train_time:192869ms step_avg:147.91ms
step:1315/1390 train_time:193025ms step_avg:147.91ms
step:1316/1390 train_time:193179ms step_avg:147.92ms
step:1317/1390 train_time:193338ms step_avg:147.92ms
step:1318/1390 train_time:193497ms step_avg:147.93ms
step:1319/1390 train_time:193652ms step_avg:147.94ms
step:1320/1390 train_time:193808ms step_avg:147.95ms
step:1321/1390 train_time:193962ms step_avg:147.95ms
step:1322/1390 train_time:194122ms step_avg:147.96ms
step:1323/1390 train_time:194278ms step_avg:147.97ms
step:1324/1390 train_time:194434ms step_avg:147.97ms
step:1325/1390 train_time:194593ms step_avg:147.98ms
step:1326/1390 train_time:194753ms step_avg:147.99ms
step:1327/1390 train_time:194906ms step_avg:147.99ms
step:1328/1390 train_time:195059ms step_avg:148.00ms
step:1329/1390 train_time:195232ms step_avg:148.01ms
step:1330/1390 train_time:195390ms step_avg:148.02ms
step:1331/1390 train_time:195596ms step_avg:148.07ms
step:1332/1390 train_time:195757ms step_avg:148.08ms
step:1333/1390 train_time:195915ms step_avg:148.08ms
step:1334/1390 train_time:196070ms step_avg:148.09ms
step:1335/1390 train_time:196222ms step_avg:148.09ms
step:1336/1390 train_time:196384ms step_avg:148.10ms
step:1337/1390 train_time:196543ms step_avg:148.11ms
step:1338/1390 train_time:196700ms step_avg:148.12ms
step:1339/1390 train_time:196858ms step_avg:148.13ms
step:1340/1390 train_time:197019ms step_avg:148.13ms
step:1341/1390 train_time:197171ms step_avg:148.14ms
step:1342/1390 train_time:197329ms step_avg:148.15ms
step:1343/1390 train_time:197484ms step_avg:148.15ms
step:1344/1390 train_time:197639ms step_avg:148.16ms
step:1345/1390 train_time:197794ms step_avg:148.16ms
step:1346/1390 train_time:197951ms step_avg:148.17ms
step:1347/1390 train_time:198109ms step_avg:148.17ms
step:1348/1390 train_time:198263ms step_avg:148.18ms
step:1349/1390 train_time:198419ms step_avg:148.18ms
step:1350/1390 train_time:198573ms step_avg:148.19ms
step:1351/1390 train_time:198732ms step_avg:148.20ms
step:1352/1390 train_time:198893ms step_avg:148.21ms
step:1353/1390 train_time:199054ms step_avg:148.22ms
step:1354/1390 train_time:199212ms step_avg:148.22ms
step:1355/1390 train_time:199365ms step_avg:148.23ms
step:1356/1390 train_time:199519ms step_avg:148.23ms
step:1357/1390 train_time:199676ms step_avg:148.24ms
step:1358/1390 train_time:199834ms step_avg:148.24ms
step:1359/1390 train_time:199989ms step_avg:148.25ms
step:1360/1390 train_time:200151ms step_avg:148.26ms
step:1361/1390 train_time:200308ms step_avg:148.27ms
step:1362/1390 train_time:200466ms step_avg:148.27ms
step:1363/1390 train_time:200629ms step_avg:148.28ms
step:1364/1390 train_time:200784ms step_avg:148.29ms
step:1365/1390 train_time:200938ms step_avg:148.29ms
step:1366/1390 train_time:201097ms step_avg:148.30ms
step:1367/1390 train_time:201256ms step_avg:148.31ms
step:1368/1390 train_time:201412ms step_avg:148.32ms
step:1369/1390 train_time:201577ms step_avg:148.33ms
step:1370/1390 train_time:201739ms step_avg:148.34ms
step:1371/1390 train_time:201896ms step_avg:148.34ms
step:1372/1390 train_time:202057ms step_avg:148.35ms
step:1373/1390 train_time:202214ms step_avg:148.36ms
step:1374/1390 train_time:202372ms step_avg:148.37ms
step:1375/1390 train_time:202525ms step_avg:148.37ms
step:1375/1390 val_loss:3.2855 train_time:202602ms step_avg:148.43ms
step:1376/1390 train_time:202682ms step_avg:148.38ms
step:1377/1390 train_time:202837ms step_avg:148.38ms
step:1378/1390 train_time:202991ms step_avg:148.39ms
step:1379/1390 train_time:203148ms step_avg:148.39ms
step:1380/1390 train_time:203304ms step_avg:148.40ms
step:1381/1390 train_time:203465ms step_avg:148.41ms
step:1382/1390 train_time:203622ms step_avg:148.41ms
step:1383/1390 train_time:203777ms step_avg:148.42ms
step:1384/1390 train_time:203937ms step_avg:148.43ms
step:1385/1390 train_time:204089ms step_avg:148.43ms
step:1386/1390 train_time:204246ms step_avg:148.43ms
step:1387/1390 train_time:204403ms step_avg:148.44ms
step:1388/1390 train_time:204559ms step_avg:148.45ms
step:1389/1390 train_time:204715ms step_avg:148.45ms
step:1390/1390 train_time:204871ms step_avg:148.46ms
step:1390/1390 val_loss:3.2838 train_time:204952ms step_avg:148.52ms
peak memory consumption: 31561 MiB
