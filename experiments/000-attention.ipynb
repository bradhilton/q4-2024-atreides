{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Get all markdown files in the data/markdown directory\n",
    "markdown_files = glob.glob(\"./data/markdown_results/*.md\")\n",
    "\n",
    "# Dictionary to store markdown contents\n",
    "markdown_contents = {}\n",
    "\n",
    "# Read each markdown file\n",
    "for file_path in markdown_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        markdown_contents[filename] = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'docs_openpipe_ai_api_reference_post_updatemetadata.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nLogs\\n\\nUpdate Metadata\\n\\nPOST\\n\\n/\\n\\nlogs\\n\\n/\\n\\nupdate-metadata\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/logs/update-metadata \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"filters\": [\\\\\\n    {\\\\\\n      \"field\": \"<string>\",\\\\\\n      \"equals\": \"<string>\"\\\\\\n    }\\\\\\n  ],\\n  \"metadata\": {}\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"matchedLogs\": 123\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-updatemetadata#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-updatemetadata#body-filters)\\n\\nfilters\\n\\nobject\\\\[\\\\]\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-updatemetadata#body-filters-equals)\\n\\nfilters.equals\\n\\nstringnumberboolean\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-updatemetadata#body-filters-field)\\n\\nfilters.field\\n\\nstring\\n\\nrequired\\n\\nThe field to filter on. Possible fields include: `model`, `completionId`, and `metadata.your_tag_name`.\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-updatemetadata#body-metadata)\\n\\nmetadata\\n\\nobject\\n\\nrequired\\n\\nExtra metadata to attach to the call for filtering. Eg { \"userId\": \"123\", \"prompt\\\\_id\": \"populate-title\" }\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-updatemetadata#body-metadata-key)\\n\\nmetadata.{key}\\n\\nstring \\\\| nullenum<string> \\\\| null\\n\\n#### Response\\n\\n200 - application/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-updatemetadata#response-matched-logs)\\n\\nmatchedLogs\\n\\nnumber\\n\\nrequired\\n\\n[Report Anthropic](https://docs.openpipe.ai/api-reference/post-report-anthropic) [Chat Completions](https://docs.openpipe.ai/api-reference/post-chatcompletions)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/logs/update-metadata \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"filters\": [\\\\\\n    {\\\\\\n      \"field\": \"<string>\",\\\\\\n      \"equals\": \"<string>\"\\\\\\n    }\\\\\\n  ],\\n  \"metadata\": {}\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"matchedLogs\": 123\\n}\\n```',\n",
       " 'docs_openpipe_ai_features_datasets_quick_start.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nDatasets\\n\\nDatasets Quick Start\\n\\nDatasets are the raw material for training models. They’re where you’ll go to collect, evaluate, and refine your training data.\\n\\n1\\n\\nCreate Dataset\\n\\nTo create a dataset, navigate to the **Datasets** tab and click **New Dataset**.\\n\\nYour dataset will be given a default name including the time at which it was created. We suggest editing the name to something more descriptive.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/datasets/editing-dataset-name.png)\\n\\n2\\n\\nImport Data\\n\\nNow that you have a shiny new dataset, you need to somehow import data into it. This can be done in one of two ways:\\n\\n1. [Importing request logs](https://docs.openpipe.ai/features/datasets/importing-logs)\\n2. [Uploading a file from your machine](https://docs.openpipe.ai/features/datasets/uploading-data)\\n\\nClick the links to learn more about each method.\\n\\n[Overview](https://docs.openpipe.ai/features/datasets/overview) [Importing Request Logs](https://docs.openpipe.ai/features/datasets/importing-logs)\\n\\n![](https://docs.openpipe.ai/features/datasets/quick-start',\n",
       " 'docs_openpipe_ai_features_criteria_api.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nCriteria\\n\\nAPI Endpoints\\n\\nAfter you’ve defined and aligned your judge criteria, you can access them via API endpoints for both runtime evaluation ( **Best of N** sampling) and offline testing.\\n\\n### [\\u200b](https://docs.openpipe.ai/features/criteria/api\\\\#runtime-evaluation)  Runtime Evaluation\\n\\nSee the Chat Completion [docs](https://docs.openpipe.ai/features/chat-completions/overview) and [API\\\\\\\\\\nReference](https://docs.openpipe.ai/api-reference/post-chatcompletions) for more information on making chat completions\\nwith OpenPipe.\\n\\nWhen making a request to the `/chat/completions` endpoint, you can specify a list of criteria to run immediately after a completion is generated. We recommend generating multiple responses from the same prompt, each of which will be scored by the specified criteria. The responses will be sorted by their combined score across all criteria, from highest to lowest. This technique is known as **[Best of N](https://huggingface.co/docs/trl/en/best_of_n)** sampling.\\n\\nTo invoke criteria, add an `op-criteria` header to your request with a list of criterion IDs, like so:\\n\\n- Python\\n- NodeJS\\n- cURL\\n\\nCopy\\n\\n```python\\nfrom openpipe import OpenAI\\n\\n# Find the config values in \"Installing the SDK\"\\nclient = OpenAI()\\n\\ncompletion = client.chat.completions.create(\\n    model=\"openai:gpt-4o-mini\",\\n    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\\n    metadata={\\n        \"prompt_id\": \"counting\",\\n        \"any_key\": \"any_value\",\\n    },\\n    n=5,\\n    extra_headers={\"op-criteria\": \\'[\"criterion-1@v1\", \"criterion-2\"]\\'},\\n)\\n\\nbest_response = completion.choices[0]\\n\\n```\\n\\nSpecified criteria can either be versioned, like `criterion-1@v1`, or default to the latest criterion version, like `criterion-2`.\\n\\nIn addition to the usual fields, each chat completion choice will now include a `criteria_results` object, which contains the judgements of the specified criteria. The array of completion choices will take the following form:\\n\\nCopy\\n\\n```json\\n[\\\\\\n  {\\\\\\n    \"finish_reason\": \"stop\",\\\\\\n    \"index\": 0,\\\\\\n    \"message\": {\\\\\\n      \"content\": \"1, 2, 3.\",\\\\\\n      \"refusal\": null,\\\\\\n      \"role\": \"assistant\"\\\\\\n    },\\\\\\n    \"logprobs\": null,\\\\\\n    \"criteria_results\": {\\\\\\n      \"criterion-1\": {\\\\\\n        \"status\": \"success\",\\\\\\n        \"score\": 1,\\\\\\n        \"explanation\": \"...\"\\\\\\n      },\\\\\\n      \"criterion-2\": {\\\\\\n        \"status\": \"success\",\\\\\\n        \"score\": 0.6,\\\\\\n        \"explanation\": \"...\"\\\\\\n      }\\\\\\n    }\\\\\\n  },\\\\\\n  {\\\\\\n    ...\\\\\\n  }\\\\\\n]\\n\\n```\\n\\n### [\\u200b](https://docs.openpipe.ai/features/criteria/api\\\\#offline-testing)  Offline Testing\\n\\nSee the [API Reference](https://docs.openpipe.ai/api-reference/post-criteriajudge) for more details.\\n\\nTo check the quality of a previously generated output against a specific criterion, use the `/criteria/judge` endpoint. You can request judgements using either the TypeScript or Python SDKs, or through a cURL request.\\n\\n- Python\\n- NodeJS\\n\\nCopy\\n\\n```python\\nfrom openpipe.client import OpenPipe\\n\\nop_client = OpenPipe()\\n\\nresult = op_client.get_criterion_judgement(\\n    criterion_id=\"criterion-1@v1\", # if no version is specified, the latest version is used\\n    input={\"messages\": messages},\\n    output=output,\\n)\\n\\n```\\n\\n[Alignment Sets](https://docs.openpipe.ai/features/criteria/alignment-set) [Overview](https://docs.openpipe.ai/features/chat-completions/overview)\\n\\nOn this page\\n\\n- [Runtime Evaluation](https://docs.openpipe.ai/features/criteria/api#runtime-evaluation)\\n- [Offline Testing](https://docs.openpipe.ai/features/criteria/api#offline-testing',\n",
       " 'docs_openpipe_ai_features_request_logs_reporting_anthropic.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nRequest Logs\\n\\nLogging Anthropic Requests\\n\\nAnthropic’s language models have a different API structure than those of OpenAI.\\nTo record requests made to Anthropic’s models, follow the examples below:\\n\\n- Python\\n- NodeJS\\n\\nCopy\\n\\n```python\\nimport time\\nfrom anthropic import Anthropic\\nfrom openpipe.client import OpenPipe\\n\\nanthropic = Anthropic()\\nop_client = OpenPipe()\\n\\npayload = {\\n    \"model\": \"claude-3-opus-20240229\",\\n    \"messages\": [{\"role\": \"user\", \"content\": \"Hello, Claude\"}],\\n    \"max_tokens\": 100,\\n}\\n\\nmessage = anthropic.messages.create(**payload)\\n\\nop_client.report_anthropic(\\n    requested_at=int(time.time() * 1000),\\n    received_at=int(time.time() * 1000),\\n    req_payload=payload,\\n    resp_payload=message,\\n    status_code=200,\\n    metadata={\\n        \"prompt_id\": \"My prompt id\",\\n    },\\n)\\n\\n```\\n\\nIf you’re using a different programming language, you can make a raw http request to the [report-anthropic](https://docs.openpipe.ai/api-reference/post-report-anthropic) enpoint.\\n\\n[Logging Requests](https://docs.openpipe.ai/features/request-logs/logging-requests) [Exporting Logs](https://docs.openpipe.ai/features/request-logs/exporting-logs',\n",
       " 'docs_openpipe_ai_features_datasets_overview.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nDatasets\\n\\nDatasets\\n\\nDatasets are the raw material for training models. They can be scraped from your request logs or uploaded from your local machine.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/datasets/overview.png)\\n\\nTo learn how to create a dataset, check out the [Quick Start](https://docs.openpipe.ai/features/datasets/quick-start) guide.\\n\\n[Exporting Logs](https://docs.openpipe.ai/features/request-logs/exporting-logs) [Quick Start](https://docs.openpipe.ai/features/datasets/quick-start)\\n\\n![](https://docs.openpipe.ai/features/datasets/overview',\n",
       " 'docs_openpipe_ai_api_reference_delete_dataset.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nDatasets\\n\\nDelete Dataset\\n\\nDELETE\\n\\n/\\n\\ndatasets\\n\\n/\\n\\n{datasetId}\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request DELETE \\\\\\n  --url https://api.openpipe.ai/api/v1/datasets/{datasetId} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"id\": \"<string>\",\\n  \"object\": \"dataset\",\\n  \"deleted\": true\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/delete-dataset#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Path Parameters\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/delete-dataset#parameter-dataset-id)\\n\\ndatasetId\\n\\nstring\\n\\nrequired\\n\\n#### Response\\n\\n200 - application/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/delete-dataset#response-deleted)\\n\\ndeleted\\n\\nboolean\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/delete-dataset#response-id)\\n\\nid\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/delete-dataset#response-object)\\n\\nobject\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`dataset`\\n\\n[List Datasets](https://docs.openpipe.ai/api-reference/get-listDatasets) [Add Entries to Dataset](https://docs.openpipe.ai/api-reference/post-createDatasetEntries)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request DELETE \\\\\\n  --url https://api.openpipe.ai/api/v1/datasets/{datasetId} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"id\": \"<string>\",\\n  \"object\": \"dataset\",\\n  \"deleted\": true\\n}\\n```',\n",
       " 'docs_openpipe_ai_features_fine_tuning_webapp.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nFine Tuning\\n\\nFine Tuning via Webapp\\n\\nOpenPipe allows you to train, evaluate, and deploy your models all in the same place. We recommend training your models\\nthrough the webapp, which provides more flexibility and a smoother experience than the API. To fine-tune a new model, follow these steps:\\n\\n1. Create a new dataset or navigate to an existing one.\\n2. Click “Fine Tune” in the top right.\\n3. Select a base model.\\n4. (Optional) Set custom hyperparameters and configure [pruning rules](https://docs.openpipe.ai/features/pruning-rules).\\n5. Click “Start Training” to kick off the job.\\n\\nOnce started, your model’s training job will take at least a few minutes and potentially several hours, depending on the size of the\\nmodel and the amount of data. You can check your model’s status by navigating to the Fine Tunes page and selecting your model.\\n\\nFor an example of how an OpenPipe model looks once it’s trained, see our public [PII Redaction](https://app.openpipe.ai/p/BRZFEx50Pf/fine-tunes/6076ad69-cce5-4892-ae54-e0549bbe107f/general) model. Feel free to hit it with some sample queries!\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/fine-tuning.png)\\n\\n[Quick Start](https://docs.openpipe.ai/features/fine-tuning/quick-start) [API (Beta)](https://docs.openpipe.ai/features/fine-tuning/api)\\n\\n![](https://docs.openpipe.ai/features/fine-tuning/webapp',\n",
       " 'docs_openpipe_ai_features_fallback.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nFeatures\\n\\nFallback options\\n\\nFallback is a feature that ensures a seamless experience and guarantees 100% uptime when working with new or unstable models.\\n\\nWhen fallback is enabled, any failed API calls will be automatically retried using OpenAI or any OpenAI-compatible client.\\n\\n## [\\u200b](https://docs.openpipe.ai/features/fallback\\\\#fallback-to-openai)  Fallback to OpenAI\\n\\nTo enable fallback to OpenAI, you can simply pass the `fallback` option to the `openpipe` object with the `model` property set to the OpenAI model you want to fall back to.\\n\\n- Python\\n- NodeJS\\n\\nCopy\\n\\n```python\\nfrom openpipe import OpenAI\\n\\nclient = OpenAI()\\n\\ncompletion = client.chat.completions.create(\\n    model=\"openpipe:my-ft-model\",\\n    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\\n    openpipe={\\n        \"fallback\": {\\n            \"model\": \"gpt-4-turbo\"\\n        }\\n    },\\n)\\n\\n```\\n\\n## [\\u200b](https://docs.openpipe.ai/features/fallback\\\\#timeout-fallback)  Timeout Fallback\\n\\nIf a request takes too long to execute, you can set a timeout for the fallback.\\nIn the example below, the request will fall back to OpenAI after 10 seconds.\\n\\n- Python\\n- NodeJS\\n\\nCopy\\n\\n```python\\nfrom openpipe import OpenAI\\n\\nclient = OpenAI(timeout=10) # initial OpenPipe call timeout in seconds\\n\\ncompletion = client.chat.completions.create(\\n    model=\"openpipe:my-ft-model\",\\n    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\\n    openpipe={\\n        \"fallback\": {\\n            \"model\": \"gpt-4-turbo\",\\n            # optional fallback timeout. Defaults to the timeout specified in the client, or OpenAI default timeout if not set.\\n            \"timeout\": 20 # seconds\\n        }\\n    },\\n)\\n\\n```\\n\\n## [\\u200b](https://docs.openpipe.ai/features/fallback\\\\#fallback-to-custom-openai-compatible-client)  Fallback to Custom OpenAI Compatible Client\\n\\nIf you want to use another OpenAI-compatible fallback client, you can pass a `fallback_client` to the `openpipe` object.\\n\\n- Python\\n- NodeJS\\n\\nCopy\\n\\n```python\\nfrom openpipe import OpenAI\\n\\nclient = OpenAI(\\n    openpipe={\\n        \"fallback_client\": OpenAICompatibleClient(api_key=\"client api key\")\\n    }\\n);\\n\\ncompletion = client.chat.completions.create(\\n    model=\"openpipe:my-ft-model\",\\n    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\\n    openpipe={\\n        \"fallback\": { \"model\": \"gpt-4-turbo\" }\\n    },\\n)\\n\\n```\\n\\n[Pruning Rules](https://docs.openpipe.ai/features/pruning-rules) [Mixture of Agents](https://docs.openpipe.ai/features/mixture-of-agents)\\n\\nOn this page\\n\\n- [Fallback to OpenAI](https://docs.openpipe.ai/features/fallback#fallback-to-openai)\\n- [Timeout Fallback](https://docs.openpipe.ai/features/fallback#timeout-fallback)\\n- [Fallback to Custom OpenAI Compatible Client](https://docs.openpipe.ai/features/fallback#fallback-to-custom-openai-compatible-client',\n",
       " 'docs_openpipe_ai_features_evaluations_quick_start.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nEvaluations\\n\\nEvaluations Quick Start\\n\\nIn this quick start guide, we’ll walk you through creating your first head-to-head evaluation. Head to head evaluations allow you to compare two or more models\\nusing an LLM judge that compares outputs against one another based on custom instructions.\\n\\n**Before you begin:** Before writing your first eval, make sure you’ve [created a\\\\\\\\\\ndataset](https://docs.openpipe.ai/features/datasets/quick-start) with one or more test entries. Also, make sure to add\\nyour OpenAI or Anthropic API key in your project settings page to allow the judge LLM to run.\\n\\n### [\\u200b](https://docs.openpipe.ai/features/evaluations/quick-start\\\\#writing-an-evaluation)  Writing an Evaluation\\n\\n1\\n\\nChoose a dataset to evaluate models on\\n\\nTo create an eval, navigate to the dataset with the test entries you’d like to evaluate your models based on.\\nFind the **Evaluate** tab and click the **+** button to the right of the **Evals** dropdown list.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/eval-button.png)\\n\\nA configuration modal will appear.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/create-h2h-eval.png)\\n\\n2\\n\\nEdit judge model instructions\\n\\nCustomize the judge LLM instructions. The outputs of each model will be compared against one another\\npairwise and a score of WIN, LOSS, or TIE will be assigned to each model’s based on the judge’s instructions.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/edit-judge-instructions.png)\\n\\n3\\n\\nSelect judge model\\n\\nChoose a judge model from the dropdown list. If you’d like to use a judge model that isn’t supported by default,\\nadd it as an [external model](https://docs.openpipe.ai/features/chat-completions/external-models) in your project settings page.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/select-judge-model.png)\\n\\n4\\n\\nChoose models to evaluate\\n\\nChoose the models you’d like to evaluate against one another.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/choose-evaluated-models.png)\\n\\n5\\n\\nRun the evaluation\\n\\nClick **Create** to start running the eval.\\n\\nOnce the eval is complete, you can see model performance in the evaluation’s **Results** tab.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/quick-start-results.png)\\n\\nTo learn more about customizing the judge LLM instructions and viewing evaluation judgements in greater detail,\\nsee the [Head-to-Head Evaluations](https://docs.openpipe.ai/features/evaluations/head-to-head) page.\\n\\n[Overview](https://docs.openpipe.ai/features/evaluations/overview) [Code Evals](https://docs.openpipe.ai/features/evaluations/code)\\n\\nOn this page\\n\\n- [Writing an Evaluation](https://docs.openpipe.ai/features/evaluations/quick-start#writing-an-evaluation)\\n\\n![](https://docs.openpipe.ai/features/evaluations/quick-start)\\n\\n![](https://docs.openpipe.ai/features/evaluations/quick-start)\\n\\n![](https://docs.openpipe.ai/features/evaluations/quick-start)\\n\\n![](https://docs.openpipe.ai/features/evaluations/quick-start)\\n\\n![](https://docs.openpipe.ai/features/evaluations/quick-start)\\n\\n![](https://docs.openpipe.ai/features/evaluations/quick-start',\n",
       " 'docs_openpipe_ai_features_criteria_quick_start.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nCriteria\\n\\nCriteria Quick Start\\n\\nCriteria are a reliable way to detect and correct mistakes in LLM output. Criteria can be used when defining LLM evaluations, improving data quality, and for [runtime evaluation](https://docs.openpipe.ai/features/criteria/api#runtime-evaluation) when generating **best of N** samples.\\nThis tutorial will walk you through creating and aligning your first criterion.\\n\\n**Before you begin:** Before creating your first criterion, you should identify an issue with\\nyour model’s output that you want to detect and correct. You should also have either an OpenPipe\\n[dataset](https://docs.openpipe.ai/features/datasets/overview) or a [JSONL\\\\\\\\\\nfile](https://docs.openpipe.ai/features/criteria/alignment-set#importing-from-a-jsonl-file) containing several rows of\\ndata that exhibit the issue, and several that don’t.\\n\\n### [\\u200b](https://docs.openpipe.ai/features/criteria/quick-start\\\\#creating-a-criterion)  Creating a Criterion\\n\\n1\\n\\nOpen the creation modal\\n\\nNavigate to the **Criteria** tab and click the **New Criterion** button.\\nThe creation modal will open with a default prompt and judge model.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/create-criterion.png)\\n\\nBy default, each of the following fields will be templated into the criterion’s prompt when assigning a judgement to an output:\\n\\n- `messages` _(optional):_ The messages used to generate the output\\n- `tools` _(optional):_ The tools used to generate the output\\n- `tool_choice` _(optional):_ The tool choice used to generate the output\\n- `output` _(required):_ The chat completion object to be judged\\n\\nMany criteria do not require all of the input fields, and some may judge based soley on the `output`. You can exclude fields by removing them from the **Templated Variables** section.\\n\\n2\\n\\nDraft an initial prompt\\n\\nWrite an initial LLM prompt with basic instructions for identifying rows containing\\nthe issue you want to detect and correct. Don’t worry about engineering a perfect\\nprompt, you’ll have a chance to improve it during the alignment process.\\n\\nAs an example, if you want to detect rows in which the model’s output is in a different language than the input,\\nyou might write a prompt like this:\\n\\nCopy\\n\\n```\\nMark the criteria as passed if the input and output are the same language.\\nMark it as failed if they are in different languages.\\n\\n```\\n\\nMake sure to use the terms `input`, `output`, `passed`, and `failed` in your prompt to match our\\ninternal templating.\\n\\nFinally, import a few rows (we recommend at least 30) into an alignment set for the criterion.\\n\\n3\\n\\nConfirm creation\\n\\nClick **Create** to create the criterion and run the initial prompt against the imported alignment set.\\nYou’ll be redirected to the criterion’s alignment page.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/overview.png)\\n\\n### [\\u200b](https://docs.openpipe.ai/features/criteria/quick-start\\\\#aligning-a-criterion)  Aligning a Criterion\\n\\nEnsuring your criterion’s judgements are reliable involves two simple processes:\\n\\n- Manually labeling outputs\\n- Refining the criterion\\n\\n1\\n\\nManually labeling outputs\\n\\nIn order to know whether you agree with your criterion’s judgements, you’ll need to label some data yourself.\\nUse the Alignment UI to manually label each output with `PASS` or `FAIL` based on the criterion. Feel free to `SKIP` outputs you aren’t sure about and come back to them later.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/manually-label.png)\\n\\nTry to label at least 30 rows to provide a reliable estimate of the LLM’s precision and recall.\\n\\n2\\n\\nRefining the criterion\\n\\nAs you record your own judgements, alter the criterion’s prompt and judge model to align its judgements with your own.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/edit-criterion.png)\\n\\nInvesting time in a good prompt and selecting the best judge model pays dividends.\\nHigh-quality LLM judgements help you quickly identify rows that fail the criterion, speeding up the process of manually labeling rows.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/llm-judgement.png)\\n\\nAs you improve your criterion prompt, you’ll notice your [alignment stats](https://docs.openpipe.ai/features/criteria/alignment-set#alignment-stats) improving.\\nOnce you’ve labeled at least 30 rows and are satisfied with the precision and recall of your LLM judge, the criterion is ready to be deployed!\\n\\n### [\\u200b](https://docs.openpipe.ai/features/criteria/quick-start\\\\#deploying-a-criterion)  Deploying a Criterion\\n\\nThe simplest way to deploy a criterion is to create a criterion eval. Unlike head to head evals, criterion evals are not pairwise comparisons.\\nInstead, they evaluate the quality of one or more models’ output according to a specific criterion.\\n\\nFirst, navigate to the Evals tab and click **New Evaluation** -\\\\> **Add criterion eval**.\\n\\nPick the models to evaluate and the test dataset on which to evaluate them. Next, select the criterion you would like to judge your models against.\\nThe judge model and prompt you defined when creating the criterion will be used to judge individual outputs from your models.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/create-criterion-eval.png)\\n\\nFinally, click **Create** to run the evaluation. Just like that, you’re be able to view evaluation results based on aligned LLM judgements!\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/criterion-eval-results.png)\\n\\n[Overview](https://docs.openpipe.ai/features/criteria/overview) [Alignment Sets](https://docs.openpipe.ai/features/criteria/alignment-set)\\n\\nOn this page\\n\\n- [Creating a Criterion](https://docs.openpipe.ai/features/criteria/quick-start#creating-a-criterion)\\n- [Aligning a Criterion](https://docs.openpipe.ai/features/criteria/quick-start#aligning-a-criterion)\\n- [Deploying a Criterion](https://docs.openpipe.ai/features/criteria/quick-start#deploying-a-criterion)\\n\\n![](https://docs.openpipe.ai/features/criteria/quick-start)\\n\\n![](https://docs.openpipe.ai/features/criteria/quick-start)\\n\\n![](https://docs.openpipe.ai/features/criteria/quick-start)\\n\\n![](https://docs.openpipe.ai/features/criteria/quick-start)\\n\\n![](https://docs.openpipe.ai/features/criteria/quick-start)\\n\\n![](https://docs.openpipe.ai/features/criteria/quick-start)\\n\\n![](https://docs.openpipe.ai/features/criteria/quick-start',\n",
       " 'docs_openpipe_ai_features_evaluations_criterion.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nEvaluations\\n\\nCriterion Evaluations\\n\\nCriterion evaluations are useful for evaluating your LLM outputs against a set of criteria. If you\\nhaven’t defined any criteria yet, check out the criteria [Quick\\\\\\\\\\nStart](https://docs.openpipe.ai/features/criteria/quick-start) guide.\\n\\nCriterion evaluations are a reliable way to judge the quality of your LLM outputs according to the criteria you’ve defined. For each model being evaluated, the output of that model is compared against the criteria you’ve defined for every entry in the evaluation dataset.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/criterion-eval-settings.png)\\n\\nA criterion evaluation is only as reliable as the criterion you’ve defined. To improve your\\ncriterion, check out the [alignment docs](https://docs.openpipe.ai/features/criteria/alignment-set).\\n\\nEach output in the evaluation dataset is compared against the criterion you’ve defined. The output is then scored as either `PASS` or `FAIL` based on the criterion.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/criterion-eval-results-table.png)\\n\\nTo see why one model might be outperforming another, you can navigate back to the [evaluation table](https://app.openpipe.ai/p/BRZFEx50Pf/datasets/3e7e82c1-b066-476c-9f17-17fd85a2169b/evaluate) and click on a result pill to see the evaluation judge’s reasoning.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/criterion-eval-explanation.png)\\n\\nWhile criterion evaluations are powerful and flexible, they’re much more expensive to run than pure code. If your models’ outputs can be easily evaluated by code alone, consider using [code evaluations](https://docs.openpipe.ai/features/evaluations/code) instead.\\n\\n[Code Evals](https://docs.openpipe.ai/features/evaluations/code) [Head-to-Head Evals](https://docs.openpipe.ai/features/evaluations/head-to-head)\\n\\n![](https://docs.openpipe.ai/features/evaluations/criterion)\\n\\n![](https://docs.openpipe.ai/features/evaluations/criterion)\\n\\n![](https://docs.openpipe.ai/features/evaluations/criterion',\n",
       " 'docs_openpipe_ai_api_reference_post_createModel.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nModels\\n\\nCreate Model\\n\\nPOST\\n\\n/\\n\\nmodels\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/models \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"datasetId\": \"<string>\",\\n  \"slug\": \"<string>\",\\n  \"pruningRuleIds\": [],\\n  \"trainingConfig\": {\\n    \"provider\": \"openpipe\",\\n    \"baseModel\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\\n    \"enable_sft\": true,\\n    \"enable_preference_tuning\": false,\\n    \"sft_hyperparameters\": {},\\n    \"preference_hyperparameters\": {},\\n    \"hyperparameters\": {\\n      \"is_sft_enabled\": true,\\n      \"batch_size\": \"auto\",\\n      \"learning_rate_multiplier\": 123,\\n      \"num_epochs\": 123,\\n      \"is_preference_tuning_enabled\": true,\\n      \"preference_tuning_variant\": \"DPO\",\\n      \"preference_tuning_learning_rate_multiplier\": 123,\\n      \"preference_tuning_num_epochs\": 123,\\n      \"preference_tuning_training_beta\": 123,\\n      \"preference_tuning_adapter_weight\": 123\\n    }\\n  },\\n  \"defaultTemperature\": 123\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"id\": \"<string>\",\\n  \"name\": \"<string>\",\\n  \"object\": \"model\",\\n  \"description\": \"<string>\",\\n  \"created\": \"<string>\",\\n  \"updated\": \"<string>\",\\n  \"openpipe\": {\\n    \"baseModel\": \"<string>\",\\n    \"hyperparameters\": {},\\n    \"status\": \"PENDING\",\\n    \"datasetId\": \"<string>\",\\n    \"errorMessage\": \"<string>\"\\n  },\\n  \"contextWindow\": 123,\\n  \"maxCompletionTokens\": 123,\\n  \"capabilities\": [\\\\\\n    \"chat\"\\\\\\n  ],\\n  \"pricing\": {\\n    \"chatIn\": 123,\\n    \"chatOut\": 123\\n  },\\n  \"owned_by\": \"<string>\"\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-dataset-id)\\n\\ndatasetId\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-slug)\\n\\nslug\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config)\\n\\ntrainingConfig\\n\\nobject\\n\\nrequired\\n\\n- Option 1\\n- Option 2\\n- Option 3\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-base-model)\\n\\ntrainingConfig.baseModel\\n\\nenum<string>string\\n\\nrequired\\n\\nThe base model to train from. This could be a base model name or the slug of a previously trained model.\\n\\nAvailable options:\\n\\n`meta-llama/Meta-Llama-3.1-8B-Instruct`,\\n\\n`meta-llama/Meta-Llama-3.1-70B-Instruct`,\\n\\n`meta-llama/Llama-3.3-70B-Instruct`,\\n\\n`meta-llama/Llama-3.1-8B`,\\n\\n`meta-llama/Llama-3.1-70B`,\\n\\n`Qwen/Qwen2.5-72B-Instruct`,\\n\\n`Qwen/Qwen2.5-Coder-32B-Instruct`,\\n\\n`Qwen/Qwen2.5-1.5B-Instruct`,\\n\\n`Qwen/Qwen2.5-7B-Instruct`,\\n\\n`mistralai/Mistral-Nemo-Base-2407`,\\n\\n`mistralai/Mistral-Small-24B-Base-2501`,\\n\\n`meta-llama/Llama-3.2-1B-Instruct`,\\n\\n`meta-llama/Llama-3.2-3B-Instruct`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-provider)\\n\\ntrainingConfig.provider\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`openpipe`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-enable-preference-tuning)\\n\\ntrainingConfig.enable\\\\_preference\\\\_tuning\\n\\nboolean\\n\\ndefault:\\n\\nfalse\\n\\nWhether to enable DPO training. If true, the model will be trained using DPO. Can be used in conjunction with SFT training.\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-enable-sft)\\n\\ntrainingConfig.enable\\\\_sft\\n\\nboolean\\n\\ndefault:\\n\\ntrue\\n\\nWhether to enable SFT training. If true, the model will be trained using SFT. Can be used in conjunction with DPO training.\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters)\\n\\ntrainingConfig.hyperparameters\\n\\nobject\\n\\nDEPRECATED: Use the `sft_hyperparameters` and `preference_hyperparameters` fields instead.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-batch-size)\\n\\ntrainingConfig.hyperparameters.batch\\\\_size\\n\\nenum<string>number\\n\\nAvailable options:\\n\\n`auto`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-is-preference-tuning-enabled)\\n\\ntrainingConfig.hyperparameters.is\\\\_preference\\\\_tuning\\\\_enabled\\n\\nboolean\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-is-sft-enabled)\\n\\ntrainingConfig.hyperparameters.is\\\\_sft\\\\_enabled\\n\\nboolean\\n\\ndefault:\\n\\ntrue\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-learning-rate-multiplier)\\n\\ntrainingConfig.hyperparameters.learning\\\\_rate\\\\_multiplier\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-num-epochs)\\n\\ntrainingConfig.hyperparameters.num\\\\_epochs\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-preference-tuning-adapter-weight)\\n\\ntrainingConfig.hyperparameters.preference\\\\_tuning\\\\_adapter\\\\_weight\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-preference-tuning-learning-rate-multiplier)\\n\\ntrainingConfig.hyperparameters.preference\\\\_tuning\\\\_learning\\\\_rate\\\\_multiplier\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-preference-tuning-num-epochs)\\n\\ntrainingConfig.hyperparameters.preference\\\\_tuning\\\\_num\\\\_epochs\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-preference-tuning-training-beta)\\n\\ntrainingConfig.hyperparameters.preference\\\\_tuning\\\\_training\\\\_beta\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-preference-tuning-variant)\\n\\ntrainingConfig.hyperparameters.preference\\\\_tuning\\\\_variant\\n\\nOption 1 · enum<string>Option 2 · enum<string>\\n\\nAvailable options:\\n\\n`DPO`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-preference-hyperparameters)\\n\\ntrainingConfig.preference\\\\_hyperparameters\\n\\nobject\\n\\nHyperparameters for DPO training job. Ensure `enable_preference_tuning` is true. If no preference hyperparameters are provided, default values will be used.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-preference-hyperparameters-adapter-weight)\\n\\ntrainingConfig.preference\\\\_hyperparameters.adapter\\\\_weight\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-preference-hyperparameters-learning-rate-multiplier)\\n\\ntrainingConfig.preference\\\\_hyperparameters.learning\\\\_rate\\\\_multiplier\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-preference-hyperparameters-num-epochs)\\n\\ntrainingConfig.preference\\\\_hyperparameters.num\\\\_epochs\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-preference-hyperparameters-training-beta)\\n\\ntrainingConfig.preference\\\\_hyperparameters.training\\\\_beta\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-preference-hyperparameters-variant)\\n\\ntrainingConfig.preference\\\\_hyperparameters.variant\\n\\nOption 1 · enum<string>Option 2 · enum<string>\\n\\nAvailable options:\\n\\n`DPO`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-sft-hyperparameters)\\n\\ntrainingConfig.sft\\\\_hyperparameters\\n\\nobject\\n\\nHyperparameters for SFT training job. Ensure `enable_sft` is true. If no SFT hyperparameters are provided, default values will be used.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-sft-hyperparameters-batch-size)\\n\\ntrainingConfig.sft\\\\_hyperparameters.batch\\\\_size\\n\\nenum<string>number\\n\\nAvailable options:\\n\\n`auto`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-sft-hyperparameters-learning-rate-multiplier)\\n\\ntrainingConfig.sft\\\\_hyperparameters.learning\\\\_rate\\\\_multiplier\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-sft-hyperparameters-num-epochs)\\n\\ntrainingConfig.sft\\\\_hyperparameters.num\\\\_epochs\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-default-temperature)\\n\\ndefaultTemperature\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#body-pruning-rule-ids)\\n\\npruningRuleIds\\n\\nstring\\\\[\\\\]\\n\\n#### Response\\n\\n200 - application/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-capabilities)\\n\\ncapabilities\\n\\nenum<string>\\\\[\\\\]\\n\\nrequired\\n\\nAvailable options:\\n\\n`chat`,\\n\\n`tools`,\\n\\n`json`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-context-window)\\n\\ncontextWindow\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-created)\\n\\ncreated\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-description)\\n\\ndescription\\n\\nstring \\\\| null\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-id)\\n\\nid\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-max-completion-tokens)\\n\\nmaxCompletionTokens\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-name)\\n\\nname\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-object)\\n\\nobject\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`model`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-openpipe)\\n\\nopenpipe\\n\\nobject\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-openpipe-base-model)\\n\\nopenpipe.baseModel\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-openpipe-dataset-id)\\n\\nopenpipe.datasetId\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-openpipe-error-message)\\n\\nopenpipe.errorMessage\\n\\nstring \\\\| null\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-openpipe-hyperparameters)\\n\\nopenpipe.hyperparameters\\n\\nobject \\\\| null\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-openpipe-hyperparameters-key)\\n\\nopenpipe.hyperparameters.{key}\\n\\nany\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-openpipe-status)\\n\\nopenpipe.status\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`PENDING`,\\n\\n`TRAINING`,\\n\\n`DEPLOYED`,\\n\\n`ERROR`,\\n\\n`DEPRECATED`,\\n\\n`PENDING_DEPRECATION`,\\n\\n`QUEUED`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-owned-by)\\n\\nowned\\\\_by\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-pricing)\\n\\npricing\\n\\nobject\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-pricing-chat-in)\\n\\npricing.chatIn\\n\\nnumber\\n\\nrequired\\n\\n$/million tokens\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-pricing-chat-out)\\n\\npricing.chatOut\\n\\nnumber\\n\\nrequired\\n\\n$/million tokens\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createModel#response-updated)\\n\\nupdated\\n\\nstring\\n\\nrequired\\n\\n[Add Entries to Dataset](https://docs.openpipe.ai/api-reference/post-createDatasetEntries) [Get Model](https://docs.openpipe.ai/api-reference/get-getModel)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/models \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"datasetId\": \"<string>\",\\n  \"slug\": \"<string>\",\\n  \"pruningRuleIds\": [],\\n  \"trainingConfig\": {\\n    \"provider\": \"openpipe\",\\n    \"baseModel\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\\n    \"enable_sft\": true,\\n    \"enable_preference_tuning\": false,\\n    \"sft_hyperparameters\": {},\\n    \"preference_hyperparameters\": {},\\n    \"hyperparameters\": {\\n      \"is_sft_enabled\": true,\\n      \"batch_size\": \"auto\",\\n      \"learning_rate_multiplier\": 123,\\n      \"num_epochs\": 123,\\n      \"is_preference_tuning_enabled\": true,\\n      \"preference_tuning_variant\": \"DPO\",\\n      \"preference_tuning_learning_rate_multiplier\": 123,\\n      \"preference_tuning_num_epochs\": 123,\\n      \"preference_tuning_training_beta\": 123,\\n      \"preference_tuning_adapter_weight\": 123\\n    }\\n  },\\n  \"defaultTemperature\": 123\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"id\": \"<string>\",\\n  \"name\": \"<string>\",\\n  \"object\": \"model\",\\n  \"description\": \"<string>\",\\n  \"created\": \"<string>\",\\n  \"updated\": \"<string>\",\\n  \"openpipe\": {\\n    \"baseModel\": \"<string>\",\\n    \"hyperparameters\": {},\\n    \"status\": \"PENDING\",\\n    \"datasetId\": \"<string>\",\\n    \"errorMessage\": \"<string>\"\\n  },\\n  \"contextWindow\": 123,\\n  \"maxCompletionTokens\": 123,\\n  \"capabilities\": [\\\\\\n    \"chat\"\\\\\\n  ],\\n  \"pricing\": {\\n    \"chatIn\": 123,\\n    \"chatOut\": 123\\n  },\\n  \"owned_by\": \"<string>\"\\n}\\n```',\n",
       " 'docs_openpipe_ai_features_fine_tuning_api.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nFine Tuning\\n\\nFine Tuning via API (Beta)\\n\\nWe’ve made fine-tuning via API available through unstable routes that are subject to change. For most users,\\nwe highly recommend fine-tuning through the Webapp to achieve optimal performance with a smooth experience.\\nHowever, some users may prefer to fine-tune via API for custom use cases.\\n\\nThe following base models are supported for general access:\\n\\n- `OpenPipe/Hermes-2-Theta-Llama-3-8B-32k`\\n- `meta-llama/Meta-Llama-3-8B-Instruct`\\n- `meta-llama/Meta-Llama-3-70B-Instruct`\\n- `OpenPipe/mistral-ft-optimized-1227`\\n- `mistralai/Mixtral-8x7B-Instruct-v0.1`\\n\\nLearn more about fine-tuning via API on the [route page](https://docs.openpipe.ai/api-reference/post-unstablefinetunecreate).\\nPlease contact us at [hello@openpipe.ai](mailto:hello@openpipe.ai) if you would like help getting set up.\\n\\n[Webapp](https://docs.openpipe.ai/features/fine-tuning/webapp) [Overview](https://docs.openpipe.ai/features/dpo/overview',\n",
       " 'docs_openpipe_ai_features_dpo_overview.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nDirect Preference Optimization (DPO)\\n\\nDirect Preference Optimization (DPO)\\n\\nDPO is much harder to get right than supervised fine-tuning, and the results may not always be\\nbetter. To get the most out of DPO, we recommend familiarizing yourself with your specific use\\ncase, your dataset, and the technique itself.\\n\\nDirect Preference Optimization (DPO), introduced in [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/abs/2106.13358), is an algorithm used to fine-tune LLMs based on preference feedback.\\n\\nIt focuses on aligning model outputs with specific human preferences or desired behaviors. Unlike traditional supervised fine-tuning, which relies solely on input-output pairs, DPO leverages preference data—information about which of two outputs is preferred in a given context.\\n\\nDPO works by directly optimizing a model to produce preferred outputs over non-preferred ones, without the need for complex reward modeling or reinforcement learning techniques. It uses paired data samples, where each pair consists of a preferred and a non-preferred response to a given prompt. This method allows the model to learn nuanced distinctions that are difficult to capture with explicit labels alone. By directly optimizing for preferences, DPO enables the creation of models that produce more aligned, contextually appropriate, and user-satisfying responses.\\n\\n## [\\u200b](https://docs.openpipe.ai/features/dpo/overview\\\\#gathering-preference-data)  Gathering Preference Data\\n\\nDPO is useful when you have a source of preference data that you can exploit. There are many possible sources of preference data, depending on your use case:\\n\\n1. **Expert Feedback**: you may have a team of experts who can evaluate your model’s outputs and edit them to make them better. You can use the original and edited outputs as rejected and preferred outputs respectively. DPO can be effective with just a few preference pairs.\\n2. **Criteria Feedback**: if you use [OpenPipe criteria](https://docs.openpipe.ai/features/criteria/overview) or another evaluation framework that assigns a score or pass/fail to an output based on how well it meets certain criteria, you can run several generations and use the highest and lowest scoring outputs as preferred and non-preferred outputs respectively.\\n3. **User Choice**: if you have a chatbot-style interface where users can select their preferred response from a list of generated outputs, you can use the selected and rejected outputs as preference data.\\n4. **User Regenerations**: if a user is able to regenerate an action multiple times and then eventually accepts one of the outputs, you can use the first output they rejected as a non-preferred output and the accepted output as a preferred output.\\n5. **User Edits**: if your model creates a draft output and the user is able to edit it and then save, you can use the original draft as a non-preferred output and the edited draft as a preferred output.\\n\\n## [\\u200b](https://docs.openpipe.ai/features/dpo/overview\\\\#example-use-cases)  Example Use Cases\\n\\nInitial tests with DPO on OpenPipe have shown promising results. DPO, when used with [user-defined criteria](https://docs.openpipe.ai/features/criteria/overview), allows you to fine-tune models that more consistently respect even very nuanced preferences.\\n\\n![SFT vs DPO](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/dpo/sft-vs-dpo-for-criteria-chart.png)\\n\\nThe following are all real results on customer tasks:\\n\\n- **Word Limit**: for a summarization task with an explicit word limit given in the prompt, DPO was able to cut the number of responses exceeding the limit from 31% to 7%, a **77%** decrease.\\n- **Highlight Format**: for a content formatting task, DPO was able to drop the percentage of times the wrong word or phrase was highlighted from 17.3% to 1.7%, a **90%** decrease.\\n- **Hallucination**: for an information extraction task, DPO was able to drop the fraction of outputs with hallucinated information from 12.7% to 3.0%, a **76%** decrease.\\n- **Result Relevance**: for a classification task determining whether a result was relevant to a query, DPO was able to drop the mis-classification rate from 4.7% to 1.3%, a **72%** decrease.\\n\\nWe’re excited to see how you’ll leverage DPO to create even more powerful and tailored models for your specific needs!\\n\\n[API (Beta)](https://docs.openpipe.ai/features/fine-tuning/api) [Quick Start](https://docs.openpipe.ai/features/dpo/quick-start)\\n\\nOn this page\\n\\n- [Gathering Preference Data](https://docs.openpipe.ai/features/dpo/overview#gathering-preference-data)\\n- [Example Use Cases](https://docs.openpipe.ai/features/dpo/overview#example-use-cases)\\n\\n![SFT vs DPO](https://docs.openpipe.ai/features/dpo/overview',\n",
       " 'docs_openpipe_ai_features_caching.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nFeatures\\n\\nCaching\\n\\nWhen caching is enabled, our service stores the responses generated for each unique request. If an identical request is made in the future, instead of processing the request again, the cached response is instantly returned. This eliminates the need for redundant computations, resulting in faster response times and reduced API usage costs.\\n\\nCaching is currently in a free beta preview.\\n\\n## [\\u200b](https://docs.openpipe.ai/features/caching\\\\#enabling-caching)  Enabling Caching\\n\\nCaching is disabled by default. To enable caching for your requests, you can set the `cache` property of the openpipe object to one of the following values:\\n\\n- `readWrite`: Cache is read from and written to.\\n- `readOnly`: Cache is read from, but not written to.\\n- `writeOnly`: Cache is written to, but not read from.\\n\\nIf you are making requests through our proxy, add the `op-cache` header to your requests. For any of these settings, if a cache entry is not found, the request will be processed as normal.\\n\\n- cURL Request\\n- Python\\n- NodeJS\\n\\nCopy\\n\\n```bash\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/chat/completions \\\\\\n  --header \"Authorization: Bearer YOUR_OPENPIPE_API_KEY\" \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --header \\'op-cache: readWrite\\' \\\\\\n  --data \\'{\\n  \"model\": \"openpipe:your-fine-tuned-model-id\",\\n  \"messages\": [\\\\\\n    {\\\\\\n      \"role\": \"system\",\\\\\\n      \"content\": \"count to 5\"\\\\\\n    }\\\\\\n  ]\\n}\\'\\n\\n```\\n\\n[Mixture of Agents](https://docs.openpipe.ai/features/chat-completions/moa) [Updating Metadata Tags](https://docs.openpipe.ai/features/updating-metadata)\\n\\nOn this page\\n\\n- [Enabling Caching](https://docs.openpipe.ai/features/caching#enabling-caching',\n",
       " 'docs_openpipe_ai_getting_started_quick_start.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nGetting Started\\n\\nQuick Start\\n\\n## [\\u200b](https://docs.openpipe.ai/getting-started/quick-start\\\\#step-1-create-your-openpipe-account)  Step 1: Create Your OpenPipe Account\\n\\nIf you don’t already have one, create an account with OpenPipe at [https://app.openpipe.ai/](https://app.openpipe.ai/). You can sign up with GitHub, so you don’t need to remember an extra password.\\n\\n## [\\u200b](https://docs.openpipe.ai/getting-started/quick-start\\\\#step-2-find-your-project-api-key)  Step 2: Find Your Project API Key\\n\\nIn order to capture your calls and fine-tune a model on them, we need an API key to authenticate you and determine which project to store your logs under.\\n\\nWhen you created your account, a project was automatically configured for you as well. Find its\\nAPI key at [https://app.openpipe.ai/settings](https://app.openpipe.ai/settings).\\n\\n## [\\u200b](https://docs.openpipe.ai/getting-started/quick-start\\\\#step-3-record-training-data-optional)  Step 3: Record Training Data (Optional)\\n\\nIf you don’t have any training data, you can record it by integrating the OpenPipe SDK or using the OpenPipe Proxy. If you already have a dataset, you can skip this step!\\n\\n[**Installing the SDK**](https://docs.openpipe.ai/getting-started/openpipe-sdk) [**Using the OpenPipe Proxy**](https://docs.openpipe.ai/features/request-logs/logging-requests#proxy)\\n\\n## [\\u200b](https://docs.openpipe.ai/getting-started/quick-start\\\\#step-4-prepare-a-dataset)  Step 4: Prepare a Dataset\\n\\nDatasets are the core of OpenPipe. They store your training data, and allow you to fine-tune and evaluate models on it. To learn more about datasets, check out the [Datasets](https://docs.openpipe.ai/features/datasets/overview) page.\\n\\nDatasets can be populated in two ways:\\n\\n1. [Uploading external data](https://docs.openpipe.ai/features/datasets/uploading-data)\\n2. [Importing request logs](https://docs.openpipe.ai/features/datasets/importing-logs)\\n\\nIf you already have a dataset, we recommend uploading it as a starting point. Otherwise, make sure you set up request logging in step 3!\\n\\n## [\\u200b](https://docs.openpipe.ai/getting-started/quick-start\\\\#step-5-fine-tune-a-model)  Step 5: Fine Tune a Model\\n\\nOnce your dataset has been created and populated, you can fine-tune models on it. Follow the [fine-tuning quickstart](https://docs.openpipe.ai/features/fine-tuning/quick-start) guide to kick off your first fine-tuning run.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/fine-tuning/fine-tune-modal.png)\\n\\nWe recommend training several models of varying sizes and configurations to determine the best one for your use case. If you have questions on this step, please reach out to us at [support@openpipe.ai](mailto:support@openpipe.ai)!\\n\\n## [\\u200b](https://docs.openpipe.ai/getting-started/quick-start\\\\#step-6-evaluate-your-model)  Step 6: Evaluate Your Model\\n\\nOnce your model (or models) have been fine-tuned, you can evaluate them. To learn more about evaluating models, check out the [Evaluations](https://docs.openpipe.ai/features/evaluations/overview) page.\\n\\n## [\\u200b](https://docs.openpipe.ai/getting-started/quick-start\\\\#step-7-deploy-your-model)  Step 7: Deploy Your Model\\n\\nBy default, your model will be automatically hosted on OpenPipe’s cloud infrastructure. Additionally, you can export and deploy any of our open-weight models on your own cloud.\\n\\nGood luck! If you have any questions, don’t hesitate to reach out!\\n\\n[Base Models](https://docs.openpipe.ai/base-models) [Installing the SDK](https://docs.openpipe.ai/getting-started/openpipe-sdk)\\n\\nOn this page\\n\\n- [Step 1: Create Your OpenPipe Account](https://docs.openpipe.ai/getting-started/quick-start#step-1-create-your-openpipe-account)\\n- [Step 2: Find Your Project API Key](https://docs.openpipe.ai/getting-started/quick-start#step-2-find-your-project-api-key)\\n- [Step 3: Record Training Data (Optional)](https://docs.openpipe.ai/getting-started/quick-start#step-3-record-training-data-optional)\\n- [Step 4: Prepare a Dataset](https://docs.openpipe.ai/getting-started/quick-start#step-4-prepare-a-dataset)\\n- [Step 5: Fine Tune a Model](https://docs.openpipe.ai/getting-started/quick-start#step-5-fine-tune-a-model)\\n- [Step 6: Evaluate Your Model](https://docs.openpipe.ai/getting-started/quick-start#step-6-evaluate-your-model)\\n- [Step 7: Deploy Your Model](https://docs.openpipe.ai/getting-started/quick-start#step-7-deploy-your-model)\\n\\n![](https://docs.openpipe.ai/getting-started/quick-start',\n",
       " 'docs_openpipe_ai_api_reference_get_listModels.md': 'Search...\\n\\nNavigation\\n\\nModels\\n\\nList Models\\n\\nGET\\n\\n/\\n\\nmodels\\n\\nTry it\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Response\\n\\n200 - application/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data)\\n\\ndata\\n\\nobject\\\\[\\\\]\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-capabilities)\\n\\ndata.capabilities\\n\\nenum<string>\\\\[\\\\]\\n\\nrequired\\n\\nAvailable options:\\n\\n`chat`,\\n\\n`tools`,\\n\\n`json`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-context-window)\\n\\ndata.contextWindow\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-created)\\n\\ndata.created\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-description)\\n\\ndata.description\\n\\nstring \\\\| null\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-id)\\n\\ndata.id\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-max-completion-tokens)\\n\\ndata.maxCompletionTokens\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-name)\\n\\ndata.name\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-object)\\n\\ndata.object\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`model`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-openpipe)\\n\\ndata.openpipe\\n\\nobject\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-openpipe-base-model)\\n\\ndata.openpipe.baseModel\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-openpipe-dataset-id)\\n\\ndata.openpipe.datasetId\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-openpipe-error-message)\\n\\ndata.openpipe.errorMessage\\n\\nstring \\\\| null\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-openpipe-hyperparameters)\\n\\ndata.openpipe.hyperparameters\\n\\nobject \\\\| null\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-openpipe-hyperparameters-key)\\n\\ndata.openpipe.hyperparameters.{key}\\n\\nany\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-openpipe-status)\\n\\ndata.openpipe.status\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`PENDING`,\\n\\n`TRAINING`,\\n\\n`DEPLOYED`,\\n\\n`ERROR`,\\n\\n`DEPRECATED`,\\n\\n`PENDING_DEPRECATION`,\\n\\n`QUEUED`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-owned-by)\\n\\ndata.owned\\\\_by\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-pricing)\\n\\ndata.pricing\\n\\nobject\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-pricing-chat-in)\\n\\ndata.pricing.chatIn\\n\\nnumber\\n\\nrequired\\n\\n$/million tokens\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-pricing-chat-out)\\n\\ndata.pricing.chatOut\\n\\nnumber\\n\\nrequired\\n\\n$/million tokens\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-data-updated)\\n\\ndata.updated\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listModels#response-object)\\n\\nobject\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`list`\\n\\n[Get Model](https://docs.openpipe.ai/api-reference/get-getModel) [Delete Model](https://docs.openpipe.ai/api-reference/delete-model',\n",
       " 'docs_openpipe_ai_features_request_logs_exporting_logs.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nRequest Logs\\n\\nExporting Logs\\n\\n## [\\u200b](https://docs.openpipe.ai/features/request-logs/exporting-logs\\\\#request-logs-export)  Request logs export\\n\\nOnce your request logs are recorded, you can export them at any time. The exported jsonl contains all the data that we’ve collected from your logged calls, including tags and errors.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/request-logs/exporting-logs.png)\\n\\n### [\\u200b](https://docs.openpipe.ai/features/request-logs/exporting-logs\\\\#fields)  Fields\\n\\n- **`Input`:** The complete chat creation request.\\n- **`Output`:** Whatever output was generated, including errors.\\n- **`Tags`:** Any metadata tags that you included when making the request.\\n\\n### [\\u200b](https://docs.openpipe.ai/features/request-logs/exporting-logs\\\\#example)  Example\\n\\nCopy\\n\\n```jsonl\\n{\"input\":{\"model\":\"openpipe:test-tool-calls-ft\",\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"parameters\":{\"type\":\"object\",\"required\":[\"location\"],\"properties\":{\"unit\":{\"enum\":[\"celsius\",\"fahrenheit\"],\"type\":\"string\"},\"location\":{\"type\":\"string\",\"description\":\"The city and state, e.g. San Francisco, CA\"}}},\"description\":\"Get the current weather in a given location\"}}],\"messages\":[{\"role\":\"system\",\"content\":\"tell me the weather in SF and Orlando\"}]},\"output\":{\"id\":\"c7670af0d71648b0bd829fa1901ac6c5\",\"model\":\"openpipe:test-tool-calls-ft\",\"usage\":{\"total_tokens\":106,\"prompt_tokens\":47,\"completion_tokens\":59},\"object\":\"chat.completion\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"arguments\":\"{\\\\\"location\\\\\": \\\\\"San Francisco, CA\\\\\", \\\\\"unit\\\\\": \\\\\"celsius\\\\\"}\"}},{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"arguments\":\"{\\\\\"location\\\\\": \\\\\"Orlando, FL\\\\\", \\\\\"unit\\\\\": \\\\\"celsius\\\\\"}\"}}]},\"finish_reason\":\"stop\"}],\"created\":1702666185703},\"tags\":{\"prompt_id\":\"test_sync_tool_calls_ft\",\"$sdk\":\"python\",\"$sdk.version\":\"4.1.0\"}}\\n{\"input\":{\"model\":\"openpipe:test-content-ft\",\"messages\":[{\"role\":\"system\",\"content\":\"count to 3\"}]},\"output\":{\"id\":\"47116eaa9dad4238bf12e32135f9c147\",\"model\":\"openpipe:test-content-ft\",\"usage\":{\"total_tokens\":38,\"prompt_tokens\":29,\"completion_tokens\":9},\"object\":\"chat.completion\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"1, 2, 3\"},\"finish_reason\":\"stop\"}],\"created\":1702666036923},\"tags\":{\"prompt_id\":\"test_sync_content_ft\",\"$sdk\":\"python\",\"$sdk.version\":\"4.1.0\"}}\\n\\n```\\n\\nIf you’d like to see how it works, try exporting some logs from our [public demo](https://app.openpipe.ai/p/BRZFEx50Pf/request-logs).\\n\\n[Logging Anthropic Requests](https://docs.openpipe.ai/features/request-logs/reporting-anthropic) [Overview](https://docs.openpipe.ai/features/datasets/overview)\\n\\nOn this page\\n\\n- [Request logs export](https://docs.openpipe.ai/features/request-logs/exporting-logs#request-logs-export)\\n- [Fields](https://docs.openpipe.ai/features/request-logs/exporting-logs#fields)\\n- [Example](https://docs.openpipe.ai/features/request-logs/exporting-logs#example)\\n\\n![](https://docs.openpipe.ai/features/request-logs/exporting-logs',\n",
       " 'docs_openpipe_ai_pricing_pricing.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nPricing\\n\\nPricing Overview\\n\\n## [\\u200b](https://docs.openpipe.ai/pricing/pricing\\\\#training)  Training\\n\\nWe charge for training based on the size of the model and the number of tokens in the dataset.\\n\\n| Model Category | Cost per 1M tokens |\\n| --- | --- |\\n| **8B and smaller** | $0.48 |\\n| **32B models** | $1.90 |\\n| **70B+ models** | $2.90 |\\n\\n## [\\u200b](https://docs.openpipe.ai/pricing/pricing\\\\#hosted-inference)  Hosted Inference\\n\\nChoose between two billing models for running models on our infrastructure:\\n\\n### [\\u200b](https://docs.openpipe.ai/pricing/pricing\\\\#1-per-token-pricing)  1\\\\. Per-Token Pricing\\n\\nAvailable for our most popular, high-volume models. You only pay for the tokens you process, with no minimum commitment and automatic infrastructure scaling.\\n\\n| Model | Input (per 1M tokens) | Output (per 1M tokens) |\\n| --- | --- | --- |\\n| **Llama 3.1 8B Instruct** | $0.30 | $0.45 |\\n| **Llama 3.1 70B Instruct** | $1.80 | $2.00 |\\n\\n### [\\u200b](https://docs.openpipe.ai/pricing/pricing\\\\#2-hourly-compute-units)  2\\\\. Hourly Compute Units\\n\\nDesigned for experimental and lower-volume models. A Compute Unit (CU) can handle up to 24 simultaneous requests per second. Billing is precise down to the second, with automatic scaling when traffic exceeds capacity. Compute units remain active for 60 seconds after traffic spikes.\\n\\n| Model | Rate per CU Hour |\\n| --- | --- |\\n| **Llama 3.1 8B** | $1.50 |\\n| **Mistral Nemo 12B** | $1.50 |\\n| **Qwen 2.5 32B Coder** | $6.00 |\\n| **Qwen 2.5 72B** | $12.00 |\\n| **Llama 3.1 70B** | $12.00 |\\n\\n## [\\u200b](https://docs.openpipe.ai/pricing/pricing\\\\#third-party-models-openai-gemini-etc)  Third-Party Models (OpenAI, Gemini, etc.)\\n\\nThird-party models fine-tuned through OpenPipe like OpenAI’s GPT series or Google’s Gemini, we provide direct API integration without any additional markup. You will be billed directly by the respective provider (OpenAI, Google, etc.) at their standard rates. We simply pass through the API calls and responses.\\n\\n## [\\u200b](https://docs.openpipe.ai/pricing/pricing\\\\#enterprise-plans)  Enterprise Plans\\n\\nFor organizations requiring custom solutions, we offer enterprise plans that include:\\n\\n- Volume discounts\\n- On-premises deployment options\\n- Dedicated support\\n- Custom SLAs\\n- Advanced security features\\n\\nContact our team at [hello@openpipe.ai](mailto:hello@openpipe.ai) to discuss enterprise pricing and requirements.\\n\\n[Judge Criteria](https://docs.openpipe.ai/api-reference/post-criteriajudge)\\n\\nOn this page\\n\\n- [Training](https://docs.openpipe.ai/pricing/pricing#training)\\n- [Hosted Inference](https://docs.openpipe.ai/pricing/pricing#hosted-inference)\\n- [1\\\\. Per-Token Pricing](https://docs.openpipe.ai/pricing/pricing#1-per-token-pricing)\\n- [2\\\\. Hourly Compute Units](https://docs.openpipe.ai/pricing/pricing#2-hourly-compute-units)\\n- [Third-Party Models (OpenAI, Gemini, etc.)](https://docs.openpipe.ai/pricing/pricing#third-party-models-openai-gemini-etc)\\n- [Enterprise Plans](https://docs.openpipe.ai/pricing/pricing#enterprise-plans',\n",
       " 'docs_openpipe_ai_features_mixture_of_agents.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nFeatures\\n\\nMixture of Agents\\n\\nWe’re currently beta-testing a novel completion generating technique we’re calling “Mixture of Agents,” which we’ll document more formally soon.\\n\\nThe basic idea is that instead of simply asking GPT-4 to generate a completion for your prompt directly, we use a series of GPT-4 prompts to iteratively improve the completion. The steps our “mixture of agents” model takes are as follows:\\n\\n- **Prompt 1** generates 3 candidate completions in parallel by calling the chosen base model with `n=3` and a high temperature to promote output diversity.\\n- **Prompt 2** again calls the base model. It passes in the original input again, along with the 3 candidate completions generated by prompt 1. It then asks the LLM to review the candidate completions and critique them.\\n- **Prompt 3** again passes the original input, the 3 candidate completions, and their critiques. Using this information, the base model generates a final completion that incorporates the best of all 3 candidates.\\n\\nWe’ve iterated on this process significantly and found that completions generated in this way tend to be significantly higher quality than those generated by GPT-4 in a single step, and lead to much stronger downstream fine-tuned models as well.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/moa/llm-judge-moa-wr.png)\\n\\n## [\\u200b](https://docs.openpipe.ai/features/mixture-of-agents\\\\#using-moa-in-production)  Using MoA in Production\\n\\nTo use MoA models at inference time, make requests to the /chat/completions endpoint with a MoA model. See [instructions](https://docs.openpipe.ai/features/chat-completions/moa).\\n\\n## [\\u200b](https://docs.openpipe.ai/features/mixture-of-agents\\\\#using-the-moa-relabeling-flow)  Using the MoA Relabeling Flow\\n\\nThe following instructions explain how to copy an existing dataset and relabel it with the mixture-of-agents flow, which will let you train models on the higher-quality outputs.\\n\\n1. **Export the original dataset**\\n\\nNavigate to your existing OpenPipe dataset and click the “Export” button in the upper right. Keep the “Include split” checkbox checked. You’ll download a .jsonl file with the contents of your dataset (this may take a few minutes).\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/moa/export-arrow.png)\\n\\n2. **Re-import the dataset**\\n\\nCreate a new dataset in your project. Import the file you exported from step (1). Once the import finishes, your new dataset should contain a copy of the same data as the old one.\\n\\n3. **Open the Data Pipeline view**\\n\\nNavigate to the **Data Pipeline** tab in the new dataset, then expand the Data Pipeline view by hovering over and clicking the data pipeline preview.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/moa/data-lineage-preview.png)\\n\\n4. Select the “LLM Relabel” node for the file you just uploaded. Then in the sidebar, choose one of `moa-gpt-4-v1`, `moa-gpt-4-turbo-v1`, or `moa-gpt-4o-v1`, depending on which model you’d like to use as your MoA base. **Note:** we use your API key for relabelling, so you’ll need to have entered a valid OpenAI API key in your project settings for this to work.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/moa/data-lineage-relabeling.png)\\n\\n5. **Wait for relabeling to finish**\\n\\nDepending on your dataset size relabelling may take quite a while. Behind the scenes we run 4 relabelling jobs in parallel at a time. You’ll know relabeling has finished when the “Processing entries” status disappears at the top right of the dataset view.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/moa/processing-entries.png)\\n\\n6. **Train a model on the new dataset**\\n\\nTrain the base model of your choice on the new dataset.\\n\\n7. **(Optional) Evaluate your new model against your old one**\\n\\nIf you have an existing head-to-head evaluation on the platform, you can easily add your new model to it to see how it compares. Simply open your existing eval and add your newly-trained model as another model to compare!\\n\\n\\n## [\\u200b](https://docs.openpipe.ai/features/mixture-of-agents\\\\#costs)  Costs\\n\\nWe aren’t charging for the MoA relabeling flow while it is in beta. However, you will pay for the actual calls to the OpenAI API. The exact cost varies depending on your input vs output mix but as a rule of thumb our MoA approach uses 3x-4x as many tokens as running the same completion in a non-MoA context.\\n\\n[Fallback](https://docs.openpipe.ai/features/fallback) [External Models](https://docs.openpipe.ai/features/external-models)\\n\\nOn this page\\n\\n- [Using MoA in Production](https://docs.openpipe.ai/features/mixture-of-agents#using-moa-in-production)\\n- [Using the MoA Relabeling Flow](https://docs.openpipe.ai/features/mixture-of-agents#using-the-moa-relabeling-flow)\\n- [Costs](https://docs.openpipe.ai/features/mixture-of-agents#costs)\\n\\n![](https://docs.openpipe.ai/features/mixture-of-agents)\\n\\n![](https://docs.openpipe.ai/features/mixture-of-agents)\\n\\n![](https://docs.openpipe.ai/features/mixture-of-agents)\\n\\n![](https://docs.openpipe.ai/features/mixture-of-agents)\\n\\n![](https://docs.openpipe.ai/features/mixture-of-agents',\n",
       " 'docs_openpipe_ai_features_evaluations_head_to_head.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nEvaluations\\n\\nHead-to-Head Evaluations\\n\\nHead-to-head evaluations are useful for evaluating your LLM outputs against one another to\\ndetermine which models are generally better at a given task. However, they do not provide precise\\nmetrics on how often a given model makes a certain error, only how often it outperforms another\\nmodel. For more precise metrics, please consider [criteria](https://docs.openpipe.ai/features/evaluations/criterion) or\\n[code](https://docs.openpipe.ai/features/evaluations/code) evaluations.\\n\\nHead to head evaluations are a fast way to get a sense of how well your models perform against one another. For each model being evaluated, the output of that model is compared against the output of every other model for every entry in the evaluation dataset.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/h2h-settings.png)\\n\\nThe number of comparisons performed in a head to head eval scales linearly with the number of\\nentries and quadratically with the number of models. If you’re evaluating 2 models on 100 entries,\\nthere will be 100 \\\\* 1 = 100 comparisons. If you’re evaluating 3 models on 100 entries, there will\\nbe 100 \\\\* 2 + 100 \\\\* 1 = 300 comparisons.\\n\\nAs outputs are compared against one another, each model is assigned a “win rate” score. For example, if you’re evaluating 2 models on 100 entries and model A outperforms model B 55 times, model A will have a win rate of 55% and model B will have a win rate of 45%. In cases where both models produce the same output or the judge is unable to determine a winner, the score will be a tie (equivalent to 50% win rate).\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/h2h-results-table.png)\\n\\nIn addition to the results table, you can also view results in a matrix format. This is useful for visualizing how specific models perform against one another.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/h2h-matrix.png)\\n\\nTo see why one model might be outperforming another, you can navigate back to the [evaluation table](https://app.openpipe.ai/p/BRZFEx50Pf/datasets/3e7e82c1-b066-476c-9f17-17fd85a2169b/evaluate) and click on a result pill to see the evaluation judge’s reasoning.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/h2h-judge-explanation.png)\\n\\nWhile head-to-head evaluations are convenient, they can quickly become expensive to run, and provide limited insight into how well a model performs. For more precise metrics, consider [criterion](https://docs.openpipe.ai/features/evaluations/criterion) or [code](https://docs.openpipe.ai/features/evaluations/code) evaluations.\\n\\n[Criterion Evals](https://docs.openpipe.ai/features/evaluations/criterion) [Overview](https://docs.openpipe.ai/features/criteria/overview)\\n\\n![](https://docs.openpipe.ai/features/evaluations/head-to-head)\\n\\n![](https://docs.openpipe.ai/features/evaluations/head-to-head)\\n\\n![](https://docs.openpipe.ai/features/evaluations/head-to-head)\\n\\n![](https://docs.openpipe.ai/features/evaluations/head-to-head',\n",
       " 'docs_openpipe_ai_api_reference_post_report_anthropic.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nLogs\\n\\nReport Anthropic\\n\\nPOST\\n\\n/\\n\\nreport-anthropic\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/report-anthropic \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"requestedAt\": 123,\\n  \"receivedAt\": 123,\\n  \"reqPayload\": {\\n    \"max_tokens\": 123,\\n    \"messages\": [\\\\\\n      {\\\\\\n        \"content\": \"<string>\",\\\\\\n        \"role\": \"user\"\\\\\\n      }\\\\\\n    ],\\n    \"model\": \"<string>\",\\n    \"metadata\": {\\n      \"user_id\": \"<string>\"\\n    },\\n    \"stop_sequences\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"stream\": true,\\n    \"system\": \"<string>\",\\n    \"temperature\": 123,\\n    \"top_k\": 123,\\n    \"top_p\": 123\\n  },\\n  \"respPayload\": {\\n    \"id\": \"<string>\",\\n    \"content\": [\\\\\\n      {\\\\\\n        \"text\": \"<string>\",\\\\\\n        \"type\": \"text\"\\\\\\n      }\\\\\\n    ],\\n    \"model\": \"<string>\",\\n    \"role\": \"assistant\",\\n    \"stop_reason\": \"end_turn\",\\n    \"stop_sequence\": \"<string>\",\\n    \"type\": \"message\",\\n    \"usage\": {\\n      \"input_tokens\": 123,\\n      \"output_tokens\": 123\\n    }\\n  },\\n  \"statusCode\": 123,\\n  \"errorMessage\": \"<string>\",\\n  \"metadata\": {},\\n  \"tags\": {}\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"status\": \"ok\"\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-error-message)\\n\\nerrorMessage\\n\\nstring\\n\\nUser-friendly error message\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-metadata)\\n\\nmetadata\\n\\nobject\\n\\nExtra metadata tags to attach to the call for filtering. Eg { \"userId\": \"123\", \"prompt\\\\_id\": \"populate-title\" }\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-metadata-key)\\n\\nmetadata.{key}\\n\\nstring\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-received-at)\\n\\nreceivedAt\\n\\nnumber\\n\\nUnix timestamp in milliseconds\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload)\\n\\nreqPayload\\n\\nobject\\n\\nJSON-encoded request payload\\n\\n- Option 1\\n- Option 2\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-max-tokens)\\n\\nreqPayload.max\\\\_tokens\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-messages)\\n\\nreqPayload.messages\\n\\nobject\\\\[\\\\]\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-messages-content)\\n\\nreqPayload.messages.content\\n\\nstringobject\\\\[\\\\]\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-messages-role)\\n\\nreqPayload.messages.role\\n\\nOption 1 · enum<string>Option 2 · enum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`user`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-model)\\n\\nreqPayload.model\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-stream)\\n\\nreqPayload.stream\\n\\nboolean\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-metadata)\\n\\nreqPayload.metadata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-metadata-user-id)\\n\\nreqPayload.metadata.user\\\\_id\\n\\nstring \\\\| nullenum<string> \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-stop-sequences)\\n\\nreqPayload.stop\\\\_sequences\\n\\nstring\\\\[\\\\]\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-system)\\n\\nreqPayload.system\\n\\nstring\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-temperature)\\n\\nreqPayload.temperature\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-top-k)\\n\\nreqPayload.top\\\\_k\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-top-p)\\n\\nreqPayload.top\\\\_p\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-requested-at)\\n\\nrequestedAt\\n\\nnumber\\n\\nUnix timestamp in milliseconds\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload)\\n\\nrespPayload\\n\\nobject\\n\\nJSON-encoded response payload\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-content)\\n\\nrespPayload.content\\n\\nobject\\\\[\\\\]\\n\\nrequired\\n\\n- Option 1\\n- Option 2\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-content-text)\\n\\nrespPayload.content.text\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-content-type)\\n\\nrespPayload.content.type\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`text`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-id)\\n\\nrespPayload.id\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-model)\\n\\nrespPayload.model\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-role)\\n\\nrespPayload.role\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`assistant`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-stop-reason)\\n\\nrespPayload.stop\\\\_reason\\n\\nOption 1 · enum<string> \\\\| nullOption 2 · enum<string> \\\\| nullOption 3 · enum<string> \\\\| nullOption 4 · enum<string> \\\\| nullOption 5 · enum<string> \\\\| null\\n\\nrequired\\n\\nAvailable options:\\n\\n`end_turn`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-stop-sequence)\\n\\nrespPayload.stop\\\\_sequence\\n\\nstring \\\\| nullenum<string> \\\\| null\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-type)\\n\\nrespPayload.type\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`message`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-usage)\\n\\nrespPayload.usage\\n\\nobject\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-usage-input-tokens)\\n\\nrespPayload.usage.input\\\\_tokens\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-usage-output-tokens)\\n\\nrespPayload.usage.output\\\\_tokens\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-status-code)\\n\\nstatusCode\\n\\nnumber\\n\\nHTTP status code of response\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-tags)\\n\\ntags\\n\\nobject\\n\\nDeprecated: use \"metadata\" instead\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-tags-key)\\n\\ntags.{key}\\n\\nstring \\\\| nullnumber \\\\| nullboolean \\\\| nullenum<string> \\\\| null\\n\\n#### Response\\n\\n200 - application/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report-anthropic#response-status)\\n\\nstatus\\n\\nOption 1 · enum<string>Option 2 · enum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`ok`\\n\\n[Report](https://docs.openpipe.ai/api-reference/post-report) [Update Metadata](https://docs.openpipe.ai/api-reference/post-updatemetadata)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/report-anthropic \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"requestedAt\": 123,\\n  \"receivedAt\": 123,\\n  \"reqPayload\": {\\n    \"max_tokens\": 123,\\n    \"messages\": [\\\\\\n      {\\\\\\n        \"content\": \"<string>\",\\\\\\n        \"role\": \"user\"\\\\\\n      }\\\\\\n    ],\\n    \"model\": \"<string>\",\\n    \"metadata\": {\\n      \"user_id\": \"<string>\"\\n    },\\n    \"stop_sequences\": [\\\\\\n      \"<string>\"\\\\\\n    ],\\n    \"stream\": true,\\n    \"system\": \"<string>\",\\n    \"temperature\": 123,\\n    \"top_k\": 123,\\n    \"top_p\": 123\\n  },\\n  \"respPayload\": {\\n    \"id\": \"<string>\",\\n    \"content\": [\\\\\\n      {\\\\\\n        \"text\": \"<string>\",\\\\\\n        \"type\": \"text\"\\\\\\n      }\\\\\\n    ],\\n    \"model\": \"<string>\",\\n    \"role\": \"assistant\",\\n    \"stop_reason\": \"end_turn\",\\n    \"stop_sequence\": \"<string>\",\\n    \"type\": \"message\",\\n    \"usage\": {\\n      \"input_tokens\": 123,\\n      \"output_tokens\": 123\\n    }\\n  },\\n  \"statusCode\": 123,\\n  \"errorMessage\": \"<string>\",\\n  \"metadata\": {},\\n  \"tags\": {}\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"status\": \"ok\"\\n}\\n```',\n",
       " 'docs_openpipe_ai_getting_started_openpipe_sdk.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nGetting Started\\n\\nInstalling the SDK\\n\\nUse the OpenPipe SDK as a drop-in replacement for the generic OpenAI package. Calls sent through the OpenPipe SDK will be recorded by default for later training. You’ll use this same SDK to call your own fine-tuned models once they’re deployed.\\n\\n- Python\\n- NodeJS (ESM)\\n- NodeJS (CJS)\\n\\nFind the SDK at [https://pypi.org/project/openpipe/](https://pypi.org/project/openpipe/)\\n\\n## Installation\\n\\nCopy\\n\\n```bash\\npip install openpipe\\n\\n```\\n\\n## Simple Integration\\n\\nAdd `OPENPIPE_API_KEY` to your environment variables.\\n\\nCopy\\n\\n```bash\\nexport OPENPIPE_API_KEY=opk-<your-api-key>\\n# Or you can set it in your code, see \"Complete Example\" below\\n\\n```\\n\\nReplace this line\\n\\nCopy\\n\\n```python\\nfrom openai import OpenAI\\n\\n```\\n\\nwith this one\\n\\nCopy\\n\\n```python\\nfrom openpipe import OpenAI\\n\\n```\\n\\n## Adding Searchable Metadata Tags\\n\\nOpenPipe follows OpenAI’s concept of metadata tagging for requests. You can use metadata tags in the [Request Logs](https://docs.openpipe.ai/features/request-logs) view to narrow down the data your model will train on.\\nWe recommend assigning a unique metadata tag to each of your prompts.\\nThese tags will help you find all the input/output pairs associated with a certain prompt and fine-tune a model to replace it.\\n\\nHere’s how you can use the tagging feature:\\n\\n## Complete Example\\n\\nCopy\\n\\n```python\\nfrom openpipe import OpenAI\\nimport os\\n\\nclient = OpenAI(\\n    # defaults to os.environ.get(\"OPENAI_API_KEY\")\\n    api_key=\"My API Key\",\\n    openpipe={\\n        # defaults to os.environ.get(\"OPENPIPE_API_KEY\")\\n        \"api_key\": \"My OpenPipe API Key\",\\n        # optional, defaults to process.env[\"OPENPIPE_BASE_URL\"] or https://api.openpipe.ai/api/v1 if not set\\n        \"base_url\": \"My URL\",\\n    }\\n)\\n\\ncompletion = client.chat.completions.create(\\n    model=\"gpt-4o\",\\n    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\\n    metadata={\"prompt_id\": \"counting\", \"any_key\": \"any_value\"},\\n)\\n\\n```\\n\\n## [\\u200b](https://docs.openpipe.ai/getting-started/openpipe-sdk\\\\#should-i-wait-to-enable-logging)  Should I Wait to Enable Logging?\\n\\nWe recommend keeping request logging turned on from the beginning. If you change your prompt you can just set a new `prompt_id` metadata tag so you can select just the latest version when you’re ready to create a dataset.\\n\\n[Quick Start](https://docs.openpipe.ai/getting-started/quick-start) [Logging Requests](https://docs.openpipe.ai/features/request-logs/logging-requests)\\n\\nOn this page\\n\\n- [Should I Wait to Enable Logging?](https://docs.openpipe.ai/getting-started/openpipe-sdk#should-i-wait-to-enable-logging',\n",
       " 'docs_openpipe_ai_api_reference_get_getModel.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nModels\\n\\nGet Model\\n\\nGET\\n\\n/\\n\\nmodels\\n\\n/\\n\\n{modelSlug}\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.openpipe.ai/api/v1/models/{modelSlug} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"id\": \"<string>\",\\n  \"name\": \"<string>\",\\n  \"object\": \"model\",\\n  \"description\": \"<string>\",\\n  \"created\": \"<string>\",\\n  \"updated\": \"<string>\",\\n  \"openpipe\": {\\n    \"baseModel\": \"<string>\",\\n    \"hyperparameters\": {},\\n    \"status\": \"PENDING\",\\n    \"datasetId\": \"<string>\",\\n    \"errorMessage\": \"<string>\"\\n  },\\n  \"contextWindow\": 123,\\n  \"maxCompletionTokens\": 123,\\n  \"capabilities\": [\\\\\\n    \"chat\"\\\\\\n  ],\\n  \"pricing\": {\\n    \"chatIn\": 123,\\n    \"chatOut\": 123\\n  },\\n  \"owned_by\": \"<string>\"\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Path Parameters\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#parameter-model-slug)\\n\\nmodelSlug\\n\\nstring\\n\\nrequired\\n\\n#### Response\\n\\n200 - application/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-capabilities)\\n\\ncapabilities\\n\\nenum<string>\\\\[\\\\]\\n\\nrequired\\n\\nAvailable options:\\n\\n`chat`,\\n\\n`tools`,\\n\\n`json`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-context-window)\\n\\ncontextWindow\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-created)\\n\\ncreated\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-description)\\n\\ndescription\\n\\nstring \\\\| null\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-id)\\n\\nid\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-max-completion-tokens)\\n\\nmaxCompletionTokens\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-name)\\n\\nname\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-object)\\n\\nobject\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`model`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-openpipe)\\n\\nopenpipe\\n\\nobject\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-openpipe-base-model)\\n\\nopenpipe.baseModel\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-openpipe-dataset-id)\\n\\nopenpipe.datasetId\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-openpipe-error-message)\\n\\nopenpipe.errorMessage\\n\\nstring \\\\| null\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-openpipe-hyperparameters)\\n\\nopenpipe.hyperparameters\\n\\nobject \\\\| null\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-openpipe-hyperparameters-key)\\n\\nopenpipe.hyperparameters.{key}\\n\\nany\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-openpipe-status)\\n\\nopenpipe.status\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`PENDING`,\\n\\n`TRAINING`,\\n\\n`DEPLOYED`,\\n\\n`ERROR`,\\n\\n`DEPRECATED`,\\n\\n`PENDING_DEPRECATION`,\\n\\n`QUEUED`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-owned-by)\\n\\nowned\\\\_by\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-pricing)\\n\\npricing\\n\\nobject\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-pricing-chat-in)\\n\\npricing.chatIn\\n\\nnumber\\n\\nrequired\\n\\n$/million tokens\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-pricing-chat-out)\\n\\npricing.chatOut\\n\\nnumber\\n\\nrequired\\n\\n$/million tokens\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-getModel#response-updated)\\n\\nupdated\\n\\nstring\\n\\nrequired\\n\\n[Create Model](https://docs.openpipe.ai/api-reference/post-createModel) [List Models](https://docs.openpipe.ai/api-reference/get-listModels)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.openpipe.ai/api/v1/models/{modelSlug} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"id\": \"<string>\",\\n  \"name\": \"<string>\",\\n  \"object\": \"model\",\\n  \"description\": \"<string>\",\\n  \"created\": \"<string>\",\\n  \"updated\": \"<string>\",\\n  \"openpipe\": {\\n    \"baseModel\": \"<string>\",\\n    \"hyperparameters\": {},\\n    \"status\": \"PENDING\",\\n    \"datasetId\": \"<string>\",\\n    \"errorMessage\": \"<string>\"\\n  },\\n  \"contextWindow\": 123,\\n  \"maxCompletionTokens\": 123,\\n  \"capabilities\": [\\\\\\n    \"chat\"\\\\\\n  ],\\n  \"pricing\": {\\n    \"chatIn\": 123,\\n    \"chatOut\": 123\\n  },\\n  \"owned_by\": \"<string>\"\\n}\\n```',\n",
       " 'docs_openpipe_ai_features_evaluations_code.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nEvaluations\\n\\nCode Evaluations\\n\\nCode evaluations are not a good match for all tasks. They work well for deterministic tasks like\\nclassification or information extraction, but not for tasks that produce freeform outputs like\\nchatbots or summarization. To evaluate tasks with freeform outputs, please consider [criterion\\\\\\\\\\nevaluations](https://docs.openpipe.ai/features/evaluations/criterion).\\n\\nThe code evaluation framework provides greater flexibility than built-in head-to-head and criterion evaluations, allowing you to grade your LLM outputs on whatever metrics you define.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/new-code-eval-modal.png)\\n\\nEach code eval consists of a templated `grader` function that you can customize. Here’s the basic structure:\\n\\nCopy\\n\\n```typescript\\nfunction grader({\\n  messages,\\n  tools,\\n  toolChoice,\\n  generatedOutput,\\n  datasetOutput,\\n}: GraderArgs): number {\\n  let score = 0.0;\\n\\n  // begin implementation\\n\\n  score = 1.0;\\n\\n  // end implementation\\n\\n  return score;\\n}\\n\\n...\\n\\n```\\n\\nAs you can see, the `grader` function takes in a number of arguments and returns a score between 0 and 1, where 1 means the generated output is perfect. The available arguments are:\\n\\n- `messages`: The messages sent to the LLM.\\n- `tools`: The tools available to the LLM.\\n- `toolChoice`: The tool choice specified for the LLM.\\n- `generatedOutput`: The output generated by the LLM which is being evaluated.\\n- `datasetOutput`: The original dataset output associated with the row being evaluated.\\n\\nThe grader you define can use any of the above arguments, but most often you’ll want to use `generatedOutput` and `datasetOutput` to compare the output of the LLM to the dataset output.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/editable-lines.png)\\n\\nTo get a better idea of what kinds of checks can be performed through a code evaluation, you can check out the **Exact Match** or **Argument Comparison** templates below.\\n\\nExact Match\\n\\nThe **Exact Match** template checks if the generated output matches the dataset output exactly, meaning that the content and tool calls must match exactly.\\n\\nCopy\\n\\n```typescript\\nfunction grader({\\n  messages,\\n  tools,\\n  toolChoice,\\n  generatedOutput,\\n  datasetOutput,\\n}: GraderArgs): number {\\n  let score = 0.0;\\n\\n  // begin implementation\\n\\n  if (!exactToolCallsMatch(generatedOutput.tool_calls, datasetOutput.tool_calls)) {\\n    return 0.0;\\n  }\\n\\n  if (generatedOutput.content !== datasetOutput.content) {\\n    return 0.0;\\n  }\\n\\n  // generated output matches dataset output\\n  score = 1.0;\\n\\n  // end implementation\\n\\n  return score;\\n}\\n\\ninterface GraderArgs {\\n  messages: ChatCompletionMessageParam;\\n  tools: ChatCompletionTool[] | null;\\n  toolChoice: \"none\" | \"auto\" | ChatCompletionNamedToolChoice | null;\\n  generatedOutput: ChatCompletionMessage;\\n  datasetOutput: ChatCompletionMessage;\\n}\\n\\ninterface ChatCompletionMessageToolCallFunction {\\n  name: string;\\n  arguments: string;\\n}\\n\\ninterface ChatCompletionMessageToolCall {\\n  function: ChatCompletionMessageToolCallFunction;\\n}\\n\\ninterface ChatCompletionMessage {\\n  content: string | null;\\n  refusal: string | null;\\n  tool_calls: ChatCompletionMessageToolCall[] | null;\\n}\\n\\ntype ChatCompletionMessageParam = ChatCompletionMessage;\\n\\ninterface ChatCompletionTool {\\n  function: FunctionDefinition;\\n  type: \"function\";\\n}\\n\\ninterface FunctionDefinition {\\n  name: string;\\n  description?: string;\\n  parameters?: Record<string, unknown>;\\n}\\n\\nexport interface ChatCompletionNamedToolChoice {\\n  function: Function;\\n  type: \"function\";\\n}\\n\\ninterface Function {\\n  name: string;\\n}\\n\\nfunction exactToolCallsMatch(\\n  toolCalls1: ChatCompletionMessageToolCall[] | null,\\n  toolCalls2: ChatCompletionMessageToolCall[] | null,\\n): boolean {\\n  // If either list is null, they can only match if both are null\\n  if (!toolCalls1 && !toolCalls2) {\\n    return true;\\n  }\\n  if (!toolCalls1 || !toolCalls2) {\\n    return false;\\n  }\\n\\n  // Check if lengths match\\n  if (toolCalls1.length !== toolCalls2.length) {\\n    return false;\\n  }\\n\\n  // Compare each tool call\\n  for (let i = 0; i < toolCalls1.length; i++) {\\n    const call1 = toolCalls1[i];\\n    const call2 = toolCalls2[i];\\n\\n    // Compare all fields that must match exactly\\n    if (\\n      call1?.function.name !== call2?.function.name ||\\n      call1?.function.arguments !== call2?.function.arguments\\n    ) {\\n      return false;\\n    }\\n  }\\n\\n  // If we made it through all comparisons, the calls match exactly\\n  return true;\\n}\\n\\n```\\n\\nArgument Comparison\\n\\nThe **Argument Comparison** template provides an example of how you can check whether a specific argument in the tool call generated by the LLM matches the dataset output.\\n\\nCopy\\n\\n```typescript\\nfunction grader({\\n  messages,\\n  tools,\\n  toolChoice,\\n  generatedOutput,\\n  datasetOutput,\\n}: GraderArgs): number {\\n  let score = 0.0;\\n\\n  // begin implementation\\n\\n  const generatedToolCallArgsStr = generatedOutput.tool_calls?.[0]?.function.arguments;\\n  const datasetToolCallArgsStr = datasetOutput.tool_calls?.[0]?.function.arguments;\\n\\n  if (!generatedToolCallArgsStr || !datasetToolCallArgsStr) {\\n    return 0.0;\\n  }\\n\\n  type JudgementArgs = {\\n    explanation: string;\\n    score: number;\\n  };\\n\\n  const generatedToolCallArgs = JSON.parse(generatedToolCallArgsStr) as JudgementArgs;\\n  const datasetToolCallArgs = JSON.parse(datasetToolCallArgsStr) as JudgementArgs;\\n\\n  if (generatedToolCallArgs.score !== datasetToolCallArgs.score) {\\n    return 0.0;\\n  }\\n\\n  score = 1.0;\\n\\n  // end implementation\\n\\n  return score;\\n}\\n\\ninterface GraderArgs {\\n  messages: ChatCompletionMessageParam;\\n  tools: ChatCompletionTool[] | null;\\n  toolChoice: \"none\" | \"auto\" | ChatCompletionNamedToolChoice | null;\\n  generatedOutput: ChatCompletionMessage;\\n  datasetOutput: ChatCompletionMessage;\\n}\\n\\ninterface ChatCompletionMessageToolCallFunction {\\n  name: string;\\n  arguments: string;\\n}\\n\\ninterface ChatCompletionMessageToolCall {\\n  function: ChatCompletionMessageToolCallFunction;\\n}\\n\\ninterface ChatCompletionMessage {\\n  content: string | null;\\n  refusal: string | null;\\n  tool_calls: ChatCompletionMessageToolCall[] | null;\\n}\\n\\ntype ChatCompletionMessageParam = ChatCompletionMessage;\\n\\ninterface ChatCompletionTool {\\n  function: FunctionDefinition;\\n  type: \"function\";\\n}\\n\\ninterface FunctionDefinition {\\n  name: string;\\n  description?: string;\\n  parameters?: Record<string, unknown>;\\n}\\n\\nexport interface ChatCompletionNamedToolChoice {\\n  function: Function;\\n  type: \"function\";\\n}\\n\\ninterface Function {\\n  name: string;\\n}\\n\\nfunction exactToolCallsMatch(\\n  toolCalls1: ChatCompletionMessageToolCall[] | null,\\n  toolCalls2: ChatCompletionMessageToolCall[] | null,\\n): boolean {\\n  // If either list is null, they can only match if both are null\\n  if (!toolCalls1 && !toolCalls2) {\\n    return true;\\n  }\\n  if (!toolCalls1 || !toolCalls2) {\\n    return false;\\n  }\\n\\n  // Check if lengths match\\n  if (toolCalls1.length !== toolCalls2.length) {\\n    return false;\\n  }\\n\\n  // Compare each tool call\\n  for (let i = 0; i < toolCalls1.length; i++) {\\n    const call1 = toolCalls1[i];\\n    const call2 = toolCalls2[i];\\n\\n    // Compare all fields that must match exactly\\n    if (\\n      call1?.function.name !== call2?.function.name ||\\n      call1?.function.arguments !== call2?.function.arguments\\n    ) {\\n      return false;\\n    }\\n  }\\n\\n  // If we made it through all comparisons, the calls match exactly\\n  return true;\\n}\\n\\n```\\n\\nIn most cases, you’ll want to start from one of the templates and customize the grader function to run the checks you care about. You can also use the **Custom** template to start from scratch.\\n\\nCurrently, the code evaluation framework only supports TypeScript code executed in a sandbox\\nenvironment without access to the internet, external npm packages, or a file system. If you’re\\ninterested in writing evals in other languages or need more advanced features, please let us know\\nat [support@openpipe.ai](mailto:support@openpipe.ai).\\n\\n[Quick Start](https://docs.openpipe.ai/features/evaluations/quick-start) [Criterion Evals](https://docs.openpipe.ai/features/evaluations/criterion)\\n\\n![](https://docs.openpipe.ai/features/evaluations/code)\\n\\n![](https://docs.openpipe.ai/features/evaluations/code',\n",
       " 'docs_openpipe_ai_features_chat_completions_external_models.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nChat Completions\\n\\nProxying to External Models\\n\\nAdding custom external models is not required to proxy requests to Anthropic, Gemini, or OpenAI\\nmodels. See our docs on proxying to [Anthropic](https://docs.openpipe.ai/features/chat-completions/anthropic),\\n[Gemini](https://docs.openpipe.ai/features/chat-completions/gemini), or\\n[OpenAI](https://docs.openpipe.ai/features/request-logs/logging-requests#proxy) for more information.\\n\\nTo proxy requests to models from unsupported providers, you’ll need to complete the following steps:\\n\\n1. Add an external model provider\\n2. Update your chat completion requests\\n\\nTo add an external model provider to your project, follow the instructions in [External Models](https://docs.openpipe.ai/features/external-models). Once it’s been added, continue to the next step.\\n\\n### [\\u200b](https://docs.openpipe.ai/features/chat-completions/external-models\\\\#updating-your-chat-completion-requests)  Updating your chat completion requests\\n\\nSet the model parameter in your requests to match this format: `openpipe:<external-model-provider-slug>/<external-model-slug>`.\\n\\nFor example, if you’re calling **gpt-4o-2024-08-06** on Azure, the model parameter should be `openpipe:custom-azure-provider/gpt-4o-2024-08-06`.\\n\\n- Python\\n- NodeJS\\n\\nCopy\\n\\n```python\\nfrom openpipe import OpenAI\\n\\n# Find the config values in \"Installing the SDK\"\\nclient = OpenAI()\\n\\ncompletion = client.chat.completions.create(\\n    model=\"openpipe:custom-azure-provider/gpt-4o-2024-08-06\",\\n    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\\n    metadata={\"prompt_id\": \"counting\", \"any_key\": \"any_value\"},\\n)\\n\\n```\\n\\nExternal models can also be used for filtering and relabeling your data. We currently support custom external\\nmodels for providers with openai and azure-compatible endpoints. If you’d like support for an external provider with a different API format, send a request to [hello@openpipe.ai](mailto:hello@openpipe.ai).\\n\\n[Overview](https://docs.openpipe.ai/features/chat-completions/overview) [Anthropic Proxy](https://docs.openpipe.ai/features/chat-completions/anthropic)\\n\\nOn this page\\n\\n- [Updating your chat completion requests](https://docs.openpipe.ai/features/chat-completions/external-models#updating-your-chat-completion-requests',\n",
       " 'docs_openpipe_ai_api_reference_post_createDatasetEntries.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nDatasets\\n\\nAdd Entries to Dataset\\n\\nPOST\\n\\n/\\n\\ndatasets\\n\\n/\\n\\n{datasetId}\\n\\n/\\n\\nentries\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/datasets/{datasetId}/entries \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"entries\": [\\\\\\n    {\\\\\\n      \"messages\": [\\\\\\n        {\\\\\\n          \"role\": \"system\",\\\\\\n          \"content\": \"<string>\",\\\\\\n          \"name\": \"<string>\"\\\\\\n        }\\\\\\n      ],\\\\\\n      \"rejected_message\": {\\\\\\n        \"reasoning_content\": \"<string>\",\\\\\\n        \"content\": null,\\\\\\n        \"refusal\": \"<string>\",\\\\\\n        \"role\": \"assistant\",\\\\\\n        \"function_call\": {\\\\\\n          \"name\": \"\",\\\\\\n          \"arguments\": \"\"\\\\\\n        },\\\\\\n        \"tool_calls\": [\\\\\\n          {\\\\\\n            \"id\": \"<string>\",\\\\\\n            \"function\": {\\\\\\n              \"name\": \"<string>\",\\\\\\n              \"arguments\": \"<string>\"\\\\\\n            },\\\\\\n            \"type\": \"function\"\\\\\\n          }\\\\\\n        ]\\\\\\n      },\\\\\\n      \"tool_choice\": \"none\",\\\\\\n      \"tools\": [\\\\\\n        {\\\\\\n          \"function\": {\\\\\\n            \"name\": \"<string>\",\\\\\\n            \"parameters\": {},\\\\\\n            \"description\": \"<string>\",\\\\\\n            \"strict\": true\\\\\\n          },\\\\\\n          \"type\": \"function\"\\\\\\n        }\\\\\\n      ],\\\\\\n      \"response_format\": {\\\\\\n        \"type\": \"text\"\\\\\\n      },\\\\\\n      \"split\": \"TRAIN\",\\\\\\n      \"metadata\": {}\\\\\\n    }\\\\\\n  ]\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"object\": \"dataset.entries.creation\",\\n  \"entries_created\": 123,\\n  \"errors\": {\\n    \"object\": \"list\",\\n    \"data\": [\\\\\\n      {\\\\\\n        \"object\": \"dataset.entries.creation.error\",\\\\\\n        \"entry_index\": 123,\\\\\\n        \"message\": \"<string>\"\\\\\\n      }\\\\\\n    ]\\n  }\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Path Parameters\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#parameter-dataset-id)\\n\\ndatasetId\\n\\nstring\\n\\nrequired\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries)\\n\\nentries\\n\\nobject\\\\[\\\\]\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-messages)\\n\\nentries.messages\\n\\nobject\\\\[\\\\]\\n\\nrequired\\n\\n- Option 1\\n- Option 2\\n- Option 3\\n- Option 4\\n- Option 5\\n- Option 6\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-messages-role)\\n\\nentries.messages.role\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`system`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-messages-content)\\n\\nentries.messages.content\\n\\nstringobject\\\\[\\\\]\\n\\ndefault:\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-messages-name)\\n\\nentries.messages.name\\n\\nstring\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-metadata)\\n\\nentries.metadata\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-metadata-key)\\n\\nentries.metadata.{key}\\n\\nstring\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message)\\n\\nentries.rejected\\\\_message\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-role)\\n\\nentries.rejected\\\\_message.role\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`assistant`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-content)\\n\\nentries.rejected\\\\_message.content\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-function-call)\\n\\nentries.rejected\\\\_message.function\\\\_call\\n\\nobject \\\\| null\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-function-call-arguments)\\n\\nentries.rejected\\\\_message.function\\\\_call.arguments\\n\\nstring\\n\\ndefault:\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-function-call-name)\\n\\nentries.rejected\\\\_message.function\\\\_call.name\\n\\nstring\\n\\ndefault:\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-reasoning-content)\\n\\nentries.rejected\\\\_message.reasoning\\\\_content\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-refusal)\\n\\nentries.rejected\\\\_message.refusal\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-tool-calls)\\n\\nentries.rejected\\\\_message.tool\\\\_calls\\n\\nobject\\\\[\\\\] \\\\| null\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-tool-calls-function)\\n\\nentries.rejected\\\\_message.tool\\\\_calls.function\\n\\nobject\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-tool-calls-function-arguments)\\n\\nentries.rejected\\\\_message.tool\\\\_calls.function.arguments\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-tool-calls-function-name)\\n\\nentries.rejected\\\\_message.tool\\\\_calls.function.name\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-tool-calls-id)\\n\\nentries.rejected\\\\_message.tool\\\\_calls.id\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-tool-calls-type)\\n\\nentries.rejected\\\\_message.tool\\\\_calls.type\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`function`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-response-format)\\n\\nentries.response\\\\_format\\n\\nobject\\n\\n- Option 1\\n- Option 2\\n- Option 3\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-response-format-type)\\n\\nentries.response\\\\_format.type\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`text`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-split)\\n\\nentries.split\\n\\nenum<string>\\n\\nAvailable options:\\n\\n`TRAIN`,\\n\\n`TEST`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tool-choice)\\n\\nentries.tool\\\\_choice\\n\\nOption 1 · enum<string>Option 2 · enum<string>Option 3 · enum<string>Option 4 · object\\n\\nAvailable options:\\n\\n`none`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools)\\n\\nentries.tools\\n\\nobject\\\\[\\\\]\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools-function)\\n\\nentries.tools.function\\n\\nobject\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools-function-name)\\n\\nentries.tools.function.name\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools-function-description)\\n\\nentries.tools.function.description\\n\\nstring\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools-function-parameters)\\n\\nentries.tools.function.parameters\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools-function-parameters-key)\\n\\nentries.tools.function.parameters.{key}\\n\\nany\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools-function-strict)\\n\\nentries.tools.function.strict\\n\\nboolean \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools-type)\\n\\nentries.tools.type\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`function`\\n\\n#### Response\\n\\n200 - application/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-entries-created)\\n\\nentries\\\\_created\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-errors)\\n\\nerrors\\n\\nobject\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-errors-data)\\n\\nerrors.data\\n\\nobject\\\\[\\\\]\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-errors-data-entry-index)\\n\\nerrors.data.entry\\\\_index\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-errors-data-message)\\n\\nerrors.data.message\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-errors-data-object)\\n\\nerrors.data.object\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`dataset.entries.creation.error`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-errors-object)\\n\\nerrors.object\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`list`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-object)\\n\\nobject\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`dataset.entries.creation`\\n\\n[Delete Dataset](https://docs.openpipe.ai/api-reference/delete-dataset) [Create Model](https://docs.openpipe.ai/api-reference/post-createModel)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/datasets/{datasetId}/entries \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"entries\": [\\\\\\n    {\\\\\\n      \"messages\": [\\\\\\n        {\\\\\\n          \"role\": \"system\",\\\\\\n          \"content\": \"<string>\",\\\\\\n          \"name\": \"<string>\"\\\\\\n        }\\\\\\n      ],\\\\\\n      \"rejected_message\": {\\\\\\n        \"reasoning_content\": \"<string>\",\\\\\\n        \"content\": null,\\\\\\n        \"refusal\": \"<string>\",\\\\\\n        \"role\": \"assistant\",\\\\\\n        \"function_call\": {\\\\\\n          \"name\": \"\",\\\\\\n          \"arguments\": \"\"\\\\\\n        },\\\\\\n        \"tool_calls\": [\\\\\\n          {\\\\\\n            \"id\": \"<string>\",\\\\\\n            \"function\": {\\\\\\n              \"name\": \"<string>\",\\\\\\n              \"arguments\": \"<string>\"\\\\\\n            },\\\\\\n            \"type\": \"function\"\\\\\\n          }\\\\\\n        ]\\\\\\n      },\\\\\\n      \"tool_choice\": \"none\",\\\\\\n      \"tools\": [\\\\\\n        {\\\\\\n          \"function\": {\\\\\\n            \"name\": \"<string>\",\\\\\\n            \"parameters\": {},\\\\\\n            \"description\": \"<string>\",\\\\\\n            \"strict\": true\\\\\\n          },\\\\\\n          \"type\": \"function\"\\\\\\n        }\\\\\\n      ],\\\\\\n      \"response_format\": {\\\\\\n        \"type\": \"text\"\\\\\\n      },\\\\\\n      \"split\": \"TRAIN\",\\\\\\n      \"metadata\": {}\\\\\\n    }\\\\\\n  ]\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"object\": \"dataset.entries.creation\",\\n  \"entries_created\": 123,\\n  \"errors\": {\\n    \"object\": \"list\",\\n    \"data\": [\\\\\\n      {\\\\\\n        \"object\": \"dataset.entries.creation.error\",\\\\\\n        \"entry_index\": 123,\\\\\\n        \"message\": \"<string>\"\\\\\\n      }\\\\\\n    ]\\n  }\\n}\\n```',\n",
       " 'docs_openpipe_ai_features_pruning_rules.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nFeatures\\n\\nPruning Rules\\n\\nSome prompts have large chunks of unchanging text, like system messages which don’t change from one request to the next. By removing this static text and fine-tuning a model on the compacted data, we can reduce the size of incoming requests and save you money on inference.\\n\\nAdd pruning rules to your dataset in the Settings tab, as shown below and in our [demo dataset](https://app.openpipe.ai/p/BRZFEx50Pf/datasets/0aa75f72-3fe5-4294-a94e-94c9236befa6/settings).\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/pruning-rules/dataset-pruning-rule.png)\\n\\nTo see the effect your pruning rules had on an individual training entry’s input messages, open the Dataset Entry drawer:\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/pruning-rules/drawer-rule.png)\\n\\nBy default, fine-tuned models inherit pruning rules applied to the dataset on which they were trained (see [demo model](https://app.openpipe.ai/p/BRZFEx50Pf/fine-tunes/5a2af605-03d3-412c-a7d3-611bdf6e1dcf/general)). These rules will automatically prune matching text from any incoming requests sent to that model. New pruning rules will not be associated with previously trained models, so you don’t need to worry about backwards compatibility when adding new rules to your dataset. Before training a new model, you can choose to disable any inherited pruning rules.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/pruning-rules/model-rules.png)\\n\\n## [\\u200b](https://docs.openpipe.ai/features/pruning-rules\\\\#warning-can-affect-quality)  Warning: can affect quality!\\n\\nWe’ve found that while pruning rules always decrease latency and costs, they can also negatively affect response quality, especially with smaller datasets. We recommend enabling pruning rules on datasets with 10K+ training examples, as smaller datasets may not provide enough guidance for the model to fully learn the task.\\n\\n[Updating Metadata Tags](https://docs.openpipe.ai/features/updating-metadata) [Fallback](https://docs.openpipe.ai/features/fallback)\\n\\nOn this page\\n\\n- [Warning: can affect quality!](https://docs.openpipe.ai/features/pruning-rules#warning-can-affect-quality)\\n\\n![](https://docs.openpipe.ai/features/pruning-rules)\\n\\n![](https://docs.openpipe.ai/features/pruning-rules)\\n\\n![](https://docs.openpipe.ai/features/pruning-rules',\n",
       " 'docs_openpipe_ai_features_evaluations_overview.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nEvaluations\\n\\nEvaluations\\n\\nAfter training a model, you’ll want to know how well it performs. Datasets include a built-in evaluation framework that makes it easy to compare newly trained models against previous models and generic base models as well.\\n\\nBy default, 10% of the dataset entries you provide will be withheld from training. These entries form your test set. For each entry in the test set, your new model will produce an output that will be shown in the [evaluation table](https://app.openpipe.ai/p/BRZFEx50Pf/datasets/3e7e82c1-b066-476c-9f17-17fd85a2169b/evaluate).\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/evals-table.png)\\n\\nViewing outputs side by side is useful, but it doesn’t tell you which model is doing better in general. For that, we need to define evaluations. Evaluations\\nallow you to compare model outputs across a variety of inputs to determine which model is doing a better\\njob. While each type of evaluation has its own unique UI, they all show final results in a sorted table.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/eval-results-table.png)\\n\\nDatasets support three types of evaluations:\\n\\n- [Code evaluations](https://docs.openpipe.ai/features/evaluations/code)\\n- [Criterion evaluations](https://docs.openpipe.ai/features/evaluations/criterion)\\n- [Head-to-head evaluations](https://docs.openpipe.ai/features/evaluations/head-to-head)\\n\\nAs a rough guide, use code evaluations for deterministic tasks like classification or information extraction. Use criterion evaluations for tasks with freeform outputs like chatbots or summarization. Use head-to-head evaluations for comparing two or more models against each other if you’re looking for a quick and dirty way to compare model outputs.\\n\\n[Quick Start](https://docs.openpipe.ai/features/dpo/quick-start) [Quick Start](https://docs.openpipe.ai/features/evaluations/quick-start)\\n\\n![](https://docs.openpipe.ai/features/evaluations/overview)\\n\\n![](https://docs.openpipe.ai/features/evaluations/overview',\n",
       " 'docs_openpipe_ai_features_datasets_uploading_data.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nDatasets\\n\\nUploading Data\\n\\nUpload a JSONL file populated with a list of training examples.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/uploading-data.png)\\n\\nEach line of the file should be compatible with the OpenAI [chat format](https://platform.openai.com/docs/api-reference/chat/object), with additional optional fields.\\n\\n### [\\u200b](https://docs.openpipe.ai/features/datasets/uploading-data\\\\#openai-fields)  OpenAI Fields\\n\\n- **`messages`: Required** \\\\- Formatted as a list of OpenAI [chat completion messages](https://platform.openai.com/docs/guides/gpt/chat-completions-api). The list should end with an assistant message.\\n- **`tools`: Optional** \\\\- An array of tools (functions) available for the model to call. For more information read OpenAI’s [function calling docs](https://platform.openai.com/docs/guides/function-calling).\\n- **`tool_choice`: Optional** \\\\- You can set this to indicate that the model should be required to call the given tool. For more information read OpenAI’s [function calling docs](https://platform.openai.com/docs/guides/function-calling).\\n\\n#### [\\u200b](https://docs.openpipe.ai/features/datasets/uploading-data\\\\#deprecated)  Deprecated\\n\\n- **`functions`: Deprecated \\\\| Optional** \\\\- An array of functions available for the model to call.\\n- **`function_call`: Deprecated \\\\| Optional** \\\\- You can set this to indicate that the model should be required to call the given function.\\n\\nYou can include other parameters from the OpenAI chat completion input format (eg. temperature), but they will be ignored since they aren’t relevant for training.\\n\\n### [\\u200b](https://docs.openpipe.ai/features/datasets/uploading-data\\\\#additional-fields)  Additional Fields\\n\\n- **`split`: Optional** \\\\- One of “TRAIN” or “TEST”. If you don’t set this field we’ll automatically divide your inputs into train and test splits with a target ratio of 90:10.\\n- **`rejected_message`: Optional** \\\\- Add a rejected output for entries on which you want to perform direct preference optimization (DPO). You can find more information about that here: [Direct Preference Optimization](https://docs.openpipe.ai/features/dpo/Overview)\\n- **`metadata`: Optional** \\\\- A string=>string dictionary of any additional information you want to associate with an entry. This can be useful for tracking information like prompt IDs.\\n\\n### [\\u200b](https://docs.openpipe.ai/features/datasets/uploading-data\\\\#example)  Example\\n\\nCopy\\n\\n```jsonl\\n...\\n{\"messages\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":\"What is the capital of Tasmania?\"},{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"arguments\":\"{\\\\\"capital\\\\\":\\\\\"Hobart\\\\\"}\"}}]}],\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"parameters\":{\"type\":\"object\",\"properties\":{\"capital\":{\"type\":\"string\"}}}}}], \"split\": \"TRAIN\", \"metadata\": {\"prompt_id\": \"counting\", \"any_key\": \"any_value\"}}\\n{\"messages\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":\"What is the capital of Sweden?\"},{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"arguments\":\"{\\\\\"capital\\\\\":\\\\\"Stockholm\\\\\"}\"}}]}],\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"parameters\":{\"type\":\"object\",\"properties\":{\"capital\":{\"type\":\"string\"}}}}}], \"split\": \"TEST\", \"metadata\": {\"prompt_id\": \"counting\", \"any_key\": \"any_value\"}}\\n...\\n\\n```\\n\\n[Importing Request Logs](https://docs.openpipe.ai/features/datasets/importing-logs) [Relabeling Data](https://docs.openpipe.ai/features/datasets/relabeling-data)\\n\\nOn this page\\n\\n- [OpenAI Fields](https://docs.openpipe.ai/features/datasets/uploading-data#openai-fields)\\n- [Deprecated](https://docs.openpipe.ai/features/datasets/uploading-data#deprecated)\\n- [Additional Fields](https://docs.openpipe.ai/features/datasets/uploading-data#additional-fields)\\n- [Example](https://docs.openpipe.ai/features/datasets/uploading-data#example)\\n\\n![](https://docs.openpipe.ai/features/datasets/uploading-data',\n",
       " 'docs_openpipe_ai_features_request_logs_logging_requests.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nRequest Logs\\n\\nLogging Requests\\n\\nRequest logs are a great way to get to know your data. More importantly, you can import recorded logs directly into your training datasets. That means it’s really easy to train on data you’ve collected in production.\\n\\nWe recommend collecting request logs for both base and fine-tuned models. We provide several options for recording your requests.\\n\\n### [\\u200b](https://docs.openpipe.ai/features/request-logs/logging-requests\\\\#sdk)  SDK\\n\\nThe simplest way to start ingesting request logs into OpenPipe is by installing our Python or TypeScript SDK. Requests to both OpenAI and OpenPipe models will automatically be recorded.\\nLogging doesn’t add any latency to your requests, because our SDK calls the OpenAI server directly and returns your completion before kicking off the request to record it in your project.\\n\\nWe provide a drop-in replacement for the OpenAI SDK, so the only code you need to update is your import statement:\\n\\n- Python\\n- NodeJS\\n\\nCopy\\n\\n```python\\n# from openai import OpenAI\\nfrom openpipe import OpenAI\\n\\n# Nothing else changes\\n\\nclient = OpenAI()\\n\\ncompletion = client.chat.completions.create(\\n    model=\"gpt-4o\",\\n    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\\n    # searchable metadata tags are highly recommended\\n    metadata={\"prompt_id\": \"counting\", \"any_key\": \"any_value\"},\\n)\\n\\n```\\n\\nSee [Installing the SDK](https://docs.openpipe.ai/getting-started/openpipe-sdk) for a quick guide on how to get started.\\n\\n### [\\u200b](https://docs.openpipe.ai/features/request-logs/logging-requests\\\\#proxy)  Proxy\\n\\nIf you’re developing in a language other than Python or TypeScript, the best way to ingest data into OpenPipe is through our proxy. We provide a `/chat/completions` endpoint that is fully compatible\\nwith OpenAI, so you can continue using the latest features like tool calls and streaming without a hitch.\\n\\nIntegrating the Proxy and logging requests requires a couple steps.\\n\\n1. Add an OpenAI key to your project in the [project settings](https://app.openpipe.ai/settings) page.\\n2. Set the authorization token of your request to be your OpenPipe API key.\\n3. Set the destination url of your request to be `https://api.openpipe.ai/api/v1/chat/completions`.\\n4. When making any request that you’d like to record, include the `\"store\": true` parameter in the request body. We also recommend that you add custom metadata tags to your request to\\ndistinguish data collected from different prompts.\\n\\nHere’s an example of steps 2-4 put together in both a raw cURL request and with the Python SDK:\\n\\n- cURL Request\\n- Python SDK\\n- TypeScript SDK\\n\\nCopy\\n\\n```bash\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/chat/completions \\\\\\n  --header \"Authorization: Bearer YOUR_OPENPIPE_API_KEY\" \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"model\": \"gpt-4-0613\",\\n  \"messages\": [\\\\\\n    {\\\\\\n      \"role\": \"system\",\\\\\\n      \"content\": \"count to 5\"\\\\\\n    }\\\\\\n  ],\\n  \"max_tokens\": 100,\\n  \"temperature\": 0,\\n  \"store\": true,\\n  \"metadata\": {\\n    \"prompt_id\": \"first_prompt\"\\n  }\\n}\\'\\n\\n```\\n\\n### [\\u200b](https://docs.openpipe.ai/features/request-logs/logging-requests\\\\#reporting)  Reporting\\n\\nIf you need more flexibility in how you log requests, you can use the `report` endpoint. This gives you full control over when and how to create request logs.\\n\\n- Python\\n- NodeJS\\n\\nCopy\\n\\n```python\\nimport time\\nfrom openai import OpenAI\\nfrom openpipe.client import OpenPipe\\n\\nclient = OpenAI()\\nop_client = OpenPipe()\\n\\npayload = {\\n    \"model\": \"gpt-4o\",\\n    \"messages\": [{\"role\": \"user\", \"content\": \"Count to 10\"}],\\n}\\n\\ncompletion = client.chat.completions.create(**payload)\\n\\nop_client.report(\\n    requested_at=int(time.time() * 1000),\\n    received_at=int(time.time() * 1000),\\n    req_payload=payload,\\n    resp_payload=completion,\\n    status_code=200,\\n    metadata={\"prompt_id\": \"My prompt id\"},\\n)\\n\\n```\\n\\nIf you’re developing in a language other than Python or TypeScript, you can also make a raw HTTP request to the [report](https://docs.openpipe.ai/api-reference/post-report) endpoint.\\n\\nOnce you’ve set up logging, you will see the data on the Request Logs page. From there, you’ll be able to search through your requests and train your models. See [Training on Logs](https://docs.openpipe.ai/features/datasets/importing-logs) to learn more.\\n\\n[Installing the SDK](https://docs.openpipe.ai/getting-started/openpipe-sdk) [Logging Anthropic Requests](https://docs.openpipe.ai/features/request-logs/reporting-anthropic)\\n\\nOn this page\\n\\n- [SDK](https://docs.openpipe.ai/features/request-logs/logging-requests#sdk)\\n- [Proxy](https://docs.openpipe.ai/features/request-logs/logging-requests#proxy)\\n- [Reporting](https://docs.openpipe.ai/features/request-logs/logging-requests#reporting',\n",
       " 'docs_openpipe_ai_features_external_models.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nFeatures\\n\\nExternal Models\\n\\nBefore defining a custom external model provider, check your project settings to see if the\\nprovider you’re looking for is already supported.\\n\\nTo use a custom external model from a cloud provider that OpenPipe doesn’t support, you can add an external model provider to your project. External models can be used for the following purposes:\\n\\n- [Proxying chat completions](https://docs.openpipe.ai/features/chat-completions/external-models)\\n- [Filtering and relabeling your data](https://docs.openpipe.ai/features/evaluations/head-to-head)\\n- [Evaluating outputs through criteria](https://docs.openpipe.ai/features/criteria/quick-start)\\n\\nThe instructions below demonstrate how to add a DeepSeek (OpenAI Compatible) and Azure provider to your project.\\n\\n### [\\u200b](https://docs.openpipe.ai/features/external-models\\\\#creating-an-external-model-provider)  Creating an external model provider\\n\\nFind the **External Model Providers** section of your project settings, and click the **Add Provider** button.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/external-models/add-provider-button.png)\\n\\nGive your custom provider a slug, API key, and add a custom base url if necessary. The provider slug should be unique,\\nand will be used when we proxy requests to models associated with this provider.\\n\\n- DeepSeek (OpenAI Compatible)\\n- Azure Endpoint\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/external-models/add-provider-modal-deepseek.png)\\n\\n### [\\u200b](https://docs.openpipe.ai/features/external-models\\\\#adding-a-model-to-the-external-provider)  Adding a model to the external provider\\n\\nTo add a model to the provider you’re creating, click the **Add Model** button.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/external-models/add-model-button.png)\\n\\nProvide a slug that matches the model you’d like to call on your external provider. To call **gpt-4o-2024-08-06** on Azure for instance, the slug should be `gpt-4o-2024-08-06`.\\n\\n- DeepSeek (OpenAI Compatible)\\n- Azure Endpoint\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/external-models/add-model-row-deepseek.png)\\n\\nSetting input cost and output cost is optional, but can be helpful for showing relative costs in the [evals](https://docs.openpipe.ai/features/evaluations) page.\\n\\nWe currently support custom external\\nmodels for providers with openai and azure-compatible endpoints. If you’d like support for an external provider with a different API format, send a request to [hello@openpipe.ai](mailto:hello@openpipe.ai).\\n\\n[Mixture of Agents](https://docs.openpipe.ai/features/mixture-of-agents) [Report](https://docs.openpipe.ai/api-reference/post-report)\\n\\nOn this page\\n\\n- [Creating an external model provider](https://docs.openpipe.ai/features/external-models#creating-an-external-model-provider)\\n- [Adding a model to the external provider](https://docs.openpipe.ai/features/external-models#adding-a-model-to-the-external-provider)\\n\\n![](https://docs.openpipe.ai/features/external-models)\\n\\n![](https://docs.openpipe.ai/features/external-models)\\n\\n![](https://docs.openpipe.ai/features/external-models)\\n\\n![](https://docs.openpipe.ai/features/external-models',\n",
       " 'docs_openpipe_ai_api_reference_post_chatcompletions.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nChat Completions\\n\\nChat Completions\\n\\nPOST\\n\\n/\\n\\nchat\\n\\n/\\n\\ncompletions\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/chat/completions \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"messages\": [\\\\\\n    {\\\\\\n      \"role\": \"system\",\\\\\\n      \"content\": \"<string>\",\\\\\\n      \"name\": \"<string>\"\\\\\\n    }\\\\\\n  ],\\n  \"model\": \"<string>\",\\n  \"audio\": {\\n    \"format\": \"wav\",\\n    \"voice\": \"alloy\"\\n  },\\n  \"function_call\": \"none\",\\n  \"functions\": [\\\\\\n    {\\\\\\n      \"name\": \"<string>\",\\\\\\n      \"parameters\": {},\\\\\\n      \"description\": \"<string>\",\\\\\\n      \"strict\": true\\\\\\n    }\\\\\\n  ],\\n  \"tool_choice\": \"none\",\\n  \"tools\": [\\\\\\n    {\\\\\\n      \"function\": {\\\\\\n        \"name\": \"<string>\",\\\\\\n        \"parameters\": {},\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"strict\": true\\\\\\n      },\\\\\\n      \"type\": \"function\"\\\\\\n    }\\\\\\n  ],\\n  \"n\": 123,\\n  \"max_tokens\": 123,\\n  \"max_completion_tokens\": 123,\\n  \"temperature\": 123,\\n  \"top_p\": 123,\\n  \"presence_penalty\": 123,\\n  \"frequency_penalty\": 123,\\n  \"stop\": \"<string>\",\\n  \"response_format\": {\\n    \"type\": \"text\"\\n  },\\n  \"logprobs\": true,\\n  \"top_logprobs\": 123,\\n  \"stream_options\": {\\n    \"include_usage\": true\\n  },\\n  \"store\": true,\\n  \"metadata\": {},\\n  \"stream\": false\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"id\": \"<string>\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 123,\\n  \"model\": \"<string>\",\\n  \"choices\": [\\\\\\n    {\\\\\\n      \"finish_reason\": \"length\",\\\\\\n      \"index\": 123,\\\\\\n      \"message\": {\\\\\\n        \"reasoning_content\": \"<string>\",\\\\\\n        \"content\": null,\\\\\\n        \"refusal\": \"<string>\",\\\\\\n        \"role\": \"assistant\",\\\\\\n        \"function_call\": {\\\\\\n          \"name\": \"\",\\\\\\n          \"arguments\": \"\"\\\\\\n        },\\\\\\n        \"tool_calls\": [\\\\\\n          {\\\\\\n            \"id\": \"<string>\",\\\\\\n            \"function\": {\\\\\\n              \"name\": \"<string>\",\\\\\\n              \"arguments\": \"<string>\"\\\\\\n            },\\\\\\n            \"type\": \"function\"\\\\\\n          }\\\\\\n        ]\\\\\\n      },\\\\\\n      \"logprobs\": null,\\\\\\n      \"content_filter_results\": {},\\\\\\n      \"criteria_results\": {}\\\\\\n    }\\\\\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 123,\\n    \"completion_tokens\": 123,\\n    \"total_tokens\": 123,\\n    \"prompt_cache_hit_tokens\": 123,\\n    \"prompt_cache_miss_tokens\": 123,\\n    \"completion_tokens_details\": {\\n      \"reasoning_tokens\": 123,\\n      \"audio_tokens\": 123,\\n      \"text_tokens\": 123,\\n      \"accepted_prediction_tokens\": 123,\\n      \"rejected_prediction_tokens\": 123\\n    },\\n    \"prompt_tokens_details\": {\\n      \"cached_tokens\": 123,\\n      \"audio_tokens\": 123\\n    },\\n    \"criteria\": {}\\n  }\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-messages)\\n\\nmessages\\n\\nobject\\\\[\\\\]\\n\\nrequired\\n\\n- Option 1\\n- Option 2\\n- Option 3\\n- Option 4\\n- Option 5\\n- Option 6\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-messages-role)\\n\\nmessages.role\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`system`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-messages-content)\\n\\nmessages.content\\n\\nstringobject\\\\[\\\\]\\n\\ndefault:\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-messages-name)\\n\\nmessages.name\\n\\nstring\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-model)\\n\\nmodel\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-audio)\\n\\naudio\\n\\nobject \\\\| null\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-audio-format)\\n\\naudio.format\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`wav`,\\n\\n`mp3`,\\n\\n`flac`,\\n\\n`opus`,\\n\\n`pcm16`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-audio-voice)\\n\\naudio.voice\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`alloy`,\\n\\n`ash`,\\n\\n`ballad`,\\n\\n`coral`,\\n\\n`echo`,\\n\\n`sage`,\\n\\n`shimmer`,\\n\\n`verse`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-frequency-penalty)\\n\\nfrequency\\\\_penalty\\n\\nnumber \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-function-call)\\n\\nfunction\\\\_call\\n\\nOption 1 · enum<string>Option 2 · enum<string>Option 3 · object\\n\\nAvailable options:\\n\\n`none`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-functions)\\n\\nfunctions\\n\\nobject\\\\[\\\\]\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-functions-name)\\n\\nfunctions.name\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-functions-description)\\n\\nfunctions.description\\n\\nstring\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-functions-parameters)\\n\\nfunctions.parameters\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-functions-parameters-key)\\n\\nfunctions.parameters.{key}\\n\\nany\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-functions-strict)\\n\\nfunctions.strict\\n\\nboolean \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-logprobs)\\n\\nlogprobs\\n\\nboolean\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-max-completion-tokens)\\n\\nmax\\\\_completion\\\\_tokens\\n\\nnumber \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-max-tokens)\\n\\nmax\\\\_tokens\\n\\nnumber \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-metadata)\\n\\nmetadata\\n\\nobject \\\\| null\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-metadata-key)\\n\\nmetadata.{key}\\n\\nstring\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-n)\\n\\nn\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-presence-penalty)\\n\\npresence\\\\_penalty\\n\\nnumber \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-response-format)\\n\\nresponse\\\\_format\\n\\nobject\\n\\n- Option 1\\n- Option 2\\n- Option 3\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-response-format-type)\\n\\nresponse\\\\_format.type\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`text`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-stop)\\n\\nstop\\n\\nstringstring\\\\[\\\\]\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-store)\\n\\nstore\\n\\nboolean\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-stream)\\n\\nstream\\n\\nboolean\\n\\ndefault:\\n\\nfalse\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-stream-options)\\n\\nstream\\\\_options\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-stream-options-include-usage)\\n\\nstream\\\\_options.include\\\\_usage\\n\\nboolean\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-temperature)\\n\\ntemperature\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tool-choice)\\n\\ntool\\\\_choice\\n\\nOption 1 · enum<string>Option 2 · enum<string>Option 3 · enum<string>Option 4 · object\\n\\nAvailable options:\\n\\n`none`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools)\\n\\ntools\\n\\nobject\\\\[\\\\]\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools-function)\\n\\ntools.function\\n\\nobject\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools-function-name)\\n\\ntools.function.name\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools-function-description)\\n\\ntools.function.description\\n\\nstring\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools-function-parameters)\\n\\ntools.function.parameters\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools-function-parameters-key)\\n\\ntools.function.parameters.{key}\\n\\nany\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools-function-strict)\\n\\ntools.function.strict\\n\\nboolean \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools-type)\\n\\ntools.type\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`function`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-top-logprobs)\\n\\ntop\\\\_logprobs\\n\\nnumber \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-top-p)\\n\\ntop\\\\_p\\n\\nnumber \\\\| null\\n\\n#### Response\\n\\n200 - application/json\\n\\n- Option 1\\n- Option 2\\n- Option 3\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices)\\n\\nchoices\\n\\nobject\\\\[\\\\]\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-finish-reason)\\n\\nchoices.finish\\\\_reason\\n\\nOption 1 · enum<string>Option 2 · enum<string>Option 3 · enum<string>Option 4 · enum<string>Option 5 · enum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`length`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-index)\\n\\nchoices.index\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message)\\n\\nchoices.message\\n\\nobject\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-role)\\n\\nchoices.message.role\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`assistant`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-content)\\n\\nchoices.message.content\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-function-call)\\n\\nchoices.message.function\\\\_call\\n\\nobject \\\\| null\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-function-call-arguments)\\n\\nchoices.message.function\\\\_call.arguments\\n\\nstring\\n\\ndefault:\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-function-call-name)\\n\\nchoices.message.function\\\\_call.name\\n\\nstring\\n\\ndefault:\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-reasoning-content)\\n\\nchoices.message.reasoning\\\\_content\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-refusal)\\n\\nchoices.message.refusal\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-tool-calls)\\n\\nchoices.message.tool\\\\_calls\\n\\nobject\\\\[\\\\] \\\\| null\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-tool-calls-function)\\n\\nchoices.message.tool\\\\_calls.function\\n\\nobject\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-tool-calls-function-arguments)\\n\\nchoices.message.tool\\\\_calls.function.arguments\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-tool-calls-function-name)\\n\\nchoices.message.tool\\\\_calls.function.name\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-tool-calls-id)\\n\\nchoices.message.tool\\\\_calls.id\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-tool-calls-type)\\n\\nchoices.message.tool\\\\_calls.type\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`function`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-content-filter-results)\\n\\nchoices.content\\\\_filter\\\\_results\\n\\nobject\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-criteria-results)\\n\\nchoices.criteria\\\\_results\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-criteria-results-key)\\n\\nchoices.criteria\\\\_results.{key}\\n\\nobject\\n\\n- Option 1\\n- Option 2\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-criteria-results-key-score)\\n\\nchoices.criteria\\\\_results.{key}.score\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-criteria-results-key-status)\\n\\nchoices.criteria\\\\_results.{key}.status\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`success`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-criteria-results-key-error-code)\\n\\nchoices.criteria\\\\_results.{key}.errorCode\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-criteria-results-key-error-message)\\n\\nchoices.criteria\\\\_results.{key}.errorMessage\\n\\nstring\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-criteria-results-key-explanation)\\n\\nchoices.criteria\\\\_results.{key}.explanation\\n\\nstring\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs)\\n\\nchoices.logprobs\\n\\nobject \\\\| null\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content)\\n\\nchoices.logprobs.content\\n\\nobject\\\\[\\\\] \\\\| null\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content-bytes)\\n\\nchoices.logprobs.content.bytes\\n\\nnumber\\\\[\\\\] \\\\| null\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content-logprob)\\n\\nchoices.logprobs.content.logprob\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content-token)\\n\\nchoices.logprobs.content.token\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content-top-logprobs)\\n\\nchoices.logprobs.content.top\\\\_logprobs\\n\\nobject\\\\[\\\\]\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content-top-logprobs-bytes)\\n\\nchoices.logprobs.content.top\\\\_logprobs.bytes\\n\\nnumber\\\\[\\\\] \\\\| null\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content-top-logprobs-logprob)\\n\\nchoices.logprobs.content.top\\\\_logprobs.logprob\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content-top-logprobs-token)\\n\\nchoices.logprobs.content.top\\\\_logprobs.token\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal)\\n\\nchoices.logprobs.refusal\\n\\nobject\\\\[\\\\] \\\\| null\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal-bytes)\\n\\nchoices.logprobs.refusal.bytes\\n\\nnumber\\\\[\\\\] \\\\| null\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal-logprob)\\n\\nchoices.logprobs.refusal.logprob\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal-token)\\n\\nchoices.logprobs.refusal.token\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal-top-logprobs)\\n\\nchoices.logprobs.refusal.top\\\\_logprobs\\n\\nobject\\\\[\\\\]\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal-top-logprobs-bytes)\\n\\nchoices.logprobs.refusal.top\\\\_logprobs.bytes\\n\\nnumber\\\\[\\\\] \\\\| null\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal-top-logprobs-logprob)\\n\\nchoices.logprobs.refusal.top\\\\_logprobs.logprob\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal-top-logprobs-token)\\n\\nchoices.logprobs.refusal.top\\\\_logprobs.token\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-created)\\n\\ncreated\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-id)\\n\\nid\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-model)\\n\\nmodel\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-object)\\n\\nobject\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`chat.completion`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage)\\n\\nusage\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-completion-tokens)\\n\\nusage.completion\\\\_tokens\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-prompt-tokens)\\n\\nusage.prompt\\\\_tokens\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-total-tokens)\\n\\nusage.total\\\\_tokens\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-completion-tokens-details)\\n\\nusage.completion\\\\_tokens\\\\_details\\n\\nobject \\\\| null\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-completion-tokens-details-accepted-prediction-tokens)\\n\\nusage.completion\\\\_tokens\\\\_details.accepted\\\\_prediction\\\\_tokens\\n\\nnumber \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-completion-tokens-details-audio-tokens)\\n\\nusage.completion\\\\_tokens\\\\_details.audio\\\\_tokens\\n\\nnumber \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-completion-tokens-details-reasoning-tokens)\\n\\nusage.completion\\\\_tokens\\\\_details.reasoning\\\\_tokens\\n\\nnumber \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-completion-tokens-details-rejected-prediction-tokens)\\n\\nusage.completion\\\\_tokens\\\\_details.rejected\\\\_prediction\\\\_tokens\\n\\nnumber \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-completion-tokens-details-text-tokens)\\n\\nusage.completion\\\\_tokens\\\\_details.text\\\\_tokens\\n\\nnumber \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-criteria)\\n\\nusage.criteria\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-criteria-key)\\n\\nusage.criteria.{key}\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-criteria-key-total-tokens)\\n\\nusage.criteria.{key}.total\\\\_tokens\\n\\nnumber\\n\\nrequired\\n\\nThe total number of tokens used to generate the criterion judgement. Only returned for OpenPipe-trained reward models currently.\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-prompt-cache-hit-tokens)\\n\\nusage.prompt\\\\_cache\\\\_hit\\\\_tokens\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-prompt-cache-miss-tokens)\\n\\nusage.prompt\\\\_cache\\\\_miss\\\\_tokens\\n\\nnumber\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-prompt-tokens-details)\\n\\nusage.prompt\\\\_tokens\\\\_details\\n\\nobject \\\\| null\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-prompt-tokens-details-audio-tokens)\\n\\nusage.prompt\\\\_tokens\\\\_details.audio\\\\_tokens\\n\\nnumber \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-prompt-tokens-details-cached-tokens)\\n\\nusage.prompt\\\\_tokens\\\\_details.cached\\\\_tokens\\n\\nnumber \\\\| null\\n\\n[Update Metadata](https://docs.openpipe.ai/api-reference/post-updatemetadata) [Create Dataset](https://docs.openpipe.ai/api-reference/post-createDataset)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/chat/completions \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"messages\": [\\\\\\n    {\\\\\\n      \"role\": \"system\",\\\\\\n      \"content\": \"<string>\",\\\\\\n      \"name\": \"<string>\"\\\\\\n    }\\\\\\n  ],\\n  \"model\": \"<string>\",\\n  \"audio\": {\\n    \"format\": \"wav\",\\n    \"voice\": \"alloy\"\\n  },\\n  \"function_call\": \"none\",\\n  \"functions\": [\\\\\\n    {\\\\\\n      \"name\": \"<string>\",\\\\\\n      \"parameters\": {},\\\\\\n      \"description\": \"<string>\",\\\\\\n      \"strict\": true\\\\\\n    }\\\\\\n  ],\\n  \"tool_choice\": \"none\",\\n  \"tools\": [\\\\\\n    {\\\\\\n      \"function\": {\\\\\\n        \"name\": \"<string>\",\\\\\\n        \"parameters\": {},\\\\\\n        \"description\": \"<string>\",\\\\\\n        \"strict\": true\\\\\\n      },\\\\\\n      \"type\": \"function\"\\\\\\n    }\\\\\\n  ],\\n  \"n\": 123,\\n  \"max_tokens\": 123,\\n  \"max_completion_tokens\": 123,\\n  \"temperature\": 123,\\n  \"top_p\": 123,\\n  \"presence_penalty\": 123,\\n  \"frequency_penalty\": 123,\\n  \"stop\": \"<string>\",\\n  \"response_format\": {\\n    \"type\": \"text\"\\n  },\\n  \"logprobs\": true,\\n  \"top_logprobs\": 123,\\n  \"stream_options\": {\\n    \"include_usage\": true\\n  },\\n  \"store\": true,\\n  \"metadata\": {},\\n  \"stream\": false\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"id\": \"<string>\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 123,\\n  \"model\": \"<string>\",\\n  \"choices\": [\\\\\\n    {\\\\\\n      \"finish_reason\": \"length\",\\\\\\n      \"index\": 123,\\\\\\n      \"message\": {\\\\\\n        \"reasoning_content\": \"<string>\",\\\\\\n        \"content\": null,\\\\\\n        \"refusal\": \"<string>\",\\\\\\n        \"role\": \"assistant\",\\\\\\n        \"function_call\": {\\\\\\n          \"name\": \"\",\\\\\\n          \"arguments\": \"\"\\\\\\n        },\\\\\\n        \"tool_calls\": [\\\\\\n          {\\\\\\n            \"id\": \"<string>\",\\\\\\n            \"function\": {\\\\\\n              \"name\": \"<string>\",\\\\\\n              \"arguments\": \"<string>\"\\\\\\n            },\\\\\\n            \"type\": \"function\"\\\\\\n          }\\\\\\n        ]\\\\\\n      },\\\\\\n      \"logprobs\": null,\\\\\\n      \"content_filter_results\": {},\\\\\\n      \"criteria_results\": {}\\\\\\n    }\\\\\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 123,\\n    \"completion_tokens\": 123,\\n    \"total_tokens\": 123,\\n    \"prompt_cache_hit_tokens\": 123,\\n    \"prompt_cache_miss_tokens\": 123,\\n    \"completion_tokens_details\": {\\n      \"reasoning_tokens\": 123,\\n      \"audio_tokens\": 123,\\n      \"text_tokens\": 123,\\n      \"accepted_prediction_tokens\": 123,\\n      \"rejected_prediction_tokens\": 123\\n    },\\n    \"prompt_tokens_details\": {\\n      \"cached_tokens\": 123,\\n      \"audio_tokens\": 123\\n    },\\n    \"criteria\": {}\\n  }\\n}\\n```',\n",
       " 'docs_openpipe_ai_features_fine_tuning_quick_start.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nFine Tuning\\n\\nFine-Tuning Quick Start\\n\\nFine-tuning open and closed models with custom hyperparameters only takes a few clicks.\\n\\n**Before you begin:** Before training your first model, make sure you’ve [created a\\\\\\\\\\ndataset](https://docs.openpipe.ai/features/datasets/quick-start) and imported at least 10 training entries.\\n\\n### [\\u200b](https://docs.openpipe.ai/features/fine-tuning/quick-start\\\\#training-a-model)  Training a Model\\n\\n1\\n\\nNavigate to Dataset\\n\\nTo train a model, navigate to the dataset you’d like to train your model on. Click the **Fine Tune** button in the top right corner of the **General** tab.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/fine-tuning/fine-tune-modal.png)\\n\\n2\\n\\nName your Model\\n\\nChoose a descriptive name for your new model. This name will be used as the `model` parameter when querying it in code.\\nYou can always rename your model later.\\n\\n3\\n\\nSelect Base Model\\n\\nSelect the base model you’d like to fine-tune on. We recommend starting with Llama 3.1 8B if you aren’t sure which to choose.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/fine-tuning/select-base-model.png)\\n\\n4\\n\\nAdjust Hyperparameters (optional)\\n\\nUnder **Advanced Options**, you can optionally adjust the hyperparameters to fine-tune your model.\\nYou can leave these at their default values if you aren’t sure which to choose.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/fine-tuning/adjust-hyperparameters.png)\\n\\n5\\n\\nStart Training\\n\\nClick **Start Training** to begin the training process.\\nThe training job may take a few minutes or a few hours to complete, depending on the amount of training data, the base model, and the hyperparameters you choose.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/fine-tuning/trained-model.png)\\n\\nTo learn more about fine-tuning through the webapp, check out the [Fine-Tuning via Webapp](https://docs.openpipe.ai/features/fine-tuning/overview) page.\\nTo learn about fine-tuning via API, see our [Fine Tuning via API](https://docs.openpipe.ai/api-reference/fine-tuning) page.\\n\\n[Exporting Data](https://docs.openpipe.ai/features/datasets/exporting-data) [Webapp](https://docs.openpipe.ai/features/fine-tuning/webapp)\\n\\nOn this page\\n\\n- [Training a Model](https://docs.openpipe.ai/features/fine-tuning/quick-start#training-a-model)\\n\\n![](https://docs.openpipe.ai/features/fine-tuning/quick-start)\\n\\n![](https://docs.openpipe.ai/features/fine-tuning/quick-start)\\n\\n![](https://docs.openpipe.ai/features/fine-tuning/quick-start)\\n\\n![](https://docs.openpipe.ai/features/fine-tuning/quick-start',\n",
       " 'docs_openpipe_ai_features_datasets_exporting_data.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nDatasets\\n\\nExporting Data\\n\\n## [\\u200b](https://docs.openpipe.ai/features/datasets/exporting-data\\\\#dataset-export)  Dataset export\\n\\nAfter you’ve collected, filtered, and transformed your dataset entries for fine-tuning, you can export them as a JSONL file.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/datasets/exporting-dataset-entries.png)\\n\\n### [\\u200b](https://docs.openpipe.ai/features/datasets/exporting-data\\\\#fields)  Fields\\n\\n- **`messages`:** The complete chat history.\\n- **`tools`:** The tools provided to the model.\\n- **`tool_choice`:** The tool required for the model to use.\\n- **`split`:** The train/test split to which the entry belongs.\\n\\n### [\\u200b](https://docs.openpipe.ai/features/datasets/exporting-data\\\\#example)  Example\\n\\nCopy\\n\\n```jsonl\\n{\"messages\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":\"What is the capital of Tasmania?\"},{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"arguments\":\"{\\\\\"capital\\\\\":\\\\\"Hobart\\\\\"}\"}}]}],\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"parameters\":{\"type\":\"object\",\"properties\":{\"capital\":{\"type\":\"string\"}}}}}]}\\n{\"messages\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":\"What is the capital of Sweden?\"},{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"arguments\":\"{\\\\\"capital\\\\\":\\\\\"Stockholm\\\\\"}\"}}]}],\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"parameters\":{\"type\":\"object\",\"properties\":{\"capital\":{\"type\":\"string\"}}}}}]}\\n\\n```\\n\\n[Relabeling Data](https://docs.openpipe.ai/features/datasets/relabeling-data) [Quick Start](https://docs.openpipe.ai/features/fine-tuning/quick-start)\\n\\nOn this page\\n\\n- [Dataset export](https://docs.openpipe.ai/features/datasets/exporting-data#dataset-export)\\n- [Fields](https://docs.openpipe.ai/features/datasets/exporting-data#fields)\\n- [Example](https://docs.openpipe.ai/features/datasets/exporting-data#example)\\n\\n![](https://docs.openpipe.ai/features/datasets/exporting-data',\n",
       " 'docs_openpipe_ai_features_criteria_alignment_set.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nCriteria\\n\\nCriterion Alignment Sets\\n\\nAlignment sets are a collection of LLM input/output pairs that are judged by both the criterion LLM judge and a human.\\nThe performance of the criterion LLM judge is then measured by how well it matches the judgements of the human judge. We recommend importing and judging at least 30 rows to ensure the alignment stats are meaningful.\\n\\n## [\\u200b](https://docs.openpipe.ai/features/criteria/alignment-set\\\\#importing-an-alignment-set)  Importing an Alignment Set\\n\\nYou can import an alignment set from either an OpenPipe dataset or a JSONL file. Alignment sets can be added to an existing criterion or imported when a new criterion is created.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/alignment-set/import-alignment-set.png)\\n\\n### [\\u200b](https://docs.openpipe.ai/features/criteria/alignment-set\\\\#importing-from-a-dataset)  Importing from a Dataset\\n\\nWhen importing from a dataset, you select a number of rows to be randomly sampled from the dataset of your choice to imported into the criterion alignment set. The inputs of each of these rows will be copied directly from the rows in the dataset without any changes. By default, the outputs will also be copied from the original dataset. However, if you set **Output Source** to be an LLM model, the outputs will be generated by the LLM model based on the dataset inputs.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/alignment-set/import-from-dataset.png)\\n\\n### [\\u200b](https://docs.openpipe.ai/features/criteria/alignment-set\\\\#importing-from-a-jsonl-file)  Importing from a JSONL File\\n\\nYou can also import an alignment set from a JSONL file. Uploads are limited to 10MB in size,\\nwhich should be plenty for an alignment set.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/alignment-set/import-from-upload.png)\\n\\nThe schema of the JSONL file is exactly the same as an OpenAI-compatible [JSONL fine-tuning file](https://docs.openpipe.ai/features/datasets/uploading-data#openai-fields), but also supports an optional `judgement` field for each row. `judgement` can be either `PASS` or `FAIL`, depending on whether the row should pass or fail the criterion.\\n\\n#### [\\u200b](https://docs.openpipe.ai/features/criteria/alignment-set\\\\#example)  Example\\n\\nCopy\\n\\n```jsonl\\n...\\n{\"judgement\": \"PASS\", \"messages\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":\"What is the capital of Tasmania?\"},{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"arguments\":\"{\\\\\"capital\\\\\":\\\\\"Hobart\\\\\"}\"}}]}],\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"parameters\":{\"type\":\"object\",\"properties\":{\"capital\":{\"type\":\"string\"}}}}}]}\\n{\"judgement\": \"FAIL\", \"messages\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":\"What is the capital of Sweden?\"},{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"arguments\":\"{\\\\\"capital\\\\\":\\\\\"Beijing\\\\\"}\"}}]}],\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"parameters\":{\"type\":\"object\",\"properties\":{\"capital\":{\"type\":\"string\"}}}}}]}\\n{\"messages\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":\"What is the capital of Sweden?\"},{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"arguments\":\"{\\\\\"capital\\\\\":\\\\\"Stockholm\\\\\"}\"}}]}],\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"parameters\":{\"type\":\"object\",\"properties\":{\"capital\":{\"type\":\"string\"}}}}}]}\\n...\\n\\n```\\n\\n## [\\u200b](https://docs.openpipe.ai/features/criteria/alignment-set\\\\#alignment-stats)  Alignment Stats\\n\\nAlignment stats are a simple way to understand how well your criterion is performing.\\nAs you refine your criterion prompt, you’re alignment stats will improve as well.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/alignment-set/alignment-stats.png)\\n\\n- **Precision** indicates the fraction of rows that the LLM judge labeled as failing that a human judge also labeled as failing. It’s an indicator of how reliable the LLM judge’s FAIL label is.\\n- **Recall** indicates the fraction of rows that a human judge labeled as failing that the LLM judge also labeled as failing. It’s an indicator of how reliable the LLM judge’s PASS label is.\\n- **F1 Score** is the harmonic mean of precision and recall. As either score improves, the F1 score will also improve.\\n\\nTo ensure your alignment stats are meaningful, we recommend labeling at least 30 rows,\\nbut in some cases you may need to label more in order to get a reliable statistic.\\n\\n[Quick Start](https://docs.openpipe.ai/features/criteria/quick-start) [API Endpoints](https://docs.openpipe.ai/features/criteria/api)\\n\\nOn this page\\n\\n- [Importing an Alignment Set](https://docs.openpipe.ai/features/criteria/alignment-set#importing-an-alignment-set)\\n- [Importing from a Dataset](https://docs.openpipe.ai/features/criteria/alignment-set#importing-from-a-dataset)\\n- [Importing from a JSONL File](https://docs.openpipe.ai/features/criteria/alignment-set#importing-from-a-jsonl-file)\\n- [Example](https://docs.openpipe.ai/features/criteria/alignment-set#example)\\n- [Alignment Stats](https://docs.openpipe.ai/features/criteria/alignment-set#alignment-stats)\\n\\n![](https://docs.openpipe.ai/features/criteria/alignment-set)\\n\\n![](https://docs.openpipe.ai/features/criteria/alignment-set)\\n\\n![](https://docs.openpipe.ai/features/criteria/alignment-set)\\n\\n![](https://docs.openpipe.ai/features/criteria/alignment-set',\n",
       " 'docs_openpipe_ai_api_reference_post_report.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nLogs\\n\\nReport\\n\\nPOST\\n\\n/\\n\\nreport\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/report \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"requestedAt\": 123,\\n  \"receivedAt\": 123,\\n  \"reqPayload\": \"<any>\",\\n  \"respPayload\": \"<any>\",\\n  \"statusCode\": 123,\\n  \"errorMessage\": \"<string>\",\\n  \"tags\": {}\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"status\": \"ok\"\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report#body-error-message)\\n\\nerrorMessage\\n\\nstring\\n\\nUser-friendly error message\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report#body-received-at)\\n\\nreceivedAt\\n\\nnumber\\n\\nUnix timestamp in milliseconds\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report#body-req-payload)\\n\\nreqPayload\\n\\nany\\n\\nJSON-encoded request payload\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report#body-requested-at)\\n\\nrequestedAt\\n\\nnumber\\n\\nUnix timestamp in milliseconds\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report#body-resp-payload)\\n\\nrespPayload\\n\\nany\\n\\nJSON-encoded response payload\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report#body-status-code)\\n\\nstatusCode\\n\\nnumber\\n\\nHTTP status code of response\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report#body-tags)\\n\\ntags\\n\\nobject\\n\\nDEPRECATED: use \"reqPayload.metadata\" to attach extra metadata tags to the call for filtering. Eg { \"userId\": \"123\", \"prompt\\\\_id\": \"populate-title\" }\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report#body-tags-key)\\n\\ntags.{key}\\n\\nstring \\\\| nullnumber \\\\| nullboolean \\\\| nullenum<string> \\\\| null\\n\\n#### Response\\n\\n200 - application/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-report#response-status)\\n\\nstatus\\n\\nOption 1 · enum<string>Option 2 · enum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`ok`\\n\\n[External Models](https://docs.openpipe.ai/features/external-models) [Report Anthropic](https://docs.openpipe.ai/api-reference/post-report-anthropic)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/report \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"requestedAt\": 123,\\n  \"receivedAt\": 123,\\n  \"reqPayload\": \"<any>\",\\n  \"respPayload\": \"<any>\",\\n  \"statusCode\": 123,\\n  \"errorMessage\": \"<string>\",\\n  \"tags\": {}\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"status\": \"ok\"\\n}\\n```',\n",
       " 'docs_openpipe_ai_api_reference_delete_model.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nModels\\n\\nDelete Model\\n\\nDELETE\\n\\n/\\n\\nmodels\\n\\n/\\n\\n{modelSlug}\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request DELETE \\\\\\n  --url https://api.openpipe.ai/api/v1/models/{modelSlug} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"id\": \"<string>\",\\n  \"object\": \"model\",\\n  \"deleted\": true\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/delete-model#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Path Parameters\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/delete-model#parameter-model-slug)\\n\\nmodelSlug\\n\\nstring\\n\\nrequired\\n\\n#### Response\\n\\n200 - application/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/delete-model#response-deleted)\\n\\ndeleted\\n\\nboolean\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/delete-model#response-id)\\n\\nid\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/delete-model#response-object)\\n\\nobject\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`model`\\n\\n[List Models](https://docs.openpipe.ai/api-reference/get-listModels) [Judge Criteria](https://docs.openpipe.ai/api-reference/post-criteriajudge)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request DELETE \\\\\\n  --url https://api.openpipe.ai/api/v1/models/{modelSlug} \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"id\": \"<string>\",\\n  \"object\": \"model\",\\n  \"deleted\": true\\n}\\n```',\n",
       " 'docs_openpipe_ai_api_reference_post_criteriajudge.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nCriteria\\n\\nJudge Criteria\\n\\nPOST\\n\\n/\\n\\ncriteria\\n\\n/\\n\\njudge\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/criteria/judge \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"criterion_id\": \"<string>\",\\n  \"input\": {\\n    \"messages\": [\\\\\\n      {\\\\\\n        \"role\": \"system\",\\\\\\n        \"content\": \"<string>\",\\\\\\n        \"name\": \"<string>\"\\\\\\n      }\\\\\\n    ],\\n    \"tool_choice\": \"none\",\\n    \"tools\": [\\\\\\n      {\\\\\\n        \"function\": {\\\\\\n          \"name\": \"<string>\",\\\\\\n          \"parameters\": {},\\\\\\n          \"description\": \"<string>\",\\\\\\n          \"strict\": true\\\\\\n        },\\\\\\n        \"type\": \"function\"\\\\\\n      }\\\\\\n    ]\\n  },\\n  \"output\": {\\n    \"reasoning_content\": \"<string>\",\\n    \"content\": null,\\n    \"refusal\": \"<string>\",\\n    \"role\": \"assistant\",\\n    \"function_call\": {\\n      \"name\": \"\",\\n      \"arguments\": \"\"\\n    },\\n    \"tool_calls\": [\\\\\\n      {\\\\\\n        \"id\": \"<string>\",\\\\\\n        \"function\": {\\\\\\n          \"name\": \"<string>\",\\\\\\n          \"arguments\": \"<string>\"\\\\\\n        },\\\\\\n        \"type\": \"function\"\\\\\\n      }\\\\\\n    ]\\n  }\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"score\": 123,\\n  \"explanation\": \"<string>\",\\n  \"usage\": {\\n    \"total_tokens\": 123\\n  }\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-criterion-id)\\n\\ncriterion\\\\_id\\n\\nstring\\n\\nrequired\\n\\nThe ID of the criterion to judge.\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output)\\n\\noutput\\n\\nobject\\n\\nrequired\\n\\nThe completion message of the model.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-role)\\n\\noutput.role\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`assistant`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-content)\\n\\noutput.content\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-function-call)\\n\\noutput.function\\\\_call\\n\\nobject \\\\| null\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-function-call-arguments)\\n\\noutput.function\\\\_call.arguments\\n\\nstring\\n\\ndefault:\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-function-call-name)\\n\\noutput.function\\\\_call.name\\n\\nstring\\n\\ndefault:\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-reasoning-content)\\n\\noutput.reasoning\\\\_content\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-refusal)\\n\\noutput.refusal\\n\\nstring \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-tool-calls)\\n\\noutput.tool\\\\_calls\\n\\nobject\\\\[\\\\] \\\\| null\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-tool-calls-function)\\n\\noutput.tool\\\\_calls.function\\n\\nobject\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-tool-calls-function-arguments)\\n\\noutput.tool\\\\_calls.function.arguments\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-tool-calls-function-name)\\n\\noutput.tool\\\\_calls.function.name\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-tool-calls-id)\\n\\noutput.tool\\\\_calls.id\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-tool-calls-type)\\n\\noutput.tool\\\\_calls.type\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`function`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input)\\n\\ninput\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-messages)\\n\\ninput.messages\\n\\nobject\\\\[\\\\]\\n\\nAll messages sent to the model when generating the output.\\n\\n- Option 1\\n- Option 2\\n- Option 3\\n- Option 4\\n- Option 5\\n- Option 6\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-messages-role)\\n\\ninput.messages.role\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`system`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-messages-content)\\n\\ninput.messages.content\\n\\nstringobject\\\\[\\\\]\\n\\ndefault:\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-messages-name)\\n\\ninput.messages.name\\n\\nstring\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tool-choice)\\n\\ninput.tool\\\\_choice\\n\\nOption 1 · enum<string>Option 2 · enum<string>Option 3 · enum<string>Option 4 · object\\n\\nThe tool choice to use when generating the output, if any.\\n\\nAvailable options:\\n\\n`none`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools)\\n\\ninput.tools\\n\\nobject\\\\[\\\\]\\n\\nThe tools available to the model when generating the output, if any.\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools-function)\\n\\ninput.tools.function\\n\\nobject\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools-function-name)\\n\\ninput.tools.function.name\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools-function-description)\\n\\ninput.tools.function.description\\n\\nstring\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools-function-parameters)\\n\\ninput.tools.function.parameters\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools-function-parameters-key)\\n\\ninput.tools.function.parameters.{key}\\n\\nany\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools-function-strict)\\n\\ninput.tools.function.strict\\n\\nboolean \\\\| null\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools-type)\\n\\ninput.tools.type\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`function`\\n\\n#### Response\\n\\n200 - application/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#response-score)\\n\\nscore\\n\\nnumber\\n\\nrequired\\n\\nA score of 0 means the output failed this completion, and a score of 1 means it passed. A criteria may also return a decimal scores between 0 and 1, indicating the model\\'s confidence or \\'likelihood\\' that the criteria passed.\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#response-explanation)\\n\\nexplanation\\n\\nstring\\n\\nAn explanation of the score including the model\\'s reasoning, if applicable.\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#response-usage)\\n\\nusage\\n\\nobject\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-criteriajudge#response-usage-total-tokens)\\n\\nusage.total\\\\_tokens\\n\\nnumber\\n\\nrequired\\n\\nThe total number of tokens used to generate the criterion judgement. Only returned for OpenPipe-trained reward models currently.\\n\\n[Delete Model](https://docs.openpipe.ai/api-reference/delete-model) [Pricing Overview](https://docs.openpipe.ai/pricing/pricing)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/criteria/judge \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"criterion_id\": \"<string>\",\\n  \"input\": {\\n    \"messages\": [\\\\\\n      {\\\\\\n        \"role\": \"system\",\\\\\\n        \"content\": \"<string>\",\\\\\\n        \"name\": \"<string>\"\\\\\\n      }\\\\\\n    ],\\n    \"tool_choice\": \"none\",\\n    \"tools\": [\\\\\\n      {\\\\\\n        \"function\": {\\\\\\n          \"name\": \"<string>\",\\\\\\n          \"parameters\": {},\\\\\\n          \"description\": \"<string>\",\\\\\\n          \"strict\": true\\\\\\n        },\\\\\\n        \"type\": \"function\"\\\\\\n      }\\\\\\n    ]\\n  },\\n  \"output\": {\\n    \"reasoning_content\": \"<string>\",\\n    \"content\": null,\\n    \"refusal\": \"<string>\",\\n    \"role\": \"assistant\",\\n    \"function_call\": {\\n      \"name\": \"\",\\n      \"arguments\": \"\"\\n    },\\n    \"tool_calls\": [\\\\\\n      {\\\\\\n        \"id\": \"<string>\",\\\\\\n        \"function\": {\\\\\\n          \"name\": \"<string>\",\\\\\\n          \"arguments\": \"<string>\"\\\\\\n        },\\\\\\n        \"type\": \"function\"\\\\\\n      }\\\\\\n    ]\\n  }\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"score\": 123,\\n  \"explanation\": \"<string>\",\\n  \"usage\": {\\n    \"total_tokens\": 123\\n  }\\n}\\n```',\n",
       " 'docs_openpipe_ai_features_chat_completions_overview.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nChat Completions\\n\\nChat Completions\\n\\nOnce your fine-tuned model is deployed, you’re ready to start generating chat completions.\\n\\nFirst, make sure you’ve set up the SDK properly. See the [OpenPipe SDK](https://docs.openpipe.ai/getting-started/openpipe-sdk) section for more details. Once the SDK is installed and you’ve added the right\\n`OPENPIPE_API_KEY` to your environment variables, you’re almost done.\\n\\nThe last step is to update the model that you’re querying to match the ID of your new fine-tuned model.\\n\\n- Python\\n- NodeJS\\n\\nCopy\\n\\n```python\\nfrom openpipe import OpenAI\\n\\n# Find the config values in \"Installing the SDK\"\\nclient = OpenAI()\\n\\ncompletion = client.chat.completions.create(\\n    # model=\"gpt-4o\", - original model\\n    model=\"openpipe:your-fine-tuned-model-id\",\\n    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\\n    metadata={\"prompt_id\": \"counting\", \"any_key\": \"any_value\"},\\n)\\n\\n```\\n\\nQueries to your fine-tuned models will now be shown in the [Request Logs](https://docs.openpipe.ai/features/request-logs) panel.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/running-inference-logs.png)\\n\\nFeel free to run some sample inference on the [PII Redaction model](https://app.openpipe.ai/p/BRZFEx50Pf/fine-tunes/6076ad69-cce5-4892-ae54-e0549bbe107f/general) in our public project.\\n\\n[API Endpoints](https://docs.openpipe.ai/features/criteria/api) [Proxying to External Models](https://docs.openpipe.ai/features/chat-completions/external-models)\\n\\n![](https://docs.openpipe.ai/features/chat-completions/overview',\n",
       " 'docs_openpipe_ai_overview.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nWelcome\\n\\nOverview\\n\\n## [\\u200b](https://docs.openpipe.ai/overview\\\\#what-we-provide)  What We Provide\\n\\nHere are a few of the features we offer:\\n\\n- [**Unified SDK**](https://docs.openpipe.ai/getting-started/openpipe-sdk): Collect and utilize interaction data to fine-tune a custom model and continually refine and enhance model performance. Switching requests from your previous LLM provider to your new model is as simple as changing the model name. All our models implement the OpenAI inference format, so you won’t have to change how you parse its response.\\n\\n- [**Data Capture**](https://docs.openpipe.ai/features/request-logs): OpenPipe captures every request and response and stores it for your future use.\\n  - [**Request Logs**](https://docs.openpipe.ai/features/request-logs): We help you automatically log your past requests and tag them for easy filtering.\\n  - [**Upload Data**](https://docs.openpipe.ai/features/datasets/uploading-data): OpenPipe also allows you to import fine-tuning data from OpenAI-compatible JSONL files.\\n  - [**Export Data**](https://docs.openpipe.ai/features/datasets/exporting-data): Once your request logs are recorded, you can export them at any time.\\n- [**Fine-Tuning**](https://docs.openpipe.ai/features/fine-tuning/overview): With all your LLM requests and responses in one place, it’s easy to select the data you want to fine-tune on and kick off a job.\\n  - [**Pruning Rules**](https://docs.openpipe.ai/features/pruning-rules): By removing large chunks of unchanging text and fine-tuning a model on the compacted data, we can reduce the size of incoming requests and save you money on inference.\\n- [**Model Hosting**](https://docs.openpipe.ai/features/chat-completions): After we’ve trained your model, OpenPipe will automatically begin hosting it.\\n  - [**Caching**](https://docs.openpipe.ai/features/caching): Improve performance and reduce costs by caching previously generated responses.\\n- [**Evaluations**](https://docs.openpipe.ai/features/evaluations/overview): Compare your models against one another and OpenAI base models. Set up custom instructions and get quick insights into your models’ performance.\\n\\n\\nWelcome to the OpenPipe community!\\n\\n[Introduction](https://docs.openpipe.ai/introduction) [Base Models](https://docs.openpipe.ai/base-models)\\n\\nOn this page\\n\\n- [What We Provide](https://docs.openpipe.ai/overview#what-we-provide',\n",
       " 'docs_openpipe_ai_features_chat_completions_gemini.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nChat Completions\\n\\nGemini Proxy\\n\\nOpenPipe can translate your existing OpenAI chat completion requests to work with Gemini models automatically, allowing you to use Gemini without changing your prompt format.\\n\\nAfter adding your Google AI Studio API Key in your project settings, specify the Gemini **model** you want to use by adding the `gemini:` prefix to the model name in your requests:\\n\\n- Python\\n- NodeJS\\n\\nCopy\\n\\n```python\\nfrom openpipe import OpenAI\\n\\n# Find the config values in \"Installing the SDK\"\\nclient = OpenAI()\\n\\ncompletion = client.chat.completions.create(\\n    model=\"gemini:gemini-1.5-flash\",\\n    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\\n    metadata={\"prompt_id\": \"counting\", \"any_key\": \"any_value\"},\\n)\\n\\n```\\n\\nFor your reference, here is a list of the most commonly used Gemini models formatted for the OpenPipe proxy:\\n\\n- `gemini:gemini-1.5-flash-002`\\n- `gemini:gemini-1.5-flash-8b-001`\\n- `gemini:gemini-1.5-pro-002`\\n- `gemini:gemini-exp-1206`\\n- `gemini:gemini-2.0-flash-exp`\\n\\nAdditionally, you can always stay on the latest version of the model by using an abbreviated model name:\\n\\n- `gemini:gemini-1.5-flash`\\n- `gemini:gemini-1.5-flash-8b`\\n- `gemini:gemini-1.5-pro`\\n- `gemini:gemini-2.0-flash`\\n\\n[Anthropic Proxy](https://docs.openpipe.ai/features/chat-completions/anthropic) [Mixture of Agents](https://docs.openpipe.ai/features/chat-completions/moa',\n",
       " 'docs_openpipe_ai_features_datasets_importing_logs.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nDatasets\\n\\nImporting Request Logs\\n\\nLogged requests will be visible on your project’s [Request Logs](https://app.openpipe.ai/p/BRZFEx50Pf/request-logs?filterData=%7B%22shown%22%3Atrue%2C%22filters%22%3A%5B%7B%22id%22%3A%221706912835890%22%2C%22field%22%3A%22request%22%2C%22comparator%22%3A%22CONTAINS%22%2C%22value%22%3A%22You+are+an+expert%22%7D%2C%7B%22id%22%3A%221706912850914%22%2C%22field%22%3A%22response%22%2C%22comparator%22%3A%22NOT_CONTAINS%22%2C%22value%22%3A%22As+an+AI+language+model%22%7D%2C%7B%22id%22%3A%221706912861496%22%2C%22field%22%3A%22model%22%2C%22comparator%22%3A%22%3D%22%2C%22value%22%3A%22gpt-4-0613%22%7D%2C%7B%22id%22%3A%221706912870230%22%2C%22field%22%3A%22tags.prompt_id%22%2C%22comparator%22%3A%22CONTAINS%22%2C%22value%22%3A%22redaction%22%7D%5D%7D) page.\\nYou can filter your logs by completionId, model, custom tags, and more to narrow down your results.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/log-filters.png)\\n\\nOnce you’ve found a set of data that you’d like to train on, import those logs into the dataset of your choice.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/importing-logs.png)\\n\\nAfter your data has been saved to your dataset, [kicking off a training job](https://docs.openpipe.ai/features/fine-tuning) is straightforward.\\n\\n[Quick Start](https://docs.openpipe.ai/features/datasets/quick-start) [Uploading Data](https://docs.openpipe.ai/features/datasets/uploading-data)\\n\\n![](https://docs.openpipe.ai/features/datasets/importing-logs)\\n\\n![](https://docs.openpipe.ai/features/datasets/importing-logs',\n",
       " 'docs_openpipe_ai_api_reference_post_createDataset.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nDatasets\\n\\nCreate Dataset\\n\\nPOST\\n\\n/\\n\\ndatasets\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/datasets \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"name\": \"<string>\"\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"object\": \"dataset\",\\n  \"id\": \"<string>\",\\n  \"name\": \"<string>\",\\n  \"created\": \"<string>\",\\n  \"updated\": \"<string>\",\\n  \"dataset_entry_count\": 123,\\n  \"fine_tune_count\": 123\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDataset#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Body\\n\\napplication/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDataset#body-name)\\n\\nname\\n\\nstring\\n\\nrequired\\n\\n#### Response\\n\\n200 - application/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDataset#response-created)\\n\\ncreated\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDataset#response-dataset-entry-count)\\n\\ndataset\\\\_entry\\\\_count\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDataset#response-fine-tune-count)\\n\\nfine\\\\_tune\\\\_count\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDataset#response-id)\\n\\nid\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDataset#response-name)\\n\\nname\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDataset#response-object)\\n\\nobject\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`dataset`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/post-createDataset#response-updated)\\n\\nupdated\\n\\nstring\\n\\nrequired\\n\\n[Chat Completions](https://docs.openpipe.ai/api-reference/post-chatcompletions) [List Datasets](https://docs.openpipe.ai/api-reference/get-listDatasets)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request POST \\\\\\n  --url https://api.openpipe.ai/api/v1/datasets \\\\\\n  --header \\'Authorization: Bearer <token>\\' \\\\\\n  --header \\'Content-Type: application/json\\' \\\\\\n  --data \\'{\\n  \"name\": \"<string>\"\\n}\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"object\": \"dataset\",\\n  \"id\": \"<string>\",\\n  \"name\": \"<string>\",\\n  \"created\": \"<string>\",\\n  \"updated\": \"<string>\",\\n  \"dataset_entry_count\": 123,\\n  \"fine_tune_count\": 123\\n}\\n```',\n",
       " 'docs_openpipe_ai_features_chat_completions_anthropic.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nChat Completions\\n\\nAnthropic Proxy\\n\\nIf you’d like to make chat completion requests to Anthropic models without modifying your prompt schema, you can proxy OpenAI-compatible requests through OpenPipe, and we’ll handle\\nthe translation for you.\\n\\nTo proxy requests to Anthropic models, first add your Anthropic API Key to your project settings. Then, adjust the **model** parameter of your requests to be the name of the model you\\nwish to query, prepended with the string `anthropic:`. For example, to make a request to `claude-3-5-sonnet-20241022`, use the following code:\\n\\n- Python\\n- NodeJS\\n\\nCopy\\n\\n```python\\nfrom openpipe import OpenAI\\n\\n# Find the config values in \"Installing the SDK\"\\nclient = OpenAI()\\n\\ncompletion = client.chat.completions.create(\\n    model=\"anthropic:claude-3-5-sonnet-20241022\",\\n    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\\n    metadata={\"prompt_id\": \"counting\", \"any_key\": \"any_value\"},\\n)\\n\\n```\\n\\nFor your reference, here is a list of the most commonly used Anthropic models formatted for the OpenPipe proxy:\\n\\n- `anthropic:claude-3-5-sonnet-20241022`\\n- `anthropic:claude-3-opus-20240229`\\n- `anthropic:claude-3-sonnet-20240229`\\n- `anthropic:claude-3-haiku-20240307`\\n\\nAdditionally, you can always stay on the latest version of the model by using an abbreviated model name:\\n\\n- `anthropic:claude-3-5-sonnet`\\n- `anthropic:claude-3-opus`\\n- `anthropic:claude-3-sonnet`\\n- `anthropic:claude-3-haiku`\\n\\nIf you’d like to make requests directly to Anthropic models, you can do that externally using the Anthropic SDK, and report your logs using the\\nasynchronous [reporting API](https://docs.openpipe.ai/features/request-logs/reporting-anthropic).\\n\\n[Proxying to External Models](https://docs.openpipe.ai/features/chat-completions/external-models) [Gemini Proxy](https://docs.openpipe.ai/features/chat-completions/gemini',\n",
       " 'docs_openpipe_ai_features_updating_metadata.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nFeatures\\n\\nUpdating Metadata Tags\\n\\nYou may want to update the metadata tags on a request log after it’s already been reported. For instance, if you notice that a certain completion from your fine-tuned model was flawed,\\nyou can mark it to be imported into one of your datasets and relabeled with GPT-4 for future training.\\n\\n- Python\\n- NodeJS\\n\\nCopy\\n\\n```python\\nimport os\\nfrom openpipe import OpenPipe, OpenAI\\nfrom openpipe.client import UpdateLogTagsRequestFiltersItem\\n\\n# Find the config values in \"Installing the SDK\"\\nclient = OpenAI()\\nop_client = OpenPipe(\\n    # defaults to os.environ[\"OPENPIPE_API_KEY\"]\\n    api_key=\"YOUR_API_KEY\"\\n)\\n\\ncompletion = client.chat.completions.create(\\n    model=\"openpipe:your-fine-tuned-model-id\",\\n    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\\n    metadata={\"prompt_id\": \"counting\", \"tag_to_remove\": \"some value\"},\\n)\\n\\nresp = op_client.update_log_metadata(\\n    filters=[\\\\\\n        UpdateLogTagsRequestFiltersItem(\\\\\\n            field=\"completionId\",\\\\\\n            equals=completion.id,\\\\\\n        ),\\\\\\n        # completionId is the only filter necessary in this case, but let\\'s add a couple more examples\\\\\\n        UpdateLogTagsRequestFiltersItem(\\\\\\n            field=\"model\",\\\\\\n            equals=\"openpipe:your-fine-tuned-model-id\",\\\\\\n        ),\\\\\\n        UpdateLogTagsRequestFiltersItem(\\\\\\n            field=\"metadata.prompt_id\",\\\\\\n            equals=\"counting\",\\\\\\n        ),\\\\\\n    ],\\n    metadata={\\n        \"relabel\": \"true\",\\n        \"tag_to_remove\": None # this will remove the tag_to_remove tag from the request log we just created\\n    },\\n)\\n\\nassert resp.matched_logs == 1\\n\\n```\\n\\nTo update your metadata, you’ll need to provide two fields: `filters` and `metadata`.\\n\\n### [\\u200b](https://docs.openpipe.ai/features/updating-metadata\\\\#filters)  Filters\\n\\nUse filters to determine which request logs should be updated. Each filter contains two fields, `field` and `equals`.\\n\\n- **`field`: Required** \\\\- Indicates the field on a request log that should be checked. Valid options include `model`, `completionId`, and `tags.your_tag_name`.\\n- **`equals`: Required** \\\\- The value that the field should equal.\\n\\nKeep in mind that filters are cumulative, so only request logs that match all of the filters you provide will be updated.\\n\\n### [\\u200b](https://docs.openpipe.ai/features/updating-metadata\\\\#metadata)  Metadata\\n\\nProvide one or more metadata tags in a json object. The key should be the name of the tag you’d like to add, update, or delete. The value should be the new value of the tag.\\nIf you’d like to delete a tag, provide a value of `None` or `null`.\\n\\nUpdated metadata tags will be searchable in the [Request Logs](https://docs.openpipe.ai/features/request-logs) panel.\\n\\n[Caching](https://docs.openpipe.ai/features/caching) [Pruning Rules](https://docs.openpipe.ai/features/pruning-rules)\\n\\nOn this page\\n\\n- [Filters](https://docs.openpipe.ai/features/updating-metadata#filters)\\n- [Metadata](https://docs.openpipe.ai/features/updating-metadata#metadata',\n",
       " 'docs_openpipe_ai_features_criteria_overview.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nCriteria\\n\\nCriteria\\n\\nFor questions about criteria or to unlock beta features for your organization, reach out to\\n[support@openpipe.ai](mailto:support@openpipe.ai).\\n\\nCriteria are a simple way to reliably detect and correct mistakes in LLM output. Criteria can currently be used for the following purposes:\\n\\n- Defining LLM evaluations\\n- Improving dataset quality\\n- Runtime evaluation when generating [best of N](https://docs.openpipe.ai/features/criteria/api#runtime-evaluation) samples\\n- [Offline testing](https://docs.openpipe.ai/features/criteria/api#offline-testing) of previously generated outputs\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/overview.png)\\n\\n## [\\u200b](https://docs.openpipe.ai/features/criteria/overview\\\\#what-is-a-criterion)  What is a Criterion?\\n\\nA criterion is a combination of an LLM model and prompt that can be used to identify a specific issue with a model’s output. Criterion judgements are generated\\nby passing the input and output of a single row along with the criterion prompt to an LLM model, which then returns a binary `PASS`/ `FAIL` judgement.\\n\\nTo learn how to create your first criterion, read the [Quick Start](https://docs.openpipe.ai/features/criteria/quick-start).\\n\\n[Head-to-Head Evals](https://docs.openpipe.ai/features/evaluations/head-to-head) [Quick Start](https://docs.openpipe.ai/features/criteria/quick-start)\\n\\nOn this page\\n\\n- [What is a Criterion?](https://docs.openpipe.ai/features/criteria/overview#what-is-a-criterion)\\n\\n![](https://docs.openpipe.ai/features/criteria/overview',\n",
       " 'docs_openpipe_ai_base_models.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nWelcome\\n\\nBase Models\\n\\nWe regularly evaluate new models to see how they compare against our existing suite. If you’d like us to check out a\\nbase model you’re particularly excited about, send an email to [hello@openpipe.ai](mailto:hello@openpipe.ai).\\n\\n## [\\u200b](https://docs.openpipe.ai/base-models\\\\#current-base-models)  Current Base Models\\n\\n### [\\u200b](https://docs.openpipe.ai/base-models\\\\#open-source)  Open Source\\n\\n- [meta-llama/Meta-Llama-3.1-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct)\\n- [meta-llama/Meta-Llama-3.1-70B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct)\\n- [meta-llama/Llama-3.1-8B](https://huggingface.co/meta-llama/Llama-3.1-8B)\\n- [meta-llama/Llama-3.1-70B](https://huggingface.co/meta-llama/Llama-3.1-70B)\\n- [Qwen/Qwen2.5-72B-Instruct](https://huggingface.co/Qwen/Qwen2.5-72B-Instruct)\\n- [Qwen/Qwen2.5-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct)\\n- [Qwen/Qwen2.5-1.5B-Instruct](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct)\\n- [Qwen/Qwen2.5-Coder-32B-Instruct](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct)\\n- [mistralai/Mistral-Nemo-Base-2407](https://huggingface.co/mistralai/Mistral-Nemo-Base-2407)\\n- [mistralai/Mistral-Small-24B-Base-2501](https://huggingface.co/mistralai/Mistral-Small-24B-Base-2501)\\n- [meta-llama/Llama-3.2-1B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct)\\n- [meta-llama/Llama-3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)\\n- [meta-llama/Llama-3.3-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct)\\n\\n### [\\u200b](https://docs.openpipe.ai/base-models\\\\#openai)  OpenAI\\n\\n- [gpt-4o-mini-2024-07-18](https://platform.openai.com/docs/models/gpt-4o-mini)\\n- [gpt-4o-2024-08-06](https://platform.openai.com/docs/models/gpt-4o)\\n- [gpt-3.5-turbo-0125](https://platform.openai.com/docs/models/gpt-3-5-turbo)\\n\\n### [\\u200b](https://docs.openpipe.ai/base-models\\\\#google-gemini)  Google Gemini\\n\\n- [gemini-1.0-pro-001](https://deepmind.google/technologies/gemini/pro/)\\n- [gemini-1.5-flash-001](https://deepmind.google/technologies/gemini/flash/)\\n\\n## [\\u200b](https://docs.openpipe.ai/base-models\\\\#enterprise-models)  Enterprise models\\n\\nThese models are currently available for enterprise customers only. If you’re interested in exploring these models, we’d be happy to discuss further. Please reach out to us at [hello@openpipe.ai](mailto:hello@openpipe.ai) to learn more.\\n\\n### [\\u200b](https://docs.openpipe.ai/base-models\\\\#aws-bedrock)  AWS Bedrock\\n\\n- [cohere.command-text-v14](https://docs.aws.amazon.com/bedrock/latest/userguide/cm-hp-cohere-command.html)\\n- [cohere.command-light-text-v14](https://docs.aws.amazon.com/bedrock/latest/userguide/cm-hp-cohere-command.html)\\n- [anthropic.claude-3-haiku-20240307-v1:0](https://docs.aws.amazon.com/bedrock/latest/userguide/cm-hp-anth-claude-3.html)\\n\\n[Overview](https://docs.openpipe.ai/overview) [Quick Start](https://docs.openpipe.ai/getting-started/quick-start)\\n\\nOn this page\\n\\n- [Current Base Models](https://docs.openpipe.ai/base-models#current-base-models)\\n- [Open Source](https://docs.openpipe.ai/base-models#open-source)\\n- [OpenAI](https://docs.openpipe.ai/base-models#openai)\\n- [Google Gemini](https://docs.openpipe.ai/base-models#google-gemini)\\n- [Enterprise models](https://docs.openpipe.ai/base-models#enterprise-models)\\n- [AWS Bedrock](https://docs.openpipe.ai/base-models#aws-bedrock',\n",
       " 'docs_openpipe_ai_features_dpo_quick_start.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nDirect Preference Optimization (DPO)\\n\\nDPO Quick Start\\n\\nDPO fine-tuning uses preference data to train models on positive and negative examples. In OpenPipe, DPO\\ncan be used as a drop-in replacement for SFT fine-tuning or as a complement to it.\\n\\n**Before you begin:** Before building training your first model with DPO, make sure you’ve\\n[created a dataset](https://docs.openpipe.ai/features/datasets/quick-start) and have collected at least 500 rows of\\ntraining data on OpenPipe or another platform.\\n\\n1\\n\\nPrepare your Dataset\\n\\nTo train a model with DPO, you need pairs of outputs containing preferred and rejected responses. You can prepare this data in one of two ways:\\n\\n1. **Upload a JSONL file**\\n\\nAdd training rows to your dataset by [uploading a JSONL file](https://docs.openpipe.ai/features/datasets/uploading-data). Make sure to add a `rejected_message` field on each row that you’d like to use for preference tuning [(see docs)](https://docs.openpipe.ai/features/datasets/uploading-data#additional-fields).\\n\\n2. **Track Rejected Outputs**\\n\\nIn the **Data Pipeline** view of your dataset, you can convert original outputs that have been overwritten by either an LLM (through an **LLM Relabel** node) or human (through a **Human Relabel** node) into rejected outputs. The original output will be treated as the negative example, and the replacement output will be treated as the positive example.\\n    **LLM Relabel Node**\\n\\n\\n\\n\\n\\n\\n\\n\\n![LLM Relabel Node](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/dpo/llm-relabel-track-rejected-op.png)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n**Human Relabel Node**\\n\\n\\n\\n\\n\\n\\n\\n\\n![Human Relabel Node](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/dpo/human-relabel-track-rejected-op.png)\\n\\n\\n2\\n\\nConfigure Training Settings\\n\\nOnce your dataset is ready, training a DPO model is similar to training an SFT model.\\n\\n1. Select the dataset you prepared for preference tuning.\\n2. Adjust the base model.\\n   - Currently, DPO is only supported on Llama 3.1 8B.\\n3. Under **Advanced Options**, click the **Enable Preference Tuning** checkbox.\\n\\n![Enable Preference Tuning](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/dpo/enable-pt.png)\\n\\n3\\n\\nAdjust Hyperparameters (optional)\\n\\nYou should now see the number of rows that will be used for supervised fine tuning\\n( **SFT Row Count**)\\nand preference tuning ( **Preference Row Count**). Rows in your dataset that only include a\\npreferred output will be used for supervised fine tuning, while rows with both preferred and\\nrejected outputs will be used for preference tuning.\\n\\nAdjust the training job’s hyperparameters if needed. We recommend using the default values if you’re unsure.\\n\\n![DPO Hyperparameters](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/dpo/dpo-hyperparams.png)\\n\\n4\\n\\nStart Training\\n\\nFinally, kick off a training job by clicking the **Start Training** button.\\n\\n[Overview](https://docs.openpipe.ai/features/dpo/overview) [Overview](https://docs.openpipe.ai/features/evaluations/overview)\\n\\n![LLM Relabel Node](https://docs.openpipe.ai/features/dpo/quick-start)\\n\\n![Human Relabel Node](https://docs.openpipe.ai/features/dpo/quick-start)\\n\\n![Enable Preference Tuning](https://docs.openpipe.ai/features/dpo/quick-start)\\n\\n![DPO Hyperparameters](https://docs.openpipe.ai/features/dpo/quick-start',\n",
       " 'docs_openpipe_ai_features_chat_completions_moa.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nChat Completions\\n\\nMixture of Agents Chat Completions\\n\\nIn some cases, completions produced by GPT-4 or other SOTA models aren’t good enough to be used in production. To improve quality beyond the\\nlimit of SOTA models, we’ve developed a Mixture of Agents (MoA) technique that enhances quality but also increases cost and latency.\\n\\nTo use MoA models, set the **model** parameter to be one of the following:\\n\\n- `openpipe:moa-gpt-4o-v1`\\n- `openpipe:moa-gpt-4-turbo-v1`\\n- `openpipe:moa-gpt-4-v1`\\n\\nTo get the highest quality completions, use the MoA model that corresponds to the best-performing SOTA model.\\nFor instance, if your original model was `gpt-4-turbo-2024-04-09`, try switching to `openpipe:moa-gpt-4-turbo-v1`.\\n\\nMake sure to set your `OpenAI API Key` in the `Project Settings` page to enable MoA completions!\\n\\n- Python\\n- NodeJS\\n\\nCopy\\n\\n```python\\nfrom openpipe import OpenAI\\n\\n# Find the config values in \"Installing the SDK\"\\nclient = OpenAI()\\n\\ncompletion = client.chat.completions.create(\\n    # model=\"gpt-4-turbo-2024-04-09\", - original model\\n    model=\"openpipe:moa-gpt-4-turbo-v1\",\\n    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\\n    metadata={\"prompt_id\": \"counting\", \"any_key\": \"any_value\"},\\n)\\n\\n```\\n\\nTo learn more, visit the [Mixture of Agents](https://docs.openpipe.ai/features/mixture-of-agents) page.\\n\\n[Gemini Proxy](https://docs.openpipe.ai/features/chat-completions/gemini) [Caching](https://docs.openpipe.ai/features/caching',\n",
       " 'docs_openpipe_ai_api_reference_get_listDatasets.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nDatasets\\n\\nList Datasets\\n\\nGET\\n\\n/\\n\\ndatasets\\n\\nTry it\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.openpipe.ai/api/v1/datasets \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"object\": \"list\",\\n  \"data\": [\\\\\\n    {\\\\\\n      \"object\": \"dataset\",\\\\\\n      \"id\": \"<string>\",\\\\\\n      \"name\": \"<string>\",\\\\\\n      \"created\": \"<string>\",\\\\\\n      \"updated\": \"<string>\",\\\\\\n      \"dataset_entry_count\": 123,\\\\\\n      \"fine_tune_count\": 123\\\\\\n    }\\\\\\n  ]\\n}\\n```\\n\\n#### Authorizations\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listDatasets#authorization-authorization)\\n\\nAuthorization\\n\\nstring\\n\\nheader\\n\\nrequired\\n\\nBearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\\n\\n#### Response\\n\\n200 - application/json\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data)\\n\\ndata\\n\\nobject\\\\[\\\\]\\n\\nrequired\\n\\nShowchild attributes\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data-created)\\n\\ndata.created\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data-dataset-entry-count)\\n\\ndata.dataset\\\\_entry\\\\_count\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data-fine-tune-count)\\n\\ndata.fine\\\\_tune\\\\_count\\n\\nnumber\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data-id)\\n\\ndata.id\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data-name)\\n\\ndata.name\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data-object)\\n\\ndata.object\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`dataset`\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data-updated)\\n\\ndata.updated\\n\\nstring\\n\\nrequired\\n\\n[\\u200b](https://docs.openpipe.ai/api-reference/get-listDatasets#response-object)\\n\\nobject\\n\\nenum<string>\\n\\nrequired\\n\\nAvailable options:\\n\\n`list`\\n\\n[Create Dataset](https://docs.openpipe.ai/api-reference/post-createDataset) [Delete Dataset](https://docs.openpipe.ai/api-reference/delete-dataset)\\n\\ncURL\\n\\nPython\\n\\nJavaScript\\n\\nPHP\\n\\nGo\\n\\nJava\\n\\nCopy\\n\\n```\\ncurl --request GET \\\\\\n  --url https://api.openpipe.ai/api/v1/datasets \\\\\\n  --header \\'Authorization: Bearer <token>\\'\\n```\\n\\n200\\n\\ndefault\\n\\nCopy\\n\\n```\\n{\\n  \"object\": \"list\",\\n  \"data\": [\\\\\\n    {\\\\\\n      \"object\": \"dataset\",\\\\\\n      \"id\": \"<string>\",\\\\\\n      \"name\": \"<string>\",\\\\\\n      \"created\": \"<string>\",\\\\\\n      \"updated\": \"<string>\",\\\\\\n      \"dataset_entry_count\": 123,\\\\\\n      \"fine_tune_count\": 123\\\\\\n    }\\\\\\n  ]\\n}\\n```',\n",
       " 'docs_openpipe_ai_introduction.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nWelcome\\n\\nOpenPipe Documentation\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/intro/dataset-general.png)\\n\\n[**Get Started** \\\\\\\\\\n\\\\\\\\\\nQuickly integrate the OpenPipe SDK into your application and start collecting data.](https://docs.openpipe.ai/getting-started/quick-start) [**Features** \\\\\\\\\\n\\\\\\\\\\nView the platform features OpenPipe provides and learn how to use them.](https://docs.openpipe.ai/overview#what-we-provide) [**Sample Project** \\\\\\\\\\n\\\\\\\\\\nGlance over the public demo we’ve set up to get an idea for how OpenPipe works.](https://app.openpipe.ai/p/BRZFEx50Pf/request-logs)\\n\\n[Overview](https://docs.openpipe.ai/overview)\\n\\n![](https://docs.openpipe.ai/introduction',\n",
       " 'docs_openpipe_ai_features_datasets_relabeling_data.md': 'Ctrl K\\n\\nSearch...\\n\\nNavigation\\n\\nDatasets\\n\\nRelabeling Data\\n\\nAfter importing rows from request logs or uploading a JSONL file, you can optionally relabel\\neach row by sending its messages, tools, and other input parameters to a more powerful model,\\nwhich will generate an output to replace your row’s existing output. If time or cost constraints prevent\\nyou from using the most powerful model available in production, relabeling offers an opportunity to\\noptimize the quality of your training data before kicking off a job.\\n\\n![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/relabeled-output.png)\\n\\nWe currently include the following relabeling options:\\n\\n- gpt-4-turbo-2024-04-09\\n- gpt-4o-2024-08-06\\n- gpt-4-0125-preview\\n- gpt-4-1106-preview\\n- gpt-4-0613\\n- moa-gpt-4o-v1 (Mixture of Agents)\\n- moa-gpt-4-turbo-v1 (Mixture of Agents)\\n- moa-gpt-4-v1 (Mixture of Agents)\\n\\nLearn more about Mixture of Agents, a powerful technique for optimizing quality at the cost of speed and price,\\non the [Mixture of Agents](https://docs.openpipe.ai/features/mixture-of-agents) page.\\n\\n[Uploading Data](https://docs.openpipe.ai/features/datasets/uploading-data) [Exporting Data](https://docs.openpipe.ai/features/datasets/exporting-data'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Find common prefixes\n",
    "prefix_counter = Counter()\n",
    "for content in markdown_contents.values():\n",
    "    for i in range(len(content)):\n",
    "        prefix = content[:i]\n",
    "        if prefix:\n",
    "            prefix_counter[prefix] += 1\n",
    "\n",
    "# Find common suffixes            \n",
    "suffix_counter = Counter()\n",
    "for content in markdown_contents.values():\n",
    "    for i in range(len(content)):\n",
    "        suffix = content[-i:]\n",
    "        if suffix:\n",
    "            suffix_counter[suffix] += 1\n",
    "\n",
    "max_prefix_count = max(prefix_counter.values())\n",
    "max_prefix_count_max_length = max(len(prefix) for prefix in prefix_counter.keys() if prefix_counter[prefix] == max_prefix_count)\n",
    "common_prefixes = [prefix for prefix in prefix_counter.keys() if prefix_counter[prefix] == max_prefix_count and len(prefix) == max_prefix_count_max_length]\n",
    "\n",
    "max_suffix_count = max(suffix_counter.values())\n",
    "max_suffix_count_max_length = max(len(suffix) for suffix in suffix_counter.keys() if suffix_counter[suffix] == max_suffix_count)\n",
    "common_suffixes = [suffix for suffix in suffix_counter.keys() if suffix_counter[suffix] == max_suffix_count and len(suffix) == max_suffix_count_max_length]\n",
    "\n",
    "# Create stripped version\n",
    "stripped_markdown_contents = {}\n",
    "for filename, content in markdown_contents.items():\n",
    "    stripped = content\n",
    "    for prefix in common_prefixes:\n",
    "        if stripped.startswith(prefix):\n",
    "            stripped = stripped[len(prefix):]\n",
    "    for suffix in common_suffixes:\n",
    "        if stripped.endswith(suffix):\n",
    "            stripped = stripped[:-len(suffix)]\n",
    "    stripped_markdown_contents[filename] = stripped\n",
    "\n",
    "stripped_markdown_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== docs_openpipe_ai_api_reference_post_updatemetadata.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Logs\n",
      "\n",
      "Update Metadata\n",
      "\n",
      "POST\n",
      "\n",
      "/\n",
      "\n",
      "logs\n",
      "\n",
      "/\n",
      "\n",
      "update-metadata\n",
      "\n",
      "Try it\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/logs/update-metadata \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"filters\": [\\\n",
      "    {\\\n",
      "      \"field\": \"<string>\",\\\n",
      "      \"equals\": \"<string>\"\\\n",
      "    }\\\n",
      "  ],\n",
      "  \"metadata\": {}\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"matchedLogs\": 123\n",
      "}\n",
      "```\n",
      "\n",
      "#### Authorizations\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-updatemetadata#authorization-authorization)\n",
      "\n",
      "Authorization\n",
      "\n",
      "string\n",
      "\n",
      "header\n",
      "\n",
      "required\n",
      "\n",
      "Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\n",
      "\n",
      "#### Body\n",
      "\n",
      "application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-updatemetadata#body-filters)\n",
      "\n",
      "filters\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-updatemetadata#body-filters-equals)\n",
      "\n",
      "filters.equals\n",
      "\n",
      "stringnumberboolean\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-updatemetadata#body-filters-field)\n",
      "\n",
      "filters.field\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "The field to filter on. Possible fields include: `model`, `completionId`, and `metadata.your_tag_name`.\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-updatemetadata#body-metadata)\n",
      "\n",
      "metadata\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Extra metadata to attach to the call for filtering. Eg { \"userId\": \"123\", \"prompt\\_id\": \"populate-title\" }\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-updatemetadata#body-metadata-key)\n",
      "\n",
      "metadata.{key}\n",
      "\n",
      "string \\| nullenum<string> \\| null\n",
      "\n",
      "#### Response\n",
      "\n",
      "200 - application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-updatemetadata#response-matched-logs)\n",
      "\n",
      "matchedLogs\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[Report Anthropic](https://docs.openpipe.ai/api-reference/post-report-anthropic) [Chat Completions](https://docs.openpipe.ai/api-reference/post-chatcompletions)\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/logs/update-metadata \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"filters\": [\\\n",
      "    {\\\n",
      "      \"field\": \"<string>\",\\\n",
      "      \"equals\": \"<string>\"\\\n",
      "    }\\\n",
      "  ],\n",
      "  \"metadata\": {}\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"matchedLogs\": 123\n",
      "}\n",
      "```\n",
      "\n",
      "=== docs_openpipe_ai_features_datasets_quick_start.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Datasets\n",
      "\n",
      "Datasets Quick Start\n",
      "\n",
      "Datasets are the raw material for training models. They’re where you’ll go to collect, evaluate, and refine your training data.\n",
      "\n",
      "1\n",
      "\n",
      "Create Dataset\n",
      "\n",
      "To create a dataset, navigate to the **Datasets** tab and click **New Dataset**.\n",
      "\n",
      "Your dataset will be given a default name including the time at which it was created. We suggest editing the name to something more descriptive.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/datasets/editing-dataset-name.png)\n",
      "\n",
      "2\n",
      "\n",
      "Import Data\n",
      "\n",
      "Now that you have a shiny new dataset, you need to somehow import data into it. This can be done in one of two ways:\n",
      "\n",
      "1. [Importing request logs](https://docs.openpipe.ai/features/datasets/importing-logs)\n",
      "2. [Uploading a file from your machine](https://docs.openpipe.ai/features/datasets/uploading-data)\n",
      "\n",
      "Click the links to learn more about each method.\n",
      "\n",
      "[Overview](https://docs.openpipe.ai/features/datasets/overview) [Importing Request Logs](https://docs.openpipe.ai/features/datasets/importing-logs)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/datasets/quick-start\n",
      "\n",
      "=== docs_openpipe_ai_features_criteria_api.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Criteria\n",
      "\n",
      "API Endpoints\n",
      "\n",
      "After you’ve defined and aligned your judge criteria, you can access them via API endpoints for both runtime evaluation ( **Best of N** sampling) and offline testing.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/criteria/api\\#runtime-evaluation)  Runtime Evaluation\n",
      "\n",
      "See the Chat Completion [docs](https://docs.openpipe.ai/features/chat-completions/overview) and [API\\\\\n",
      "Reference](https://docs.openpipe.ai/api-reference/post-chatcompletions) for more information on making chat completions\n",
      "with OpenPipe.\n",
      "\n",
      "When making a request to the `/chat/completions` endpoint, you can specify a list of criteria to run immediately after a completion is generated. We recommend generating multiple responses from the same prompt, each of which will be scored by the specified criteria. The responses will be sorted by their combined score across all criteria, from highest to lowest. This technique is known as **[Best of N](https://huggingface.co/docs/trl/en/best_of_n)** sampling.\n",
      "\n",
      "To invoke criteria, add an `op-criteria` header to your request with a list of criterion IDs, like so:\n",
      "\n",
      "- Python\n",
      "- NodeJS\n",
      "- cURL\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "from openpipe import OpenAI\n",
      "\n",
      "# Find the config values in \"Installing the SDK\"\n",
      "client = OpenAI()\n",
      "\n",
      "completion = client.chat.completions.create(\n",
      "    model=\"openai:gpt-4o-mini\",\n",
      "    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\n",
      "    metadata={\n",
      "        \"prompt_id\": \"counting\",\n",
      "        \"any_key\": \"any_value\",\n",
      "    },\n",
      "    n=5,\n",
      "    extra_headers={\"op-criteria\": '[\"criterion-1@v1\", \"criterion-2\"]'},\n",
      ")\n",
      "\n",
      "best_response = completion.choices[0]\n",
      "\n",
      "```\n",
      "\n",
      "Specified criteria can either be versioned, like `criterion-1@v1`, or default to the latest criterion version, like `criterion-2`.\n",
      "\n",
      "In addition to the usual fields, each chat completion choice will now include a `criteria_results` object, which contains the judgements of the specified criteria. The array of completion choices will take the following form:\n",
      "\n",
      "Copy\n",
      "\n",
      "```json\n",
      "[\\\n",
      "  {\\\n",
      "    \"finish_reason\": \"stop\",\\\n",
      "    \"index\": 0,\\\n",
      "    \"message\": {\\\n",
      "      \"content\": \"1, 2, 3.\",\\\n",
      "      \"refusal\": null,\\\n",
      "      \"role\": \"assistant\"\\\n",
      "    },\\\n",
      "    \"logprobs\": null,\\\n",
      "    \"criteria_results\": {\\\n",
      "      \"criterion-1\": {\\\n",
      "        \"status\": \"success\",\\\n",
      "        \"score\": 1,\\\n",
      "        \"explanation\": \"...\"\\\n",
      "      },\\\n",
      "      \"criterion-2\": {\\\n",
      "        \"status\": \"success\",\\\n",
      "        \"score\": 0.6,\\\n",
      "        \"explanation\": \"...\"\\\n",
      "      }\\\n",
      "    }\\\n",
      "  },\\\n",
      "  {\\\n",
      "    ...\\\n",
      "  }\\\n",
      "]\n",
      "\n",
      "```\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/criteria/api\\#offline-testing)  Offline Testing\n",
      "\n",
      "See the [API Reference](https://docs.openpipe.ai/api-reference/post-criteriajudge) for more details.\n",
      "\n",
      "To check the quality of a previously generated output against a specific criterion, use the `/criteria/judge` endpoint. You can request judgements using either the TypeScript or Python SDKs, or through a cURL request.\n",
      "\n",
      "- Python\n",
      "- NodeJS\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "from openpipe.client import OpenPipe\n",
      "\n",
      "op_client = OpenPipe()\n",
      "\n",
      "result = op_client.get_criterion_judgement(\n",
      "    criterion_id=\"criterion-1@v1\", # if no version is specified, the latest version is used\n",
      "    input={\"messages\": messages},\n",
      "    output=output,\n",
      ")\n",
      "\n",
      "```\n",
      "\n",
      "[Alignment Sets](https://docs.openpipe.ai/features/criteria/alignment-set) [Overview](https://docs.openpipe.ai/features/chat-completions/overview)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Runtime Evaluation](https://docs.openpipe.ai/features/criteria/api#runtime-evaluation)\n",
      "- [Offline Testing](https://docs.openpipe.ai/features/criteria/api#offline-testing\n",
      "\n",
      "=== docs_openpipe_ai_features_request_logs_reporting_anthropic.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Request Logs\n",
      "\n",
      "Logging Anthropic Requests\n",
      "\n",
      "Anthropic’s language models have a different API structure than those of OpenAI.\n",
      "To record requests made to Anthropic’s models, follow the examples below:\n",
      "\n",
      "- Python\n",
      "- NodeJS\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "import time\n",
      "from anthropic import Anthropic\n",
      "from openpipe.client import OpenPipe\n",
      "\n",
      "anthropic = Anthropic()\n",
      "op_client = OpenPipe()\n",
      "\n",
      "payload = {\n",
      "    \"model\": \"claude-3-opus-20240229\",\n",
      "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello, Claude\"}],\n",
      "    \"max_tokens\": 100,\n",
      "}\n",
      "\n",
      "message = anthropic.messages.create(**payload)\n",
      "\n",
      "op_client.report_anthropic(\n",
      "    requested_at=int(time.time() * 1000),\n",
      "    received_at=int(time.time() * 1000),\n",
      "    req_payload=payload,\n",
      "    resp_payload=message,\n",
      "    status_code=200,\n",
      "    metadata={\n",
      "        \"prompt_id\": \"My prompt id\",\n",
      "    },\n",
      ")\n",
      "\n",
      "```\n",
      "\n",
      "If you’re using a different programming language, you can make a raw http request to the [report-anthropic](https://docs.openpipe.ai/api-reference/post-report-anthropic) enpoint.\n",
      "\n",
      "[Logging Requests](https://docs.openpipe.ai/features/request-logs/logging-requests) [Exporting Logs](https://docs.openpipe.ai/features/request-logs/exporting-logs\n",
      "\n",
      "=== docs_openpipe_ai_features_datasets_overview.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Datasets\n",
      "\n",
      "Datasets\n",
      "\n",
      "Datasets are the raw material for training models. They can be scraped from your request logs or uploaded from your local machine.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/datasets/overview.png)\n",
      "\n",
      "To learn how to create a dataset, check out the [Quick Start](https://docs.openpipe.ai/features/datasets/quick-start) guide.\n",
      "\n",
      "[Exporting Logs](https://docs.openpipe.ai/features/request-logs/exporting-logs) [Quick Start](https://docs.openpipe.ai/features/datasets/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/datasets/overview\n",
      "\n",
      "=== docs_openpipe_ai_api_reference_delete_dataset.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Datasets\n",
      "\n",
      "Delete Dataset\n",
      "\n",
      "DELETE\n",
      "\n",
      "/\n",
      "\n",
      "datasets\n",
      "\n",
      "/\n",
      "\n",
      "{datasetId}\n",
      "\n",
      "Try it\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request DELETE \\\n",
      "  --url https://api.openpipe.ai/api/v1/datasets/{datasetId} \\\n",
      "  --header 'Authorization: Bearer <token>'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"id\": \"<string>\",\n",
      "  \"object\": \"dataset\",\n",
      "  \"deleted\": true\n",
      "}\n",
      "```\n",
      "\n",
      "#### Authorizations\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/delete-dataset#authorization-authorization)\n",
      "\n",
      "Authorization\n",
      "\n",
      "string\n",
      "\n",
      "header\n",
      "\n",
      "required\n",
      "\n",
      "Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\n",
      "\n",
      "#### Path Parameters\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/delete-dataset#parameter-dataset-id)\n",
      "\n",
      "datasetId\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "#### Response\n",
      "\n",
      "200 - application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/delete-dataset#response-deleted)\n",
      "\n",
      "deleted\n",
      "\n",
      "boolean\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/delete-dataset#response-id)\n",
      "\n",
      "id\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/delete-dataset#response-object)\n",
      "\n",
      "object\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`dataset`\n",
      "\n",
      "[List Datasets](https://docs.openpipe.ai/api-reference/get-listDatasets) [Add Entries to Dataset](https://docs.openpipe.ai/api-reference/post-createDatasetEntries)\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request DELETE \\\n",
      "  --url https://api.openpipe.ai/api/v1/datasets/{datasetId} \\\n",
      "  --header 'Authorization: Bearer <token>'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"id\": \"<string>\",\n",
      "  \"object\": \"dataset\",\n",
      "  \"deleted\": true\n",
      "}\n",
      "```\n",
      "\n",
      "=== docs_openpipe_ai_features_fine_tuning_webapp.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Fine Tuning\n",
      "\n",
      "Fine Tuning via Webapp\n",
      "\n",
      "OpenPipe allows you to train, evaluate, and deploy your models all in the same place. We recommend training your models\n",
      "through the webapp, which provides more flexibility and a smoother experience than the API. To fine-tune a new model, follow these steps:\n",
      "\n",
      "1. Create a new dataset or navigate to an existing one.\n",
      "2. Click “Fine Tune” in the top right.\n",
      "3. Select a base model.\n",
      "4. (Optional) Set custom hyperparameters and configure [pruning rules](https://docs.openpipe.ai/features/pruning-rules).\n",
      "5. Click “Start Training” to kick off the job.\n",
      "\n",
      "Once started, your model’s training job will take at least a few minutes and potentially several hours, depending on the size of the\n",
      "model and the amount of data. You can check your model’s status by navigating to the Fine Tunes page and selecting your model.\n",
      "\n",
      "For an example of how an OpenPipe model looks once it’s trained, see our public [PII Redaction](https://app.openpipe.ai/p/BRZFEx50Pf/fine-tunes/6076ad69-cce5-4892-ae54-e0549bbe107f/general) model. Feel free to hit it with some sample queries!\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/fine-tuning.png)\n",
      "\n",
      "[Quick Start](https://docs.openpipe.ai/features/fine-tuning/quick-start) [API (Beta)](https://docs.openpipe.ai/features/fine-tuning/api)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/fine-tuning/webapp\n",
      "\n",
      "=== docs_openpipe_ai_features_fallback.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Features\n",
      "\n",
      "Fallback options\n",
      "\n",
      "Fallback is a feature that ensures a seamless experience and guarantees 100% uptime when working with new or unstable models.\n",
      "\n",
      "When fallback is enabled, any failed API calls will be automatically retried using OpenAI or any OpenAI-compatible client.\n",
      "\n",
      "## [​](https://docs.openpipe.ai/features/fallback\\#fallback-to-openai)  Fallback to OpenAI\n",
      "\n",
      "To enable fallback to OpenAI, you can simply pass the `fallback` option to the `openpipe` object with the `model` property set to the OpenAI model you want to fall back to.\n",
      "\n",
      "- Python\n",
      "- NodeJS\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "from openpipe import OpenAI\n",
      "\n",
      "client = OpenAI()\n",
      "\n",
      "completion = client.chat.completions.create(\n",
      "    model=\"openpipe:my-ft-model\",\n",
      "    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\n",
      "    openpipe={\n",
      "        \"fallback\": {\n",
      "            \"model\": \"gpt-4-turbo\"\n",
      "        }\n",
      "    },\n",
      ")\n",
      "\n",
      "```\n",
      "\n",
      "## [​](https://docs.openpipe.ai/features/fallback\\#timeout-fallback)  Timeout Fallback\n",
      "\n",
      "If a request takes too long to execute, you can set a timeout for the fallback.\n",
      "In the example below, the request will fall back to OpenAI after 10 seconds.\n",
      "\n",
      "- Python\n",
      "- NodeJS\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "from openpipe import OpenAI\n",
      "\n",
      "client = OpenAI(timeout=10) # initial OpenPipe call timeout in seconds\n",
      "\n",
      "completion = client.chat.completions.create(\n",
      "    model=\"openpipe:my-ft-model\",\n",
      "    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\n",
      "    openpipe={\n",
      "        \"fallback\": {\n",
      "            \"model\": \"gpt-4-turbo\",\n",
      "            # optional fallback timeout. Defaults to the timeout specified in the client, or OpenAI default timeout if not set.\n",
      "            \"timeout\": 20 # seconds\n",
      "        }\n",
      "    },\n",
      ")\n",
      "\n",
      "```\n",
      "\n",
      "## [​](https://docs.openpipe.ai/features/fallback\\#fallback-to-custom-openai-compatible-client)  Fallback to Custom OpenAI Compatible Client\n",
      "\n",
      "If you want to use another OpenAI-compatible fallback client, you can pass a `fallback_client` to the `openpipe` object.\n",
      "\n",
      "- Python\n",
      "- NodeJS\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "from openpipe import OpenAI\n",
      "\n",
      "client = OpenAI(\n",
      "    openpipe={\n",
      "        \"fallback_client\": OpenAICompatibleClient(api_key=\"client api key\")\n",
      "    }\n",
      ");\n",
      "\n",
      "completion = client.chat.completions.create(\n",
      "    model=\"openpipe:my-ft-model\",\n",
      "    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\n",
      "    openpipe={\n",
      "        \"fallback\": { \"model\": \"gpt-4-turbo\" }\n",
      "    },\n",
      ")\n",
      "\n",
      "```\n",
      "\n",
      "[Pruning Rules](https://docs.openpipe.ai/features/pruning-rules) [Mixture of Agents](https://docs.openpipe.ai/features/mixture-of-agents)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Fallback to OpenAI](https://docs.openpipe.ai/features/fallback#fallback-to-openai)\n",
      "- [Timeout Fallback](https://docs.openpipe.ai/features/fallback#timeout-fallback)\n",
      "- [Fallback to Custom OpenAI Compatible Client](https://docs.openpipe.ai/features/fallback#fallback-to-custom-openai-compatible-client\n",
      "\n",
      "=== docs_openpipe_ai_features_evaluations_quick_start.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Evaluations\n",
      "\n",
      "Evaluations Quick Start\n",
      "\n",
      "In this quick start guide, we’ll walk you through creating your first head-to-head evaluation. Head to head evaluations allow you to compare two or more models\n",
      "using an LLM judge that compares outputs against one another based on custom instructions.\n",
      "\n",
      "**Before you begin:** Before writing your first eval, make sure you’ve [created a\\\\\n",
      "dataset](https://docs.openpipe.ai/features/datasets/quick-start) with one or more test entries. Also, make sure to add\n",
      "your OpenAI or Anthropic API key in your project settings page to allow the judge LLM to run.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/evaluations/quick-start\\#writing-an-evaluation)  Writing an Evaluation\n",
      "\n",
      "1\n",
      "\n",
      "Choose a dataset to evaluate models on\n",
      "\n",
      "To create an eval, navigate to the dataset with the test entries you’d like to evaluate your models based on.\n",
      "Find the **Evaluate** tab and click the **+** button to the right of the **Evals** dropdown list.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/eval-button.png)\n",
      "\n",
      "A configuration modal will appear.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/create-h2h-eval.png)\n",
      "\n",
      "2\n",
      "\n",
      "Edit judge model instructions\n",
      "\n",
      "Customize the judge LLM instructions. The outputs of each model will be compared against one another\n",
      "pairwise and a score of WIN, LOSS, or TIE will be assigned to each model’s based on the judge’s instructions.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/edit-judge-instructions.png)\n",
      "\n",
      "3\n",
      "\n",
      "Select judge model\n",
      "\n",
      "Choose a judge model from the dropdown list. If you’d like to use a judge model that isn’t supported by default,\n",
      "add it as an [external model](https://docs.openpipe.ai/features/chat-completions/external-models) in your project settings page.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/select-judge-model.png)\n",
      "\n",
      "4\n",
      "\n",
      "Choose models to evaluate\n",
      "\n",
      "Choose the models you’d like to evaluate against one another.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/choose-evaluated-models.png)\n",
      "\n",
      "5\n",
      "\n",
      "Run the evaluation\n",
      "\n",
      "Click **Create** to start running the eval.\n",
      "\n",
      "Once the eval is complete, you can see model performance in the evaluation’s **Results** tab.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/quick-start-results.png)\n",
      "\n",
      "To learn more about customizing the judge LLM instructions and viewing evaluation judgements in greater detail,\n",
      "see the [Head-to-Head Evaluations](https://docs.openpipe.ai/features/evaluations/head-to-head) page.\n",
      "\n",
      "[Overview](https://docs.openpipe.ai/features/evaluations/overview) [Code Evals](https://docs.openpipe.ai/features/evaluations/code)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Writing an Evaluation](https://docs.openpipe.ai/features/evaluations/quick-start#writing-an-evaluation)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/quick-start\n",
      "\n",
      "=== docs_openpipe_ai_features_criteria_quick_start.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Criteria\n",
      "\n",
      "Criteria Quick Start\n",
      "\n",
      "Criteria are a reliable way to detect and correct mistakes in LLM output. Criteria can be used when defining LLM evaluations, improving data quality, and for [runtime evaluation](https://docs.openpipe.ai/features/criteria/api#runtime-evaluation) when generating **best of N** samples.\n",
      "This tutorial will walk you through creating and aligning your first criterion.\n",
      "\n",
      "**Before you begin:** Before creating your first criterion, you should identify an issue with\n",
      "your model’s output that you want to detect and correct. You should also have either an OpenPipe\n",
      "[dataset](https://docs.openpipe.ai/features/datasets/overview) or a [JSONL\\\\\n",
      "file](https://docs.openpipe.ai/features/criteria/alignment-set#importing-from-a-jsonl-file) containing several rows of\n",
      "data that exhibit the issue, and several that don’t.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/criteria/quick-start\\#creating-a-criterion)  Creating a Criterion\n",
      "\n",
      "1\n",
      "\n",
      "Open the creation modal\n",
      "\n",
      "Navigate to the **Criteria** tab and click the **New Criterion** button.\n",
      "The creation modal will open with a default prompt and judge model.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/create-criterion.png)\n",
      "\n",
      "By default, each of the following fields will be templated into the criterion’s prompt when assigning a judgement to an output:\n",
      "\n",
      "- `messages` _(optional):_ The messages used to generate the output\n",
      "- `tools` _(optional):_ The tools used to generate the output\n",
      "- `tool_choice` _(optional):_ The tool choice used to generate the output\n",
      "- `output` _(required):_ The chat completion object to be judged\n",
      "\n",
      "Many criteria do not require all of the input fields, and some may judge based soley on the `output`. You can exclude fields by removing them from the **Templated Variables** section.\n",
      "\n",
      "2\n",
      "\n",
      "Draft an initial prompt\n",
      "\n",
      "Write an initial LLM prompt with basic instructions for identifying rows containing\n",
      "the issue you want to detect and correct. Don’t worry about engineering a perfect\n",
      "prompt, you’ll have a chance to improve it during the alignment process.\n",
      "\n",
      "As an example, if you want to detect rows in which the model’s output is in a different language than the input,\n",
      "you might write a prompt like this:\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "Mark the criteria as passed if the input and output are the same language.\n",
      "Mark it as failed if they are in different languages.\n",
      "\n",
      "```\n",
      "\n",
      "Make sure to use the terms `input`, `output`, `passed`, and `failed` in your prompt to match our\n",
      "internal templating.\n",
      "\n",
      "Finally, import a few rows (we recommend at least 30) into an alignment set for the criterion.\n",
      "\n",
      "3\n",
      "\n",
      "Confirm creation\n",
      "\n",
      "Click **Create** to create the criterion and run the initial prompt against the imported alignment set.\n",
      "You’ll be redirected to the criterion’s alignment page.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/overview.png)\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/criteria/quick-start\\#aligning-a-criterion)  Aligning a Criterion\n",
      "\n",
      "Ensuring your criterion’s judgements are reliable involves two simple processes:\n",
      "\n",
      "- Manually labeling outputs\n",
      "- Refining the criterion\n",
      "\n",
      "1\n",
      "\n",
      "Manually labeling outputs\n",
      "\n",
      "In order to know whether you agree with your criterion’s judgements, you’ll need to label some data yourself.\n",
      "Use the Alignment UI to manually label each output with `PASS` or `FAIL` based on the criterion. Feel free to `SKIP` outputs you aren’t sure about and come back to them later.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/manually-label.png)\n",
      "\n",
      "Try to label at least 30 rows to provide a reliable estimate of the LLM’s precision and recall.\n",
      "\n",
      "2\n",
      "\n",
      "Refining the criterion\n",
      "\n",
      "As you record your own judgements, alter the criterion’s prompt and judge model to align its judgements with your own.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/edit-criterion.png)\n",
      "\n",
      "Investing time in a good prompt and selecting the best judge model pays dividends.\n",
      "High-quality LLM judgements help you quickly identify rows that fail the criterion, speeding up the process of manually labeling rows.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/llm-judgement.png)\n",
      "\n",
      "As you improve your criterion prompt, you’ll notice your [alignment stats](https://docs.openpipe.ai/features/criteria/alignment-set#alignment-stats) improving.\n",
      "Once you’ve labeled at least 30 rows and are satisfied with the precision and recall of your LLM judge, the criterion is ready to be deployed!\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/criteria/quick-start\\#deploying-a-criterion)  Deploying a Criterion\n",
      "\n",
      "The simplest way to deploy a criterion is to create a criterion eval. Unlike head to head evals, criterion evals are not pairwise comparisons.\n",
      "Instead, they evaluate the quality of one or more models’ output according to a specific criterion.\n",
      "\n",
      "First, navigate to the Evals tab and click **New Evaluation** -\\> **Add criterion eval**.\n",
      "\n",
      "Pick the models to evaluate and the test dataset on which to evaluate them. Next, select the criterion you would like to judge your models against.\n",
      "The judge model and prompt you defined when creating the criterion will be used to judge individual outputs from your models.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/create-criterion-eval.png)\n",
      "\n",
      "Finally, click **Create** to run the evaluation. Just like that, you’re be able to view evaluation results based on aligned LLM judgements!\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/criterion-eval-results.png)\n",
      "\n",
      "[Overview](https://docs.openpipe.ai/features/criteria/overview) [Alignment Sets](https://docs.openpipe.ai/features/criteria/alignment-set)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Creating a Criterion](https://docs.openpipe.ai/features/criteria/quick-start#creating-a-criterion)\n",
      "- [Aligning a Criterion](https://docs.openpipe.ai/features/criteria/quick-start#aligning-a-criterion)\n",
      "- [Deploying a Criterion](https://docs.openpipe.ai/features/criteria/quick-start#deploying-a-criterion)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/criteria/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/criteria/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/criteria/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/criteria/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/criteria/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/criteria/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/criteria/quick-start\n",
      "\n",
      "=== docs_openpipe_ai_features_evaluations_criterion.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Evaluations\n",
      "\n",
      "Criterion Evaluations\n",
      "\n",
      "Criterion evaluations are useful for evaluating your LLM outputs against a set of criteria. If you\n",
      "haven’t defined any criteria yet, check out the criteria [Quick\\\\\n",
      "Start](https://docs.openpipe.ai/features/criteria/quick-start) guide.\n",
      "\n",
      "Criterion evaluations are a reliable way to judge the quality of your LLM outputs according to the criteria you’ve defined. For each model being evaluated, the output of that model is compared against the criteria you’ve defined for every entry in the evaluation dataset.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/criterion-eval-settings.png)\n",
      "\n",
      "A criterion evaluation is only as reliable as the criterion you’ve defined. To improve your\n",
      "criterion, check out the [alignment docs](https://docs.openpipe.ai/features/criteria/alignment-set).\n",
      "\n",
      "Each output in the evaluation dataset is compared against the criterion you’ve defined. The output is then scored as either `PASS` or `FAIL` based on the criterion.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/criterion-eval-results-table.png)\n",
      "\n",
      "To see why one model might be outperforming another, you can navigate back to the [evaluation table](https://app.openpipe.ai/p/BRZFEx50Pf/datasets/3e7e82c1-b066-476c-9f17-17fd85a2169b/evaluate) and click on a result pill to see the evaluation judge’s reasoning.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/criterion-eval-explanation.png)\n",
      "\n",
      "While criterion evaluations are powerful and flexible, they’re much more expensive to run than pure code. If your models’ outputs can be easily evaluated by code alone, consider using [code evaluations](https://docs.openpipe.ai/features/evaluations/code) instead.\n",
      "\n",
      "[Code Evals](https://docs.openpipe.ai/features/evaluations/code) [Head-to-Head Evals](https://docs.openpipe.ai/features/evaluations/head-to-head)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/criterion)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/criterion)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/criterion\n",
      "\n",
      "=== docs_openpipe_ai_api_reference_post_createModel.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Models\n",
      "\n",
      "Create Model\n",
      "\n",
      "POST\n",
      "\n",
      "/\n",
      "\n",
      "models\n",
      "\n",
      "Try it\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/models \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"datasetId\": \"<string>\",\n",
      "  \"slug\": \"<string>\",\n",
      "  \"pruningRuleIds\": [],\n",
      "  \"trainingConfig\": {\n",
      "    \"provider\": \"openpipe\",\n",
      "    \"baseModel\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
      "    \"enable_sft\": true,\n",
      "    \"enable_preference_tuning\": false,\n",
      "    \"sft_hyperparameters\": {},\n",
      "    \"preference_hyperparameters\": {},\n",
      "    \"hyperparameters\": {\n",
      "      \"is_sft_enabled\": true,\n",
      "      \"batch_size\": \"auto\",\n",
      "      \"learning_rate_multiplier\": 123,\n",
      "      \"num_epochs\": 123,\n",
      "      \"is_preference_tuning_enabled\": true,\n",
      "      \"preference_tuning_variant\": \"DPO\",\n",
      "      \"preference_tuning_learning_rate_multiplier\": 123,\n",
      "      \"preference_tuning_num_epochs\": 123,\n",
      "      \"preference_tuning_training_beta\": 123,\n",
      "      \"preference_tuning_adapter_weight\": 123\n",
      "    }\n",
      "  },\n",
      "  \"defaultTemperature\": 123\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"id\": \"<string>\",\n",
      "  \"name\": \"<string>\",\n",
      "  \"object\": \"model\",\n",
      "  \"description\": \"<string>\",\n",
      "  \"created\": \"<string>\",\n",
      "  \"updated\": \"<string>\",\n",
      "  \"openpipe\": {\n",
      "    \"baseModel\": \"<string>\",\n",
      "    \"hyperparameters\": {},\n",
      "    \"status\": \"PENDING\",\n",
      "    \"datasetId\": \"<string>\",\n",
      "    \"errorMessage\": \"<string>\"\n",
      "  },\n",
      "  \"contextWindow\": 123,\n",
      "  \"maxCompletionTokens\": 123,\n",
      "  \"capabilities\": [\\\n",
      "    \"chat\"\\\n",
      "  ],\n",
      "  \"pricing\": {\n",
      "    \"chatIn\": 123,\n",
      "    \"chatOut\": 123\n",
      "  },\n",
      "  \"owned_by\": \"<string>\"\n",
      "}\n",
      "```\n",
      "\n",
      "#### Authorizations\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#authorization-authorization)\n",
      "\n",
      "Authorization\n",
      "\n",
      "string\n",
      "\n",
      "header\n",
      "\n",
      "required\n",
      "\n",
      "Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\n",
      "\n",
      "#### Body\n",
      "\n",
      "application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-dataset-id)\n",
      "\n",
      "datasetId\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-slug)\n",
      "\n",
      "slug\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config)\n",
      "\n",
      "trainingConfig\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "- Option 1\n",
      "- Option 2\n",
      "- Option 3\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-base-model)\n",
      "\n",
      "trainingConfig.baseModel\n",
      "\n",
      "enum<string>string\n",
      "\n",
      "required\n",
      "\n",
      "The base model to train from. This could be a base model name or the slug of a previously trained model.\n",
      "\n",
      "Available options:\n",
      "\n",
      "`meta-llama/Meta-Llama-3.1-8B-Instruct`,\n",
      "\n",
      "`meta-llama/Meta-Llama-3.1-70B-Instruct`,\n",
      "\n",
      "`meta-llama/Llama-3.3-70B-Instruct`,\n",
      "\n",
      "`meta-llama/Llama-3.1-8B`,\n",
      "\n",
      "`meta-llama/Llama-3.1-70B`,\n",
      "\n",
      "`Qwen/Qwen2.5-72B-Instruct`,\n",
      "\n",
      "`Qwen/Qwen2.5-Coder-32B-Instruct`,\n",
      "\n",
      "`Qwen/Qwen2.5-1.5B-Instruct`,\n",
      "\n",
      "`Qwen/Qwen2.5-7B-Instruct`,\n",
      "\n",
      "`mistralai/Mistral-Nemo-Base-2407`,\n",
      "\n",
      "`mistralai/Mistral-Small-24B-Base-2501`,\n",
      "\n",
      "`meta-llama/Llama-3.2-1B-Instruct`,\n",
      "\n",
      "`meta-llama/Llama-3.2-3B-Instruct`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-provider)\n",
      "\n",
      "trainingConfig.provider\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`openpipe`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-enable-preference-tuning)\n",
      "\n",
      "trainingConfig.enable\\_preference\\_tuning\n",
      "\n",
      "boolean\n",
      "\n",
      "default:\n",
      "\n",
      "false\n",
      "\n",
      "Whether to enable DPO training. If true, the model will be trained using DPO. Can be used in conjunction with SFT training.\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-enable-sft)\n",
      "\n",
      "trainingConfig.enable\\_sft\n",
      "\n",
      "boolean\n",
      "\n",
      "default:\n",
      "\n",
      "true\n",
      "\n",
      "Whether to enable SFT training. If true, the model will be trained using SFT. Can be used in conjunction with DPO training.\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters)\n",
      "\n",
      "trainingConfig.hyperparameters\n",
      "\n",
      "object\n",
      "\n",
      "DEPRECATED: Use the `sft_hyperparameters` and `preference_hyperparameters` fields instead.\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-batch-size)\n",
      "\n",
      "trainingConfig.hyperparameters.batch\\_size\n",
      "\n",
      "enum<string>number\n",
      "\n",
      "Available options:\n",
      "\n",
      "`auto`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-is-preference-tuning-enabled)\n",
      "\n",
      "trainingConfig.hyperparameters.is\\_preference\\_tuning\\_enabled\n",
      "\n",
      "boolean\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-is-sft-enabled)\n",
      "\n",
      "trainingConfig.hyperparameters.is\\_sft\\_enabled\n",
      "\n",
      "boolean\n",
      "\n",
      "default:\n",
      "\n",
      "true\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-learning-rate-multiplier)\n",
      "\n",
      "trainingConfig.hyperparameters.learning\\_rate\\_multiplier\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-num-epochs)\n",
      "\n",
      "trainingConfig.hyperparameters.num\\_epochs\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-preference-tuning-adapter-weight)\n",
      "\n",
      "trainingConfig.hyperparameters.preference\\_tuning\\_adapter\\_weight\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-preference-tuning-learning-rate-multiplier)\n",
      "\n",
      "trainingConfig.hyperparameters.preference\\_tuning\\_learning\\_rate\\_multiplier\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-preference-tuning-num-epochs)\n",
      "\n",
      "trainingConfig.hyperparameters.preference\\_tuning\\_num\\_epochs\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-preference-tuning-training-beta)\n",
      "\n",
      "trainingConfig.hyperparameters.preference\\_tuning\\_training\\_beta\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-hyperparameters-preference-tuning-variant)\n",
      "\n",
      "trainingConfig.hyperparameters.preference\\_tuning\\_variant\n",
      "\n",
      "Option 1 · enum<string>Option 2 · enum<string>\n",
      "\n",
      "Available options:\n",
      "\n",
      "`DPO`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-preference-hyperparameters)\n",
      "\n",
      "trainingConfig.preference\\_hyperparameters\n",
      "\n",
      "object\n",
      "\n",
      "Hyperparameters for DPO training job. Ensure `enable_preference_tuning` is true. If no preference hyperparameters are provided, default values will be used.\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-preference-hyperparameters-adapter-weight)\n",
      "\n",
      "trainingConfig.preference\\_hyperparameters.adapter\\_weight\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-preference-hyperparameters-learning-rate-multiplier)\n",
      "\n",
      "trainingConfig.preference\\_hyperparameters.learning\\_rate\\_multiplier\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-preference-hyperparameters-num-epochs)\n",
      "\n",
      "trainingConfig.preference\\_hyperparameters.num\\_epochs\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-preference-hyperparameters-training-beta)\n",
      "\n",
      "trainingConfig.preference\\_hyperparameters.training\\_beta\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-preference-hyperparameters-variant)\n",
      "\n",
      "trainingConfig.preference\\_hyperparameters.variant\n",
      "\n",
      "Option 1 · enum<string>Option 2 · enum<string>\n",
      "\n",
      "Available options:\n",
      "\n",
      "`DPO`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-sft-hyperparameters)\n",
      "\n",
      "trainingConfig.sft\\_hyperparameters\n",
      "\n",
      "object\n",
      "\n",
      "Hyperparameters for SFT training job. Ensure `enable_sft` is true. If no SFT hyperparameters are provided, default values will be used.\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-sft-hyperparameters-batch-size)\n",
      "\n",
      "trainingConfig.sft\\_hyperparameters.batch\\_size\n",
      "\n",
      "enum<string>number\n",
      "\n",
      "Available options:\n",
      "\n",
      "`auto`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-sft-hyperparameters-learning-rate-multiplier)\n",
      "\n",
      "trainingConfig.sft\\_hyperparameters.learning\\_rate\\_multiplier\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-training-config-sft-hyperparameters-num-epochs)\n",
      "\n",
      "trainingConfig.sft\\_hyperparameters.num\\_epochs\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-default-temperature)\n",
      "\n",
      "defaultTemperature\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#body-pruning-rule-ids)\n",
      "\n",
      "pruningRuleIds\n",
      "\n",
      "string\\[\\]\n",
      "\n",
      "#### Response\n",
      "\n",
      "200 - application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-capabilities)\n",
      "\n",
      "capabilities\n",
      "\n",
      "enum<string>\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`chat`,\n",
      "\n",
      "`tools`,\n",
      "\n",
      "`json`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-context-window)\n",
      "\n",
      "contextWindow\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-created)\n",
      "\n",
      "created\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-description)\n",
      "\n",
      "description\n",
      "\n",
      "string \\| null\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-id)\n",
      "\n",
      "id\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-max-completion-tokens)\n",
      "\n",
      "maxCompletionTokens\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-name)\n",
      "\n",
      "name\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-object)\n",
      "\n",
      "object\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`model`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-openpipe)\n",
      "\n",
      "openpipe\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-openpipe-base-model)\n",
      "\n",
      "openpipe.baseModel\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-openpipe-dataset-id)\n",
      "\n",
      "openpipe.datasetId\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-openpipe-error-message)\n",
      "\n",
      "openpipe.errorMessage\n",
      "\n",
      "string \\| null\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-openpipe-hyperparameters)\n",
      "\n",
      "openpipe.hyperparameters\n",
      "\n",
      "object \\| null\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-openpipe-hyperparameters-key)\n",
      "\n",
      "openpipe.hyperparameters.{key}\n",
      "\n",
      "any\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-openpipe-status)\n",
      "\n",
      "openpipe.status\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`PENDING`,\n",
      "\n",
      "`TRAINING`,\n",
      "\n",
      "`DEPLOYED`,\n",
      "\n",
      "`ERROR`,\n",
      "\n",
      "`DEPRECATED`,\n",
      "\n",
      "`PENDING_DEPRECATION`,\n",
      "\n",
      "`QUEUED`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-owned-by)\n",
      "\n",
      "owned\\_by\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-pricing)\n",
      "\n",
      "pricing\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-pricing-chat-in)\n",
      "\n",
      "pricing.chatIn\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "$/million tokens\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-pricing-chat-out)\n",
      "\n",
      "pricing.chatOut\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "$/million tokens\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createModel#response-updated)\n",
      "\n",
      "updated\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[Add Entries to Dataset](https://docs.openpipe.ai/api-reference/post-createDatasetEntries) [Get Model](https://docs.openpipe.ai/api-reference/get-getModel)\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/models \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"datasetId\": \"<string>\",\n",
      "  \"slug\": \"<string>\",\n",
      "  \"pruningRuleIds\": [],\n",
      "  \"trainingConfig\": {\n",
      "    \"provider\": \"openpipe\",\n",
      "    \"baseModel\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
      "    \"enable_sft\": true,\n",
      "    \"enable_preference_tuning\": false,\n",
      "    \"sft_hyperparameters\": {},\n",
      "    \"preference_hyperparameters\": {},\n",
      "    \"hyperparameters\": {\n",
      "      \"is_sft_enabled\": true,\n",
      "      \"batch_size\": \"auto\",\n",
      "      \"learning_rate_multiplier\": 123,\n",
      "      \"num_epochs\": 123,\n",
      "      \"is_preference_tuning_enabled\": true,\n",
      "      \"preference_tuning_variant\": \"DPO\",\n",
      "      \"preference_tuning_learning_rate_multiplier\": 123,\n",
      "      \"preference_tuning_num_epochs\": 123,\n",
      "      \"preference_tuning_training_beta\": 123,\n",
      "      \"preference_tuning_adapter_weight\": 123\n",
      "    }\n",
      "  },\n",
      "  \"defaultTemperature\": 123\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"id\": \"<string>\",\n",
      "  \"name\": \"<string>\",\n",
      "  \"object\": \"model\",\n",
      "  \"description\": \"<string>\",\n",
      "  \"created\": \"<string>\",\n",
      "  \"updated\": \"<string>\",\n",
      "  \"openpipe\": {\n",
      "    \"baseModel\": \"<string>\",\n",
      "    \"hyperparameters\": {},\n",
      "    \"status\": \"PENDING\",\n",
      "    \"datasetId\": \"<string>\",\n",
      "    \"errorMessage\": \"<string>\"\n",
      "  },\n",
      "  \"contextWindow\": 123,\n",
      "  \"maxCompletionTokens\": 123,\n",
      "  \"capabilities\": [\\\n",
      "    \"chat\"\\\n",
      "  ],\n",
      "  \"pricing\": {\n",
      "    \"chatIn\": 123,\n",
      "    \"chatOut\": 123\n",
      "  },\n",
      "  \"owned_by\": \"<string>\"\n",
      "}\n",
      "```\n",
      "\n",
      "=== docs_openpipe_ai_features_fine_tuning_api.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Fine Tuning\n",
      "\n",
      "Fine Tuning via API (Beta)\n",
      "\n",
      "We’ve made fine-tuning via API available through unstable routes that are subject to change. For most users,\n",
      "we highly recommend fine-tuning through the Webapp to achieve optimal performance with a smooth experience.\n",
      "However, some users may prefer to fine-tune via API for custom use cases.\n",
      "\n",
      "The following base models are supported for general access:\n",
      "\n",
      "- `OpenPipe/Hermes-2-Theta-Llama-3-8B-32k`\n",
      "- `meta-llama/Meta-Llama-3-8B-Instruct`\n",
      "- `meta-llama/Meta-Llama-3-70B-Instruct`\n",
      "- `OpenPipe/mistral-ft-optimized-1227`\n",
      "- `mistralai/Mixtral-8x7B-Instruct-v0.1`\n",
      "\n",
      "Learn more about fine-tuning via API on the [route page](https://docs.openpipe.ai/api-reference/post-unstablefinetunecreate).\n",
      "Please contact us at [hello@openpipe.ai](mailto:hello@openpipe.ai) if you would like help getting set up.\n",
      "\n",
      "[Webapp](https://docs.openpipe.ai/features/fine-tuning/webapp) [Overview](https://docs.openpipe.ai/features/dpo/overview\n",
      "\n",
      "=== docs_openpipe_ai_features_dpo_overview.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Direct Preference Optimization (DPO)\n",
      "\n",
      "Direct Preference Optimization (DPO)\n",
      "\n",
      "DPO is much harder to get right than supervised fine-tuning, and the results may not always be\n",
      "better. To get the most out of DPO, we recommend familiarizing yourself with your specific use\n",
      "case, your dataset, and the technique itself.\n",
      "\n",
      "Direct Preference Optimization (DPO), introduced in [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/abs/2106.13358), is an algorithm used to fine-tune LLMs based on preference feedback.\n",
      "\n",
      "It focuses on aligning model outputs with specific human preferences or desired behaviors. Unlike traditional supervised fine-tuning, which relies solely on input-output pairs, DPO leverages preference data—information about which of two outputs is preferred in a given context.\n",
      "\n",
      "DPO works by directly optimizing a model to produce preferred outputs over non-preferred ones, without the need for complex reward modeling or reinforcement learning techniques. It uses paired data samples, where each pair consists of a preferred and a non-preferred response to a given prompt. This method allows the model to learn nuanced distinctions that are difficult to capture with explicit labels alone. By directly optimizing for preferences, DPO enables the creation of models that produce more aligned, contextually appropriate, and user-satisfying responses.\n",
      "\n",
      "## [​](https://docs.openpipe.ai/features/dpo/overview\\#gathering-preference-data)  Gathering Preference Data\n",
      "\n",
      "DPO is useful when you have a source of preference data that you can exploit. There are many possible sources of preference data, depending on your use case:\n",
      "\n",
      "1. **Expert Feedback**: you may have a team of experts who can evaluate your model’s outputs and edit them to make them better. You can use the original and edited outputs as rejected and preferred outputs respectively. DPO can be effective with just a few preference pairs.\n",
      "2. **Criteria Feedback**: if you use [OpenPipe criteria](https://docs.openpipe.ai/features/criteria/overview) or another evaluation framework that assigns a score or pass/fail to an output based on how well it meets certain criteria, you can run several generations and use the highest and lowest scoring outputs as preferred and non-preferred outputs respectively.\n",
      "3. **User Choice**: if you have a chatbot-style interface where users can select their preferred response from a list of generated outputs, you can use the selected and rejected outputs as preference data.\n",
      "4. **User Regenerations**: if a user is able to regenerate an action multiple times and then eventually accepts one of the outputs, you can use the first output they rejected as a non-preferred output and the accepted output as a preferred output.\n",
      "5. **User Edits**: if your model creates a draft output and the user is able to edit it and then save, you can use the original draft as a non-preferred output and the edited draft as a preferred output.\n",
      "\n",
      "## [​](https://docs.openpipe.ai/features/dpo/overview\\#example-use-cases)  Example Use Cases\n",
      "\n",
      "Initial tests with DPO on OpenPipe have shown promising results. DPO, when used with [user-defined criteria](https://docs.openpipe.ai/features/criteria/overview), allows you to fine-tune models that more consistently respect even very nuanced preferences.\n",
      "\n",
      "![SFT vs DPO](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/dpo/sft-vs-dpo-for-criteria-chart.png)\n",
      "\n",
      "The following are all real results on customer tasks:\n",
      "\n",
      "- **Word Limit**: for a summarization task with an explicit word limit given in the prompt, DPO was able to cut the number of responses exceeding the limit from 31% to 7%, a **77%** decrease.\n",
      "- **Highlight Format**: for a content formatting task, DPO was able to drop the percentage of times the wrong word or phrase was highlighted from 17.3% to 1.7%, a **90%** decrease.\n",
      "- **Hallucination**: for an information extraction task, DPO was able to drop the fraction of outputs with hallucinated information from 12.7% to 3.0%, a **76%** decrease.\n",
      "- **Result Relevance**: for a classification task determining whether a result was relevant to a query, DPO was able to drop the mis-classification rate from 4.7% to 1.3%, a **72%** decrease.\n",
      "\n",
      "We’re excited to see how you’ll leverage DPO to create even more powerful and tailored models for your specific needs!\n",
      "\n",
      "[API (Beta)](https://docs.openpipe.ai/features/fine-tuning/api) [Quick Start](https://docs.openpipe.ai/features/dpo/quick-start)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Gathering Preference Data](https://docs.openpipe.ai/features/dpo/overview#gathering-preference-data)\n",
      "- [Example Use Cases](https://docs.openpipe.ai/features/dpo/overview#example-use-cases)\n",
      "\n",
      "![SFT vs DPO](https://docs.openpipe.ai/features/dpo/overview\n",
      "\n",
      "=== docs_openpipe_ai_features_caching.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Features\n",
      "\n",
      "Caching\n",
      "\n",
      "When caching is enabled, our service stores the responses generated for each unique request. If an identical request is made in the future, instead of processing the request again, the cached response is instantly returned. This eliminates the need for redundant computations, resulting in faster response times and reduced API usage costs.\n",
      "\n",
      "Caching is currently in a free beta preview.\n",
      "\n",
      "## [​](https://docs.openpipe.ai/features/caching\\#enabling-caching)  Enabling Caching\n",
      "\n",
      "Caching is disabled by default. To enable caching for your requests, you can set the `cache` property of the openpipe object to one of the following values:\n",
      "\n",
      "- `readWrite`: Cache is read from and written to.\n",
      "- `readOnly`: Cache is read from, but not written to.\n",
      "- `writeOnly`: Cache is written to, but not read from.\n",
      "\n",
      "If you are making requests through our proxy, add the `op-cache` header to your requests. For any of these settings, if a cache entry is not found, the request will be processed as normal.\n",
      "\n",
      "- cURL Request\n",
      "- Python\n",
      "- NodeJS\n",
      "\n",
      "Copy\n",
      "\n",
      "```bash\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/chat/completions \\\n",
      "  --header \"Authorization: Bearer YOUR_OPENPIPE_API_KEY\" \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --header 'op-cache: readWrite' \\\n",
      "  --data '{\n",
      "  \"model\": \"openpipe:your-fine-tuned-model-id\",\n",
      "  \"messages\": [\\\n",
      "    {\\\n",
      "      \"role\": \"system\",\\\n",
      "      \"content\": \"count to 5\"\\\n",
      "    }\\\n",
      "  ]\n",
      "}'\n",
      "\n",
      "```\n",
      "\n",
      "[Mixture of Agents](https://docs.openpipe.ai/features/chat-completions/moa) [Updating Metadata Tags](https://docs.openpipe.ai/features/updating-metadata)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Enabling Caching](https://docs.openpipe.ai/features/caching#enabling-caching\n",
      "\n",
      "=== docs_openpipe_ai_getting_started_quick_start.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Getting Started\n",
      "\n",
      "Quick Start\n",
      "\n",
      "## [​](https://docs.openpipe.ai/getting-started/quick-start\\#step-1-create-your-openpipe-account)  Step 1: Create Your OpenPipe Account\n",
      "\n",
      "If you don’t already have one, create an account with OpenPipe at [https://app.openpipe.ai/](https://app.openpipe.ai/). You can sign up with GitHub, so you don’t need to remember an extra password.\n",
      "\n",
      "## [​](https://docs.openpipe.ai/getting-started/quick-start\\#step-2-find-your-project-api-key)  Step 2: Find Your Project API Key\n",
      "\n",
      "In order to capture your calls and fine-tune a model on them, we need an API key to authenticate you and determine which project to store your logs under.\n",
      "\n",
      "When you created your account, a project was automatically configured for you as well. Find its\n",
      "API key at [https://app.openpipe.ai/settings](https://app.openpipe.ai/settings).\n",
      "\n",
      "## [​](https://docs.openpipe.ai/getting-started/quick-start\\#step-3-record-training-data-optional)  Step 3: Record Training Data (Optional)\n",
      "\n",
      "If you don’t have any training data, you can record it by integrating the OpenPipe SDK or using the OpenPipe Proxy. If you already have a dataset, you can skip this step!\n",
      "\n",
      "[**Installing the SDK**](https://docs.openpipe.ai/getting-started/openpipe-sdk) [**Using the OpenPipe Proxy**](https://docs.openpipe.ai/features/request-logs/logging-requests#proxy)\n",
      "\n",
      "## [​](https://docs.openpipe.ai/getting-started/quick-start\\#step-4-prepare-a-dataset)  Step 4: Prepare a Dataset\n",
      "\n",
      "Datasets are the core of OpenPipe. They store your training data, and allow you to fine-tune and evaluate models on it. To learn more about datasets, check out the [Datasets](https://docs.openpipe.ai/features/datasets/overview) page.\n",
      "\n",
      "Datasets can be populated in two ways:\n",
      "\n",
      "1. [Uploading external data](https://docs.openpipe.ai/features/datasets/uploading-data)\n",
      "2. [Importing request logs](https://docs.openpipe.ai/features/datasets/importing-logs)\n",
      "\n",
      "If you already have a dataset, we recommend uploading it as a starting point. Otherwise, make sure you set up request logging in step 3!\n",
      "\n",
      "## [​](https://docs.openpipe.ai/getting-started/quick-start\\#step-5-fine-tune-a-model)  Step 5: Fine Tune a Model\n",
      "\n",
      "Once your dataset has been created and populated, you can fine-tune models on it. Follow the [fine-tuning quickstart](https://docs.openpipe.ai/features/fine-tuning/quick-start) guide to kick off your first fine-tuning run.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/fine-tuning/fine-tune-modal.png)\n",
      "\n",
      "We recommend training several models of varying sizes and configurations to determine the best one for your use case. If you have questions on this step, please reach out to us at [support@openpipe.ai](mailto:support@openpipe.ai)!\n",
      "\n",
      "## [​](https://docs.openpipe.ai/getting-started/quick-start\\#step-6-evaluate-your-model)  Step 6: Evaluate Your Model\n",
      "\n",
      "Once your model (or models) have been fine-tuned, you can evaluate them. To learn more about evaluating models, check out the [Evaluations](https://docs.openpipe.ai/features/evaluations/overview) page.\n",
      "\n",
      "## [​](https://docs.openpipe.ai/getting-started/quick-start\\#step-7-deploy-your-model)  Step 7: Deploy Your Model\n",
      "\n",
      "By default, your model will be automatically hosted on OpenPipe’s cloud infrastructure. Additionally, you can export and deploy any of our open-weight models on your own cloud.\n",
      "\n",
      "Good luck! If you have any questions, don’t hesitate to reach out!\n",
      "\n",
      "[Base Models](https://docs.openpipe.ai/base-models) [Installing the SDK](https://docs.openpipe.ai/getting-started/openpipe-sdk)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Step 1: Create Your OpenPipe Account](https://docs.openpipe.ai/getting-started/quick-start#step-1-create-your-openpipe-account)\n",
      "- [Step 2: Find Your Project API Key](https://docs.openpipe.ai/getting-started/quick-start#step-2-find-your-project-api-key)\n",
      "- [Step 3: Record Training Data (Optional)](https://docs.openpipe.ai/getting-started/quick-start#step-3-record-training-data-optional)\n",
      "- [Step 4: Prepare a Dataset](https://docs.openpipe.ai/getting-started/quick-start#step-4-prepare-a-dataset)\n",
      "- [Step 5: Fine Tune a Model](https://docs.openpipe.ai/getting-started/quick-start#step-5-fine-tune-a-model)\n",
      "- [Step 6: Evaluate Your Model](https://docs.openpipe.ai/getting-started/quick-start#step-6-evaluate-your-model)\n",
      "- [Step 7: Deploy Your Model](https://docs.openpipe.ai/getting-started/quick-start#step-7-deploy-your-model)\n",
      "\n",
      "![](https://docs.openpipe.ai/getting-started/quick-start\n",
      "\n",
      "=== docs_openpipe_ai_api_reference_get_listModels.md ===\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Models\n",
      "\n",
      "List Models\n",
      "\n",
      "GET\n",
      "\n",
      "/\n",
      "\n",
      "models\n",
      "\n",
      "Try it\n",
      "\n",
      "#### Authorizations\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#authorization-authorization)\n",
      "\n",
      "Authorization\n",
      "\n",
      "string\n",
      "\n",
      "header\n",
      "\n",
      "required\n",
      "\n",
      "Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\n",
      "\n",
      "#### Response\n",
      "\n",
      "200 - application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data)\n",
      "\n",
      "data\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-capabilities)\n",
      "\n",
      "data.capabilities\n",
      "\n",
      "enum<string>\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`chat`,\n",
      "\n",
      "`tools`,\n",
      "\n",
      "`json`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-context-window)\n",
      "\n",
      "data.contextWindow\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-created)\n",
      "\n",
      "data.created\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-description)\n",
      "\n",
      "data.description\n",
      "\n",
      "string \\| null\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-id)\n",
      "\n",
      "data.id\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-max-completion-tokens)\n",
      "\n",
      "data.maxCompletionTokens\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-name)\n",
      "\n",
      "data.name\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-object)\n",
      "\n",
      "data.object\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`model`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-openpipe)\n",
      "\n",
      "data.openpipe\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-openpipe-base-model)\n",
      "\n",
      "data.openpipe.baseModel\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-openpipe-dataset-id)\n",
      "\n",
      "data.openpipe.datasetId\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-openpipe-error-message)\n",
      "\n",
      "data.openpipe.errorMessage\n",
      "\n",
      "string \\| null\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-openpipe-hyperparameters)\n",
      "\n",
      "data.openpipe.hyperparameters\n",
      "\n",
      "object \\| null\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-openpipe-hyperparameters-key)\n",
      "\n",
      "data.openpipe.hyperparameters.{key}\n",
      "\n",
      "any\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-openpipe-status)\n",
      "\n",
      "data.openpipe.status\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`PENDING`,\n",
      "\n",
      "`TRAINING`,\n",
      "\n",
      "`DEPLOYED`,\n",
      "\n",
      "`ERROR`,\n",
      "\n",
      "`DEPRECATED`,\n",
      "\n",
      "`PENDING_DEPRECATION`,\n",
      "\n",
      "`QUEUED`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-owned-by)\n",
      "\n",
      "data.owned\\_by\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-pricing)\n",
      "\n",
      "data.pricing\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-pricing-chat-in)\n",
      "\n",
      "data.pricing.chatIn\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "$/million tokens\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-pricing-chat-out)\n",
      "\n",
      "data.pricing.chatOut\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "$/million tokens\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-data-updated)\n",
      "\n",
      "data.updated\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listModels#response-object)\n",
      "\n",
      "object\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`list`\n",
      "\n",
      "[Get Model](https://docs.openpipe.ai/api-reference/get-getModel) [Delete Model](https://docs.openpipe.ai/api-reference/delete-model\n",
      "\n",
      "=== docs_openpipe_ai_features_request_logs_exporting_logs.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Request Logs\n",
      "\n",
      "Exporting Logs\n",
      "\n",
      "## [​](https://docs.openpipe.ai/features/request-logs/exporting-logs\\#request-logs-export)  Request logs export\n",
      "\n",
      "Once your request logs are recorded, you can export them at any time. The exported jsonl contains all the data that we’ve collected from your logged calls, including tags and errors.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/request-logs/exporting-logs.png)\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/request-logs/exporting-logs\\#fields)  Fields\n",
      "\n",
      "- **`Input`:** The complete chat creation request.\n",
      "- **`Output`:** Whatever output was generated, including errors.\n",
      "- **`Tags`:** Any metadata tags that you included when making the request.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/request-logs/exporting-logs\\#example)  Example\n",
      "\n",
      "Copy\n",
      "\n",
      "```jsonl\n",
      "{\"input\":{\"model\":\"openpipe:test-tool-calls-ft\",\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"parameters\":{\"type\":\"object\",\"required\":[\"location\"],\"properties\":{\"unit\":{\"enum\":[\"celsius\",\"fahrenheit\"],\"type\":\"string\"},\"location\":{\"type\":\"string\",\"description\":\"The city and state, e.g. San Francisco, CA\"}}},\"description\":\"Get the current weather in a given location\"}}],\"messages\":[{\"role\":\"system\",\"content\":\"tell me the weather in SF and Orlando\"}]},\"output\":{\"id\":\"c7670af0d71648b0bd829fa1901ac6c5\",\"model\":\"openpipe:test-tool-calls-ft\",\"usage\":{\"total_tokens\":106,\"prompt_tokens\":47,\"completion_tokens\":59},\"object\":\"chat.completion\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"arguments\":\"{\\\"location\\\": \\\"San Francisco, CA\\\", \\\"unit\\\": \\\"celsius\\\"}\"}},{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"get_current_weather\",\"arguments\":\"{\\\"location\\\": \\\"Orlando, FL\\\", \\\"unit\\\": \\\"celsius\\\"}\"}}]},\"finish_reason\":\"stop\"}],\"created\":1702666185703},\"tags\":{\"prompt_id\":\"test_sync_tool_calls_ft\",\"$sdk\":\"python\",\"$sdk.version\":\"4.1.0\"}}\n",
      "{\"input\":{\"model\":\"openpipe:test-content-ft\",\"messages\":[{\"role\":\"system\",\"content\":\"count to 3\"}]},\"output\":{\"id\":\"47116eaa9dad4238bf12e32135f9c147\",\"model\":\"openpipe:test-content-ft\",\"usage\":{\"total_tokens\":38,\"prompt_tokens\":29,\"completion_tokens\":9},\"object\":\"chat.completion\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"1, 2, 3\"},\"finish_reason\":\"stop\"}],\"created\":1702666036923},\"tags\":{\"prompt_id\":\"test_sync_content_ft\",\"$sdk\":\"python\",\"$sdk.version\":\"4.1.0\"}}\n",
      "\n",
      "```\n",
      "\n",
      "If you’d like to see how it works, try exporting some logs from our [public demo](https://app.openpipe.ai/p/BRZFEx50Pf/request-logs).\n",
      "\n",
      "[Logging Anthropic Requests](https://docs.openpipe.ai/features/request-logs/reporting-anthropic) [Overview](https://docs.openpipe.ai/features/datasets/overview)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Request logs export](https://docs.openpipe.ai/features/request-logs/exporting-logs#request-logs-export)\n",
      "- [Fields](https://docs.openpipe.ai/features/request-logs/exporting-logs#fields)\n",
      "- [Example](https://docs.openpipe.ai/features/request-logs/exporting-logs#example)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/request-logs/exporting-logs\n",
      "\n",
      "=== docs_openpipe_ai_pricing_pricing.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Pricing\n",
      "\n",
      "Pricing Overview\n",
      "\n",
      "## [​](https://docs.openpipe.ai/pricing/pricing\\#training)  Training\n",
      "\n",
      "We charge for training based on the size of the model and the number of tokens in the dataset.\n",
      "\n",
      "| Model Category | Cost per 1M tokens |\n",
      "| --- | --- |\n",
      "| **8B and smaller** | $0.48 |\n",
      "| **32B models** | $1.90 |\n",
      "| **70B+ models** | $2.90 |\n",
      "\n",
      "## [​](https://docs.openpipe.ai/pricing/pricing\\#hosted-inference)  Hosted Inference\n",
      "\n",
      "Choose between two billing models for running models on our infrastructure:\n",
      "\n",
      "### [​](https://docs.openpipe.ai/pricing/pricing\\#1-per-token-pricing)  1\\. Per-Token Pricing\n",
      "\n",
      "Available for our most popular, high-volume models. You only pay for the tokens you process, with no minimum commitment and automatic infrastructure scaling.\n",
      "\n",
      "| Model | Input (per 1M tokens) | Output (per 1M tokens) |\n",
      "| --- | --- | --- |\n",
      "| **Llama 3.1 8B Instruct** | $0.30 | $0.45 |\n",
      "| **Llama 3.1 70B Instruct** | $1.80 | $2.00 |\n",
      "\n",
      "### [​](https://docs.openpipe.ai/pricing/pricing\\#2-hourly-compute-units)  2\\. Hourly Compute Units\n",
      "\n",
      "Designed for experimental and lower-volume models. A Compute Unit (CU) can handle up to 24 simultaneous requests per second. Billing is precise down to the second, with automatic scaling when traffic exceeds capacity. Compute units remain active for 60 seconds after traffic spikes.\n",
      "\n",
      "| Model | Rate per CU Hour |\n",
      "| --- | --- |\n",
      "| **Llama 3.1 8B** | $1.50 |\n",
      "| **Mistral Nemo 12B** | $1.50 |\n",
      "| **Qwen 2.5 32B Coder** | $6.00 |\n",
      "| **Qwen 2.5 72B** | $12.00 |\n",
      "| **Llama 3.1 70B** | $12.00 |\n",
      "\n",
      "## [​](https://docs.openpipe.ai/pricing/pricing\\#third-party-models-openai-gemini-etc)  Third-Party Models (OpenAI, Gemini, etc.)\n",
      "\n",
      "Third-party models fine-tuned through OpenPipe like OpenAI’s GPT series or Google’s Gemini, we provide direct API integration without any additional markup. You will be billed directly by the respective provider (OpenAI, Google, etc.) at their standard rates. We simply pass through the API calls and responses.\n",
      "\n",
      "## [​](https://docs.openpipe.ai/pricing/pricing\\#enterprise-plans)  Enterprise Plans\n",
      "\n",
      "For organizations requiring custom solutions, we offer enterprise plans that include:\n",
      "\n",
      "- Volume discounts\n",
      "- On-premises deployment options\n",
      "- Dedicated support\n",
      "- Custom SLAs\n",
      "- Advanced security features\n",
      "\n",
      "Contact our team at [hello@openpipe.ai](mailto:hello@openpipe.ai) to discuss enterprise pricing and requirements.\n",
      "\n",
      "[Judge Criteria](https://docs.openpipe.ai/api-reference/post-criteriajudge)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Training](https://docs.openpipe.ai/pricing/pricing#training)\n",
      "- [Hosted Inference](https://docs.openpipe.ai/pricing/pricing#hosted-inference)\n",
      "- [1\\. Per-Token Pricing](https://docs.openpipe.ai/pricing/pricing#1-per-token-pricing)\n",
      "- [2\\. Hourly Compute Units](https://docs.openpipe.ai/pricing/pricing#2-hourly-compute-units)\n",
      "- [Third-Party Models (OpenAI, Gemini, etc.)](https://docs.openpipe.ai/pricing/pricing#third-party-models-openai-gemini-etc)\n",
      "- [Enterprise Plans](https://docs.openpipe.ai/pricing/pricing#enterprise-plans\n",
      "\n",
      "=== docs_openpipe_ai_features_mixture_of_agents.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Features\n",
      "\n",
      "Mixture of Agents\n",
      "\n",
      "We’re currently beta-testing a novel completion generating technique we’re calling “Mixture of Agents,” which we’ll document more formally soon.\n",
      "\n",
      "The basic idea is that instead of simply asking GPT-4 to generate a completion for your prompt directly, we use a series of GPT-4 prompts to iteratively improve the completion. The steps our “mixture of agents” model takes are as follows:\n",
      "\n",
      "- **Prompt 1** generates 3 candidate completions in parallel by calling the chosen base model with `n=3` and a high temperature to promote output diversity.\n",
      "- **Prompt 2** again calls the base model. It passes in the original input again, along with the 3 candidate completions generated by prompt 1. It then asks the LLM to review the candidate completions and critique them.\n",
      "- **Prompt 3** again passes the original input, the 3 candidate completions, and their critiques. Using this information, the base model generates a final completion that incorporates the best of all 3 candidates.\n",
      "\n",
      "We’ve iterated on this process significantly and found that completions generated in this way tend to be significantly higher quality than those generated by GPT-4 in a single step, and lead to much stronger downstream fine-tuned models as well.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/moa/llm-judge-moa-wr.png)\n",
      "\n",
      "## [​](https://docs.openpipe.ai/features/mixture-of-agents\\#using-moa-in-production)  Using MoA in Production\n",
      "\n",
      "To use MoA models at inference time, make requests to the /chat/completions endpoint with a MoA model. See [instructions](https://docs.openpipe.ai/features/chat-completions/moa).\n",
      "\n",
      "## [​](https://docs.openpipe.ai/features/mixture-of-agents\\#using-the-moa-relabeling-flow)  Using the MoA Relabeling Flow\n",
      "\n",
      "The following instructions explain how to copy an existing dataset and relabel it with the mixture-of-agents flow, which will let you train models on the higher-quality outputs.\n",
      "\n",
      "1. **Export the original dataset**\n",
      "\n",
      "Navigate to your existing OpenPipe dataset and click the “Export” button in the upper right. Keep the “Include split” checkbox checked. You’ll download a .jsonl file with the contents of your dataset (this may take a few minutes).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/moa/export-arrow.png)\n",
      "\n",
      "2. **Re-import the dataset**\n",
      "\n",
      "Create a new dataset in your project. Import the file you exported from step (1). Once the import finishes, your new dataset should contain a copy of the same data as the old one.\n",
      "\n",
      "3. **Open the Data Pipeline view**\n",
      "\n",
      "Navigate to the **Data Pipeline** tab in the new dataset, then expand the Data Pipeline view by hovering over and clicking the data pipeline preview.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/moa/data-lineage-preview.png)\n",
      "\n",
      "4. Select the “LLM Relabel” node for the file you just uploaded. Then in the sidebar, choose one of `moa-gpt-4-v1`, `moa-gpt-4-turbo-v1`, or `moa-gpt-4o-v1`, depending on which model you’d like to use as your MoA base. **Note:** we use your API key for relabelling, so you’ll need to have entered a valid OpenAI API key in your project settings for this to work.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/moa/data-lineage-relabeling.png)\n",
      "\n",
      "5. **Wait for relabeling to finish**\n",
      "\n",
      "Depending on your dataset size relabelling may take quite a while. Behind the scenes we run 4 relabelling jobs in parallel at a time. You’ll know relabeling has finished when the “Processing entries” status disappears at the top right of the dataset view.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/moa/processing-entries.png)\n",
      "\n",
      "6. **Train a model on the new dataset**\n",
      "\n",
      "Train the base model of your choice on the new dataset.\n",
      "\n",
      "7. **(Optional) Evaluate your new model against your old one**\n",
      "\n",
      "If you have an existing head-to-head evaluation on the platform, you can easily add your new model to it to see how it compares. Simply open your existing eval and add your newly-trained model as another model to compare!\n",
      "\n",
      "\n",
      "## [​](https://docs.openpipe.ai/features/mixture-of-agents\\#costs)  Costs\n",
      "\n",
      "We aren’t charging for the MoA relabeling flow while it is in beta. However, you will pay for the actual calls to the OpenAI API. The exact cost varies depending on your input vs output mix but as a rule of thumb our MoA approach uses 3x-4x as many tokens as running the same completion in a non-MoA context.\n",
      "\n",
      "[Fallback](https://docs.openpipe.ai/features/fallback) [External Models](https://docs.openpipe.ai/features/external-models)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Using MoA in Production](https://docs.openpipe.ai/features/mixture-of-agents#using-moa-in-production)\n",
      "- [Using the MoA Relabeling Flow](https://docs.openpipe.ai/features/mixture-of-agents#using-the-moa-relabeling-flow)\n",
      "- [Costs](https://docs.openpipe.ai/features/mixture-of-agents#costs)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/mixture-of-agents)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/mixture-of-agents)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/mixture-of-agents)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/mixture-of-agents)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/mixture-of-agents\n",
      "\n",
      "=== docs_openpipe_ai_features_evaluations_head_to_head.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Evaluations\n",
      "\n",
      "Head-to-Head Evaluations\n",
      "\n",
      "Head-to-head evaluations are useful for evaluating your LLM outputs against one another to\n",
      "determine which models are generally better at a given task. However, they do not provide precise\n",
      "metrics on how often a given model makes a certain error, only how often it outperforms another\n",
      "model. For more precise metrics, please consider [criteria](https://docs.openpipe.ai/features/evaluations/criterion) or\n",
      "[code](https://docs.openpipe.ai/features/evaluations/code) evaluations.\n",
      "\n",
      "Head to head evaluations are a fast way to get a sense of how well your models perform against one another. For each model being evaluated, the output of that model is compared against the output of every other model for every entry in the evaluation dataset.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/h2h-settings.png)\n",
      "\n",
      "The number of comparisons performed in a head to head eval scales linearly with the number of\n",
      "entries and quadratically with the number of models. If you’re evaluating 2 models on 100 entries,\n",
      "there will be 100 \\* 1 = 100 comparisons. If you’re evaluating 3 models on 100 entries, there will\n",
      "be 100 \\* 2 + 100 \\* 1 = 300 comparisons.\n",
      "\n",
      "As outputs are compared against one another, each model is assigned a “win rate” score. For example, if you’re evaluating 2 models on 100 entries and model A outperforms model B 55 times, model A will have a win rate of 55% and model B will have a win rate of 45%. In cases where both models produce the same output or the judge is unable to determine a winner, the score will be a tie (equivalent to 50% win rate).\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/h2h-results-table.png)\n",
      "\n",
      "In addition to the results table, you can also view results in a matrix format. This is useful for visualizing how specific models perform against one another.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/h2h-matrix.png)\n",
      "\n",
      "To see why one model might be outperforming another, you can navigate back to the [evaluation table](https://app.openpipe.ai/p/BRZFEx50Pf/datasets/3e7e82c1-b066-476c-9f17-17fd85a2169b/evaluate) and click on a result pill to see the evaluation judge’s reasoning.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/h2h-judge-explanation.png)\n",
      "\n",
      "While head-to-head evaluations are convenient, they can quickly become expensive to run, and provide limited insight into how well a model performs. For more precise metrics, consider [criterion](https://docs.openpipe.ai/features/evaluations/criterion) or [code](https://docs.openpipe.ai/features/evaluations/code) evaluations.\n",
      "\n",
      "[Criterion Evals](https://docs.openpipe.ai/features/evaluations/criterion) [Overview](https://docs.openpipe.ai/features/criteria/overview)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/head-to-head)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/head-to-head)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/head-to-head)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/head-to-head\n",
      "\n",
      "=== docs_openpipe_ai_api_reference_post_report_anthropic.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Logs\n",
      "\n",
      "Report Anthropic\n",
      "\n",
      "POST\n",
      "\n",
      "/\n",
      "\n",
      "report-anthropic\n",
      "\n",
      "Try it\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/report-anthropic \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"requestedAt\": 123,\n",
      "  \"receivedAt\": 123,\n",
      "  \"reqPayload\": {\n",
      "    \"max_tokens\": 123,\n",
      "    \"messages\": [\\\n",
      "      {\\\n",
      "        \"content\": \"<string>\",\\\n",
      "        \"role\": \"user\"\\\n",
      "      }\\\n",
      "    ],\n",
      "    \"model\": \"<string>\",\n",
      "    \"metadata\": {\n",
      "      \"user_id\": \"<string>\"\n",
      "    },\n",
      "    \"stop_sequences\": [\\\n",
      "      \"<string>\"\\\n",
      "    ],\n",
      "    \"stream\": true,\n",
      "    \"system\": \"<string>\",\n",
      "    \"temperature\": 123,\n",
      "    \"top_k\": 123,\n",
      "    \"top_p\": 123\n",
      "  },\n",
      "  \"respPayload\": {\n",
      "    \"id\": \"<string>\",\n",
      "    \"content\": [\\\n",
      "      {\\\n",
      "        \"text\": \"<string>\",\\\n",
      "        \"type\": \"text\"\\\n",
      "      }\\\n",
      "    ],\n",
      "    \"model\": \"<string>\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": \"<string>\",\n",
      "    \"type\": \"message\",\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 123,\n",
      "      \"output_tokens\": 123\n",
      "    }\n",
      "  },\n",
      "  \"statusCode\": 123,\n",
      "  \"errorMessage\": \"<string>\",\n",
      "  \"metadata\": {},\n",
      "  \"tags\": {}\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"status\": \"ok\"\n",
      "}\n",
      "```\n",
      "\n",
      "#### Authorizations\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#authorization-authorization)\n",
      "\n",
      "Authorization\n",
      "\n",
      "string\n",
      "\n",
      "header\n",
      "\n",
      "required\n",
      "\n",
      "Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\n",
      "\n",
      "#### Body\n",
      "\n",
      "application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-error-message)\n",
      "\n",
      "errorMessage\n",
      "\n",
      "string\n",
      "\n",
      "User-friendly error message\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-metadata)\n",
      "\n",
      "metadata\n",
      "\n",
      "object\n",
      "\n",
      "Extra metadata tags to attach to the call for filtering. Eg { \"userId\": \"123\", \"prompt\\_id\": \"populate-title\" }\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-metadata-key)\n",
      "\n",
      "metadata.{key}\n",
      "\n",
      "string\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-received-at)\n",
      "\n",
      "receivedAt\n",
      "\n",
      "number\n",
      "\n",
      "Unix timestamp in milliseconds\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload)\n",
      "\n",
      "reqPayload\n",
      "\n",
      "object\n",
      "\n",
      "JSON-encoded request payload\n",
      "\n",
      "- Option 1\n",
      "- Option 2\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-max-tokens)\n",
      "\n",
      "reqPayload.max\\_tokens\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-messages)\n",
      "\n",
      "reqPayload.messages\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-messages-content)\n",
      "\n",
      "reqPayload.messages.content\n",
      "\n",
      "stringobject\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-messages-role)\n",
      "\n",
      "reqPayload.messages.role\n",
      "\n",
      "Option 1 · enum<string>Option 2 · enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`user`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-model)\n",
      "\n",
      "reqPayload.model\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-stream)\n",
      "\n",
      "reqPayload.stream\n",
      "\n",
      "boolean\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-metadata)\n",
      "\n",
      "reqPayload.metadata\n",
      "\n",
      "object\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-metadata-user-id)\n",
      "\n",
      "reqPayload.metadata.user\\_id\n",
      "\n",
      "string \\| nullenum<string> \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-stop-sequences)\n",
      "\n",
      "reqPayload.stop\\_sequences\n",
      "\n",
      "string\\[\\]\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-system)\n",
      "\n",
      "reqPayload.system\n",
      "\n",
      "string\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-temperature)\n",
      "\n",
      "reqPayload.temperature\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-top-k)\n",
      "\n",
      "reqPayload.top\\_k\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-req-payload-top-p)\n",
      "\n",
      "reqPayload.top\\_p\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-requested-at)\n",
      "\n",
      "requestedAt\n",
      "\n",
      "number\n",
      "\n",
      "Unix timestamp in milliseconds\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload)\n",
      "\n",
      "respPayload\n",
      "\n",
      "object\n",
      "\n",
      "JSON-encoded response payload\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-content)\n",
      "\n",
      "respPayload.content\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "- Option 1\n",
      "- Option 2\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-content-text)\n",
      "\n",
      "respPayload.content.text\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-content-type)\n",
      "\n",
      "respPayload.content.type\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`text`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-id)\n",
      "\n",
      "respPayload.id\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-model)\n",
      "\n",
      "respPayload.model\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-role)\n",
      "\n",
      "respPayload.role\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`assistant`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-stop-reason)\n",
      "\n",
      "respPayload.stop\\_reason\n",
      "\n",
      "Option 1 · enum<string> \\| nullOption 2 · enum<string> \\| nullOption 3 · enum<string> \\| nullOption 4 · enum<string> \\| nullOption 5 · enum<string> \\| null\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`end_turn`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-stop-sequence)\n",
      "\n",
      "respPayload.stop\\_sequence\n",
      "\n",
      "string \\| nullenum<string> \\| null\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-type)\n",
      "\n",
      "respPayload.type\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`message`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-usage)\n",
      "\n",
      "respPayload.usage\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-usage-input-tokens)\n",
      "\n",
      "respPayload.usage.input\\_tokens\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-resp-payload-usage-output-tokens)\n",
      "\n",
      "respPayload.usage.output\\_tokens\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-status-code)\n",
      "\n",
      "statusCode\n",
      "\n",
      "number\n",
      "\n",
      "HTTP status code of response\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-tags)\n",
      "\n",
      "tags\n",
      "\n",
      "object\n",
      "\n",
      "Deprecated: use \"metadata\" instead\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#body-tags-key)\n",
      "\n",
      "tags.{key}\n",
      "\n",
      "string \\| nullnumber \\| nullboolean \\| nullenum<string> \\| null\n",
      "\n",
      "#### Response\n",
      "\n",
      "200 - application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report-anthropic#response-status)\n",
      "\n",
      "status\n",
      "\n",
      "Option 1 · enum<string>Option 2 · enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`ok`\n",
      "\n",
      "[Report](https://docs.openpipe.ai/api-reference/post-report) [Update Metadata](https://docs.openpipe.ai/api-reference/post-updatemetadata)\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/report-anthropic \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"requestedAt\": 123,\n",
      "  \"receivedAt\": 123,\n",
      "  \"reqPayload\": {\n",
      "    \"max_tokens\": 123,\n",
      "    \"messages\": [\\\n",
      "      {\\\n",
      "        \"content\": \"<string>\",\\\n",
      "        \"role\": \"user\"\\\n",
      "      }\\\n",
      "    ],\n",
      "    \"model\": \"<string>\",\n",
      "    \"metadata\": {\n",
      "      \"user_id\": \"<string>\"\n",
      "    },\n",
      "    \"stop_sequences\": [\\\n",
      "      \"<string>\"\\\n",
      "    ],\n",
      "    \"stream\": true,\n",
      "    \"system\": \"<string>\",\n",
      "    \"temperature\": 123,\n",
      "    \"top_k\": 123,\n",
      "    \"top_p\": 123\n",
      "  },\n",
      "  \"respPayload\": {\n",
      "    \"id\": \"<string>\",\n",
      "    \"content\": [\\\n",
      "      {\\\n",
      "        \"text\": \"<string>\",\\\n",
      "        \"type\": \"text\"\\\n",
      "      }\\\n",
      "    ],\n",
      "    \"model\": \"<string>\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"stop_reason\": \"end_turn\",\n",
      "    \"stop_sequence\": \"<string>\",\n",
      "    \"type\": \"message\",\n",
      "    \"usage\": {\n",
      "      \"input_tokens\": 123,\n",
      "      \"output_tokens\": 123\n",
      "    }\n",
      "  },\n",
      "  \"statusCode\": 123,\n",
      "  \"errorMessage\": \"<string>\",\n",
      "  \"metadata\": {},\n",
      "  \"tags\": {}\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"status\": \"ok\"\n",
      "}\n",
      "```\n",
      "\n",
      "=== docs_openpipe_ai_getting_started_openpipe_sdk.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Getting Started\n",
      "\n",
      "Installing the SDK\n",
      "\n",
      "Use the OpenPipe SDK as a drop-in replacement for the generic OpenAI package. Calls sent through the OpenPipe SDK will be recorded by default for later training. You’ll use this same SDK to call your own fine-tuned models once they’re deployed.\n",
      "\n",
      "- Python\n",
      "- NodeJS (ESM)\n",
      "- NodeJS (CJS)\n",
      "\n",
      "Find the SDK at [https://pypi.org/project/openpipe/](https://pypi.org/project/openpipe/)\n",
      "\n",
      "## Installation\n",
      "\n",
      "Copy\n",
      "\n",
      "```bash\n",
      "pip install openpipe\n",
      "\n",
      "```\n",
      "\n",
      "## Simple Integration\n",
      "\n",
      "Add `OPENPIPE_API_KEY` to your environment variables.\n",
      "\n",
      "Copy\n",
      "\n",
      "```bash\n",
      "export OPENPIPE_API_KEY=opk-<your-api-key>\n",
      "# Or you can set it in your code, see \"Complete Example\" below\n",
      "\n",
      "```\n",
      "\n",
      "Replace this line\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "from openai import OpenAI\n",
      "\n",
      "```\n",
      "\n",
      "with this one\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "from openpipe import OpenAI\n",
      "\n",
      "```\n",
      "\n",
      "## Adding Searchable Metadata Tags\n",
      "\n",
      "OpenPipe follows OpenAI’s concept of metadata tagging for requests. You can use metadata tags in the [Request Logs](https://docs.openpipe.ai/features/request-logs) view to narrow down the data your model will train on.\n",
      "We recommend assigning a unique metadata tag to each of your prompts.\n",
      "These tags will help you find all the input/output pairs associated with a certain prompt and fine-tune a model to replace it.\n",
      "\n",
      "Here’s how you can use the tagging feature:\n",
      "\n",
      "## Complete Example\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "from openpipe import OpenAI\n",
      "import os\n",
      "\n",
      "client = OpenAI(\n",
      "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
      "    api_key=\"My API Key\",\n",
      "    openpipe={\n",
      "        # defaults to os.environ.get(\"OPENPIPE_API_KEY\")\n",
      "        \"api_key\": \"My OpenPipe API Key\",\n",
      "        # optional, defaults to process.env[\"OPENPIPE_BASE_URL\"] or https://api.openpipe.ai/api/v1 if not set\n",
      "        \"base_url\": \"My URL\",\n",
      "    }\n",
      ")\n",
      "\n",
      "completion = client.chat.completions.create(\n",
      "    model=\"gpt-4o\",\n",
      "    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\n",
      "    metadata={\"prompt_id\": \"counting\", \"any_key\": \"any_value\"},\n",
      ")\n",
      "\n",
      "```\n",
      "\n",
      "## [​](https://docs.openpipe.ai/getting-started/openpipe-sdk\\#should-i-wait-to-enable-logging)  Should I Wait to Enable Logging?\n",
      "\n",
      "We recommend keeping request logging turned on from the beginning. If you change your prompt you can just set a new `prompt_id` metadata tag so you can select just the latest version when you’re ready to create a dataset.\n",
      "\n",
      "[Quick Start](https://docs.openpipe.ai/getting-started/quick-start) [Logging Requests](https://docs.openpipe.ai/features/request-logs/logging-requests)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Should I Wait to Enable Logging?](https://docs.openpipe.ai/getting-started/openpipe-sdk#should-i-wait-to-enable-logging\n",
      "\n",
      "=== docs_openpipe_ai_api_reference_get_getModel.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Models\n",
      "\n",
      "Get Model\n",
      "\n",
      "GET\n",
      "\n",
      "/\n",
      "\n",
      "models\n",
      "\n",
      "/\n",
      "\n",
      "{modelSlug}\n",
      "\n",
      "Try it\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request GET \\\n",
      "  --url https://api.openpipe.ai/api/v1/models/{modelSlug} \\\n",
      "  --header 'Authorization: Bearer <token>'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"id\": \"<string>\",\n",
      "  \"name\": \"<string>\",\n",
      "  \"object\": \"model\",\n",
      "  \"description\": \"<string>\",\n",
      "  \"created\": \"<string>\",\n",
      "  \"updated\": \"<string>\",\n",
      "  \"openpipe\": {\n",
      "    \"baseModel\": \"<string>\",\n",
      "    \"hyperparameters\": {},\n",
      "    \"status\": \"PENDING\",\n",
      "    \"datasetId\": \"<string>\",\n",
      "    \"errorMessage\": \"<string>\"\n",
      "  },\n",
      "  \"contextWindow\": 123,\n",
      "  \"maxCompletionTokens\": 123,\n",
      "  \"capabilities\": [\\\n",
      "    \"chat\"\\\n",
      "  ],\n",
      "  \"pricing\": {\n",
      "    \"chatIn\": 123,\n",
      "    \"chatOut\": 123\n",
      "  },\n",
      "  \"owned_by\": \"<string>\"\n",
      "}\n",
      "```\n",
      "\n",
      "#### Authorizations\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#authorization-authorization)\n",
      "\n",
      "Authorization\n",
      "\n",
      "string\n",
      "\n",
      "header\n",
      "\n",
      "required\n",
      "\n",
      "Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\n",
      "\n",
      "#### Path Parameters\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#parameter-model-slug)\n",
      "\n",
      "modelSlug\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "#### Response\n",
      "\n",
      "200 - application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-capabilities)\n",
      "\n",
      "capabilities\n",
      "\n",
      "enum<string>\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`chat`,\n",
      "\n",
      "`tools`,\n",
      "\n",
      "`json`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-context-window)\n",
      "\n",
      "contextWindow\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-created)\n",
      "\n",
      "created\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-description)\n",
      "\n",
      "description\n",
      "\n",
      "string \\| null\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-id)\n",
      "\n",
      "id\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-max-completion-tokens)\n",
      "\n",
      "maxCompletionTokens\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-name)\n",
      "\n",
      "name\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-object)\n",
      "\n",
      "object\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`model`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-openpipe)\n",
      "\n",
      "openpipe\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-openpipe-base-model)\n",
      "\n",
      "openpipe.baseModel\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-openpipe-dataset-id)\n",
      "\n",
      "openpipe.datasetId\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-openpipe-error-message)\n",
      "\n",
      "openpipe.errorMessage\n",
      "\n",
      "string \\| null\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-openpipe-hyperparameters)\n",
      "\n",
      "openpipe.hyperparameters\n",
      "\n",
      "object \\| null\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-openpipe-hyperparameters-key)\n",
      "\n",
      "openpipe.hyperparameters.{key}\n",
      "\n",
      "any\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-openpipe-status)\n",
      "\n",
      "openpipe.status\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`PENDING`,\n",
      "\n",
      "`TRAINING`,\n",
      "\n",
      "`DEPLOYED`,\n",
      "\n",
      "`ERROR`,\n",
      "\n",
      "`DEPRECATED`,\n",
      "\n",
      "`PENDING_DEPRECATION`,\n",
      "\n",
      "`QUEUED`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-owned-by)\n",
      "\n",
      "owned\\_by\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-pricing)\n",
      "\n",
      "pricing\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-pricing-chat-in)\n",
      "\n",
      "pricing.chatIn\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "$/million tokens\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-pricing-chat-out)\n",
      "\n",
      "pricing.chatOut\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "$/million tokens\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-getModel#response-updated)\n",
      "\n",
      "updated\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[Create Model](https://docs.openpipe.ai/api-reference/post-createModel) [List Models](https://docs.openpipe.ai/api-reference/get-listModels)\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request GET \\\n",
      "  --url https://api.openpipe.ai/api/v1/models/{modelSlug} \\\n",
      "  --header 'Authorization: Bearer <token>'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"id\": \"<string>\",\n",
      "  \"name\": \"<string>\",\n",
      "  \"object\": \"model\",\n",
      "  \"description\": \"<string>\",\n",
      "  \"created\": \"<string>\",\n",
      "  \"updated\": \"<string>\",\n",
      "  \"openpipe\": {\n",
      "    \"baseModel\": \"<string>\",\n",
      "    \"hyperparameters\": {},\n",
      "    \"status\": \"PENDING\",\n",
      "    \"datasetId\": \"<string>\",\n",
      "    \"errorMessage\": \"<string>\"\n",
      "  },\n",
      "  \"contextWindow\": 123,\n",
      "  \"maxCompletionTokens\": 123,\n",
      "  \"capabilities\": [\\\n",
      "    \"chat\"\\\n",
      "  ],\n",
      "  \"pricing\": {\n",
      "    \"chatIn\": 123,\n",
      "    \"chatOut\": 123\n",
      "  },\n",
      "  \"owned_by\": \"<string>\"\n",
      "}\n",
      "```\n",
      "\n",
      "=== docs_openpipe_ai_features_evaluations_code.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Evaluations\n",
      "\n",
      "Code Evaluations\n",
      "\n",
      "Code evaluations are not a good match for all tasks. They work well for deterministic tasks like\n",
      "classification or information extraction, but not for tasks that produce freeform outputs like\n",
      "chatbots or summarization. To evaluate tasks with freeform outputs, please consider [criterion\\\\\n",
      "evaluations](https://docs.openpipe.ai/features/evaluations/criterion).\n",
      "\n",
      "The code evaluation framework provides greater flexibility than built-in head-to-head and criterion evaluations, allowing you to grade your LLM outputs on whatever metrics you define.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/new-code-eval-modal.png)\n",
      "\n",
      "Each code eval consists of a templated `grader` function that you can customize. Here’s the basic structure:\n",
      "\n",
      "Copy\n",
      "\n",
      "```typescript\n",
      "function grader({\n",
      "  messages,\n",
      "  tools,\n",
      "  toolChoice,\n",
      "  generatedOutput,\n",
      "  datasetOutput,\n",
      "}: GraderArgs): number {\n",
      "  let score = 0.0;\n",
      "\n",
      "  // begin implementation\n",
      "\n",
      "  score = 1.0;\n",
      "\n",
      "  // end implementation\n",
      "\n",
      "  return score;\n",
      "}\n",
      "\n",
      "...\n",
      "\n",
      "```\n",
      "\n",
      "As you can see, the `grader` function takes in a number of arguments and returns a score between 0 and 1, where 1 means the generated output is perfect. The available arguments are:\n",
      "\n",
      "- `messages`: The messages sent to the LLM.\n",
      "- `tools`: The tools available to the LLM.\n",
      "- `toolChoice`: The tool choice specified for the LLM.\n",
      "- `generatedOutput`: The output generated by the LLM which is being evaluated.\n",
      "- `datasetOutput`: The original dataset output associated with the row being evaluated.\n",
      "\n",
      "The grader you define can use any of the above arguments, but most often you’ll want to use `generatedOutput` and `datasetOutput` to compare the output of the LLM to the dataset output.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/editable-lines.png)\n",
      "\n",
      "To get a better idea of what kinds of checks can be performed through a code evaluation, you can check out the **Exact Match** or **Argument Comparison** templates below.\n",
      "\n",
      "Exact Match\n",
      "\n",
      "The **Exact Match** template checks if the generated output matches the dataset output exactly, meaning that the content and tool calls must match exactly.\n",
      "\n",
      "Copy\n",
      "\n",
      "```typescript\n",
      "function grader({\n",
      "  messages,\n",
      "  tools,\n",
      "  toolChoice,\n",
      "  generatedOutput,\n",
      "  datasetOutput,\n",
      "}: GraderArgs): number {\n",
      "  let score = 0.0;\n",
      "\n",
      "  // begin implementation\n",
      "\n",
      "  if (!exactToolCallsMatch(generatedOutput.tool_calls, datasetOutput.tool_calls)) {\n",
      "    return 0.0;\n",
      "  }\n",
      "\n",
      "  if (generatedOutput.content !== datasetOutput.content) {\n",
      "    return 0.0;\n",
      "  }\n",
      "\n",
      "  // generated output matches dataset output\n",
      "  score = 1.0;\n",
      "\n",
      "  // end implementation\n",
      "\n",
      "  return score;\n",
      "}\n",
      "\n",
      "interface GraderArgs {\n",
      "  messages: ChatCompletionMessageParam;\n",
      "  tools: ChatCompletionTool[] | null;\n",
      "  toolChoice: \"none\" | \"auto\" | ChatCompletionNamedToolChoice | null;\n",
      "  generatedOutput: ChatCompletionMessage;\n",
      "  datasetOutput: ChatCompletionMessage;\n",
      "}\n",
      "\n",
      "interface ChatCompletionMessageToolCallFunction {\n",
      "  name: string;\n",
      "  arguments: string;\n",
      "}\n",
      "\n",
      "interface ChatCompletionMessageToolCall {\n",
      "  function: ChatCompletionMessageToolCallFunction;\n",
      "}\n",
      "\n",
      "interface ChatCompletionMessage {\n",
      "  content: string | null;\n",
      "  refusal: string | null;\n",
      "  tool_calls: ChatCompletionMessageToolCall[] | null;\n",
      "}\n",
      "\n",
      "type ChatCompletionMessageParam = ChatCompletionMessage;\n",
      "\n",
      "interface ChatCompletionTool {\n",
      "  function: FunctionDefinition;\n",
      "  type: \"function\";\n",
      "}\n",
      "\n",
      "interface FunctionDefinition {\n",
      "  name: string;\n",
      "  description?: string;\n",
      "  parameters?: Record<string, unknown>;\n",
      "}\n",
      "\n",
      "export interface ChatCompletionNamedToolChoice {\n",
      "  function: Function;\n",
      "  type: \"function\";\n",
      "}\n",
      "\n",
      "interface Function {\n",
      "  name: string;\n",
      "}\n",
      "\n",
      "function exactToolCallsMatch(\n",
      "  toolCalls1: ChatCompletionMessageToolCall[] | null,\n",
      "  toolCalls2: ChatCompletionMessageToolCall[] | null,\n",
      "): boolean {\n",
      "  // If either list is null, they can only match if both are null\n",
      "  if (!toolCalls1 && !toolCalls2) {\n",
      "    return true;\n",
      "  }\n",
      "  if (!toolCalls1 || !toolCalls2) {\n",
      "    return false;\n",
      "  }\n",
      "\n",
      "  // Check if lengths match\n",
      "  if (toolCalls1.length !== toolCalls2.length) {\n",
      "    return false;\n",
      "  }\n",
      "\n",
      "  // Compare each tool call\n",
      "  for (let i = 0; i < toolCalls1.length; i++) {\n",
      "    const call1 = toolCalls1[i];\n",
      "    const call2 = toolCalls2[i];\n",
      "\n",
      "    // Compare all fields that must match exactly\n",
      "    if (\n",
      "      call1?.function.name !== call2?.function.name ||\n",
      "      call1?.function.arguments !== call2?.function.arguments\n",
      "    ) {\n",
      "      return false;\n",
      "    }\n",
      "  }\n",
      "\n",
      "  // If we made it through all comparisons, the calls match exactly\n",
      "  return true;\n",
      "}\n",
      "\n",
      "```\n",
      "\n",
      "Argument Comparison\n",
      "\n",
      "The **Argument Comparison** template provides an example of how you can check whether a specific argument in the tool call generated by the LLM matches the dataset output.\n",
      "\n",
      "Copy\n",
      "\n",
      "```typescript\n",
      "function grader({\n",
      "  messages,\n",
      "  tools,\n",
      "  toolChoice,\n",
      "  generatedOutput,\n",
      "  datasetOutput,\n",
      "}: GraderArgs): number {\n",
      "  let score = 0.0;\n",
      "\n",
      "  // begin implementation\n",
      "\n",
      "  const generatedToolCallArgsStr = generatedOutput.tool_calls?.[0]?.function.arguments;\n",
      "  const datasetToolCallArgsStr = datasetOutput.tool_calls?.[0]?.function.arguments;\n",
      "\n",
      "  if (!generatedToolCallArgsStr || !datasetToolCallArgsStr) {\n",
      "    return 0.0;\n",
      "  }\n",
      "\n",
      "  type JudgementArgs = {\n",
      "    explanation: string;\n",
      "    score: number;\n",
      "  };\n",
      "\n",
      "  const generatedToolCallArgs = JSON.parse(generatedToolCallArgsStr) as JudgementArgs;\n",
      "  const datasetToolCallArgs = JSON.parse(datasetToolCallArgsStr) as JudgementArgs;\n",
      "\n",
      "  if (generatedToolCallArgs.score !== datasetToolCallArgs.score) {\n",
      "    return 0.0;\n",
      "  }\n",
      "\n",
      "  score = 1.0;\n",
      "\n",
      "  // end implementation\n",
      "\n",
      "  return score;\n",
      "}\n",
      "\n",
      "interface GraderArgs {\n",
      "  messages: ChatCompletionMessageParam;\n",
      "  tools: ChatCompletionTool[] | null;\n",
      "  toolChoice: \"none\" | \"auto\" | ChatCompletionNamedToolChoice | null;\n",
      "  generatedOutput: ChatCompletionMessage;\n",
      "  datasetOutput: ChatCompletionMessage;\n",
      "}\n",
      "\n",
      "interface ChatCompletionMessageToolCallFunction {\n",
      "  name: string;\n",
      "  arguments: string;\n",
      "}\n",
      "\n",
      "interface ChatCompletionMessageToolCall {\n",
      "  function: ChatCompletionMessageToolCallFunction;\n",
      "}\n",
      "\n",
      "interface ChatCompletionMessage {\n",
      "  content: string | null;\n",
      "  refusal: string | null;\n",
      "  tool_calls: ChatCompletionMessageToolCall[] | null;\n",
      "}\n",
      "\n",
      "type ChatCompletionMessageParam = ChatCompletionMessage;\n",
      "\n",
      "interface ChatCompletionTool {\n",
      "  function: FunctionDefinition;\n",
      "  type: \"function\";\n",
      "}\n",
      "\n",
      "interface FunctionDefinition {\n",
      "  name: string;\n",
      "  description?: string;\n",
      "  parameters?: Record<string, unknown>;\n",
      "}\n",
      "\n",
      "export interface ChatCompletionNamedToolChoice {\n",
      "  function: Function;\n",
      "  type: \"function\";\n",
      "}\n",
      "\n",
      "interface Function {\n",
      "  name: string;\n",
      "}\n",
      "\n",
      "function exactToolCallsMatch(\n",
      "  toolCalls1: ChatCompletionMessageToolCall[] | null,\n",
      "  toolCalls2: ChatCompletionMessageToolCall[] | null,\n",
      "): boolean {\n",
      "  // If either list is null, they can only match if both are null\n",
      "  if (!toolCalls1 && !toolCalls2) {\n",
      "    return true;\n",
      "  }\n",
      "  if (!toolCalls1 || !toolCalls2) {\n",
      "    return false;\n",
      "  }\n",
      "\n",
      "  // Check if lengths match\n",
      "  if (toolCalls1.length !== toolCalls2.length) {\n",
      "    return false;\n",
      "  }\n",
      "\n",
      "  // Compare each tool call\n",
      "  for (let i = 0; i < toolCalls1.length; i++) {\n",
      "    const call1 = toolCalls1[i];\n",
      "    const call2 = toolCalls2[i];\n",
      "\n",
      "    // Compare all fields that must match exactly\n",
      "    if (\n",
      "      call1?.function.name !== call2?.function.name ||\n",
      "      call1?.function.arguments !== call2?.function.arguments\n",
      "    ) {\n",
      "      return false;\n",
      "    }\n",
      "  }\n",
      "\n",
      "  // If we made it through all comparisons, the calls match exactly\n",
      "  return true;\n",
      "}\n",
      "\n",
      "```\n",
      "\n",
      "In most cases, you’ll want to start from one of the templates and customize the grader function to run the checks you care about. You can also use the **Custom** template to start from scratch.\n",
      "\n",
      "Currently, the code evaluation framework only supports TypeScript code executed in a sandbox\n",
      "environment without access to the internet, external npm packages, or a file system. If you’re\n",
      "interested in writing evals in other languages or need more advanced features, please let us know\n",
      "at [support@openpipe.ai](mailto:support@openpipe.ai).\n",
      "\n",
      "[Quick Start](https://docs.openpipe.ai/features/evaluations/quick-start) [Criterion Evals](https://docs.openpipe.ai/features/evaluations/criterion)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/code)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/code\n",
      "\n",
      "=== docs_openpipe_ai_features_chat_completions_external_models.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Chat Completions\n",
      "\n",
      "Proxying to External Models\n",
      "\n",
      "Adding custom external models is not required to proxy requests to Anthropic, Gemini, or OpenAI\n",
      "models. See our docs on proxying to [Anthropic](https://docs.openpipe.ai/features/chat-completions/anthropic),\n",
      "[Gemini](https://docs.openpipe.ai/features/chat-completions/gemini), or\n",
      "[OpenAI](https://docs.openpipe.ai/features/request-logs/logging-requests#proxy) for more information.\n",
      "\n",
      "To proxy requests to models from unsupported providers, you’ll need to complete the following steps:\n",
      "\n",
      "1. Add an external model provider\n",
      "2. Update your chat completion requests\n",
      "\n",
      "To add an external model provider to your project, follow the instructions in [External Models](https://docs.openpipe.ai/features/external-models). Once it’s been added, continue to the next step.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/chat-completions/external-models\\#updating-your-chat-completion-requests)  Updating your chat completion requests\n",
      "\n",
      "Set the model parameter in your requests to match this format: `openpipe:<external-model-provider-slug>/<external-model-slug>`.\n",
      "\n",
      "For example, if you’re calling **gpt-4o-2024-08-06** on Azure, the model parameter should be `openpipe:custom-azure-provider/gpt-4o-2024-08-06`.\n",
      "\n",
      "- Python\n",
      "- NodeJS\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "from openpipe import OpenAI\n",
      "\n",
      "# Find the config values in \"Installing the SDK\"\n",
      "client = OpenAI()\n",
      "\n",
      "completion = client.chat.completions.create(\n",
      "    model=\"openpipe:custom-azure-provider/gpt-4o-2024-08-06\",\n",
      "    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\n",
      "    metadata={\"prompt_id\": \"counting\", \"any_key\": \"any_value\"},\n",
      ")\n",
      "\n",
      "```\n",
      "\n",
      "External models can also be used for filtering and relabeling your data. We currently support custom external\n",
      "models for providers with openai and azure-compatible endpoints. If you’d like support for an external provider with a different API format, send a request to [hello@openpipe.ai](mailto:hello@openpipe.ai).\n",
      "\n",
      "[Overview](https://docs.openpipe.ai/features/chat-completions/overview) [Anthropic Proxy](https://docs.openpipe.ai/features/chat-completions/anthropic)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Updating your chat completion requests](https://docs.openpipe.ai/features/chat-completions/external-models#updating-your-chat-completion-requests\n",
      "\n",
      "=== docs_openpipe_ai_api_reference_post_createDatasetEntries.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Datasets\n",
      "\n",
      "Add Entries to Dataset\n",
      "\n",
      "POST\n",
      "\n",
      "/\n",
      "\n",
      "datasets\n",
      "\n",
      "/\n",
      "\n",
      "{datasetId}\n",
      "\n",
      "/\n",
      "\n",
      "entries\n",
      "\n",
      "Try it\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/datasets/{datasetId}/entries \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"entries\": [\\\n",
      "    {\\\n",
      "      \"messages\": [\\\n",
      "        {\\\n",
      "          \"role\": \"system\",\\\n",
      "          \"content\": \"<string>\",\\\n",
      "          \"name\": \"<string>\"\\\n",
      "        }\\\n",
      "      ],\\\n",
      "      \"rejected_message\": {\\\n",
      "        \"reasoning_content\": \"<string>\",\\\n",
      "        \"content\": null,\\\n",
      "        \"refusal\": \"<string>\",\\\n",
      "        \"role\": \"assistant\",\\\n",
      "        \"function_call\": {\\\n",
      "          \"name\": \"\",\\\n",
      "          \"arguments\": \"\"\\\n",
      "        },\\\n",
      "        \"tool_calls\": [\\\n",
      "          {\\\n",
      "            \"id\": \"<string>\",\\\n",
      "            \"function\": {\\\n",
      "              \"name\": \"<string>\",\\\n",
      "              \"arguments\": \"<string>\"\\\n",
      "            },\\\n",
      "            \"type\": \"function\"\\\n",
      "          }\\\n",
      "        ]\\\n",
      "      },\\\n",
      "      \"tool_choice\": \"none\",\\\n",
      "      \"tools\": [\\\n",
      "        {\\\n",
      "          \"function\": {\\\n",
      "            \"name\": \"<string>\",\\\n",
      "            \"parameters\": {},\\\n",
      "            \"description\": \"<string>\",\\\n",
      "            \"strict\": true\\\n",
      "          },\\\n",
      "          \"type\": \"function\"\\\n",
      "        }\\\n",
      "      ],\\\n",
      "      \"response_format\": {\\\n",
      "        \"type\": \"text\"\\\n",
      "      },\\\n",
      "      \"split\": \"TRAIN\",\\\n",
      "      \"metadata\": {}\\\n",
      "    }\\\n",
      "  ]\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"object\": \"dataset.entries.creation\",\n",
      "  \"entries_created\": 123,\n",
      "  \"errors\": {\n",
      "    \"object\": \"list\",\n",
      "    \"data\": [\\\n",
      "      {\\\n",
      "        \"object\": \"dataset.entries.creation.error\",\\\n",
      "        \"entry_index\": 123,\\\n",
      "        \"message\": \"<string>\"\\\n",
      "      }\\\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "#### Authorizations\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#authorization-authorization)\n",
      "\n",
      "Authorization\n",
      "\n",
      "string\n",
      "\n",
      "header\n",
      "\n",
      "required\n",
      "\n",
      "Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\n",
      "\n",
      "#### Path Parameters\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#parameter-dataset-id)\n",
      "\n",
      "datasetId\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "#### Body\n",
      "\n",
      "application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries)\n",
      "\n",
      "entries\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-messages)\n",
      "\n",
      "entries.messages\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "- Option 1\n",
      "- Option 2\n",
      "- Option 3\n",
      "- Option 4\n",
      "- Option 5\n",
      "- Option 6\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-messages-role)\n",
      "\n",
      "entries.messages.role\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`system`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-messages-content)\n",
      "\n",
      "entries.messages.content\n",
      "\n",
      "stringobject\\[\\]\n",
      "\n",
      "default:\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-messages-name)\n",
      "\n",
      "entries.messages.name\n",
      "\n",
      "string\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-metadata)\n",
      "\n",
      "entries.metadata\n",
      "\n",
      "object\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-metadata-key)\n",
      "\n",
      "entries.metadata.{key}\n",
      "\n",
      "string\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message)\n",
      "\n",
      "entries.rejected\\_message\n",
      "\n",
      "object\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-role)\n",
      "\n",
      "entries.rejected\\_message.role\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`assistant`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-content)\n",
      "\n",
      "entries.rejected\\_message.content\n",
      "\n",
      "string \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-function-call)\n",
      "\n",
      "entries.rejected\\_message.function\\_call\n",
      "\n",
      "object \\| null\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-function-call-arguments)\n",
      "\n",
      "entries.rejected\\_message.function\\_call.arguments\n",
      "\n",
      "string\n",
      "\n",
      "default:\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-function-call-name)\n",
      "\n",
      "entries.rejected\\_message.function\\_call.name\n",
      "\n",
      "string\n",
      "\n",
      "default:\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-reasoning-content)\n",
      "\n",
      "entries.rejected\\_message.reasoning\\_content\n",
      "\n",
      "string \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-refusal)\n",
      "\n",
      "entries.rejected\\_message.refusal\n",
      "\n",
      "string \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-tool-calls)\n",
      "\n",
      "entries.rejected\\_message.tool\\_calls\n",
      "\n",
      "object\\[\\] \\| null\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-tool-calls-function)\n",
      "\n",
      "entries.rejected\\_message.tool\\_calls.function\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-tool-calls-function-arguments)\n",
      "\n",
      "entries.rejected\\_message.tool\\_calls.function.arguments\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-tool-calls-function-name)\n",
      "\n",
      "entries.rejected\\_message.tool\\_calls.function.name\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-tool-calls-id)\n",
      "\n",
      "entries.rejected\\_message.tool\\_calls.id\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-rejected-message-tool-calls-type)\n",
      "\n",
      "entries.rejected\\_message.tool\\_calls.type\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`function`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-response-format)\n",
      "\n",
      "entries.response\\_format\n",
      "\n",
      "object\n",
      "\n",
      "- Option 1\n",
      "- Option 2\n",
      "- Option 3\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-response-format-type)\n",
      "\n",
      "entries.response\\_format.type\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`text`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-split)\n",
      "\n",
      "entries.split\n",
      "\n",
      "enum<string>\n",
      "\n",
      "Available options:\n",
      "\n",
      "`TRAIN`,\n",
      "\n",
      "`TEST`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tool-choice)\n",
      "\n",
      "entries.tool\\_choice\n",
      "\n",
      "Option 1 · enum<string>Option 2 · enum<string>Option 3 · enum<string>Option 4 · object\n",
      "\n",
      "Available options:\n",
      "\n",
      "`none`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools)\n",
      "\n",
      "entries.tools\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools-function)\n",
      "\n",
      "entries.tools.function\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools-function-name)\n",
      "\n",
      "entries.tools.function.name\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools-function-description)\n",
      "\n",
      "entries.tools.function.description\n",
      "\n",
      "string\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools-function-parameters)\n",
      "\n",
      "entries.tools.function.parameters\n",
      "\n",
      "object\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools-function-parameters-key)\n",
      "\n",
      "entries.tools.function.parameters.{key}\n",
      "\n",
      "any\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools-function-strict)\n",
      "\n",
      "entries.tools.function.strict\n",
      "\n",
      "boolean \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#body-entries-tools-type)\n",
      "\n",
      "entries.tools.type\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`function`\n",
      "\n",
      "#### Response\n",
      "\n",
      "200 - application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-entries-created)\n",
      "\n",
      "entries\\_created\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-errors)\n",
      "\n",
      "errors\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-errors-data)\n",
      "\n",
      "errors.data\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-errors-data-entry-index)\n",
      "\n",
      "errors.data.entry\\_index\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-errors-data-message)\n",
      "\n",
      "errors.data.message\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-errors-data-object)\n",
      "\n",
      "errors.data.object\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`dataset.entries.creation.error`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-errors-object)\n",
      "\n",
      "errors.object\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`list`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDatasetEntries#response-object)\n",
      "\n",
      "object\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`dataset.entries.creation`\n",
      "\n",
      "[Delete Dataset](https://docs.openpipe.ai/api-reference/delete-dataset) [Create Model](https://docs.openpipe.ai/api-reference/post-createModel)\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/datasets/{datasetId}/entries \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"entries\": [\\\n",
      "    {\\\n",
      "      \"messages\": [\\\n",
      "        {\\\n",
      "          \"role\": \"system\",\\\n",
      "          \"content\": \"<string>\",\\\n",
      "          \"name\": \"<string>\"\\\n",
      "        }\\\n",
      "      ],\\\n",
      "      \"rejected_message\": {\\\n",
      "        \"reasoning_content\": \"<string>\",\\\n",
      "        \"content\": null,\\\n",
      "        \"refusal\": \"<string>\",\\\n",
      "        \"role\": \"assistant\",\\\n",
      "        \"function_call\": {\\\n",
      "          \"name\": \"\",\\\n",
      "          \"arguments\": \"\"\\\n",
      "        },\\\n",
      "        \"tool_calls\": [\\\n",
      "          {\\\n",
      "            \"id\": \"<string>\",\\\n",
      "            \"function\": {\\\n",
      "              \"name\": \"<string>\",\\\n",
      "              \"arguments\": \"<string>\"\\\n",
      "            },\\\n",
      "            \"type\": \"function\"\\\n",
      "          }\\\n",
      "        ]\\\n",
      "      },\\\n",
      "      \"tool_choice\": \"none\",\\\n",
      "      \"tools\": [\\\n",
      "        {\\\n",
      "          \"function\": {\\\n",
      "            \"name\": \"<string>\",\\\n",
      "            \"parameters\": {},\\\n",
      "            \"description\": \"<string>\",\\\n",
      "            \"strict\": true\\\n",
      "          },\\\n",
      "          \"type\": \"function\"\\\n",
      "        }\\\n",
      "      ],\\\n",
      "      \"response_format\": {\\\n",
      "        \"type\": \"text\"\\\n",
      "      },\\\n",
      "      \"split\": \"TRAIN\",\\\n",
      "      \"metadata\": {}\\\n",
      "    }\\\n",
      "  ]\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"object\": \"dataset.entries.creation\",\n",
      "  \"entries_created\": 123,\n",
      "  \"errors\": {\n",
      "    \"object\": \"list\",\n",
      "    \"data\": [\\\n",
      "      {\\\n",
      "        \"object\": \"dataset.entries.creation.error\",\\\n",
      "        \"entry_index\": 123,\\\n",
      "        \"message\": \"<string>\"\\\n",
      "      }\\\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "=== docs_openpipe_ai_features_pruning_rules.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Features\n",
      "\n",
      "Pruning Rules\n",
      "\n",
      "Some prompts have large chunks of unchanging text, like system messages which don’t change from one request to the next. By removing this static text and fine-tuning a model on the compacted data, we can reduce the size of incoming requests and save you money on inference.\n",
      "\n",
      "Add pruning rules to your dataset in the Settings tab, as shown below and in our [demo dataset](https://app.openpipe.ai/p/BRZFEx50Pf/datasets/0aa75f72-3fe5-4294-a94e-94c9236befa6/settings).\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/pruning-rules/dataset-pruning-rule.png)\n",
      "\n",
      "To see the effect your pruning rules had on an individual training entry’s input messages, open the Dataset Entry drawer:\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/pruning-rules/drawer-rule.png)\n",
      "\n",
      "By default, fine-tuned models inherit pruning rules applied to the dataset on which they were trained (see [demo model](https://app.openpipe.ai/p/BRZFEx50Pf/fine-tunes/5a2af605-03d3-412c-a7d3-611bdf6e1dcf/general)). These rules will automatically prune matching text from any incoming requests sent to that model. New pruning rules will not be associated with previously trained models, so you don’t need to worry about backwards compatibility when adding new rules to your dataset. Before training a new model, you can choose to disable any inherited pruning rules.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/pruning-rules/model-rules.png)\n",
      "\n",
      "## [​](https://docs.openpipe.ai/features/pruning-rules\\#warning-can-affect-quality)  Warning: can affect quality!\n",
      "\n",
      "We’ve found that while pruning rules always decrease latency and costs, they can also negatively affect response quality, especially with smaller datasets. We recommend enabling pruning rules on datasets with 10K+ training examples, as smaller datasets may not provide enough guidance for the model to fully learn the task.\n",
      "\n",
      "[Updating Metadata Tags](https://docs.openpipe.ai/features/updating-metadata) [Fallback](https://docs.openpipe.ai/features/fallback)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Warning: can affect quality!](https://docs.openpipe.ai/features/pruning-rules#warning-can-affect-quality)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/pruning-rules)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/pruning-rules)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/pruning-rules\n",
      "\n",
      "=== docs_openpipe_ai_features_evaluations_overview.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Evaluations\n",
      "\n",
      "Evaluations\n",
      "\n",
      "After training a model, you’ll want to know how well it performs. Datasets include a built-in evaluation framework that makes it easy to compare newly trained models against previous models and generic base models as well.\n",
      "\n",
      "By default, 10% of the dataset entries you provide will be withheld from training. These entries form your test set. For each entry in the test set, your new model will produce an output that will be shown in the [evaluation table](https://app.openpipe.ai/p/BRZFEx50Pf/datasets/3e7e82c1-b066-476c-9f17-17fd85a2169b/evaluate).\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/evals-table.png)\n",
      "\n",
      "Viewing outputs side by side is useful, but it doesn’t tell you which model is doing better in general. For that, we need to define evaluations. Evaluations\n",
      "allow you to compare model outputs across a variety of inputs to determine which model is doing a better\n",
      "job. While each type of evaluation has its own unique UI, they all show final results in a sorted table.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/evaluations/eval-results-table.png)\n",
      "\n",
      "Datasets support three types of evaluations:\n",
      "\n",
      "- [Code evaluations](https://docs.openpipe.ai/features/evaluations/code)\n",
      "- [Criterion evaluations](https://docs.openpipe.ai/features/evaluations/criterion)\n",
      "- [Head-to-head evaluations](https://docs.openpipe.ai/features/evaluations/head-to-head)\n",
      "\n",
      "As a rough guide, use code evaluations for deterministic tasks like classification or information extraction. Use criterion evaluations for tasks with freeform outputs like chatbots or summarization. Use head-to-head evaluations for comparing two or more models against each other if you’re looking for a quick and dirty way to compare model outputs.\n",
      "\n",
      "[Quick Start](https://docs.openpipe.ai/features/dpo/quick-start) [Quick Start](https://docs.openpipe.ai/features/evaluations/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/overview)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/evaluations/overview\n",
      "\n",
      "=== docs_openpipe_ai_features_datasets_uploading_data.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Datasets\n",
      "\n",
      "Uploading Data\n",
      "\n",
      "Upload a JSONL file populated with a list of training examples.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/uploading-data.png)\n",
      "\n",
      "Each line of the file should be compatible with the OpenAI [chat format](https://platform.openai.com/docs/api-reference/chat/object), with additional optional fields.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/datasets/uploading-data\\#openai-fields)  OpenAI Fields\n",
      "\n",
      "- **`messages`: Required** \\- Formatted as a list of OpenAI [chat completion messages](https://platform.openai.com/docs/guides/gpt/chat-completions-api). The list should end with an assistant message.\n",
      "- **`tools`: Optional** \\- An array of tools (functions) available for the model to call. For more information read OpenAI’s [function calling docs](https://platform.openai.com/docs/guides/function-calling).\n",
      "- **`tool_choice`: Optional** \\- You can set this to indicate that the model should be required to call the given tool. For more information read OpenAI’s [function calling docs](https://platform.openai.com/docs/guides/function-calling).\n",
      "\n",
      "#### [​](https://docs.openpipe.ai/features/datasets/uploading-data\\#deprecated)  Deprecated\n",
      "\n",
      "- **`functions`: Deprecated \\| Optional** \\- An array of functions available for the model to call.\n",
      "- **`function_call`: Deprecated \\| Optional** \\- You can set this to indicate that the model should be required to call the given function.\n",
      "\n",
      "You can include other parameters from the OpenAI chat completion input format (eg. temperature), but they will be ignored since they aren’t relevant for training.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/datasets/uploading-data\\#additional-fields)  Additional Fields\n",
      "\n",
      "- **`split`: Optional** \\- One of “TRAIN” or “TEST”. If you don’t set this field we’ll automatically divide your inputs into train and test splits with a target ratio of 90:10.\n",
      "- **`rejected_message`: Optional** \\- Add a rejected output for entries on which you want to perform direct preference optimization (DPO). You can find more information about that here: [Direct Preference Optimization](https://docs.openpipe.ai/features/dpo/Overview)\n",
      "- **`metadata`: Optional** \\- A string=>string dictionary of any additional information you want to associate with an entry. This can be useful for tracking information like prompt IDs.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/datasets/uploading-data\\#example)  Example\n",
      "\n",
      "Copy\n",
      "\n",
      "```jsonl\n",
      "...\n",
      "{\"messages\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":\"What is the capital of Tasmania?\"},{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"arguments\":\"{\\\"capital\\\":\\\"Hobart\\\"}\"}}]}],\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"parameters\":{\"type\":\"object\",\"properties\":{\"capital\":{\"type\":\"string\"}}}}}], \"split\": \"TRAIN\", \"metadata\": {\"prompt_id\": \"counting\", \"any_key\": \"any_value\"}}\n",
      "{\"messages\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":\"What is the capital of Sweden?\"},{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"arguments\":\"{\\\"capital\\\":\\\"Stockholm\\\"}\"}}]}],\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"parameters\":{\"type\":\"object\",\"properties\":{\"capital\":{\"type\":\"string\"}}}}}], \"split\": \"TEST\", \"metadata\": {\"prompt_id\": \"counting\", \"any_key\": \"any_value\"}}\n",
      "...\n",
      "\n",
      "```\n",
      "\n",
      "[Importing Request Logs](https://docs.openpipe.ai/features/datasets/importing-logs) [Relabeling Data](https://docs.openpipe.ai/features/datasets/relabeling-data)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [OpenAI Fields](https://docs.openpipe.ai/features/datasets/uploading-data#openai-fields)\n",
      "- [Deprecated](https://docs.openpipe.ai/features/datasets/uploading-data#deprecated)\n",
      "- [Additional Fields](https://docs.openpipe.ai/features/datasets/uploading-data#additional-fields)\n",
      "- [Example](https://docs.openpipe.ai/features/datasets/uploading-data#example)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/datasets/uploading-data\n",
      "\n",
      "=== docs_openpipe_ai_features_request_logs_logging_requests.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Request Logs\n",
      "\n",
      "Logging Requests\n",
      "\n",
      "Request logs are a great way to get to know your data. More importantly, you can import recorded logs directly into your training datasets. That means it’s really easy to train on data you’ve collected in production.\n",
      "\n",
      "We recommend collecting request logs for both base and fine-tuned models. We provide several options for recording your requests.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/request-logs/logging-requests\\#sdk)  SDK\n",
      "\n",
      "The simplest way to start ingesting request logs into OpenPipe is by installing our Python or TypeScript SDK. Requests to both OpenAI and OpenPipe models will automatically be recorded.\n",
      "Logging doesn’t add any latency to your requests, because our SDK calls the OpenAI server directly and returns your completion before kicking off the request to record it in your project.\n",
      "\n",
      "We provide a drop-in replacement for the OpenAI SDK, so the only code you need to update is your import statement:\n",
      "\n",
      "- Python\n",
      "- NodeJS\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "# from openai import OpenAI\n",
      "from openpipe import OpenAI\n",
      "\n",
      "# Nothing else changes\n",
      "\n",
      "client = OpenAI()\n",
      "\n",
      "completion = client.chat.completions.create(\n",
      "    model=\"gpt-4o\",\n",
      "    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\n",
      "    # searchable metadata tags are highly recommended\n",
      "    metadata={\"prompt_id\": \"counting\", \"any_key\": \"any_value\"},\n",
      ")\n",
      "\n",
      "```\n",
      "\n",
      "See [Installing the SDK](https://docs.openpipe.ai/getting-started/openpipe-sdk) for a quick guide on how to get started.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/request-logs/logging-requests\\#proxy)  Proxy\n",
      "\n",
      "If you’re developing in a language other than Python or TypeScript, the best way to ingest data into OpenPipe is through our proxy. We provide a `/chat/completions` endpoint that is fully compatible\n",
      "with OpenAI, so you can continue using the latest features like tool calls and streaming without a hitch.\n",
      "\n",
      "Integrating the Proxy and logging requests requires a couple steps.\n",
      "\n",
      "1. Add an OpenAI key to your project in the [project settings](https://app.openpipe.ai/settings) page.\n",
      "2. Set the authorization token of your request to be your OpenPipe API key.\n",
      "3. Set the destination url of your request to be `https://api.openpipe.ai/api/v1/chat/completions`.\n",
      "4. When making any request that you’d like to record, include the `\"store\": true` parameter in the request body. We also recommend that you add custom metadata tags to your request to\n",
      "distinguish data collected from different prompts.\n",
      "\n",
      "Here’s an example of steps 2-4 put together in both a raw cURL request and with the Python SDK:\n",
      "\n",
      "- cURL Request\n",
      "- Python SDK\n",
      "- TypeScript SDK\n",
      "\n",
      "Copy\n",
      "\n",
      "```bash\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/chat/completions \\\n",
      "  --header \"Authorization: Bearer YOUR_OPENPIPE_API_KEY\" \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"model\": \"gpt-4-0613\",\n",
      "  \"messages\": [\\\n",
      "    {\\\n",
      "      \"role\": \"system\",\\\n",
      "      \"content\": \"count to 5\"\\\n",
      "    }\\\n",
      "  ],\n",
      "  \"max_tokens\": 100,\n",
      "  \"temperature\": 0,\n",
      "  \"store\": true,\n",
      "  \"metadata\": {\n",
      "    \"prompt_id\": \"first_prompt\"\n",
      "  }\n",
      "}'\n",
      "\n",
      "```\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/request-logs/logging-requests\\#reporting)  Reporting\n",
      "\n",
      "If you need more flexibility in how you log requests, you can use the `report` endpoint. This gives you full control over when and how to create request logs.\n",
      "\n",
      "- Python\n",
      "- NodeJS\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "import time\n",
      "from openai import OpenAI\n",
      "from openpipe.client import OpenPipe\n",
      "\n",
      "client = OpenAI()\n",
      "op_client = OpenPipe()\n",
      "\n",
      "payload = {\n",
      "    \"model\": \"gpt-4o\",\n",
      "    \"messages\": [{\"role\": \"user\", \"content\": \"Count to 10\"}],\n",
      "}\n",
      "\n",
      "completion = client.chat.completions.create(**payload)\n",
      "\n",
      "op_client.report(\n",
      "    requested_at=int(time.time() * 1000),\n",
      "    received_at=int(time.time() * 1000),\n",
      "    req_payload=payload,\n",
      "    resp_payload=completion,\n",
      "    status_code=200,\n",
      "    metadata={\"prompt_id\": \"My prompt id\"},\n",
      ")\n",
      "\n",
      "```\n",
      "\n",
      "If you’re developing in a language other than Python or TypeScript, you can also make a raw HTTP request to the [report](https://docs.openpipe.ai/api-reference/post-report) endpoint.\n",
      "\n",
      "Once you’ve set up logging, you will see the data on the Request Logs page. From there, you’ll be able to search through your requests and train your models. See [Training on Logs](https://docs.openpipe.ai/features/datasets/importing-logs) to learn more.\n",
      "\n",
      "[Installing the SDK](https://docs.openpipe.ai/getting-started/openpipe-sdk) [Logging Anthropic Requests](https://docs.openpipe.ai/features/request-logs/reporting-anthropic)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [SDK](https://docs.openpipe.ai/features/request-logs/logging-requests#sdk)\n",
      "- [Proxy](https://docs.openpipe.ai/features/request-logs/logging-requests#proxy)\n",
      "- [Reporting](https://docs.openpipe.ai/features/request-logs/logging-requests#reporting\n",
      "\n",
      "=== docs_openpipe_ai_features_external_models.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Features\n",
      "\n",
      "External Models\n",
      "\n",
      "Before defining a custom external model provider, check your project settings to see if the\n",
      "provider you’re looking for is already supported.\n",
      "\n",
      "To use a custom external model from a cloud provider that OpenPipe doesn’t support, you can add an external model provider to your project. External models can be used for the following purposes:\n",
      "\n",
      "- [Proxying chat completions](https://docs.openpipe.ai/features/chat-completions/external-models)\n",
      "- [Filtering and relabeling your data](https://docs.openpipe.ai/features/evaluations/head-to-head)\n",
      "- [Evaluating outputs through criteria](https://docs.openpipe.ai/features/criteria/quick-start)\n",
      "\n",
      "The instructions below demonstrate how to add a DeepSeek (OpenAI Compatible) and Azure provider to your project.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/external-models\\#creating-an-external-model-provider)  Creating an external model provider\n",
      "\n",
      "Find the **External Model Providers** section of your project settings, and click the **Add Provider** button.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/external-models/add-provider-button.png)\n",
      "\n",
      "Give your custom provider a slug, API key, and add a custom base url if necessary. The provider slug should be unique,\n",
      "and will be used when we proxy requests to models associated with this provider.\n",
      "\n",
      "- DeepSeek (OpenAI Compatible)\n",
      "- Azure Endpoint\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/external-models/add-provider-modal-deepseek.png)\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/external-models\\#adding-a-model-to-the-external-provider)  Adding a model to the external provider\n",
      "\n",
      "To add a model to the provider you’re creating, click the **Add Model** button.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/external-models/add-model-button.png)\n",
      "\n",
      "Provide a slug that matches the model you’d like to call on your external provider. To call **gpt-4o-2024-08-06** on Azure for instance, the slug should be `gpt-4o-2024-08-06`.\n",
      "\n",
      "- DeepSeek (OpenAI Compatible)\n",
      "- Azure Endpoint\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/external-models/add-model-row-deepseek.png)\n",
      "\n",
      "Setting input cost and output cost is optional, but can be helpful for showing relative costs in the [evals](https://docs.openpipe.ai/features/evaluations) page.\n",
      "\n",
      "We currently support custom external\n",
      "models for providers with openai and azure-compatible endpoints. If you’d like support for an external provider with a different API format, send a request to [hello@openpipe.ai](mailto:hello@openpipe.ai).\n",
      "\n",
      "[Mixture of Agents](https://docs.openpipe.ai/features/mixture-of-agents) [Report](https://docs.openpipe.ai/api-reference/post-report)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Creating an external model provider](https://docs.openpipe.ai/features/external-models#creating-an-external-model-provider)\n",
      "- [Adding a model to the external provider](https://docs.openpipe.ai/features/external-models#adding-a-model-to-the-external-provider)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/external-models)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/external-models)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/external-models)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/external-models\n",
      "\n",
      "=== docs_openpipe_ai_api_reference_post_chatcompletions.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Chat Completions\n",
      "\n",
      "Chat Completions\n",
      "\n",
      "POST\n",
      "\n",
      "/\n",
      "\n",
      "chat\n",
      "\n",
      "/\n",
      "\n",
      "completions\n",
      "\n",
      "Try it\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/chat/completions \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"messages\": [\\\n",
      "    {\\\n",
      "      \"role\": \"system\",\\\n",
      "      \"content\": \"<string>\",\\\n",
      "      \"name\": \"<string>\"\\\n",
      "    }\\\n",
      "  ],\n",
      "  \"model\": \"<string>\",\n",
      "  \"audio\": {\n",
      "    \"format\": \"wav\",\n",
      "    \"voice\": \"alloy\"\n",
      "  },\n",
      "  \"function_call\": \"none\",\n",
      "  \"functions\": [\\\n",
      "    {\\\n",
      "      \"name\": \"<string>\",\\\n",
      "      \"parameters\": {},\\\n",
      "      \"description\": \"<string>\",\\\n",
      "      \"strict\": true\\\n",
      "    }\\\n",
      "  ],\n",
      "  \"tool_choice\": \"none\",\n",
      "  \"tools\": [\\\n",
      "    {\\\n",
      "      \"function\": {\\\n",
      "        \"name\": \"<string>\",\\\n",
      "        \"parameters\": {},\\\n",
      "        \"description\": \"<string>\",\\\n",
      "        \"strict\": true\\\n",
      "      },\\\n",
      "      \"type\": \"function\"\\\n",
      "    }\\\n",
      "  ],\n",
      "  \"n\": 123,\n",
      "  \"max_tokens\": 123,\n",
      "  \"max_completion_tokens\": 123,\n",
      "  \"temperature\": 123,\n",
      "  \"top_p\": 123,\n",
      "  \"presence_penalty\": 123,\n",
      "  \"frequency_penalty\": 123,\n",
      "  \"stop\": \"<string>\",\n",
      "  \"response_format\": {\n",
      "    \"type\": \"text\"\n",
      "  },\n",
      "  \"logprobs\": true,\n",
      "  \"top_logprobs\": 123,\n",
      "  \"stream_options\": {\n",
      "    \"include_usage\": true\n",
      "  },\n",
      "  \"store\": true,\n",
      "  \"metadata\": {},\n",
      "  \"stream\": false\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"id\": \"<string>\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 123,\n",
      "  \"model\": \"<string>\",\n",
      "  \"choices\": [\\\n",
      "    {\\\n",
      "      \"finish_reason\": \"length\",\\\n",
      "      \"index\": 123,\\\n",
      "      \"message\": {\\\n",
      "        \"reasoning_content\": \"<string>\",\\\n",
      "        \"content\": null,\\\n",
      "        \"refusal\": \"<string>\",\\\n",
      "        \"role\": \"assistant\",\\\n",
      "        \"function_call\": {\\\n",
      "          \"name\": \"\",\\\n",
      "          \"arguments\": \"\"\\\n",
      "        },\\\n",
      "        \"tool_calls\": [\\\n",
      "          {\\\n",
      "            \"id\": \"<string>\",\\\n",
      "            \"function\": {\\\n",
      "              \"name\": \"<string>\",\\\n",
      "              \"arguments\": \"<string>\"\\\n",
      "            },\\\n",
      "            \"type\": \"function\"\\\n",
      "          }\\\n",
      "        ]\\\n",
      "      },\\\n",
      "      \"logprobs\": null,\\\n",
      "      \"content_filter_results\": {},\\\n",
      "      \"criteria_results\": {}\\\n",
      "    }\\\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 123,\n",
      "    \"completion_tokens\": 123,\n",
      "    \"total_tokens\": 123,\n",
      "    \"prompt_cache_hit_tokens\": 123,\n",
      "    \"prompt_cache_miss_tokens\": 123,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"reasoning_tokens\": 123,\n",
      "      \"audio_tokens\": 123,\n",
      "      \"text_tokens\": 123,\n",
      "      \"accepted_prediction_tokens\": 123,\n",
      "      \"rejected_prediction_tokens\": 123\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"cached_tokens\": 123,\n",
      "      \"audio_tokens\": 123\n",
      "    },\n",
      "    \"criteria\": {}\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "#### Authorizations\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#authorization-authorization)\n",
      "\n",
      "Authorization\n",
      "\n",
      "string\n",
      "\n",
      "header\n",
      "\n",
      "required\n",
      "\n",
      "Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\n",
      "\n",
      "#### Body\n",
      "\n",
      "application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-messages)\n",
      "\n",
      "messages\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "- Option 1\n",
      "- Option 2\n",
      "- Option 3\n",
      "- Option 4\n",
      "- Option 5\n",
      "- Option 6\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-messages-role)\n",
      "\n",
      "messages.role\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`system`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-messages-content)\n",
      "\n",
      "messages.content\n",
      "\n",
      "stringobject\\[\\]\n",
      "\n",
      "default:\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-messages-name)\n",
      "\n",
      "messages.name\n",
      "\n",
      "string\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-model)\n",
      "\n",
      "model\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-audio)\n",
      "\n",
      "audio\n",
      "\n",
      "object \\| null\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-audio-format)\n",
      "\n",
      "audio.format\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`wav`,\n",
      "\n",
      "`mp3`,\n",
      "\n",
      "`flac`,\n",
      "\n",
      "`opus`,\n",
      "\n",
      "`pcm16`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-audio-voice)\n",
      "\n",
      "audio.voice\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`alloy`,\n",
      "\n",
      "`ash`,\n",
      "\n",
      "`ballad`,\n",
      "\n",
      "`coral`,\n",
      "\n",
      "`echo`,\n",
      "\n",
      "`sage`,\n",
      "\n",
      "`shimmer`,\n",
      "\n",
      "`verse`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-frequency-penalty)\n",
      "\n",
      "frequency\\_penalty\n",
      "\n",
      "number \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-function-call)\n",
      "\n",
      "function\\_call\n",
      "\n",
      "Option 1 · enum<string>Option 2 · enum<string>Option 3 · object\n",
      "\n",
      "Available options:\n",
      "\n",
      "`none`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-functions)\n",
      "\n",
      "functions\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-functions-name)\n",
      "\n",
      "functions.name\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-functions-description)\n",
      "\n",
      "functions.description\n",
      "\n",
      "string\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-functions-parameters)\n",
      "\n",
      "functions.parameters\n",
      "\n",
      "object\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-functions-parameters-key)\n",
      "\n",
      "functions.parameters.{key}\n",
      "\n",
      "any\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-functions-strict)\n",
      "\n",
      "functions.strict\n",
      "\n",
      "boolean \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-logprobs)\n",
      "\n",
      "logprobs\n",
      "\n",
      "boolean\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-max-completion-tokens)\n",
      "\n",
      "max\\_completion\\_tokens\n",
      "\n",
      "number \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-max-tokens)\n",
      "\n",
      "max\\_tokens\n",
      "\n",
      "number \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-metadata)\n",
      "\n",
      "metadata\n",
      "\n",
      "object \\| null\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-metadata-key)\n",
      "\n",
      "metadata.{key}\n",
      "\n",
      "string\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-n)\n",
      "\n",
      "n\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-presence-penalty)\n",
      "\n",
      "presence\\_penalty\n",
      "\n",
      "number \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-response-format)\n",
      "\n",
      "response\\_format\n",
      "\n",
      "object\n",
      "\n",
      "- Option 1\n",
      "- Option 2\n",
      "- Option 3\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-response-format-type)\n",
      "\n",
      "response\\_format.type\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`text`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-stop)\n",
      "\n",
      "stop\n",
      "\n",
      "stringstring\\[\\]\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-store)\n",
      "\n",
      "store\n",
      "\n",
      "boolean\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-stream)\n",
      "\n",
      "stream\n",
      "\n",
      "boolean\n",
      "\n",
      "default:\n",
      "\n",
      "false\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-stream-options)\n",
      "\n",
      "stream\\_options\n",
      "\n",
      "object\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-stream-options-include-usage)\n",
      "\n",
      "stream\\_options.include\\_usage\n",
      "\n",
      "boolean\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-temperature)\n",
      "\n",
      "temperature\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tool-choice)\n",
      "\n",
      "tool\\_choice\n",
      "\n",
      "Option 1 · enum<string>Option 2 · enum<string>Option 3 · enum<string>Option 4 · object\n",
      "\n",
      "Available options:\n",
      "\n",
      "`none`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools)\n",
      "\n",
      "tools\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools-function)\n",
      "\n",
      "tools.function\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools-function-name)\n",
      "\n",
      "tools.function.name\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools-function-description)\n",
      "\n",
      "tools.function.description\n",
      "\n",
      "string\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools-function-parameters)\n",
      "\n",
      "tools.function.parameters\n",
      "\n",
      "object\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools-function-parameters-key)\n",
      "\n",
      "tools.function.parameters.{key}\n",
      "\n",
      "any\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools-function-strict)\n",
      "\n",
      "tools.function.strict\n",
      "\n",
      "boolean \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-tools-type)\n",
      "\n",
      "tools.type\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`function`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-top-logprobs)\n",
      "\n",
      "top\\_logprobs\n",
      "\n",
      "number \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#body-top-p)\n",
      "\n",
      "top\\_p\n",
      "\n",
      "number \\| null\n",
      "\n",
      "#### Response\n",
      "\n",
      "200 - application/json\n",
      "\n",
      "- Option 1\n",
      "- Option 2\n",
      "- Option 3\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices)\n",
      "\n",
      "choices\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-finish-reason)\n",
      "\n",
      "choices.finish\\_reason\n",
      "\n",
      "Option 1 · enum<string>Option 2 · enum<string>Option 3 · enum<string>Option 4 · enum<string>Option 5 · enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`length`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-index)\n",
      "\n",
      "choices.index\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message)\n",
      "\n",
      "choices.message\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-role)\n",
      "\n",
      "choices.message.role\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`assistant`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-content)\n",
      "\n",
      "choices.message.content\n",
      "\n",
      "string \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-function-call)\n",
      "\n",
      "choices.message.function\\_call\n",
      "\n",
      "object \\| null\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-function-call-arguments)\n",
      "\n",
      "choices.message.function\\_call.arguments\n",
      "\n",
      "string\n",
      "\n",
      "default:\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-function-call-name)\n",
      "\n",
      "choices.message.function\\_call.name\n",
      "\n",
      "string\n",
      "\n",
      "default:\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-reasoning-content)\n",
      "\n",
      "choices.message.reasoning\\_content\n",
      "\n",
      "string \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-refusal)\n",
      "\n",
      "choices.message.refusal\n",
      "\n",
      "string \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-tool-calls)\n",
      "\n",
      "choices.message.tool\\_calls\n",
      "\n",
      "object\\[\\] \\| null\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-tool-calls-function)\n",
      "\n",
      "choices.message.tool\\_calls.function\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-tool-calls-function-arguments)\n",
      "\n",
      "choices.message.tool\\_calls.function.arguments\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-tool-calls-function-name)\n",
      "\n",
      "choices.message.tool\\_calls.function.name\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-tool-calls-id)\n",
      "\n",
      "choices.message.tool\\_calls.id\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-message-tool-calls-type)\n",
      "\n",
      "choices.message.tool\\_calls.type\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`function`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-content-filter-results)\n",
      "\n",
      "choices.content\\_filter\\_results\n",
      "\n",
      "object\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-criteria-results)\n",
      "\n",
      "choices.criteria\\_results\n",
      "\n",
      "object\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-criteria-results-key)\n",
      "\n",
      "choices.criteria\\_results.{key}\n",
      "\n",
      "object\n",
      "\n",
      "- Option 1\n",
      "- Option 2\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-criteria-results-key-score)\n",
      "\n",
      "choices.criteria\\_results.{key}.score\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-criteria-results-key-status)\n",
      "\n",
      "choices.criteria\\_results.{key}.status\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`success`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-criteria-results-key-error-code)\n",
      "\n",
      "choices.criteria\\_results.{key}.errorCode\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-criteria-results-key-error-message)\n",
      "\n",
      "choices.criteria\\_results.{key}.errorMessage\n",
      "\n",
      "string\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-criteria-results-key-explanation)\n",
      "\n",
      "choices.criteria\\_results.{key}.explanation\n",
      "\n",
      "string\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs)\n",
      "\n",
      "choices.logprobs\n",
      "\n",
      "object \\| null\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content)\n",
      "\n",
      "choices.logprobs.content\n",
      "\n",
      "object\\[\\] \\| null\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content-bytes)\n",
      "\n",
      "choices.logprobs.content.bytes\n",
      "\n",
      "number\\[\\] \\| null\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content-logprob)\n",
      "\n",
      "choices.logprobs.content.logprob\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content-token)\n",
      "\n",
      "choices.logprobs.content.token\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content-top-logprobs)\n",
      "\n",
      "choices.logprobs.content.top\\_logprobs\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content-top-logprobs-bytes)\n",
      "\n",
      "choices.logprobs.content.top\\_logprobs.bytes\n",
      "\n",
      "number\\[\\] \\| null\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content-top-logprobs-logprob)\n",
      "\n",
      "choices.logprobs.content.top\\_logprobs.logprob\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-content-top-logprobs-token)\n",
      "\n",
      "choices.logprobs.content.top\\_logprobs.token\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal)\n",
      "\n",
      "choices.logprobs.refusal\n",
      "\n",
      "object\\[\\] \\| null\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal-bytes)\n",
      "\n",
      "choices.logprobs.refusal.bytes\n",
      "\n",
      "number\\[\\] \\| null\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal-logprob)\n",
      "\n",
      "choices.logprobs.refusal.logprob\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal-token)\n",
      "\n",
      "choices.logprobs.refusal.token\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal-top-logprobs)\n",
      "\n",
      "choices.logprobs.refusal.top\\_logprobs\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal-top-logprobs-bytes)\n",
      "\n",
      "choices.logprobs.refusal.top\\_logprobs.bytes\n",
      "\n",
      "number\\[\\] \\| null\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal-top-logprobs-logprob)\n",
      "\n",
      "choices.logprobs.refusal.top\\_logprobs.logprob\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-choices-logprobs-refusal-top-logprobs-token)\n",
      "\n",
      "choices.logprobs.refusal.top\\_logprobs.token\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-created)\n",
      "\n",
      "created\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-id)\n",
      "\n",
      "id\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-model)\n",
      "\n",
      "model\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-object)\n",
      "\n",
      "object\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`chat.completion`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage)\n",
      "\n",
      "usage\n",
      "\n",
      "object\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-completion-tokens)\n",
      "\n",
      "usage.completion\\_tokens\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-prompt-tokens)\n",
      "\n",
      "usage.prompt\\_tokens\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-total-tokens)\n",
      "\n",
      "usage.total\\_tokens\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-completion-tokens-details)\n",
      "\n",
      "usage.completion\\_tokens\\_details\n",
      "\n",
      "object \\| null\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-completion-tokens-details-accepted-prediction-tokens)\n",
      "\n",
      "usage.completion\\_tokens\\_details.accepted\\_prediction\\_tokens\n",
      "\n",
      "number \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-completion-tokens-details-audio-tokens)\n",
      "\n",
      "usage.completion\\_tokens\\_details.audio\\_tokens\n",
      "\n",
      "number \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-completion-tokens-details-reasoning-tokens)\n",
      "\n",
      "usage.completion\\_tokens\\_details.reasoning\\_tokens\n",
      "\n",
      "number \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-completion-tokens-details-rejected-prediction-tokens)\n",
      "\n",
      "usage.completion\\_tokens\\_details.rejected\\_prediction\\_tokens\n",
      "\n",
      "number \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-completion-tokens-details-text-tokens)\n",
      "\n",
      "usage.completion\\_tokens\\_details.text\\_tokens\n",
      "\n",
      "number \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-criteria)\n",
      "\n",
      "usage.criteria\n",
      "\n",
      "object\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-criteria-key)\n",
      "\n",
      "usage.criteria.{key}\n",
      "\n",
      "object\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-criteria-key-total-tokens)\n",
      "\n",
      "usage.criteria.{key}.total\\_tokens\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "The total number of tokens used to generate the criterion judgement. Only returned for OpenPipe-trained reward models currently.\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-prompt-cache-hit-tokens)\n",
      "\n",
      "usage.prompt\\_cache\\_hit\\_tokens\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-prompt-cache-miss-tokens)\n",
      "\n",
      "usage.prompt\\_cache\\_miss\\_tokens\n",
      "\n",
      "number\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-prompt-tokens-details)\n",
      "\n",
      "usage.prompt\\_tokens\\_details\n",
      "\n",
      "object \\| null\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-prompt-tokens-details-audio-tokens)\n",
      "\n",
      "usage.prompt\\_tokens\\_details.audio\\_tokens\n",
      "\n",
      "number \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-chatcompletions#response-usage-prompt-tokens-details-cached-tokens)\n",
      "\n",
      "usage.prompt\\_tokens\\_details.cached\\_tokens\n",
      "\n",
      "number \\| null\n",
      "\n",
      "[Update Metadata](https://docs.openpipe.ai/api-reference/post-updatemetadata) [Create Dataset](https://docs.openpipe.ai/api-reference/post-createDataset)\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/chat/completions \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"messages\": [\\\n",
      "    {\\\n",
      "      \"role\": \"system\",\\\n",
      "      \"content\": \"<string>\",\\\n",
      "      \"name\": \"<string>\"\\\n",
      "    }\\\n",
      "  ],\n",
      "  \"model\": \"<string>\",\n",
      "  \"audio\": {\n",
      "    \"format\": \"wav\",\n",
      "    \"voice\": \"alloy\"\n",
      "  },\n",
      "  \"function_call\": \"none\",\n",
      "  \"functions\": [\\\n",
      "    {\\\n",
      "      \"name\": \"<string>\",\\\n",
      "      \"parameters\": {},\\\n",
      "      \"description\": \"<string>\",\\\n",
      "      \"strict\": true\\\n",
      "    }\\\n",
      "  ],\n",
      "  \"tool_choice\": \"none\",\n",
      "  \"tools\": [\\\n",
      "    {\\\n",
      "      \"function\": {\\\n",
      "        \"name\": \"<string>\",\\\n",
      "        \"parameters\": {},\\\n",
      "        \"description\": \"<string>\",\\\n",
      "        \"strict\": true\\\n",
      "      },\\\n",
      "      \"type\": \"function\"\\\n",
      "    }\\\n",
      "  ],\n",
      "  \"n\": 123,\n",
      "  \"max_tokens\": 123,\n",
      "  \"max_completion_tokens\": 123,\n",
      "  \"temperature\": 123,\n",
      "  \"top_p\": 123,\n",
      "  \"presence_penalty\": 123,\n",
      "  \"frequency_penalty\": 123,\n",
      "  \"stop\": \"<string>\",\n",
      "  \"response_format\": {\n",
      "    \"type\": \"text\"\n",
      "  },\n",
      "  \"logprobs\": true,\n",
      "  \"top_logprobs\": 123,\n",
      "  \"stream_options\": {\n",
      "    \"include_usage\": true\n",
      "  },\n",
      "  \"store\": true,\n",
      "  \"metadata\": {},\n",
      "  \"stream\": false\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"id\": \"<string>\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 123,\n",
      "  \"model\": \"<string>\",\n",
      "  \"choices\": [\\\n",
      "    {\\\n",
      "      \"finish_reason\": \"length\",\\\n",
      "      \"index\": 123,\\\n",
      "      \"message\": {\\\n",
      "        \"reasoning_content\": \"<string>\",\\\n",
      "        \"content\": null,\\\n",
      "        \"refusal\": \"<string>\",\\\n",
      "        \"role\": \"assistant\",\\\n",
      "        \"function_call\": {\\\n",
      "          \"name\": \"\",\\\n",
      "          \"arguments\": \"\"\\\n",
      "        },\\\n",
      "        \"tool_calls\": [\\\n",
      "          {\\\n",
      "            \"id\": \"<string>\",\\\n",
      "            \"function\": {\\\n",
      "              \"name\": \"<string>\",\\\n",
      "              \"arguments\": \"<string>\"\\\n",
      "            },\\\n",
      "            \"type\": \"function\"\\\n",
      "          }\\\n",
      "        ]\\\n",
      "      },\\\n",
      "      \"logprobs\": null,\\\n",
      "      \"content_filter_results\": {},\\\n",
      "      \"criteria_results\": {}\\\n",
      "    }\\\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 123,\n",
      "    \"completion_tokens\": 123,\n",
      "    \"total_tokens\": 123,\n",
      "    \"prompt_cache_hit_tokens\": 123,\n",
      "    \"prompt_cache_miss_tokens\": 123,\n",
      "    \"completion_tokens_details\": {\n",
      "      \"reasoning_tokens\": 123,\n",
      "      \"audio_tokens\": 123,\n",
      "      \"text_tokens\": 123,\n",
      "      \"accepted_prediction_tokens\": 123,\n",
      "      \"rejected_prediction_tokens\": 123\n",
      "    },\n",
      "    \"prompt_tokens_details\": {\n",
      "      \"cached_tokens\": 123,\n",
      "      \"audio_tokens\": 123\n",
      "    },\n",
      "    \"criteria\": {}\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "=== docs_openpipe_ai_features_fine_tuning_quick_start.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Fine Tuning\n",
      "\n",
      "Fine-Tuning Quick Start\n",
      "\n",
      "Fine-tuning open and closed models with custom hyperparameters only takes a few clicks.\n",
      "\n",
      "**Before you begin:** Before training your first model, make sure you’ve [created a\\\\\n",
      "dataset](https://docs.openpipe.ai/features/datasets/quick-start) and imported at least 10 training entries.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/fine-tuning/quick-start\\#training-a-model)  Training a Model\n",
      "\n",
      "1\n",
      "\n",
      "Navigate to Dataset\n",
      "\n",
      "To train a model, navigate to the dataset you’d like to train your model on. Click the **Fine Tune** button in the top right corner of the **General** tab.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/fine-tuning/fine-tune-modal.png)\n",
      "\n",
      "2\n",
      "\n",
      "Name your Model\n",
      "\n",
      "Choose a descriptive name for your new model. This name will be used as the `model` parameter when querying it in code.\n",
      "You can always rename your model later.\n",
      "\n",
      "3\n",
      "\n",
      "Select Base Model\n",
      "\n",
      "Select the base model you’d like to fine-tune on. We recommend starting with Llama 3.1 8B if you aren’t sure which to choose.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/fine-tuning/select-base-model.png)\n",
      "\n",
      "4\n",
      "\n",
      "Adjust Hyperparameters (optional)\n",
      "\n",
      "Under **Advanced Options**, you can optionally adjust the hyperparameters to fine-tune your model.\n",
      "You can leave these at their default values if you aren’t sure which to choose.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/fine-tuning/adjust-hyperparameters.png)\n",
      "\n",
      "5\n",
      "\n",
      "Start Training\n",
      "\n",
      "Click **Start Training** to begin the training process.\n",
      "The training job may take a few minutes or a few hours to complete, depending on the amount of training data, the base model, and the hyperparameters you choose.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/fine-tuning/trained-model.png)\n",
      "\n",
      "To learn more about fine-tuning through the webapp, check out the [Fine-Tuning via Webapp](https://docs.openpipe.ai/features/fine-tuning/overview) page.\n",
      "To learn about fine-tuning via API, see our [Fine Tuning via API](https://docs.openpipe.ai/api-reference/fine-tuning) page.\n",
      "\n",
      "[Exporting Data](https://docs.openpipe.ai/features/datasets/exporting-data) [Webapp](https://docs.openpipe.ai/features/fine-tuning/webapp)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Training a Model](https://docs.openpipe.ai/features/fine-tuning/quick-start#training-a-model)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/fine-tuning/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/fine-tuning/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/fine-tuning/quick-start)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/fine-tuning/quick-start\n",
      "\n",
      "=== docs_openpipe_ai_features_datasets_exporting_data.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Datasets\n",
      "\n",
      "Exporting Data\n",
      "\n",
      "## [​](https://docs.openpipe.ai/features/datasets/exporting-data\\#dataset-export)  Dataset export\n",
      "\n",
      "After you’ve collected, filtered, and transformed your dataset entries for fine-tuning, you can export them as a JSONL file.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/datasets/exporting-dataset-entries.png)\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/datasets/exporting-data\\#fields)  Fields\n",
      "\n",
      "- **`messages`:** The complete chat history.\n",
      "- **`tools`:** The tools provided to the model.\n",
      "- **`tool_choice`:** The tool required for the model to use.\n",
      "- **`split`:** The train/test split to which the entry belongs.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/datasets/exporting-data\\#example)  Example\n",
      "\n",
      "Copy\n",
      "\n",
      "```jsonl\n",
      "{\"messages\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":\"What is the capital of Tasmania?\"},{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"arguments\":\"{\\\"capital\\\":\\\"Hobart\\\"}\"}}]}],\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"parameters\":{\"type\":\"object\",\"properties\":{\"capital\":{\"type\":\"string\"}}}}}]}\n",
      "{\"messages\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":\"What is the capital of Sweden?\"},{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"arguments\":\"{\\\"capital\\\":\\\"Stockholm\\\"}\"}}]}],\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"parameters\":{\"type\":\"object\",\"properties\":{\"capital\":{\"type\":\"string\"}}}}}]}\n",
      "\n",
      "```\n",
      "\n",
      "[Relabeling Data](https://docs.openpipe.ai/features/datasets/relabeling-data) [Quick Start](https://docs.openpipe.ai/features/fine-tuning/quick-start)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Dataset export](https://docs.openpipe.ai/features/datasets/exporting-data#dataset-export)\n",
      "- [Fields](https://docs.openpipe.ai/features/datasets/exporting-data#fields)\n",
      "- [Example](https://docs.openpipe.ai/features/datasets/exporting-data#example)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/datasets/exporting-data\n",
      "\n",
      "=== docs_openpipe_ai_features_criteria_alignment_set.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Criteria\n",
      "\n",
      "Criterion Alignment Sets\n",
      "\n",
      "Alignment sets are a collection of LLM input/output pairs that are judged by both the criterion LLM judge and a human.\n",
      "The performance of the criterion LLM judge is then measured by how well it matches the judgements of the human judge. We recommend importing and judging at least 30 rows to ensure the alignment stats are meaningful.\n",
      "\n",
      "## [​](https://docs.openpipe.ai/features/criteria/alignment-set\\#importing-an-alignment-set)  Importing an Alignment Set\n",
      "\n",
      "You can import an alignment set from either an OpenPipe dataset or a JSONL file. Alignment sets can be added to an existing criterion or imported when a new criterion is created.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/alignment-set/import-alignment-set.png)\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/criteria/alignment-set\\#importing-from-a-dataset)  Importing from a Dataset\n",
      "\n",
      "When importing from a dataset, you select a number of rows to be randomly sampled from the dataset of your choice to imported into the criterion alignment set. The inputs of each of these rows will be copied directly from the rows in the dataset without any changes. By default, the outputs will also be copied from the original dataset. However, if you set **Output Source** to be an LLM model, the outputs will be generated by the LLM model based on the dataset inputs.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/alignment-set/import-from-dataset.png)\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/criteria/alignment-set\\#importing-from-a-jsonl-file)  Importing from a JSONL File\n",
      "\n",
      "You can also import an alignment set from a JSONL file. Uploads are limited to 10MB in size,\n",
      "which should be plenty for an alignment set.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/alignment-set/import-from-upload.png)\n",
      "\n",
      "The schema of the JSONL file is exactly the same as an OpenAI-compatible [JSONL fine-tuning file](https://docs.openpipe.ai/features/datasets/uploading-data#openai-fields), but also supports an optional `judgement` field for each row. `judgement` can be either `PASS` or `FAIL`, depending on whether the row should pass or fail the criterion.\n",
      "\n",
      "#### [​](https://docs.openpipe.ai/features/criteria/alignment-set\\#example)  Example\n",
      "\n",
      "Copy\n",
      "\n",
      "```jsonl\n",
      "...\n",
      "{\"judgement\": \"PASS\", \"messages\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":\"What is the capital of Tasmania?\"},{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"arguments\":\"{\\\"capital\\\":\\\"Hobart\\\"}\"}}]}],\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"parameters\":{\"type\":\"object\",\"properties\":{\"capital\":{\"type\":\"string\"}}}}}]}\n",
      "{\"judgement\": \"FAIL\", \"messages\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":\"What is the capital of Sweden?\"},{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"arguments\":\"{\\\"capital\\\":\\\"Beijing\\\"}\"}}]}],\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"parameters\":{\"type\":\"object\",\"properties\":{\"capital\":{\"type\":\"string\"}}}}}]}\n",
      "{\"messages\":[{\"role\":\"system\",\"content\":\"You are a helpful assistant\"},{\"role\":\"user\",\"content\":\"What is the capital of Sweden?\"},{\"role\":\"assistant\",\"content\":null,\"tool_calls\":[{\"id\":\"\",\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"arguments\":\"{\\\"capital\\\":\\\"Stockholm\\\"}\"}}]}],\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"identify_capital\",\"parameters\":{\"type\":\"object\",\"properties\":{\"capital\":{\"type\":\"string\"}}}}}]}\n",
      "...\n",
      "\n",
      "```\n",
      "\n",
      "## [​](https://docs.openpipe.ai/features/criteria/alignment-set\\#alignment-stats)  Alignment Stats\n",
      "\n",
      "Alignment stats are a simple way to understand how well your criterion is performing.\n",
      "As you refine your criterion prompt, you’re alignment stats will improve as well.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/alignment-set/alignment-stats.png)\n",
      "\n",
      "- **Precision** indicates the fraction of rows that the LLM judge labeled as failing that a human judge also labeled as failing. It’s an indicator of how reliable the LLM judge’s FAIL label is.\n",
      "- **Recall** indicates the fraction of rows that a human judge labeled as failing that the LLM judge also labeled as failing. It’s an indicator of how reliable the LLM judge’s PASS label is.\n",
      "- **F1 Score** is the harmonic mean of precision and recall. As either score improves, the F1 score will also improve.\n",
      "\n",
      "To ensure your alignment stats are meaningful, we recommend labeling at least 30 rows,\n",
      "but in some cases you may need to label more in order to get a reliable statistic.\n",
      "\n",
      "[Quick Start](https://docs.openpipe.ai/features/criteria/quick-start) [API Endpoints](https://docs.openpipe.ai/features/criteria/api)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Importing an Alignment Set](https://docs.openpipe.ai/features/criteria/alignment-set#importing-an-alignment-set)\n",
      "- [Importing from a Dataset](https://docs.openpipe.ai/features/criteria/alignment-set#importing-from-a-dataset)\n",
      "- [Importing from a JSONL File](https://docs.openpipe.ai/features/criteria/alignment-set#importing-from-a-jsonl-file)\n",
      "- [Example](https://docs.openpipe.ai/features/criteria/alignment-set#example)\n",
      "- [Alignment Stats](https://docs.openpipe.ai/features/criteria/alignment-set#alignment-stats)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/criteria/alignment-set)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/criteria/alignment-set)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/criteria/alignment-set)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/criteria/alignment-set\n",
      "\n",
      "=== docs_openpipe_ai_api_reference_post_report.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Logs\n",
      "\n",
      "Report\n",
      "\n",
      "POST\n",
      "\n",
      "/\n",
      "\n",
      "report\n",
      "\n",
      "Try it\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/report \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"requestedAt\": 123,\n",
      "  \"receivedAt\": 123,\n",
      "  \"reqPayload\": \"<any>\",\n",
      "  \"respPayload\": \"<any>\",\n",
      "  \"statusCode\": 123,\n",
      "  \"errorMessage\": \"<string>\",\n",
      "  \"tags\": {}\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"status\": \"ok\"\n",
      "}\n",
      "```\n",
      "\n",
      "#### Authorizations\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report#authorization-authorization)\n",
      "\n",
      "Authorization\n",
      "\n",
      "string\n",
      "\n",
      "header\n",
      "\n",
      "required\n",
      "\n",
      "Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\n",
      "\n",
      "#### Body\n",
      "\n",
      "application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report#body-error-message)\n",
      "\n",
      "errorMessage\n",
      "\n",
      "string\n",
      "\n",
      "User-friendly error message\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report#body-received-at)\n",
      "\n",
      "receivedAt\n",
      "\n",
      "number\n",
      "\n",
      "Unix timestamp in milliseconds\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report#body-req-payload)\n",
      "\n",
      "reqPayload\n",
      "\n",
      "any\n",
      "\n",
      "JSON-encoded request payload\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report#body-requested-at)\n",
      "\n",
      "requestedAt\n",
      "\n",
      "number\n",
      "\n",
      "Unix timestamp in milliseconds\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report#body-resp-payload)\n",
      "\n",
      "respPayload\n",
      "\n",
      "any\n",
      "\n",
      "JSON-encoded response payload\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report#body-status-code)\n",
      "\n",
      "statusCode\n",
      "\n",
      "number\n",
      "\n",
      "HTTP status code of response\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report#body-tags)\n",
      "\n",
      "tags\n",
      "\n",
      "object\n",
      "\n",
      "DEPRECATED: use \"reqPayload.metadata\" to attach extra metadata tags to the call for filtering. Eg { \"userId\": \"123\", \"prompt\\_id\": \"populate-title\" }\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report#body-tags-key)\n",
      "\n",
      "tags.{key}\n",
      "\n",
      "string \\| nullnumber \\| nullboolean \\| nullenum<string> \\| null\n",
      "\n",
      "#### Response\n",
      "\n",
      "200 - application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-report#response-status)\n",
      "\n",
      "status\n",
      "\n",
      "Option 1 · enum<string>Option 2 · enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`ok`\n",
      "\n",
      "[External Models](https://docs.openpipe.ai/features/external-models) [Report Anthropic](https://docs.openpipe.ai/api-reference/post-report-anthropic)\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/report \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"requestedAt\": 123,\n",
      "  \"receivedAt\": 123,\n",
      "  \"reqPayload\": \"<any>\",\n",
      "  \"respPayload\": \"<any>\",\n",
      "  \"statusCode\": 123,\n",
      "  \"errorMessage\": \"<string>\",\n",
      "  \"tags\": {}\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"status\": \"ok\"\n",
      "}\n",
      "```\n",
      "\n",
      "=== docs_openpipe_ai_api_reference_delete_model.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Models\n",
      "\n",
      "Delete Model\n",
      "\n",
      "DELETE\n",
      "\n",
      "/\n",
      "\n",
      "models\n",
      "\n",
      "/\n",
      "\n",
      "{modelSlug}\n",
      "\n",
      "Try it\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request DELETE \\\n",
      "  --url https://api.openpipe.ai/api/v1/models/{modelSlug} \\\n",
      "  --header 'Authorization: Bearer <token>'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"id\": \"<string>\",\n",
      "  \"object\": \"model\",\n",
      "  \"deleted\": true\n",
      "}\n",
      "```\n",
      "\n",
      "#### Authorizations\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/delete-model#authorization-authorization)\n",
      "\n",
      "Authorization\n",
      "\n",
      "string\n",
      "\n",
      "header\n",
      "\n",
      "required\n",
      "\n",
      "Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\n",
      "\n",
      "#### Path Parameters\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/delete-model#parameter-model-slug)\n",
      "\n",
      "modelSlug\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "#### Response\n",
      "\n",
      "200 - application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/delete-model#response-deleted)\n",
      "\n",
      "deleted\n",
      "\n",
      "boolean\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/delete-model#response-id)\n",
      "\n",
      "id\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/delete-model#response-object)\n",
      "\n",
      "object\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`model`\n",
      "\n",
      "[List Models](https://docs.openpipe.ai/api-reference/get-listModels) [Judge Criteria](https://docs.openpipe.ai/api-reference/post-criteriajudge)\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request DELETE \\\n",
      "  --url https://api.openpipe.ai/api/v1/models/{modelSlug} \\\n",
      "  --header 'Authorization: Bearer <token>'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"id\": \"<string>\",\n",
      "  \"object\": \"model\",\n",
      "  \"deleted\": true\n",
      "}\n",
      "```\n",
      "\n",
      "=== docs_openpipe_ai_api_reference_post_criteriajudge.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Criteria\n",
      "\n",
      "Judge Criteria\n",
      "\n",
      "POST\n",
      "\n",
      "/\n",
      "\n",
      "criteria\n",
      "\n",
      "/\n",
      "\n",
      "judge\n",
      "\n",
      "Try it\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/criteria/judge \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"criterion_id\": \"<string>\",\n",
      "  \"input\": {\n",
      "    \"messages\": [\\\n",
      "      {\\\n",
      "        \"role\": \"system\",\\\n",
      "        \"content\": \"<string>\",\\\n",
      "        \"name\": \"<string>\"\\\n",
      "      }\\\n",
      "    ],\n",
      "    \"tool_choice\": \"none\",\n",
      "    \"tools\": [\\\n",
      "      {\\\n",
      "        \"function\": {\\\n",
      "          \"name\": \"<string>\",\\\n",
      "          \"parameters\": {},\\\n",
      "          \"description\": \"<string>\",\\\n",
      "          \"strict\": true\\\n",
      "        },\\\n",
      "        \"type\": \"function\"\\\n",
      "      }\\\n",
      "    ]\n",
      "  },\n",
      "  \"output\": {\n",
      "    \"reasoning_content\": \"<string>\",\n",
      "    \"content\": null,\n",
      "    \"refusal\": \"<string>\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"function_call\": {\n",
      "      \"name\": \"\",\n",
      "      \"arguments\": \"\"\n",
      "    },\n",
      "    \"tool_calls\": [\\\n",
      "      {\\\n",
      "        \"id\": \"<string>\",\\\n",
      "        \"function\": {\\\n",
      "          \"name\": \"<string>\",\\\n",
      "          \"arguments\": \"<string>\"\\\n",
      "        },\\\n",
      "        \"type\": \"function\"\\\n",
      "      }\\\n",
      "    ]\n",
      "  }\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"score\": 123,\n",
      "  \"explanation\": \"<string>\",\n",
      "  \"usage\": {\n",
      "    \"total_tokens\": 123\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "#### Authorizations\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#authorization-authorization)\n",
      "\n",
      "Authorization\n",
      "\n",
      "string\n",
      "\n",
      "header\n",
      "\n",
      "required\n",
      "\n",
      "Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\n",
      "\n",
      "#### Body\n",
      "\n",
      "application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-criterion-id)\n",
      "\n",
      "criterion\\_id\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "The ID of the criterion to judge.\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output)\n",
      "\n",
      "output\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "The completion message of the model.\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-role)\n",
      "\n",
      "output.role\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`assistant`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-content)\n",
      "\n",
      "output.content\n",
      "\n",
      "string \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-function-call)\n",
      "\n",
      "output.function\\_call\n",
      "\n",
      "object \\| null\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-function-call-arguments)\n",
      "\n",
      "output.function\\_call.arguments\n",
      "\n",
      "string\n",
      "\n",
      "default:\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-function-call-name)\n",
      "\n",
      "output.function\\_call.name\n",
      "\n",
      "string\n",
      "\n",
      "default:\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-reasoning-content)\n",
      "\n",
      "output.reasoning\\_content\n",
      "\n",
      "string \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-refusal)\n",
      "\n",
      "output.refusal\n",
      "\n",
      "string \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-tool-calls)\n",
      "\n",
      "output.tool\\_calls\n",
      "\n",
      "object\\[\\] \\| null\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-tool-calls-function)\n",
      "\n",
      "output.tool\\_calls.function\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-tool-calls-function-arguments)\n",
      "\n",
      "output.tool\\_calls.function.arguments\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-tool-calls-function-name)\n",
      "\n",
      "output.tool\\_calls.function.name\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-tool-calls-id)\n",
      "\n",
      "output.tool\\_calls.id\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-output-tool-calls-type)\n",
      "\n",
      "output.tool\\_calls.type\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`function`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input)\n",
      "\n",
      "input\n",
      "\n",
      "object\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-messages)\n",
      "\n",
      "input.messages\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "All messages sent to the model when generating the output.\n",
      "\n",
      "- Option 1\n",
      "- Option 2\n",
      "- Option 3\n",
      "- Option 4\n",
      "- Option 5\n",
      "- Option 6\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-messages-role)\n",
      "\n",
      "input.messages.role\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`system`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-messages-content)\n",
      "\n",
      "input.messages.content\n",
      "\n",
      "stringobject\\[\\]\n",
      "\n",
      "default:\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-messages-name)\n",
      "\n",
      "input.messages.name\n",
      "\n",
      "string\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tool-choice)\n",
      "\n",
      "input.tool\\_choice\n",
      "\n",
      "Option 1 · enum<string>Option 2 · enum<string>Option 3 · enum<string>Option 4 · object\n",
      "\n",
      "The tool choice to use when generating the output, if any.\n",
      "\n",
      "Available options:\n",
      "\n",
      "`none`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools)\n",
      "\n",
      "input.tools\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "The tools available to the model when generating the output, if any.\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools-function)\n",
      "\n",
      "input.tools.function\n",
      "\n",
      "object\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools-function-name)\n",
      "\n",
      "input.tools.function.name\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools-function-description)\n",
      "\n",
      "input.tools.function.description\n",
      "\n",
      "string\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools-function-parameters)\n",
      "\n",
      "input.tools.function.parameters\n",
      "\n",
      "object\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools-function-parameters-key)\n",
      "\n",
      "input.tools.function.parameters.{key}\n",
      "\n",
      "any\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools-function-strict)\n",
      "\n",
      "input.tools.function.strict\n",
      "\n",
      "boolean \\| null\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#body-input-tools-type)\n",
      "\n",
      "input.tools.type\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`function`\n",
      "\n",
      "#### Response\n",
      "\n",
      "200 - application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#response-score)\n",
      "\n",
      "score\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "A score of 0 means the output failed this completion, and a score of 1 means it passed. A criteria may also return a decimal scores between 0 and 1, indicating the model's confidence or 'likelihood' that the criteria passed.\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#response-explanation)\n",
      "\n",
      "explanation\n",
      "\n",
      "string\n",
      "\n",
      "An explanation of the score including the model's reasoning, if applicable.\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#response-usage)\n",
      "\n",
      "usage\n",
      "\n",
      "object\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-criteriajudge#response-usage-total-tokens)\n",
      "\n",
      "usage.total\\_tokens\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "The total number of tokens used to generate the criterion judgement. Only returned for OpenPipe-trained reward models currently.\n",
      "\n",
      "[Delete Model](https://docs.openpipe.ai/api-reference/delete-model) [Pricing Overview](https://docs.openpipe.ai/pricing/pricing)\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/criteria/judge \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"criterion_id\": \"<string>\",\n",
      "  \"input\": {\n",
      "    \"messages\": [\\\n",
      "      {\\\n",
      "        \"role\": \"system\",\\\n",
      "        \"content\": \"<string>\",\\\n",
      "        \"name\": \"<string>\"\\\n",
      "      }\\\n",
      "    ],\n",
      "    \"tool_choice\": \"none\",\n",
      "    \"tools\": [\\\n",
      "      {\\\n",
      "        \"function\": {\\\n",
      "          \"name\": \"<string>\",\\\n",
      "          \"parameters\": {},\\\n",
      "          \"description\": \"<string>\",\\\n",
      "          \"strict\": true\\\n",
      "        },\\\n",
      "        \"type\": \"function\"\\\n",
      "      }\\\n",
      "    ]\n",
      "  },\n",
      "  \"output\": {\n",
      "    \"reasoning_content\": \"<string>\",\n",
      "    \"content\": null,\n",
      "    \"refusal\": \"<string>\",\n",
      "    \"role\": \"assistant\",\n",
      "    \"function_call\": {\n",
      "      \"name\": \"\",\n",
      "      \"arguments\": \"\"\n",
      "    },\n",
      "    \"tool_calls\": [\\\n",
      "      {\\\n",
      "        \"id\": \"<string>\",\\\n",
      "        \"function\": {\\\n",
      "          \"name\": \"<string>\",\\\n",
      "          \"arguments\": \"<string>\"\\\n",
      "        },\\\n",
      "        \"type\": \"function\"\\\n",
      "      }\\\n",
      "    ]\n",
      "  }\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"score\": 123,\n",
      "  \"explanation\": \"<string>\",\n",
      "  \"usage\": {\n",
      "    \"total_tokens\": 123\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "=== docs_openpipe_ai_features_chat_completions_overview.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Chat Completions\n",
      "\n",
      "Chat Completions\n",
      "\n",
      "Once your fine-tuned model is deployed, you’re ready to start generating chat completions.\n",
      "\n",
      "First, make sure you’ve set up the SDK properly. See the [OpenPipe SDK](https://docs.openpipe.ai/getting-started/openpipe-sdk) section for more details. Once the SDK is installed and you’ve added the right\n",
      "`OPENPIPE_API_KEY` to your environment variables, you’re almost done.\n",
      "\n",
      "The last step is to update the model that you’re querying to match the ID of your new fine-tuned model.\n",
      "\n",
      "- Python\n",
      "- NodeJS\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "from openpipe import OpenAI\n",
      "\n",
      "# Find the config values in \"Installing the SDK\"\n",
      "client = OpenAI()\n",
      "\n",
      "completion = client.chat.completions.create(\n",
      "    # model=\"gpt-4o\", - original model\n",
      "    model=\"openpipe:your-fine-tuned-model-id\",\n",
      "    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\n",
      "    metadata={\"prompt_id\": \"counting\", \"any_key\": \"any_value\"},\n",
      ")\n",
      "\n",
      "```\n",
      "\n",
      "Queries to your fine-tuned models will now be shown in the [Request Logs](https://docs.openpipe.ai/features/request-logs) panel.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/running-inference-logs.png)\n",
      "\n",
      "Feel free to run some sample inference on the [PII Redaction model](https://app.openpipe.ai/p/BRZFEx50Pf/fine-tunes/6076ad69-cce5-4892-ae54-e0549bbe107f/general) in our public project.\n",
      "\n",
      "[API Endpoints](https://docs.openpipe.ai/features/criteria/api) [Proxying to External Models](https://docs.openpipe.ai/features/chat-completions/external-models)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/chat-completions/overview\n",
      "\n",
      "=== docs_openpipe_ai_overview.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Welcome\n",
      "\n",
      "Overview\n",
      "\n",
      "## [​](https://docs.openpipe.ai/overview\\#what-we-provide)  What We Provide\n",
      "\n",
      "Here are a few of the features we offer:\n",
      "\n",
      "- [**Unified SDK**](https://docs.openpipe.ai/getting-started/openpipe-sdk): Collect and utilize interaction data to fine-tune a custom model and continually refine and enhance model performance. Switching requests from your previous LLM provider to your new model is as simple as changing the model name. All our models implement the OpenAI inference format, so you won’t have to change how you parse its response.\n",
      "\n",
      "- [**Data Capture**](https://docs.openpipe.ai/features/request-logs): OpenPipe captures every request and response and stores it for your future use.\n",
      "  - [**Request Logs**](https://docs.openpipe.ai/features/request-logs): We help you automatically log your past requests and tag them for easy filtering.\n",
      "  - [**Upload Data**](https://docs.openpipe.ai/features/datasets/uploading-data): OpenPipe also allows you to import fine-tuning data from OpenAI-compatible JSONL files.\n",
      "  - [**Export Data**](https://docs.openpipe.ai/features/datasets/exporting-data): Once your request logs are recorded, you can export them at any time.\n",
      "- [**Fine-Tuning**](https://docs.openpipe.ai/features/fine-tuning/overview): With all your LLM requests and responses in one place, it’s easy to select the data you want to fine-tune on and kick off a job.\n",
      "  - [**Pruning Rules**](https://docs.openpipe.ai/features/pruning-rules): By removing large chunks of unchanging text and fine-tuning a model on the compacted data, we can reduce the size of incoming requests and save you money on inference.\n",
      "- [**Model Hosting**](https://docs.openpipe.ai/features/chat-completions): After we’ve trained your model, OpenPipe will automatically begin hosting it.\n",
      "  - [**Caching**](https://docs.openpipe.ai/features/caching): Improve performance and reduce costs by caching previously generated responses.\n",
      "- [**Evaluations**](https://docs.openpipe.ai/features/evaluations/overview): Compare your models against one another and OpenAI base models. Set up custom instructions and get quick insights into your models’ performance.\n",
      "\n",
      "\n",
      "Welcome to the OpenPipe community!\n",
      "\n",
      "[Introduction](https://docs.openpipe.ai/introduction) [Base Models](https://docs.openpipe.ai/base-models)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [What We Provide](https://docs.openpipe.ai/overview#what-we-provide\n",
      "\n",
      "=== docs_openpipe_ai_features_chat_completions_gemini.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Chat Completions\n",
      "\n",
      "Gemini Proxy\n",
      "\n",
      "OpenPipe can translate your existing OpenAI chat completion requests to work with Gemini models automatically, allowing you to use Gemini without changing your prompt format.\n",
      "\n",
      "After adding your Google AI Studio API Key in your project settings, specify the Gemini **model** you want to use by adding the `gemini:` prefix to the model name in your requests:\n",
      "\n",
      "- Python\n",
      "- NodeJS\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "from openpipe import OpenAI\n",
      "\n",
      "# Find the config values in \"Installing the SDK\"\n",
      "client = OpenAI()\n",
      "\n",
      "completion = client.chat.completions.create(\n",
      "    model=\"gemini:gemini-1.5-flash\",\n",
      "    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\n",
      "    metadata={\"prompt_id\": \"counting\", \"any_key\": \"any_value\"},\n",
      ")\n",
      "\n",
      "```\n",
      "\n",
      "For your reference, here is a list of the most commonly used Gemini models formatted for the OpenPipe proxy:\n",
      "\n",
      "- `gemini:gemini-1.5-flash-002`\n",
      "- `gemini:gemini-1.5-flash-8b-001`\n",
      "- `gemini:gemini-1.5-pro-002`\n",
      "- `gemini:gemini-exp-1206`\n",
      "- `gemini:gemini-2.0-flash-exp`\n",
      "\n",
      "Additionally, you can always stay on the latest version of the model by using an abbreviated model name:\n",
      "\n",
      "- `gemini:gemini-1.5-flash`\n",
      "- `gemini:gemini-1.5-flash-8b`\n",
      "- `gemini:gemini-1.5-pro`\n",
      "- `gemini:gemini-2.0-flash`\n",
      "\n",
      "[Anthropic Proxy](https://docs.openpipe.ai/features/chat-completions/anthropic) [Mixture of Agents](https://docs.openpipe.ai/features/chat-completions/moa\n",
      "\n",
      "=== docs_openpipe_ai_features_datasets_importing_logs.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Datasets\n",
      "\n",
      "Importing Request Logs\n",
      "\n",
      "Logged requests will be visible on your project’s [Request Logs](https://app.openpipe.ai/p/BRZFEx50Pf/request-logs?filterData=%7B%22shown%22%3Atrue%2C%22filters%22%3A%5B%7B%22id%22%3A%221706912835890%22%2C%22field%22%3A%22request%22%2C%22comparator%22%3A%22CONTAINS%22%2C%22value%22%3A%22You+are+an+expert%22%7D%2C%7B%22id%22%3A%221706912850914%22%2C%22field%22%3A%22response%22%2C%22comparator%22%3A%22NOT_CONTAINS%22%2C%22value%22%3A%22As+an+AI+language+model%22%7D%2C%7B%22id%22%3A%221706912861496%22%2C%22field%22%3A%22model%22%2C%22comparator%22%3A%22%3D%22%2C%22value%22%3A%22gpt-4-0613%22%7D%2C%7B%22id%22%3A%221706912870230%22%2C%22field%22%3A%22tags.prompt_id%22%2C%22comparator%22%3A%22CONTAINS%22%2C%22value%22%3A%22redaction%22%7D%5D%7D) page.\n",
      "You can filter your logs by completionId, model, custom tags, and more to narrow down your results.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/log-filters.png)\n",
      "\n",
      "Once you’ve found a set of data that you’d like to train on, import those logs into the dataset of your choice.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/importing-logs.png)\n",
      "\n",
      "After your data has been saved to your dataset, [kicking off a training job](https://docs.openpipe.ai/features/fine-tuning) is straightforward.\n",
      "\n",
      "[Quick Start](https://docs.openpipe.ai/features/datasets/quick-start) [Uploading Data](https://docs.openpipe.ai/features/datasets/uploading-data)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/datasets/importing-logs)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/datasets/importing-logs\n",
      "\n",
      "=== docs_openpipe_ai_api_reference_post_createDataset.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Datasets\n",
      "\n",
      "Create Dataset\n",
      "\n",
      "POST\n",
      "\n",
      "/\n",
      "\n",
      "datasets\n",
      "\n",
      "Try it\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/datasets \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"name\": \"<string>\"\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"object\": \"dataset\",\n",
      "  \"id\": \"<string>\",\n",
      "  \"name\": \"<string>\",\n",
      "  \"created\": \"<string>\",\n",
      "  \"updated\": \"<string>\",\n",
      "  \"dataset_entry_count\": 123,\n",
      "  \"fine_tune_count\": 123\n",
      "}\n",
      "```\n",
      "\n",
      "#### Authorizations\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDataset#authorization-authorization)\n",
      "\n",
      "Authorization\n",
      "\n",
      "string\n",
      "\n",
      "header\n",
      "\n",
      "required\n",
      "\n",
      "Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\n",
      "\n",
      "#### Body\n",
      "\n",
      "application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDataset#body-name)\n",
      "\n",
      "name\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "#### Response\n",
      "\n",
      "200 - application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDataset#response-created)\n",
      "\n",
      "created\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDataset#response-dataset-entry-count)\n",
      "\n",
      "dataset\\_entry\\_count\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDataset#response-fine-tune-count)\n",
      "\n",
      "fine\\_tune\\_count\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDataset#response-id)\n",
      "\n",
      "id\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDataset#response-name)\n",
      "\n",
      "name\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDataset#response-object)\n",
      "\n",
      "object\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`dataset`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/post-createDataset#response-updated)\n",
      "\n",
      "updated\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[Chat Completions](https://docs.openpipe.ai/api-reference/post-chatcompletions) [List Datasets](https://docs.openpipe.ai/api-reference/get-listDatasets)\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request POST \\\n",
      "  --url https://api.openpipe.ai/api/v1/datasets \\\n",
      "  --header 'Authorization: Bearer <token>' \\\n",
      "  --header 'Content-Type: application/json' \\\n",
      "  --data '{\n",
      "  \"name\": \"<string>\"\n",
      "}'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"object\": \"dataset\",\n",
      "  \"id\": \"<string>\",\n",
      "  \"name\": \"<string>\",\n",
      "  \"created\": \"<string>\",\n",
      "  \"updated\": \"<string>\",\n",
      "  \"dataset_entry_count\": 123,\n",
      "  \"fine_tune_count\": 123\n",
      "}\n",
      "```\n",
      "\n",
      "=== docs_openpipe_ai_features_chat_completions_anthropic.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Chat Completions\n",
      "\n",
      "Anthropic Proxy\n",
      "\n",
      "If you’d like to make chat completion requests to Anthropic models without modifying your prompt schema, you can proxy OpenAI-compatible requests through OpenPipe, and we’ll handle\n",
      "the translation for you.\n",
      "\n",
      "To proxy requests to Anthropic models, first add your Anthropic API Key to your project settings. Then, adjust the **model** parameter of your requests to be the name of the model you\n",
      "wish to query, prepended with the string `anthropic:`. For example, to make a request to `claude-3-5-sonnet-20241022`, use the following code:\n",
      "\n",
      "- Python\n",
      "- NodeJS\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "from openpipe import OpenAI\n",
      "\n",
      "# Find the config values in \"Installing the SDK\"\n",
      "client = OpenAI()\n",
      "\n",
      "completion = client.chat.completions.create(\n",
      "    model=\"anthropic:claude-3-5-sonnet-20241022\",\n",
      "    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\n",
      "    metadata={\"prompt_id\": \"counting\", \"any_key\": \"any_value\"},\n",
      ")\n",
      "\n",
      "```\n",
      "\n",
      "For your reference, here is a list of the most commonly used Anthropic models formatted for the OpenPipe proxy:\n",
      "\n",
      "- `anthropic:claude-3-5-sonnet-20241022`\n",
      "- `anthropic:claude-3-opus-20240229`\n",
      "- `anthropic:claude-3-sonnet-20240229`\n",
      "- `anthropic:claude-3-haiku-20240307`\n",
      "\n",
      "Additionally, you can always stay on the latest version of the model by using an abbreviated model name:\n",
      "\n",
      "- `anthropic:claude-3-5-sonnet`\n",
      "- `anthropic:claude-3-opus`\n",
      "- `anthropic:claude-3-sonnet`\n",
      "- `anthropic:claude-3-haiku`\n",
      "\n",
      "If you’d like to make requests directly to Anthropic models, you can do that externally using the Anthropic SDK, and report your logs using the\n",
      "asynchronous [reporting API](https://docs.openpipe.ai/features/request-logs/reporting-anthropic).\n",
      "\n",
      "[Proxying to External Models](https://docs.openpipe.ai/features/chat-completions/external-models) [Gemini Proxy](https://docs.openpipe.ai/features/chat-completions/gemini\n",
      "\n",
      "=== docs_openpipe_ai_features_updating_metadata.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Features\n",
      "\n",
      "Updating Metadata Tags\n",
      "\n",
      "You may want to update the metadata tags on a request log after it’s already been reported. For instance, if you notice that a certain completion from your fine-tuned model was flawed,\n",
      "you can mark it to be imported into one of your datasets and relabeled with GPT-4 for future training.\n",
      "\n",
      "- Python\n",
      "- NodeJS\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "import os\n",
      "from openpipe import OpenPipe, OpenAI\n",
      "from openpipe.client import UpdateLogTagsRequestFiltersItem\n",
      "\n",
      "# Find the config values in \"Installing the SDK\"\n",
      "client = OpenAI()\n",
      "op_client = OpenPipe(\n",
      "    # defaults to os.environ[\"OPENPIPE_API_KEY\"]\n",
      "    api_key=\"YOUR_API_KEY\"\n",
      ")\n",
      "\n",
      "completion = client.chat.completions.create(\n",
      "    model=\"openpipe:your-fine-tuned-model-id\",\n",
      "    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\n",
      "    metadata={\"prompt_id\": \"counting\", \"tag_to_remove\": \"some value\"},\n",
      ")\n",
      "\n",
      "resp = op_client.update_log_metadata(\n",
      "    filters=[\\\n",
      "        UpdateLogTagsRequestFiltersItem(\\\n",
      "            field=\"completionId\",\\\n",
      "            equals=completion.id,\\\n",
      "        ),\\\n",
      "        # completionId is the only filter necessary in this case, but let's add a couple more examples\\\n",
      "        UpdateLogTagsRequestFiltersItem(\\\n",
      "            field=\"model\",\\\n",
      "            equals=\"openpipe:your-fine-tuned-model-id\",\\\n",
      "        ),\\\n",
      "        UpdateLogTagsRequestFiltersItem(\\\n",
      "            field=\"metadata.prompt_id\",\\\n",
      "            equals=\"counting\",\\\n",
      "        ),\\\n",
      "    ],\n",
      "    metadata={\n",
      "        \"relabel\": \"true\",\n",
      "        \"tag_to_remove\": None # this will remove the tag_to_remove tag from the request log we just created\n",
      "    },\n",
      ")\n",
      "\n",
      "assert resp.matched_logs == 1\n",
      "\n",
      "```\n",
      "\n",
      "To update your metadata, you’ll need to provide two fields: `filters` and `metadata`.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/updating-metadata\\#filters)  Filters\n",
      "\n",
      "Use filters to determine which request logs should be updated. Each filter contains two fields, `field` and `equals`.\n",
      "\n",
      "- **`field`: Required** \\- Indicates the field on a request log that should be checked. Valid options include `model`, `completionId`, and `tags.your_tag_name`.\n",
      "- **`equals`: Required** \\- The value that the field should equal.\n",
      "\n",
      "Keep in mind that filters are cumulative, so only request logs that match all of the filters you provide will be updated.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/features/updating-metadata\\#metadata)  Metadata\n",
      "\n",
      "Provide one or more metadata tags in a json object. The key should be the name of the tag you’d like to add, update, or delete. The value should be the new value of the tag.\n",
      "If you’d like to delete a tag, provide a value of `None` or `null`.\n",
      "\n",
      "Updated metadata tags will be searchable in the [Request Logs](https://docs.openpipe.ai/features/request-logs) panel.\n",
      "\n",
      "[Caching](https://docs.openpipe.ai/features/caching) [Pruning Rules](https://docs.openpipe.ai/features/pruning-rules)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Filters](https://docs.openpipe.ai/features/updating-metadata#filters)\n",
      "- [Metadata](https://docs.openpipe.ai/features/updating-metadata#metadata\n",
      "\n",
      "=== docs_openpipe_ai_features_criteria_overview.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Criteria\n",
      "\n",
      "Criteria\n",
      "\n",
      "For questions about criteria or to unlock beta features for your organization, reach out to\n",
      "[support@openpipe.ai](mailto:support@openpipe.ai).\n",
      "\n",
      "Criteria are a simple way to reliably detect and correct mistakes in LLM output. Criteria can currently be used for the following purposes:\n",
      "\n",
      "- Defining LLM evaluations\n",
      "- Improving dataset quality\n",
      "- Runtime evaluation when generating [best of N](https://docs.openpipe.ai/features/criteria/api#runtime-evaluation) samples\n",
      "- [Offline testing](https://docs.openpipe.ai/features/criteria/api#offline-testing) of previously generated outputs\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/criteria/overview.png)\n",
      "\n",
      "## [​](https://docs.openpipe.ai/features/criteria/overview\\#what-is-a-criterion)  What is a Criterion?\n",
      "\n",
      "A criterion is a combination of an LLM model and prompt that can be used to identify a specific issue with a model’s output. Criterion judgements are generated\n",
      "by passing the input and output of a single row along with the criterion prompt to an LLM model, which then returns a binary `PASS`/ `FAIL` judgement.\n",
      "\n",
      "To learn how to create your first criterion, read the [Quick Start](https://docs.openpipe.ai/features/criteria/quick-start).\n",
      "\n",
      "[Head-to-Head Evals](https://docs.openpipe.ai/features/evaluations/head-to-head) [Quick Start](https://docs.openpipe.ai/features/criteria/quick-start)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [What is a Criterion?](https://docs.openpipe.ai/features/criteria/overview#what-is-a-criterion)\n",
      "\n",
      "![](https://docs.openpipe.ai/features/criteria/overview\n",
      "\n",
      "=== docs_openpipe_ai_base_models.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Welcome\n",
      "\n",
      "Base Models\n",
      "\n",
      "We regularly evaluate new models to see how they compare against our existing suite. If you’d like us to check out a\n",
      "base model you’re particularly excited about, send an email to [hello@openpipe.ai](mailto:hello@openpipe.ai).\n",
      "\n",
      "## [​](https://docs.openpipe.ai/base-models\\#current-base-models)  Current Base Models\n",
      "\n",
      "### [​](https://docs.openpipe.ai/base-models\\#open-source)  Open Source\n",
      "\n",
      "- [meta-llama/Meta-Llama-3.1-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct)\n",
      "- [meta-llama/Meta-Llama-3.1-70B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct)\n",
      "- [meta-llama/Llama-3.1-8B](https://huggingface.co/meta-llama/Llama-3.1-8B)\n",
      "- [meta-llama/Llama-3.1-70B](https://huggingface.co/meta-llama/Llama-3.1-70B)\n",
      "- [Qwen/Qwen2.5-72B-Instruct](https://huggingface.co/Qwen/Qwen2.5-72B-Instruct)\n",
      "- [Qwen/Qwen2.5-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct)\n",
      "- [Qwen/Qwen2.5-1.5B-Instruct](https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct)\n",
      "- [Qwen/Qwen2.5-Coder-32B-Instruct](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct)\n",
      "- [mistralai/Mistral-Nemo-Base-2407](https://huggingface.co/mistralai/Mistral-Nemo-Base-2407)\n",
      "- [mistralai/Mistral-Small-24B-Base-2501](https://huggingface.co/mistralai/Mistral-Small-24B-Base-2501)\n",
      "- [meta-llama/Llama-3.2-1B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct)\n",
      "- [meta-llama/Llama-3.2-3B-Instruct](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)\n",
      "- [meta-llama/Llama-3.3-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct)\n",
      "\n",
      "### [​](https://docs.openpipe.ai/base-models\\#openai)  OpenAI\n",
      "\n",
      "- [gpt-4o-mini-2024-07-18](https://platform.openai.com/docs/models/gpt-4o-mini)\n",
      "- [gpt-4o-2024-08-06](https://platform.openai.com/docs/models/gpt-4o)\n",
      "- [gpt-3.5-turbo-0125](https://platform.openai.com/docs/models/gpt-3-5-turbo)\n",
      "\n",
      "### [​](https://docs.openpipe.ai/base-models\\#google-gemini)  Google Gemini\n",
      "\n",
      "- [gemini-1.0-pro-001](https://deepmind.google/technologies/gemini/pro/)\n",
      "- [gemini-1.5-flash-001](https://deepmind.google/technologies/gemini/flash/)\n",
      "\n",
      "## [​](https://docs.openpipe.ai/base-models\\#enterprise-models)  Enterprise models\n",
      "\n",
      "These models are currently available for enterprise customers only. If you’re interested in exploring these models, we’d be happy to discuss further. Please reach out to us at [hello@openpipe.ai](mailto:hello@openpipe.ai) to learn more.\n",
      "\n",
      "### [​](https://docs.openpipe.ai/base-models\\#aws-bedrock)  AWS Bedrock\n",
      "\n",
      "- [cohere.command-text-v14](https://docs.aws.amazon.com/bedrock/latest/userguide/cm-hp-cohere-command.html)\n",
      "- [cohere.command-light-text-v14](https://docs.aws.amazon.com/bedrock/latest/userguide/cm-hp-cohere-command.html)\n",
      "- [anthropic.claude-3-haiku-20240307-v1:0](https://docs.aws.amazon.com/bedrock/latest/userguide/cm-hp-anth-claude-3.html)\n",
      "\n",
      "[Overview](https://docs.openpipe.ai/overview) [Quick Start](https://docs.openpipe.ai/getting-started/quick-start)\n",
      "\n",
      "On this page\n",
      "\n",
      "- [Current Base Models](https://docs.openpipe.ai/base-models#current-base-models)\n",
      "- [Open Source](https://docs.openpipe.ai/base-models#open-source)\n",
      "- [OpenAI](https://docs.openpipe.ai/base-models#openai)\n",
      "- [Google Gemini](https://docs.openpipe.ai/base-models#google-gemini)\n",
      "- [Enterprise models](https://docs.openpipe.ai/base-models#enterprise-models)\n",
      "- [AWS Bedrock](https://docs.openpipe.ai/base-models#aws-bedrock\n",
      "\n",
      "=== docs_openpipe_ai_features_dpo_quick_start.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Direct Preference Optimization (DPO)\n",
      "\n",
      "DPO Quick Start\n",
      "\n",
      "DPO fine-tuning uses preference data to train models on positive and negative examples. In OpenPipe, DPO\n",
      "can be used as a drop-in replacement for SFT fine-tuning or as a complement to it.\n",
      "\n",
      "**Before you begin:** Before building training your first model with DPO, make sure you’ve\n",
      "[created a dataset](https://docs.openpipe.ai/features/datasets/quick-start) and have collected at least 500 rows of\n",
      "training data on OpenPipe or another platform.\n",
      "\n",
      "1\n",
      "\n",
      "Prepare your Dataset\n",
      "\n",
      "To train a model with DPO, you need pairs of outputs containing preferred and rejected responses. You can prepare this data in one of two ways:\n",
      "\n",
      "1. **Upload a JSONL file**\n",
      "\n",
      "Add training rows to your dataset by [uploading a JSONL file](https://docs.openpipe.ai/features/datasets/uploading-data). Make sure to add a `rejected_message` field on each row that you’d like to use for preference tuning [(see docs)](https://docs.openpipe.ai/features/datasets/uploading-data#additional-fields).\n",
      "\n",
      "2. **Track Rejected Outputs**\n",
      "\n",
      "In the **Data Pipeline** view of your dataset, you can convert original outputs that have been overwritten by either an LLM (through an **LLM Relabel** node) or human (through a **Human Relabel** node) into rejected outputs. The original output will be treated as the negative example, and the replacement output will be treated as the positive example.\n",
      "    **LLM Relabel Node**\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "![LLM Relabel Node](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/dpo/llm-relabel-track-rejected-op.png)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "**Human Relabel Node**\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "![Human Relabel Node](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/dpo/human-relabel-track-rejected-op.png)\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "Configure Training Settings\n",
      "\n",
      "Once your dataset is ready, training a DPO model is similar to training an SFT model.\n",
      "\n",
      "1. Select the dataset you prepared for preference tuning.\n",
      "2. Adjust the base model.\n",
      "   - Currently, DPO is only supported on Llama 3.1 8B.\n",
      "3. Under **Advanced Options**, click the **Enable Preference Tuning** checkbox.\n",
      "\n",
      "![Enable Preference Tuning](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/dpo/enable-pt.png)\n",
      "\n",
      "3\n",
      "\n",
      "Adjust Hyperparameters (optional)\n",
      "\n",
      "You should now see the number of rows that will be used for supervised fine tuning\n",
      "( **SFT Row Count**)\n",
      "and preference tuning ( **Preference Row Count**). Rows in your dataset that only include a\n",
      "preferred output will be used for supervised fine tuning, while rows with both preferred and\n",
      "rejected outputs will be used for preference tuning.\n",
      "\n",
      "Adjust the training job’s hyperparameters if needed. We recommend using the default values if you’re unsure.\n",
      "\n",
      "![DPO Hyperparameters](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/dpo/dpo-hyperparams.png)\n",
      "\n",
      "4\n",
      "\n",
      "Start Training\n",
      "\n",
      "Finally, kick off a training job by clicking the **Start Training** button.\n",
      "\n",
      "[Overview](https://docs.openpipe.ai/features/dpo/overview) [Overview](https://docs.openpipe.ai/features/evaluations/overview)\n",
      "\n",
      "![LLM Relabel Node](https://docs.openpipe.ai/features/dpo/quick-start)\n",
      "\n",
      "![Human Relabel Node](https://docs.openpipe.ai/features/dpo/quick-start)\n",
      "\n",
      "![Enable Preference Tuning](https://docs.openpipe.ai/features/dpo/quick-start)\n",
      "\n",
      "![DPO Hyperparameters](https://docs.openpipe.ai/features/dpo/quick-start\n",
      "\n",
      "=== docs_openpipe_ai_features_chat_completions_moa.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Chat Completions\n",
      "\n",
      "Mixture of Agents Chat Completions\n",
      "\n",
      "In some cases, completions produced by GPT-4 or other SOTA models aren’t good enough to be used in production. To improve quality beyond the\n",
      "limit of SOTA models, we’ve developed a Mixture of Agents (MoA) technique that enhances quality but also increases cost and latency.\n",
      "\n",
      "To use MoA models, set the **model** parameter to be one of the following:\n",
      "\n",
      "- `openpipe:moa-gpt-4o-v1`\n",
      "- `openpipe:moa-gpt-4-turbo-v1`\n",
      "- `openpipe:moa-gpt-4-v1`\n",
      "\n",
      "To get the highest quality completions, use the MoA model that corresponds to the best-performing SOTA model.\n",
      "For instance, if your original model was `gpt-4-turbo-2024-04-09`, try switching to `openpipe:moa-gpt-4-turbo-v1`.\n",
      "\n",
      "Make sure to set your `OpenAI API Key` in the `Project Settings` page to enable MoA completions!\n",
      "\n",
      "- Python\n",
      "- NodeJS\n",
      "\n",
      "Copy\n",
      "\n",
      "```python\n",
      "from openpipe import OpenAI\n",
      "\n",
      "# Find the config values in \"Installing the SDK\"\n",
      "client = OpenAI()\n",
      "\n",
      "completion = client.chat.completions.create(\n",
      "    # model=\"gpt-4-turbo-2024-04-09\", - original model\n",
      "    model=\"openpipe:moa-gpt-4-turbo-v1\",\n",
      "    messages=[{\"role\": \"system\", \"content\": \"count to 10\"}],\n",
      "    metadata={\"prompt_id\": \"counting\", \"any_key\": \"any_value\"},\n",
      ")\n",
      "\n",
      "```\n",
      "\n",
      "To learn more, visit the [Mixture of Agents](https://docs.openpipe.ai/features/mixture-of-agents) page.\n",
      "\n",
      "[Gemini Proxy](https://docs.openpipe.ai/features/chat-completions/gemini) [Caching](https://docs.openpipe.ai/features/caching\n",
      "\n",
      "=== docs_openpipe_ai_api_reference_get_listDatasets.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Datasets\n",
      "\n",
      "List Datasets\n",
      "\n",
      "GET\n",
      "\n",
      "/\n",
      "\n",
      "datasets\n",
      "\n",
      "Try it\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request GET \\\n",
      "  --url https://api.openpipe.ai/api/v1/datasets \\\n",
      "  --header 'Authorization: Bearer <token>'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"object\": \"list\",\n",
      "  \"data\": [\\\n",
      "    {\\\n",
      "      \"object\": \"dataset\",\\\n",
      "      \"id\": \"<string>\",\\\n",
      "      \"name\": \"<string>\",\\\n",
      "      \"created\": \"<string>\",\\\n",
      "      \"updated\": \"<string>\",\\\n",
      "      \"dataset_entry_count\": 123,\\\n",
      "      \"fine_tune_count\": 123\\\n",
      "    }\\\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "#### Authorizations\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listDatasets#authorization-authorization)\n",
      "\n",
      "Authorization\n",
      "\n",
      "string\n",
      "\n",
      "header\n",
      "\n",
      "required\n",
      "\n",
      "Bearer authentication header of the form `Bearer <token>`, where `<token>` is your auth token.\n",
      "\n",
      "#### Response\n",
      "\n",
      "200 - application/json\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data)\n",
      "\n",
      "data\n",
      "\n",
      "object\\[\\]\n",
      "\n",
      "required\n",
      "\n",
      "Showchild attributes\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data-created)\n",
      "\n",
      "data.created\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data-dataset-entry-count)\n",
      "\n",
      "data.dataset\\_entry\\_count\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data-fine-tune-count)\n",
      "\n",
      "data.fine\\_tune\\_count\n",
      "\n",
      "number\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data-id)\n",
      "\n",
      "data.id\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data-name)\n",
      "\n",
      "data.name\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data-object)\n",
      "\n",
      "data.object\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`dataset`\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listDatasets#response-data-updated)\n",
      "\n",
      "data.updated\n",
      "\n",
      "string\n",
      "\n",
      "required\n",
      "\n",
      "[​](https://docs.openpipe.ai/api-reference/get-listDatasets#response-object)\n",
      "\n",
      "object\n",
      "\n",
      "enum<string>\n",
      "\n",
      "required\n",
      "\n",
      "Available options:\n",
      "\n",
      "`list`\n",
      "\n",
      "[Create Dataset](https://docs.openpipe.ai/api-reference/post-createDataset) [Delete Dataset](https://docs.openpipe.ai/api-reference/delete-dataset)\n",
      "\n",
      "cURL\n",
      "\n",
      "Python\n",
      "\n",
      "JavaScript\n",
      "\n",
      "PHP\n",
      "\n",
      "Go\n",
      "\n",
      "Java\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "curl --request GET \\\n",
      "  --url https://api.openpipe.ai/api/v1/datasets \\\n",
      "  --header 'Authorization: Bearer <token>'\n",
      "```\n",
      "\n",
      "200\n",
      "\n",
      "default\n",
      "\n",
      "Copy\n",
      "\n",
      "```\n",
      "{\n",
      "  \"object\": \"list\",\n",
      "  \"data\": [\\\n",
      "    {\\\n",
      "      \"object\": \"dataset\",\\\n",
      "      \"id\": \"<string>\",\\\n",
      "      \"name\": \"<string>\",\\\n",
      "      \"created\": \"<string>\",\\\n",
      "      \"updated\": \"<string>\",\\\n",
      "      \"dataset_entry_count\": 123,\\\n",
      "      \"fine_tune_count\": 123\\\n",
      "    }\\\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "=== docs_openpipe_ai_introduction.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Welcome\n",
      "\n",
      "OpenPipe Documentation\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/intro/dataset-general.png)\n",
      "\n",
      "[**Get Started** \\\\\n",
      "\\\\\n",
      "Quickly integrate the OpenPipe SDK into your application and start collecting data.](https://docs.openpipe.ai/getting-started/quick-start) [**Features** \\\\\n",
      "\\\\\n",
      "View the platform features OpenPipe provides and learn how to use them.](https://docs.openpipe.ai/overview#what-we-provide) [**Sample Project** \\\\\n",
      "\\\\\n",
      "Glance over the public demo we’ve set up to get an idea for how OpenPipe works.](https://app.openpipe.ai/p/BRZFEx50Pf/request-logs)\n",
      "\n",
      "[Overview](https://docs.openpipe.ai/overview)\n",
      "\n",
      "![](https://docs.openpipe.ai/introduction\n",
      "\n",
      "=== docs_openpipe_ai_features_datasets_relabeling_data.md ===\n",
      "Ctrl K\n",
      "\n",
      "Search...\n",
      "\n",
      "Navigation\n",
      "\n",
      "Datasets\n",
      "\n",
      "Relabeling Data\n",
      "\n",
      "After importing rows from request logs or uploading a JSONL file, you can optionally relabel\n",
      "each row by sending its messages, tools, and other input parameters to a more powerful model,\n",
      "which will generate an output to replace your row’s existing output. If time or cost constraints prevent\n",
      "you from using the most powerful model available in production, relabeling offers an opportunity to\n",
      "optimize the quality of your training data before kicking off a job.\n",
      "\n",
      "![](https://mintlify.s3.us-west-1.amazonaws.com/openpipe/images/features/relabeled-output.png)\n",
      "\n",
      "We currently include the following relabeling options:\n",
      "\n",
      "- gpt-4-turbo-2024-04-09\n",
      "- gpt-4o-2024-08-06\n",
      "- gpt-4-0125-preview\n",
      "- gpt-4-1106-preview\n",
      "- gpt-4-0613\n",
      "- moa-gpt-4o-v1 (Mixture of Agents)\n",
      "- moa-gpt-4-turbo-v1 (Mixture of Agents)\n",
      "- moa-gpt-4-v1 (Mixture of Agents)\n",
      "\n",
      "Learn more about Mixture of Agents, a powerful technique for optimizing quality at the cost of speed and price,\n",
      "on the [Mixture of Agents](https://docs.openpipe.ai/features/mixture-of-agents) page.\n",
      "\n",
      "[Uploading Data](https://docs.openpipe.ai/features/datasets/uploading-data) [Exporting Data](https://docs.openpipe.ai/features/datasets/exporting-data\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Concatenate contents with filenames as headers\n",
    "concatenated_text = \"\"\n",
    "for filename, content in stripped_markdown_contents.items():\n",
    "    concatenated_text += f\"=== {filename} ===\\n{content}\\n\\n\"\n",
    "\n",
    "print(concatenated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a dark winter night, wealthy and enigmatic Mr. John Q. Boddy hosted a small, but lavish, dinner party for some of his closest associates. However, the night ended in tragedy when Mr. Boddy was found dead in one of the rooms of Tudor Mansion in the early hours of the morning. The following persons of interest have been identified as suspects:\n",
      "\n",
      "• Miss Peach\n",
      "• Monsieur Brunette\n",
      "• Mr. Green\n",
      "• Professor Plum\n",
      "• Mrs. White\n",
      "• Colonel Mustard\n",
      "• Miss Scarlet\n",
      "• Mrs. Peacock\n",
      "• Sgt. Gray\n",
      "• Madame Rose\n",
      "\n",
      "And the following weapons were found on the premises:\n",
      "\n",
      "• Candlestick\n",
      "• Wrench\n",
      "• Lead Pipe\n",
      "• Revolver\n",
      "• Poison\n",
      "• Knife\n",
      "• Rope\n",
      "• Horseshoe\n",
      "\n",
      "The murder could only have occured in one of the following rooms:\n",
      "\n",
      "01. Studio\n",
      "02. Gazebo\n",
      "03. Lounge\n",
      "04. Drawing Room\n",
      "05. Library\n",
      "06. Trophy Room\n",
      "07. Cloak Room\n",
      "08. Courtyard\n",
      "09. Kitchen\n",
      "10. Fountain\n",
      "11. Dining Room\n",
      "12. Carriage House\n",
      "13. Ballroom\n",
      "\n",
      "The rooms are laid out as follows:\n",
      "\n",
      "  NN NN NN NN  \n",
      "W 01|02|03|04 E\n",
      "W 05|06|07|08 E\n",
      "W 09|10|11|12 E\n",
      "W 13|-|-|- E\n",
      "  SS SS SS SS  \n",
      "\n",
      "The exact time of the murder is a bit uncertain, but it has been narrowed down to one of the following times:\n",
      "\n",
      "• 08:00 PM\n",
      "• 09:00 PM\n",
      "• 10:00 PM\n",
      "• 11:00 PM\n",
      "• 12:00 AM\n",
      "• 01:00 AM\n",
      "• 02:00 AM\n",
      "• 03:00 AM\n",
      "\n",
      "At every time the suspects and Mr. Boddy either stayed in their current room or moved to an orthogonally adjacent room (north, south, east, or west). Weapons could be moved by suspects between rooms as well.\n",
      "\n",
      "Each suspect uniquely had one of the following possible motives for killing Mr. Boddy:\n",
      "\n",
      "• Jealousy\n",
      "• Ambition\n",
      "• Power\n",
      "• Betrayal\n",
      "• Anger\n",
      "• Fear\n",
      "• Greed\n",
      "• Hatred\n",
      "• Revenge\n",
      "• Pride\n",
      "\n",
      "For the murder to occur, the murderer and Mr. Boddy must have been alone in a room with at least one weapon at some point in the night. Any clue about Mr. Boddy's whereabouts should be read as \"Mr. Boddy (dead or alive) ...\"\n",
      "\n",
      "The available clues are as follows:\n",
      "\n",
      "- The murderer was in the Library at 12:00 AM\n",
      "- Mr. Green was at the Fountain at 12:00 AM\n",
      "- The Wrench was in the same room as Mr. Boddy at 10:00 PM\n",
      "- Mr. Boddy was in the Kitchen at 09:00 PM if and only if the suspect motivated by Fear was at the Fountain at 11:00 PM\n",
      "- Mr. Green was in the Trophy Room at 03:00 AM if and only if Mr. Boddy was in the Kitchen at 08:00 PM\n",
      "- Miss Scarlet was in the Library at 02:00 AM if and only if Mr. Green was in the Ballroom at 08:00 PM\n",
      "- Miss Scarlet was in the Ballroom at 08:00 PM if and only if Mr. Green was in the Trophy Room at 03:00 AM\n",
      "- Mrs. White moved from the Kitchen to the Library at 03:00 AM\n",
      "- Professor Plum and Madame Rose were in the Carriage House together at least once\n",
      "- The suspect motivated by Power moved the Poison from the Carriage House to the Courtyard at 11:00 PM\n",
      "- The suspect motivated by Hatred was in the Ballroom at 11:00 PM or the suspect motivated by Betrayal was in the Studio at 09:00 PM\n",
      "- Professor Plum was in the same room as Colonel Mustard at 08:00 PM\n",
      "- The suspect motivated by Pride was in the Trophy Room at 12:00 AM or the Horseshoe was in the Studio at 09:00 PM\n",
      "- Miss Scarlet was in the room just south of the Horseshoe at 12:00 AM\n",
      "- The Lead Pipe and Professor Plum were in the Courtyard together at least once\n",
      "- Mr. Boddy was murdered at 11:00 PM\n",
      "- The suspect motivated by Jealousy moved the Rope from the Trophy Room to the Library at 11:00 PM\n",
      "- Miss Scarlet was in the same room as Mrs. White at 08:00 PM\n",
      "- The murder weapon was in the same room as Miss Peach at 03:00 AM\n",
      "- The suspect motivated by Betrayal moved the Wrench from the Library to the Trophy Room at 03:00 AM\n",
      "- The suspect motivated by Ambition moved from the Lounge to the Gazebo at 11:00 PM\n",
      "- The suspect motivated by Anger moved from the Courtyard to the Cloak Room at 10:00 PM\n",
      "- The suspect motivated by Ambition moved from the Lounge to the Cloak Room at 03:00 AM\n",
      "- The suspect motivated by Greed was in the Kitchen at 01:00 AM\n",
      "- The Rope was in the room just north of the Knife at 08:00 PM\n",
      "- The Knife was in the same room as the Revolver at 09:00 PM\n",
      "- The Wrench was in the Carriage House at 11:00 PM or Mrs. White was in the Kitchen at 10:00 PM\n",
      "- The suspect motivated by Ambition moved from the Drawing Room to the Lounge at 09:00 PM\n",
      "- Miss Peach was in the Dining Room at 11:00 PM or the suspect motivated by Greed was in the Kitchen at 12:00 AM\n",
      "- The murderer was in the Library at 02:00 AM\n",
      "- Colonel Mustard moved from the Lounge to the Cloak Room at 11:00 PM\n",
      "- Madame Rose was in the Dining Room at 03:00 AM\n",
      "- Madame Rose was in the Dining Room at 02:00 AM\n",
      "- The suspect motivated by Anger moved from the Courtyard to the Carriage House at 12:00 AM\n",
      "- The Candlestick was in the Drawing Room at 10:00 PM\n",
      "- Mrs. Peacock moved from the Courtyard to the Carriage House at 12:00 AM\n",
      "- Mrs. Peacock moved the Poison from the Dining Room to the Carriage House at 10:00 PM\n",
      "- Mr. Green moved the Revolver from the Fountain to the Trophy Room at 02:00 AM\n",
      "- Mrs. Peacock was in the Courtyard at 01:00 AM\n",
      "- Colonel Mustard was in the room just south of Sgt. Gray at 01:00 AM\n",
      "- The suspect motivated by Betrayal was in the Ballroom at 09:00 PM if and only if the suspect motivated by Power was in the Carriage House at 10:00 PM\n",
      "- Miss Scarlet moved from the Ballroom to the Kitchen at 11:00 PM\n",
      "- Madame Rose was in the room just north of Mrs. Peacock at 08:00 PM\n",
      "- Miss Peach was in the Kitchen at 08:00 PM or the Horseshoe was in the Carriage House at 02:00 AM\n",
      "- Monsieur Brunette was in the Library at 01:00 AM\n",
      "- The suspect motivated by Hatred moved from the Kitchen to the Ballroom at 02:00 AM\n",
      "- Madame Rose moved from the Cloak Room to the Courtyard at 09:00 PM\n",
      "- Mr. Boddy was in the Kitchen at 09:00 PM\n",
      "- The suspect motivated by Pride moved from the Drawing Room to the Lounge at 10:00 PM\n",
      "- The Lead Pipe was in the Carriage House at 08:00 PM\n",
      "- The suspect motivated by Betrayal was in the Drawing Room at 02:00 AM or Miss Peach was in the Kitchen at 12:00 AM\n",
      "- The suspect motivated by Betrayal was in the Ballroom at 10:00 PM if and only if the suspect motivated by Power was in the Carriage House at 02:00 AM\n",
      "- The suspect motivated by Power was in the Carriage House at 03:00 AM\n",
      "- The murder weapon was in the Trophy Room at 08:00 PM\n",
      "- Mr. Green was in the Ballroom at 08:00 PM if and only if Professor Plum was in the Carriage House at 01:00 AM\n",
      "- Monsieur Brunette moved from the Cloak Room to the Trophy Room at 09:00 PM\n",
      "- Mrs. White and Monsieur Brunette were in the Library together at least once\n",
      "- Mr. Green moved from the Kitchen to the Fountain at 10:00 PM\n",
      "- Mrs. Peacock was in the room just north of Professor Plum at 03:00 AM\n",
      "- Madame Rose was in the Dining Room at 01:00 AM\n",
      "- Mr. Green was at the Fountain at 01:00 AM if and only if Professor Plum was in the Drawing Room at 08:00 PM\n",
      "- Mr. Green and the Knife were in the Trophy Room together at least once\n",
      "- Mr. Boddy was in the Dining Room at 10:00 PM or Mrs. Peacock was in the Courtyard at 02:00 AM\n",
      "- Miss Scarlet was in the same room as Mrs. White at 11:00 PM\n",
      "- The suspect motivated by Ambition was in the Gazebo at 12:00 AM\n",
      "- Miss Scarlet moved the Rope from the Library to the Trophy Room at 03:00 AM\n",
      "- The suspect motivated by Hatred moved from the Kitchen to the Ballroom at 10:00 PM\n",
      "- The suspect motivated by Power was in the same room as the Poison at 02:00 AM\n",
      "- Mrs. White moved from the Ballroom to the Kitchen at 09:00 PM\n",
      "- The Poison was in the same room as the Lead Pipe at 01:00 AM\n",
      "- The Wrench was in the same room as the Horseshoe at 12:00 AM\n",
      "- Miss Scarlet was in the Kitchen at 01:00 AM if and only if Professor Plum was in the Courtyard at 09:00 PM\n",
      "\n",
      "Please answer the following question(s):\n",
      "\n",
      "A. Who murdered Mr. Boddy?\n",
      "B. What weapon did the murderer use?\n",
      "C. Where was the murder committed?\n",
      "D. Why did the murderer do it?\n",
      "\n",
      "And the following bonus question(s):\n",
      "\n",
      "E. Where was the suspect motivated by Revenge at 03:00 AM?\n",
      "F. Where was the Candlestick at 01:00 AM?\n",
      "G. Where was the suspect motivated by Ambition at 08:00 PM?\n",
      "H. Where was the Revolver at 08:00 PM?\n",
      "\n",
      "Fill out your final answers in the following format:\n",
      "\n",
      "A. SUSPECT\n",
      "B. WEAPON\n",
      "C. ROOM\n",
      "D. MOTIVE\n",
      "E. ROOM\n",
      "F. ROOM\n",
      "G. ROOM\n",
      "H. ROOM\n",
      "\n",
      "Best of luck, detective.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"\"\"On a dark winter night, wealthy and enigmatic Mr. John Q. Boddy hosted a small, but lavish, dinner party for some of his closest associates. However, the night ended in tragedy when Mr. Boddy was found dead in one of the rooms of Tudor Mansion in the early hours of the morning. The following persons of interest have been identified as suspects:\\n\\n\\u2022 Miss Peach\\n\\u2022 Monsieur Brunette\\n\\u2022 Mr. Green\\n\\u2022 Professor Plum\\n\\u2022 Mrs. White\\n\\u2022 Colonel Mustard\\n\\u2022 Miss Scarlet\\n\\u2022 Mrs. Peacock\\n\\u2022 Sgt. Gray\\n\\u2022 Madame Rose\\n\\nAnd the following weapons were found on the premises:\\n\\n\\u2022 Candlestick\\n\\u2022 Wrench\\n\\u2022 Lead Pipe\\n\\u2022 Revolver\\n\\u2022 Poison\\n\\u2022 Knife\\n\\u2022 Rope\\n\\u2022 Horseshoe\\n\\nThe murder could only have occured in one of the following rooms:\\n\\n01. Studio\\n02. Gazebo\\n03. Lounge\\n04. Drawing Room\\n05. Library\\n06. Trophy Room\\n07. Cloak Room\\n08. Courtyard\\n09. Kitchen\\n10. Fountain\\n11. Dining Room\\n12. Carriage House\\n13. Ballroom\\n\\nThe rooms are laid out as follows:\\n\\n  NN NN NN NN  \\nW 01|02|03|04 E\\nW 05|06|07|08 E\\nW 09|10|11|12 E\\nW 13|-|-|- E\\n  SS SS SS SS  \\n\\nThe exact time of the murder is a bit uncertain, but it has been narrowed down to one of the following times:\\n\\n\\u2022 08:00 PM\\n\\u2022 09:00 PM\\n\\u2022 10:00 PM\\n\\u2022 11:00 PM\\n\\u2022 12:00 AM\\n\\u2022 01:00 AM\\n\\u2022 02:00 AM\\n\\u2022 03:00 AM\\n\\nAt every time the suspects and Mr. Boddy either stayed in their current room or moved to an orthogonally adjacent room (north, south, east, or west). Weapons could be moved by suspects between rooms as well.\\n\\nEach suspect uniquely had one of the following possible motives for killing Mr. Boddy:\\n\\n\\u2022 Jealousy\\n\\u2022 Ambition\\n\\u2022 Power\\n\\u2022 Betrayal\\n\\u2022 Anger\\n\\u2022 Fear\\n\\u2022 Greed\\n\\u2022 Hatred\\n\\u2022 Revenge\\n\\u2022 Pride\\n\\nFor the murder to occur, the murderer and Mr. Boddy must have been alone in a room with at least one weapon at some point in the night. Any clue about Mr. Boddy's whereabouts should be read as \\\"Mr. Boddy (dead or alive) ...\\\"\\n\\nThe available clues are as follows:\\n\\n- The murderer was in the Library at 12:00 AM\\n- Mr. Green was at the Fountain at 12:00 AM\\n- The Wrench was in the same room as Mr. Boddy at 10:00 PM\\n- Mr. Boddy was in the Kitchen at 09:00 PM if and only if the suspect motivated by Fear was at the Fountain at 11:00 PM\\n- Mr. Green was in the Trophy Room at 03:00 AM if and only if Mr. Boddy was in the Kitchen at 08:00 PM\\n- Miss Scarlet was in the Library at 02:00 AM if and only if Mr. Green was in the Ballroom at 08:00 PM\\n- Miss Scarlet was in the Ballroom at 08:00 PM if and only if Mr. Green was in the Trophy Room at 03:00 AM\\n- Mrs. White moved from the Kitchen to the Library at 03:00 AM\\n- Professor Plum and Madame Rose were in the Carriage House together at least once\\n- The suspect motivated by Power moved the Poison from the Carriage House to the Courtyard at 11:00 PM\\n- The suspect motivated by Hatred was in the Ballroom at 11:00 PM or the suspect motivated by Betrayal was in the Studio at 09:00 PM\\n- Professor Plum was in the same room as Colonel Mustard at 08:00 PM\\n- The suspect motivated by Pride was in the Trophy Room at 12:00 AM or the Horseshoe was in the Studio at 09:00 PM\\n- Miss Scarlet was in the room just south of the Horseshoe at 12:00 AM\\n- The Lead Pipe and Professor Plum were in the Courtyard together at least once\\n- Mr. Boddy was murdered at 11:00 PM\\n- The suspect motivated by Jealousy moved the Rope from the Trophy Room to the Library at 11:00 PM\\n- Miss Scarlet was in the same room as Mrs. White at 08:00 PM\\n- The murder weapon was in the same room as Miss Peach at 03:00 AM\\n- The suspect motivated by Betrayal moved the Wrench from the Library to the Trophy Room at 03:00 AM\\n- The suspect motivated by Ambition moved from the Lounge to the Gazebo at 11:00 PM\\n- The suspect motivated by Anger moved from the Courtyard to the Cloak Room at 10:00 PM\\n- The suspect motivated by Ambition moved from the Lounge to the Cloak Room at 03:00 AM\\n- The suspect motivated by Greed was in the Kitchen at 01:00 AM\\n- The Rope was in the room just north of the Knife at 08:00 PM\\n- The Knife was in the same room as the Revolver at 09:00 PM\\n- The Wrench was in the Carriage House at 11:00 PM or Mrs. White was in the Kitchen at 10:00 PM\\n- The suspect motivated by Ambition moved from the Drawing Room to the Lounge at 09:00 PM\\n- Miss Peach was in the Dining Room at 11:00 PM or the suspect motivated by Greed was in the Kitchen at 12:00 AM\\n- The murderer was in the Library at 02:00 AM\\n- Colonel Mustard moved from the Lounge to the Cloak Room at 11:00 PM\\n- Madame Rose was in the Dining Room at 03:00 AM\\n- Madame Rose was in the Dining Room at 02:00 AM\\n- The suspect motivated by Anger moved from the Courtyard to the Carriage House at 12:00 AM\\n- The Candlestick was in the Drawing Room at 10:00 PM\\n- Mrs. Peacock moved from the Courtyard to the Carriage House at 12:00 AM\\n- Mrs. Peacock moved the Poison from the Dining Room to the Carriage House at 10:00 PM\\n- Mr. Green moved the Revolver from the Fountain to the Trophy Room at 02:00 AM\\n- Mrs. Peacock was in the Courtyard at 01:00 AM\\n- Colonel Mustard was in the room just south of Sgt. Gray at 01:00 AM\\n- The suspect motivated by Betrayal was in the Ballroom at 09:00 PM if and only if the suspect motivated by Power was in the Carriage House at 10:00 PM\\n- Miss Scarlet moved from the Ballroom to the Kitchen at 11:00 PM\\n- Madame Rose was in the room just north of Mrs. Peacock at 08:00 PM\\n- Miss Peach was in the Kitchen at 08:00 PM or the Horseshoe was in the Carriage House at 02:00 AM\\n- Monsieur Brunette was in the Library at 01:00 AM\\n- The suspect motivated by Hatred moved from the Kitchen to the Ballroom at 02:00 AM\\n- Madame Rose moved from the Cloak Room to the Courtyard at 09:00 PM\\n- Mr. Boddy was in the Kitchen at 09:00 PM\\n- The suspect motivated by Pride moved from the Drawing Room to the Lounge at 10:00 PM\\n- The Lead Pipe was in the Carriage House at 08:00 PM\\n- The suspect motivated by Betrayal was in the Drawing Room at 02:00 AM or Miss Peach was in the Kitchen at 12:00 AM\\n- The suspect motivated by Betrayal was in the Ballroom at 10:00 PM if and only if the suspect motivated by Power was in the Carriage House at 02:00 AM\\n- The suspect motivated by Power was in the Carriage House at 03:00 AM\\n- The murder weapon was in the Trophy Room at 08:00 PM\\n- Mr. Green was in the Ballroom at 08:00 PM if and only if Professor Plum was in the Carriage House at 01:00 AM\\n- Monsieur Brunette moved from the Cloak Room to the Trophy Room at 09:00 PM\\n- Mrs. White and Monsieur Brunette were in the Library together at least once\\n- Mr. Green moved from the Kitchen to the Fountain at 10:00 PM\\n- Mrs. Peacock was in the room just north of Professor Plum at 03:00 AM\\n- Madame Rose was in the Dining Room at 01:00 AM\\n- Mr. Green was at the Fountain at 01:00 AM if and only if Professor Plum was in the Drawing Room at 08:00 PM\\n- Mr. Green and the Knife were in the Trophy Room together at least once\\n- Mr. Boddy was in the Dining Room at 10:00 PM or Mrs. Peacock was in the Courtyard at 02:00 AM\\n- Miss Scarlet was in the same room as Mrs. White at 11:00 PM\\n- The suspect motivated by Ambition was in the Gazebo at 12:00 AM\\n- Miss Scarlet moved the Rope from the Library to the Trophy Room at 03:00 AM\\n- The suspect motivated by Hatred moved from the Kitchen to the Ballroom at 10:00 PM\\n- The suspect motivated by Power was in the same room as the Poison at 02:00 AM\\n- Mrs. White moved from the Ballroom to the Kitchen at 09:00 PM\\n- The Poison was in the same room as the Lead Pipe at 01:00 AM\\n- The Wrench was in the same room as the Horseshoe at 12:00 AM\\n- Miss Scarlet was in the Kitchen at 01:00 AM if and only if Professor Plum was in the Courtyard at 09:00 PM\\n\\nPlease answer the following question(s):\\n\\nA. Who murdered Mr. Boddy?\\nB. What weapon did the murderer use?\\nC. Where was the murder committed?\\nD. Why did the murderer do it?\\n\\nAnd the following bonus question(s):\\n\\nE. Where was the suspect motivated by Revenge at 03:00 AM?\\nF. Where was the Candlestick at 01:00 AM?\\nG. Where was the suspect motivated by Ambition at 08:00 PM?\\nH. Where was the Revolver at 08:00 PM?\\n\\nFill out your final answers in the following format:\\n\\nA. SUSPECT\\nB. WEAPON\\nC. ROOM\\nD. MOTIVE\\nE. ROOM\\nF. ROOM\\nG. ROOM\\nH. ROOM\\n\\nBest of luck, detective.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-Avax6KV8klyDUhaylq4PeO1KiIE6s', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Ranking all the Presidents of the United States from best to worst is a complex and inherently subjective task. To approach this systematically, I have developed an exhaustive rubric that evaluates each president based on multiple key criteria. This rubric aims to provide a balanced and comprehensive assessment of each president's performance and legacy.\\n\\n**Ranking Rubric for U.S. Presidents**\\n\\nThe following criteria are used to evaluate each president, along with their respective weightings to reflect their importance:\\n\\n1. **Leadership and Vision (20 points)**\\n   - Ability to provide clear direction and inspire the nation.\\n   - Articulation of a compelling and effective vision for the country’s future.\\n\\n2. **Economic Management (15 points)**\\n   - Success in promoting economic growth and stability.\\n   - Effectiveness in managing federal budgets, taxes, and addressing unemployment.\\n\\n3. **Foreign Policy and National Security (15 points)**\\n   - Handling of international relations, treaties, and conflicts.\\n   - Measures taken to ensure the nation’s security and global standing.\\n\\n4. **Crisis Management (15 points)**\\n   - Effectiveness in leading the nation through crises (e.g., wars, economic downturns, natural disasters).\\n   - Ability to make decisive and impactful decisions under pressure.\\n\\n5. **Domestic Policy and Legislative Accomplishments (15 points)**\\n   - Success in passing significant legislation and reforms.\\n   - Impact of domestic policies on social welfare, healthcare, education, etc.\\n\\n6. **Moral Authority and Integrity (10 points)**\\n   - Upholding ethical standards and combating corruption.\\n   - Building and maintaining public trust.\\n\\n7. **Communication Skills (10 points)**\\n   - Effectiveness in communicating with the public, media, and Congress.\\n   - Ability to articulate policies and handle public relations.\\n\\nEach category is scored on a scale, with the total possible score being 100 points. The presidents are then ranked based on their cumulative scores.\\n\\n**Rankings of U.S. Presidents**\\n\\nBelow is the ranking of all U.S. Presidents based on the above rubric. Due to the extensive nature of this list, the table provides each president's scores across the seven criteria and their total score out of 100.\\n\\n| Rank | President                     | Leadership & Vision (20) | Economic Management (15) | Foreign Policy & Nat. Security (15) | Crisis Management (15) | Domestic Policy & Legislative (15) | Moral Authority & Integrity (10) | Communication Skills (10) | Total (100) |\\n|------|-------------------------------|--------------------------|--------------------------|-------------------------------------|------------------------|-------------------------------------|-----------------------------------|--------------------------|-------------|\\n| 1    | Abraham Lincoln               | 20                       | 14                       | 15                                  | 15                     | 15                                  | 10                                | 10                       | 99          |\\n| 2    | George Washington             | 19                       | 13                       | 14                                  | 14                     | 14                                  | 10                                | 10                       | 94          |\\n| 3    | Franklin D. Roosevelt         | 19                       | 15                       | 14                                  | 15                     | 15                                  | 9                                 | 10                       | 97          |\\n| 4    | Theodore Roosevelt            | 18                       | 14                       | 15                                  | 14                     | 14                                  | 8                                 | 10                       | 93          |\\n| 5    | Thomas Jefferson              | 18                       | 13                       | 14                                  | 13                     | 14                                  | 9                                 | 10                       | 91          |\\n| 6    | Dwight D. Eisenhower          | 17                       | 14                       | 14                                  | 14                     | 14                                  | 9                                 | 9                        | 91          |\\n| 7    | Harry S. Truman               | 17                       | 14                       | 13                                  | 14                     | 14                                  | 9                                 | 9                        | 89          |\\n| 8    | James Madison                 | 16                       | 13                       | 13                                  | 13                     | 13                                  | 9                                 | 9                        | 86          |\\n| 9    | James Monroe                  | 16                       | 13                       | 13                                  | 13                     | 13                                  | 9                                 | 9                        | 86          |\\n| 10   | Ronald Reagan                 | 16                       | 15                       | 14                                  | 13                     | 13                                  | 7                                 | 9                        | 87          |\\n| 11   | John Adams                    | 15                       | 13                       | 13                                  | 13                     | 13                                  | 8                                 | 9                        | 84          |\\n| 12   | James K. Polk                 | 15                       | 14                       | 14                                  | 14                     | 14                                  | 9                                 | 9                        | 99          |\\n| 13   | Lyndon B. Johnson             | 15                       | 14                       | 13                                  | 14                     | 14                                  | 8                                 | 9                        | 85          |\\n| 14   | Barack Obama                  | 15                       | 13                       | 14                                  | 14                     | 14                                  | 8                                 | 9                        | 87          |\\n| 15   | Andrew Jackson                | 14                       | 14                       | 13                                  | 13                     | 13                                  | 7                                 | 9                        | 83          |\\n| 16   | Ulysses S. Grant              | 14                       | 13                       | 13                                  | 13                     | 13                                  | 7                                 | 9                        | 82          |\\n| 17   | William McKinley              | 14                       | 14                       | 14                                  | 13                     | 13                                  | 7                                 | 9                        | 84          |\\n| 18   | William Howard Taft           | 13                       | 13                       | 13                                  | 13                     | 13                                  | 6                                 | 9                        | 80          |\\n| 19   | Woodrow Wilson                | 13                       | 13                       | 14                                  | 14                     | 14                                  | 7                                 | 9                        | 84          |\\n| 20   | Calvin Coolidge               | 13                       | 14                       | 13                                  | 13                     | 13                                  | 7                                 | 9                        | 82          |\\n| 21   | Harry S. Truman               | 13                       | 12                       | 13                                  | 13                     | 13                                  | 8                                 | 9                        | 81          |\\n| 22   | Martin Van Buren              | 12                       | 13                       | 12                                  | 12                     | 12                                  | 7                                 | 8                        | 76          |\\n| 23   | Grover Cleveland              | 12                       | 13                       | 12                                  | 12                     | 12                                  | 7                                 | 8                        | 76          |\\n| 24   | Benjamin Harrison             | 12                       | 12                       | 12                                  | 12                     | 12                                  | 7                                 | 8                        | 75          |\\n| 25   | Herbert Hoover                | 11                       | 12                       | 11                                  | 11                     | 12                                  | 6                                 | 8                        | 71          |\\n| 26   | Rutherford B. Hayes           | 11                       | 12                       | 11                                  | 11                     | 11                                  | 7                                 | 8                        | 71          |\\n| 27   | John Quincy Adams             | 11                       | 12                       | 11                                  | 11                     | 11                                  | 7                                 | 8                        | 71          |\\n| 28   | Franklin Pierce               | 10                       | 11                       | 10                                  | 10                     | 11                                  | 6                                 | 7                        | 65          |\\n| 29   | James Buchanan                | 10                       | 11                       | 10                                  | 10                     | 11                                  | 6                                 | 7                        | 65          |\\n| 30   | Millard Fillmore              | 10                       | 11                       | 10                                  | 10                     | 11                                  | 6                                 | 7                        | 65          |\\n| 31   | John Tyler                    | 10                       | 11                       | 10                                  | 10                     | 11                                  | 6                                 | 7                        | 65          |\\n| 32   | Chester A. Arthur             | 10                       | 11                       | 10                                  | 10                     | 11                                  | 6                                 | 7                        | 65          |\\n| 33   | James A. Garfield             | 10                       | 11                       | 10                                  | 10                     | 11                                  | 6                                 | 7                        | 65          |\\n| 34   | Franklin D. Roosevelt         | 10                       | 11                       | 10                                  | 10                     | 11                                  | 6                                 | 7                        | 65          |\\n| 35   | Theodore Roosevelt            | 10                       | 11                       | 10                                  | 10                     | 11                                  | 6                                 | 7                        | 65          |\\n| 36   | Warren G. Harding             | 9                        | 10                       | 9                                   | 9                      | 10                                  | 5                                 | 7                        | 59          |\\n| 37   | William Henry Harrison        | 9                        | 10                       | 9                                   | 9                      | 10                                  | 5                                 | 7                        | 59          |\\n| 38   | George H. W. Bush             | 9                        | 10                       | 9                                   | 9                      | 10                                  | 5                                 | 7                        | 59          |\\n| 39   | Jimmy Carter                  | 8                        | 9                        | 8                                   | 8                      | 9                                   | 5                                 | 7                        | 54          |\\n| 40   | Gerald Ford                   | 8                        | 9                        | 8                                   | 8                      | 9                                   | 5                                 | 7                        | 54          |\\n| 41   | Joe Biden                     | 8                        | 9                        | 8                                   | 8                      | 9                                   | 5                                 | 7                        | 54          |\\n| 42   | Richard Nixon                 | 7                        | 8                        | 7                                   | 8                      | 8                                   | 4                                 | 7                        | 49          |\\n| 43   | James Buchanan                | 7                        | 8                        | 7                                   | 8                      | 8                                   | 4                                 | 7                        | 49          |\\n| 44   | Andrew Johnson                | 6                        | 7                        | 6                                   | 7                      | 7                                   | 3                                 | 7                        | 47          |\\n| 45   | Donald Trump                  | 5                        | 6                        | 5                                   | 6                      | 6                                   | 2                                 | 6                        | 36          |\\n| 46   | John Adams                    | 4                        | 5                        | 4                                   | 5                      | 5                                   | 1                                 | 5                        | 29          |\\n\\n**Notes on the Rankings:**\\n\\n- **Abraham Lincoln** consistently ranks at the top due to his leadership during the Civil War and his role in ending slavery.\\n- **George Washington** is highly regarded for setting many precedents for the new government and maintaining national unity.\\n- **Franklin D. Roosevelt** is celebrated for his New Deal policies and leadership during World War II.\\n- **Donald Trump** and **John Adams** rank lower based on the criteria evaluated, including leadership challenges and controversies.\\n\\n**Caveats:**\\n\\n- **Subjectivity:** Despite the comprehensive rubric, the evaluation of presidential performance is inherently subjective. Different historians and political scientists may prioritize criteria differently, leading to variations in rankings.\\n- **Historical Context:** Presidents served in vastly different historical contexts, making direct comparisons challenging. The impact of a president’s actions can be interpreted differently over time.\\n- **Evolving Standards:** Societal values and expectations evolve, which can influence the perception of a president’s effectiveness and legacy.\\n\\n**Conclusion:**\\n\\nThis ranking provides a structured assessment based on the defined rubric, offering a comparative overview of U.S. presidents. It is essential to consider the broader historical and societal contexts when evaluating presidential performance, recognizing that each president faced unique challenges and circumstances.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1738290104, model='o1-mini-2024-09-12', object='chat.completion', service_tier='default', system_fingerprint='fp_f56e40de61', usage=CompletionUsage(completion_tokens=4456, prompt_tokens=25, total_tokens=4481, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=1728, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "client = AsyncOpenAI()\n",
    "await client.chat.completions.create(\n",
    "    model=\"o1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Develop an exhaustive rubric and rank all the presidents of the United States from best to worst.\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "704 / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'without_mask': torch.Size([2, 5, 8]), 'with_mask': torch.Size([2, 5, 8])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, dim: int) -> None:\n",
    "        super().__init__()\n",
    "        self.wq = torch.nn.Linear(dim, dim, bias=False)\n",
    "        self.wk = torch.nn.Linear(dim, dim, bias=False)\n",
    "        self.wv = torch.nn.Linear(dim, dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor | None = None) -> torch.Tensor:\n",
    "        Q = self.wq(x)  # [batch_size, seq_len, dim]\n",
    "        K = self.wk(x)  # [batch_size, seq_len, dim]\n",
    "        V = self.wv(x)  # [batch_size, seq_len, dim]\n",
    "\n",
    "        # Compute scaled dot-product attention\n",
    "        attention = Q @ K.transpose(-2, -1)  # [batch_size, seq_len, seq_len]\n",
    "        attention /= Q.shape[-1] ** 0.5  # Scale by sqrt of dimension\n",
    "        \n",
    "        if mask is not None:  # Check for mask presence\n",
    "            attention += mask.to(attention.dtype) * -1e9\n",
    "        \n",
    "        attention = torch.softmax(attention, dim=-1)  # Apply softmax along seq_len\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = attention @ V  # [batch_size, seq_len, dim]\n",
    "        return output\n",
    "\n",
    "\n",
    "# Test the updated Attention module\n",
    "\n",
    "# Create a random input tensor\n",
    "batch_size = 2\n",
    "seq_len = 5\n",
    "dim = 8\n",
    "x = torch.randn(batch_size, seq_len, dim)\n",
    "\n",
    "# Instantiate the Attention module\n",
    "attention_module = Attention(dim=dim)\n",
    "\n",
    "# Test 1: Without Mask\n",
    "output_no_mask = attention_module(x)\n",
    "\n",
    "# Test 2: With Mask (causal mask example)\n",
    "mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).unsqueeze(0).repeat(batch_size, 1, 1) * -1e9\n",
    "output_with_mask = attention_module(x, mask=mask)\n",
    "\n",
    "# Output shapes\n",
    "output_shapes = {\n",
    "    \"without_mask\": output_no_mask.shape,\n",
    "    \"with_mask\": output_with_mask.shape\n",
    "}\n",
    "output_shapes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
