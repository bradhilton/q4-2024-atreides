{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.langfuse import langfuse\n",
    "# langfuse.enabled = False\n",
    "langfuse.auth_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from lib.rl.episode import Episode, EpisodeCompletion\n",
    "import random\n",
    "import re\n",
    "from typing import TypedDict\n",
    "\n",
    "\n",
    "class TemporalCluePuzzle(TypedDict):\n",
    "    num_clues: int\n",
    "    prompt: str\n",
    "    solution: dict[str, str]\n",
    "\n",
    "\n",
    "temporal_clue_puzzles: list[TemporalCluePuzzle] = json.load(\n",
    "    open(\"./data/temporal-clue-puzzles.json\")\n",
    ")\n",
    "random.seed(42)\n",
    "random.shuffle(temporal_clue_puzzles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_of_thought_examples: list[dict[str, str]] = json.load(\n",
    "    open(\"./data/chain-of-thought-examples.json\")\n",
    ")\n",
    "chain_of_thought_examples.pop(6)\n",
    "chain_of_thought_examples.pop(3)\n",
    "\n",
    "def get_episode(puzzle: TemporalCluePuzzle) -> Episode:\n",
    "\n",
    "    def validate(completion: EpisodeCompletion) -> None:\n",
    "        ...\n",
    "\n",
    "    def on_sample(completions: list[EpisodeCompletion]) -> None:\n",
    "        for completion in completions:\n",
    "            content = completion.last_assistant_message.get(\"content\")\n",
    "            assert isinstance(content, str)\n",
    "            num_correct = 0\n",
    "            for key, value in puzzle[\"solution\"].items():\n",
    "                if matches := re.findall(rf\"{key}\\. ([A-Za-z \\.:-]+)\", content):\n",
    "                    match = matches[-1]\n",
    "                    if match.strip().lower() == value.lower():\n",
    "                        num_correct += 1\n",
    "            completion.commit(reward=num_correct / len(puzzle[\"solution\"]))\n",
    "            \n",
    "    example = random.choices(chain_of_thought_examples, k=1)\n",
    "\n",
    "    return Episode(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": puzzle[\"prompt\"]\n",
    "                .replace(\n",
    "                    \"Fill out your final answers in the following format:\",\n",
    "                    \"After verifiably finding all the correct answers, fill out your final answers in the following format:\",\n",
    "                )\n",
    "                ,\n",
    "            },\n",
    "            # {\n",
    "            #     \"role\": \"assistant\",\n",
    "            #     \"content\": \"Let's think this through step by step...\",\n",
    "            # },\n",
    "        ],\n",
    "        on_sample=on_sample,\n",
    "        examples=[\n",
    "            {\"role\": \"user\", \"content\": example[0][\"prompt\"]},\n",
    "            {\n",
    "                \"role\": \"assistant\", \n",
    "                \"content\": example[0][\"chain_of_thought\"]\n",
    "                + (example[0][\"answer\"] and f\"\\n\\n---\\n\\n{example[0]['answer']}\"),\n",
    "            },\n",
    "            # {\"role\": \"user\", \"content\": example[1][\"prompt\"]},\n",
    "            # {\n",
    "            #     \"role\": \"assistant\",\n",
    "            #     \"content\": example[1][\"chain_of_thought\"] \n",
    "            #     + (example[1][\"answer\"] and f\"\\n\\n---\\n\\n{example[1]['answer']}\"),\n",
    "            # },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "temporal_clue_episodes = [get_episode(puzzle) for puzzle in temporal_clue_puzzles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "zebra_grid_questions = pl.read_parquet(\n",
    "    \"hf://datasets/allenai/ZebraLogicBench-private/grid_mode/test-00000-of-00001.parquet\"\n",
    ").to_dicts()\n",
    "random.shuffle(zebra_grid_questions)\n",
    "\n",
    "\n",
    "def get_episode(question: dict) -> Episode:\n",
    "    prompt = f\"\"\"{question[\"puzzle\"]}\n",
    "Fill in the grid with the correct values:\n",
    "\n",
    "| {' | '.join(question[\"solution\"][\"header\"])} |\n",
    "| {' | '.join([\"-\" * len(header) for header in question[\"solution\"][\"header\"]])} |\n",
    "\"\"\"\n",
    "\n",
    "    for _ in question[\"solution\"][\"rows\"]:\n",
    "        prompt += f\"| {' | '.join([\" \" * len(header) for header in question[\"solution\"][\"header\"]])} |\\n\"\n",
    "\n",
    "    pattern = re.compile(\n",
    "        r\"\\| \" + r\"\\|\".join(r\"(.*?)\" for _ in question[\"solution\"][\"header\"]) + r\" \\|\"\n",
    "    )\n",
    "\n",
    "    def on_sample(completions: list[EpisodeCompletion]):\n",
    "        for completion in completions:\n",
    "            assert \"content\" in completion.last_assistant_message and isinstance(\n",
    "                completion.last_assistant_message[\"content\"], str\n",
    "            )\n",
    "            num_cells = sum(len(row) for row in question[\"solution\"][\"rows\"])\n",
    "            num_correct = 0\n",
    "            for match, row in zip(\n",
    "                re.findall(pattern, completion.last_assistant_message[\"content\"])[\n",
    "                    -len(question[\"solution\"][\"rows\"]) :\n",
    "                ],\n",
    "                question[\"solution\"][\"rows\"],\n",
    "            ):\n",
    "                for cell, value in zip(match, row):\n",
    "                    if cell.strip().lower() == value.lower():\n",
    "                        num_correct += 1\n",
    "            completion.commit(reward=num_correct / num_cells)\n",
    "\n",
    "    return Episode(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        on_sample=on_sample,\n",
    "    )\n",
    "\n",
    "zebra_grid_episodes = [get_episode(question) for question in zebra_grid_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "math_questions = list(\n",
    "    load_dataset(\"lighteval/MATH\", \"all\")[\"train\"].to_iterable_dataset()  # type: ignore\n",
    ")\n",
    "random.shuffle(math_questions)\n",
    "\n",
    "\n",
    "question_solution = None\n",
    "pattern = re.compile(r\"\\\\boxed{([^}]+)}\")\n",
    "\n",
    "\n",
    "def get_episode(question: dict) -> Episode:\n",
    "    prompt = (\n",
    "        f\"{question['problem']}\\n\\n\"\n",
    "        \"Solve this math problem and show your work. Your final answer MUST be \"\n",
    "        \"formatted in a LaTeX box using \\\\boxed{{}}. For example: \"\n",
    "        \"$1+1=\\\\boxed{{2}}$\\n\\n\"\n",
    "        \"You can submit multiple attempts. Each attempt should end with a boxed \"\n",
    "        \"answer. Your last answer will be weighted the most, but you can get \"\n",
    "        \"partial credit if an earlier answer is correct. If after multiple \"\n",
    "        \"attempts you decide an earlier answer is the correct one, just submit \"\n",
    "        \"it again to get full credit.\"\n",
    "    )\n",
    "\n",
    "    global question_solution\n",
    "    question_solution = question[\"solution\"]\n",
    "    solution = re.search(pattern, question[\"solution\"])\n",
    "    assert solution is not None, question[\"solution\"]\n",
    "    solution = solution.group(1)\n",
    "\n",
    "    def on_sample(completions: list[EpisodeCompletion]):\n",
    "        for completion in completions:\n",
    "            content = completion.last_assistant_message.get(\"content\")\n",
    "            assert isinstance(content, str)\n",
    "            solutions = [\n",
    "                match.group(1) for match in re.finditer(r\"\\\\boxed{([^}]+)}\", content)\n",
    "            ][::-1]\n",
    "            try:\n",
    "                reward = 0.9 ** solutions.index(solution)\n",
    "            except ValueError:\n",
    "                reward = 0\n",
    "            completion.commit(reward=reward)\n",
    "\n",
    "    return Episode(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        on_sample=on_sample,\n",
    "    )\n",
    "\n",
    "\n",
    "math_episodes = [\n",
    "    get_episode(question)\n",
    "    for question in math_questions[:2048]\n",
    "    if re.search(pattern, question[\"solution\"]) is not None\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from dataclasses import dataclass, field\n",
    "from lib.rl.completion import SplitMethod\n",
    "from lib.rl.completion_sampler import CompletionSampler, SamplingKwargs\n",
    "from lib.rl.trainer import ExploreImpl, ExploreOptions\n",
    "from lib.tokenizer import Tokenizer\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DefaultExploreImpl(ExploreImpl):\n",
    "    explore_options: ExploreOptions\n",
    "\n",
    "    async def __call__(\n",
    "        self,\n",
    "        completion_sampler: CompletionSampler,\n",
    "        tokenizer: Tokenizer,\n",
    "        ready_episodes: asyncio.Queue[Episode],\n",
    "        done_episodes: asyncio.Queue[Episode | BaseException],\n",
    "        update_progress: Callable[[float], None],\n",
    "    ) -> None:\n",
    "        def done_callback(task: asyncio.Task[Episode]) -> None:\n",
    "            try:\n",
    "                done_episodes.put_nowait(task.result())\n",
    "            except BaseException as exception:\n",
    "                done_episodes.put_nowait(exception)\n",
    "\n",
    "        priority = 1\n",
    "        while episode := await ready_episodes.get():\n",
    "            asyncio.create_task(\n",
    "                self._explore_episode(\n",
    "                    completion_sampler, tokenizer, episode, update_progress, priority\n",
    "                )\n",
    "            ).add_done_callback(done_callback)\n",
    "            priority += 1\n",
    "\n",
    "    async def _explore_episode(\n",
    "        self,\n",
    "        completion_sampler: CompletionSampler,\n",
    "        tokenizer: Tokenizer,\n",
    "        episode: Episode,\n",
    "        update_progress: Callable[[float], None],\n",
    "        priority: int,\n",
    "    ) -> Episode:\n",
    "        for _ in range(self.explore_options.iterations):\n",
    "            await episode.sample_completions(\n",
    "                completion_sampler=completion_sampler,\n",
    "                tokenizer=tokenizer,\n",
    "                num_parents=self.explore_options.num_parents,\n",
    "                branch_factor=self.explore_options.branch_factor,\n",
    "                get_recovery_pattern=self.explore_options.get_recovery_pattern,\n",
    "                max_splits_per_completion=self.explore_options.max_split_points\n",
    "                or self.explore_options.num_parents,\n",
    "                priority=priority,\n",
    "                sample_probability_power=self.explore_options.get_sample_probability_power(),\n",
    "                sampling_kwargs=self.explore_options.sampling_kwargs,\n",
    "                split_by=self.explore_options.split_method,\n",
    "                split_separators=self.explore_options.split_separators,\n",
    "            )\n",
    "            update_progress(1 / self.explore_options.iterations)\n",
    "        return episode\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SimpleExploreImpl(ExploreImpl):\n",
    "    num_samples: int\n",
    "    sampling_kwargs: SamplingKwargs | None = None\n",
    "\n",
    "    async def __call__(\n",
    "        self,\n",
    "        completion_sampler: CompletionSampler,\n",
    "        tokenizer: Tokenizer,\n",
    "        ready_episodes: asyncio.Queue[Episode],\n",
    "        done_episodes: asyncio.Queue[Episode | BaseException],\n",
    "        update_progress: Callable[[float], None],\n",
    "    ) -> None:\n",
    "        while episode := await ready_episodes.get():\n",
    "            task = asyncio.create_task(\n",
    "                episode.sample_completions(\n",
    "                    completion_sampler,\n",
    "                    tokenizer,\n",
    "                    num_parents=1,\n",
    "                    branch_factor=self.num_samples,\n",
    "                    sampling_kwargs=self.sampling_kwargs,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            def done_callback(_: asyncio.Task[bool], episode=episode) -> None:\n",
    "                try:\n",
    "                    done_episodes.put_nowait(episode)\n",
    "                    update_progress(1)\n",
    "                except BaseException as e:\n",
    "                    done_episodes.put_nowait(e)\n",
    "\n",
    "            task.add_done_callback(done_callback)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TreeExploreImpl(ExploreImpl):\n",
    "    branch_factor: int\n",
    "    depth: int\n",
    "    sampling_kwargs: SamplingKwargs | None = None\n",
    "    split_method: SplitMethod = \"count\"\n",
    "    split_separators: set[str] = field(default_factory=set)\n",
    "\n",
    "    async def __call__(\n",
    "        self,\n",
    "        completion_sampler: CompletionSampler,\n",
    "        tokenizer: Tokenizer,\n",
    "        ready_episodes: asyncio.Queue[Episode],\n",
    "        done_episodes: asyncio.Queue[Episode | BaseException],\n",
    "        update_progress: Callable[[float], None],\n",
    "    ) -> None:\n",
    "        model = await completion_sampler.get_model()\n",
    "\n",
    "        async def expand(episode: Episode, priority: int) -> None:\n",
    "            pending: set[asyncio.Task] = {\n",
    "                asyncio.create_task(\n",
    "                    episode.sample_completions(\n",
    "                        completion_sampler,\n",
    "                        tokenizer,\n",
    "                        num_parents=1,\n",
    "                        branch_factor=self.branch_factor,\n",
    "                        priority=priority,\n",
    "                        sampling_kwargs=self.sampling_kwargs,\n",
    "                        split_by=self.split_method,\n",
    "                        split_separators=self.split_separators,\n",
    "                    )\n",
    "                )\n",
    "            }\n",
    "\n",
    "            num_leaves = 0\n",
    "            while pending:\n",
    "                finished, pending = await asyncio.wait(\n",
    "                    pending, return_when=asyncio.FIRST_COMPLETED\n",
    "                )\n",
    "                for task in finished:\n",
    "                    try:\n",
    "                        task.result()\n",
    "                    except BaseException as e:\n",
    "                        await done_episodes.put(e)\n",
    "                        return\n",
    "                _num_leaves = 0\n",
    "                for leaf in episode.completion.leaves(model=model):\n",
    "                    _num_leaves += 1\n",
    "                    num_partitions = self.depth - leaf.depth() + 1\n",
    "                    if num_partitions > 1:\n",
    "                        parents = list(\n",
    "                            leaf.split(\n",
    "                                by=self.split_method,\n",
    "                                at=(\n",
    "                                    split / num_partitions\n",
    "                                    for split in range(1, num_partitions)\n",
    "                                ),\n",
    "                                separators=self.split_separators,\n",
    "                                cache=True,\n",
    "                            )\n",
    "                        )[:-1]\n",
    "                        for parent in parents:\n",
    "                            pending.add(\n",
    "                                asyncio.create_task(\n",
    "                                    episode._sample_completions(\n",
    "                                        parent=parent,\n",
    "                                        model=model,\n",
    "                                        completion_sampler=completion_sampler,\n",
    "                                        tokenizer=tokenizer,\n",
    "                                        branch_factor=self.branch_factor,\n",
    "                                        fork_decay=1.0,\n",
    "                                        recovery_pattern=None,\n",
    "                                        split_separators=self.split_separators,\n",
    "                                        sampling_kwargs=self.sampling_kwargs\n",
    "                                        or SamplingKwargs(),\n",
    "                                        priority=priority,\n",
    "                                    )\n",
    "                                )\n",
    "                            )\n",
    "                update_progress(\n",
    "                    (_num_leaves - num_leaves) / (self.branch_factor**self.depth)\n",
    "                )\n",
    "                num_leaves = _num_leaves\n",
    "\n",
    "            await done_episodes.put(episode)\n",
    "\n",
    "        priority = 0\n",
    "        while episode := await ready_episodes.get():\n",
    "            priority += 1\n",
    "            asyncio.create_task(expand(episode, priority))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class IterativeVineExploreImpl(ExploreImpl):\n",
    "    branch_factor: int\n",
    "    depth: int\n",
    "    sampling_kwargs: SamplingKwargs | None = None\n",
    "    split_method: SplitMethod = \"count\"\n",
    "    split_separators: set[str] = field(default_factory=set)\n",
    "\n",
    "    async def __call__(\n",
    "        self,\n",
    "        completion_sampler: CompletionSampler,\n",
    "        tokenizer: Tokenizer,\n",
    "        ready_episodes: asyncio.Queue[Episode],\n",
    "        done_episodes: asyncio.Queue[Episode | BaseException],\n",
    "        update_progress: Callable[[float], None],\n",
    "    ) -> None:\n",
    "        model = await completion_sampler.get_model()\n",
    "\n",
    "        async def iterate_vine(episode: Episode, priority: int) -> None:\n",
    "\n",
    "            for depth in range(self.depth):\n",
    "                if depth == 0:\n",
    "                    parent = episode.completion\n",
    "                else:\n",
    "                    parent = max(\n",
    "                        episode.completion.leaves(model=model),\n",
    "                        key=lambda leaf: leaf.reward,\n",
    "                    )\n",
    "                    parent = list(\n",
    "                        parent.split(\n",
    "                            by=self.split_method,\n",
    "                            at=[1 / (self.depth - depth + 1)],\n",
    "                            separators=self.split_separators,\n",
    "                            cache=True,\n",
    "                        )\n",
    "                    )[0]\n",
    "                await episode._sample_completions(\n",
    "                    parent=parent,\n",
    "                    model=model,\n",
    "                    completion_sampler=completion_sampler,\n",
    "                    tokenizer=tokenizer,\n",
    "                    branch_factor=self.branch_factor,\n",
    "                    fork_decay=1.0,\n",
    "                    recovery_pattern=None,\n",
    "                    split_separators=self.split_separators,\n",
    "                    sampling_kwargs=self.sampling_kwargs or SamplingKwargs(),\n",
    "                    priority=priority,\n",
    "                )\n",
    "                update_progress(1 / self.depth)\n",
    "\n",
    "            await done_episodes.put(episode)\n",
    "\n",
    "        priority = 0\n",
    "        while episode := await ready_episodes.get():\n",
    "            priority += 1\n",
    "            asyncio.create_task(iterate_vine(episode, priority))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-31 15:49:11 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='NousResearch/Hermes-2-Theta-Llama-3-8B', speculative_config=None, tokenizer='NousResearch/Hermes-2-Theta-Llama-3-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=NousResearch/Hermes-2-Theta-Llama-3-8B, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbradhilton\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/atreides/experiments/wandb/run-20241231_154912-rl59</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bradhilton/atreides-experiments/runs/rl59' target=\"_blank\">rl59</a></strong> to <a href='https://wandb.ai/bradhilton/atreides-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bradhilton/atreides-experiments' target=\"_blank\">https://wandb.ai/bradhilton/atreides-experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bradhilton/atreides-experiments/runs/rl59' target=\"_blank\">https://wandb.ai/bradhilton/atreides-experiments/runs/rl59</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from aioitertools.helpers import maybe_await\n",
    "import asyncio\n",
    "import itertools as it\n",
    "from lib import clue\n",
    "from lib.rl.episode import Episode\n",
    "from lib.rl.ppo import PPOLoss\n",
    "from lib.rl.recipe import ComponentConfig, TuneRecipeConfig\n",
    "from lib.rl.trainer import Eval, ExploreOptions, Trainer, vLLMConfig\n",
    "import torch\n",
    "from torchtune.models.llama3_1 import llama3_1_8b\n",
    "from typing import AsyncIterable\n",
    "\n",
    "\n",
    "episodes_per_iteration = 64 * torch.cuda.device_count()\n",
    "\n",
    "\n",
    "async def train_episodes() -> AsyncIterable[Episode | BaseException]:\n",
    "    pending: set[asyncio.Task[Episode | BaseException]] = set()\n",
    "    episodes = (\n",
    "        maybe_await(episode)\n",
    "        for episodes in zip(\n",
    "            # (clue.sample_random_episode() for _ in it.repeat(0)),\n",
    "            it.cycle(temporal_clue_episodes[64:]),\n",
    "            # it.cycle(zebra_grid_episodes[64:]),\n",
    "            # it.cycle(math_episodes[64:]),\n",
    "        )\n",
    "        for episode in episodes\n",
    "    )\n",
    "    while True:\n",
    "        pending.update(\n",
    "            asyncio.create_task(next(episodes))\n",
    "            for _ in range(episodes_per_iteration - len(pending))  # type: ignore\n",
    "        )\n",
    "        done, pending = await asyncio.wait(pending, return_when=asyncio.FIRST_COMPLETED)\n",
    "        for task in done:\n",
    "            try:\n",
    "                yield task.result()\n",
    "            except BaseException as e:\n",
    "                yield e\n",
    "\n",
    "\n",
    "async def val_episodes() -> AsyncIterable[Episode | BaseException]:\n",
    "    for fut in asyncio.as_completed(clue.sample_random_episode() for _ in range(64)):\n",
    "        try:\n",
    "            yield await fut\n",
    "        except BaseException as e:\n",
    "            yield e\n",
    "\n",
    "\n",
    "explore_options = ExploreOptions(\n",
    "    iterations=1,\n",
    "    num_parents=6,\n",
    "    branch_factor=3,\n",
    "    patience=60,\n",
    "    advantage_max_weight=0.2,\n",
    "    sample_probability_power=None,\n",
    "    sampling_kwargs={\"max_tokens\": 4096, \"stop\": [\"://\"]},\n",
    "    # split_method=\"prob\",\n",
    "    # split_point_std_deviation=0.5,\n",
    ")\n",
    "\n",
    "model_name = \"rl59\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    base_model=\"NousResearch/Hermes-2-Theta-Llama-3-8B\",\n",
    "    output_dir=f\"./models/{model_name}\",\n",
    "    explore_options=explore_options,\n",
    "    # explore_impl=DefaultExploreImpl(explore_options),\n",
    "    # explore_impl=SimpleExploreImpl(\n",
    "    #     num_samples=8, sampling_kwargs={\"max_tokens\": 4096}\n",
    "    # ),\n",
    "    explore_impl=TreeExploreImpl(\n",
    "        branch_factor=3,\n",
    "        depth=4,\n",
    "        sampling_kwargs={\"max_tokens\": 4096, \"stop\": [\"://\"]},\n",
    "    ),\n",
    "    force_terminate_vllms=True,\n",
    "    train_episodes=train_episodes(),\n",
    "    episodes_per_iteration=episodes_per_iteration,\n",
    "    max_mask_sequence_batch_size=1,\n",
    "    evals=[\n",
    "        # Eval(\n",
    "        #     name=\"variable_clue\",\n",
    "        #     episodes=val_episodes(),\n",
    "        #     samples_per_episode=3,\n",
    "        #     sampling_kwargs={\"max_tokens\": 4096},\n",
    "        # ),\n",
    "        Eval(\n",
    "            name=\"temporal_clue\",\n",
    "            episodes=temporal_clue_episodes[:64],\n",
    "            samples_per_episode=3,\n",
    "            sampling_kwargs={\"max_tokens\": 4096, \"stop\": [\"://\"]},\n",
    "        ),\n",
    "        # Eval(\n",
    "        #     name=\"zebra_grid\",\n",
    "        #     episodes=zebra_grid_episodes[:64],\n",
    "        #     samples_per_episode=3,\n",
    "        #     sampling_kwargs={\"max_tokens\": 4096},\n",
    "        # ),\n",
    "        # Eval(\n",
    "        #     name=\"math\",\n",
    "        #     episodes=math_episodes[:64],\n",
    "        #     samples_per_episode=3,\n",
    "        #     sampling_kwargs={\"max_tokens\": 4096},\n",
    "        # ),\n",
    "    ],\n",
    "    tune_model=llama3_1_8b,\n",
    "    tune_model_type=\"LLAMA3\",\n",
    "    tune_recipe_config=TuneRecipeConfig(\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "        num_output_chunks=4,\n",
    "        resume_from_checkpoint=False,\n",
    "        batch_size=1,\n",
    "        epochs=1,\n",
    "        # max_steps_per_epoch=32,\n",
    "        optimizer=ComponentConfig(\n",
    "            \"torch.optim.AdamW\",\n",
    "            # \"bitsandbytes.optim.PagedAdamW8bit\",\n",
    "            # \"bitsandbytes.optim.AdamW\",\n",
    "            # params=PLACEHOLDER,\n",
    "            lr=4e-6,\n",
    "            fused=True,\n",
    "        ),\n",
    "        loss=ComponentConfig(\n",
    "            PPOLoss,\n",
    "            policy_coef=0.0,\n",
    "            clip_epsilon=0.2,\n",
    "            unclipped_policy_coef=0.0,\n",
    "            tanh_log_policy_coef=0.8,\n",
    "            value_coef=0.0,\n",
    "            entropy_coef=0.0,\n",
    "            entropy_target=0.6,\n",
    "            entropy_target_coef=0.05,\n",
    "            kl_coef=0.05,\n",
    "            weighted_entropy_coef=0.2,\n",
    "            weighted_kl_coef=0.0,\n",
    "            weighted_ce_coef=0.0,\n",
    "            normalize_values=False,\n",
    "            normalize_advantages=False,\n",
    "        ),\n",
    "        compile=False,\n",
    "        optimizer_in_bwd=False,\n",
    "        gradient_accumulation_steps=1,\n",
    "        enable_activation_checkpointing=True,\n",
    "        enable_activation_offloading=False,\n",
    "        custom_sharded_layers=[\"tok_embeddings\", \"output\"],\n",
    "        log_every_n_steps=1,\n",
    "        log_peak_memory_stats=True,\n",
    "    ),\n",
    "    # tune_run=False,\n",
    "    tune_sequence_length=16384,\n",
    "    vllm_config=vLLMConfig(\n",
    "        env={\"VLLM_ALLOW_LONG_MAX_MODEL_LEN\": \"1\"},\n",
    "        kwargs=dict(\n",
    "            block_size=32,\n",
    "            disable_log_requests=True,\n",
    "            enable_chunked_prefill=True,\n",
    "            enable_prefix_caching=True,\n",
    "            enforce_eager=True,\n",
    "            gpu_memory_utilization=0.9,\n",
    "            max_model_len=16384,\n",
    "            max_num_seqs=512,\n",
    "            max_num_batched_tokens=16384,\n",
    "            preemption_mode=\"swap\",\n",
    "            return_tokens_as_token_ids=True,\n",
    "            swap_space=100,\n",
    "        ),\n",
    "        max_concurrent_samples=512,\n",
    "        min_time_between_requests=0.0,\n",
    "        timeout=120 + 15 * torch.cuda.device_count(),\n",
    "    ),\n",
    "    wandb_kwargs=dict(\n",
    "        name=model_name,\n",
    "        id=model_name,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 vLLM servers...\n",
      "$ vllm serve NousResearch/Hermes-2-Theta-Llama-3-8B --port=8019 --block-size=32 --disable-log-requests --enable-chunked-prefill --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=16384 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=100 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ac8faab1504b8486354730997db667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "temporal_clue:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e53b69a49614f46b0108b4c74e861c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping temporal_clue evaluation due to expired patience (1 remaining episodes x 60.0 patience per episode = 60.0 seconds)\n"
     ]
    }
   ],
   "source": [
    "await trainer.train(iterations=15, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 vLLM servers...\n",
      "$ vllm serve /home/ubuntu/atreides/experiments/models/rl44/0001 --port=8007 --block-size=32 --disable-log-requests --enable-chunked-prefill --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=16384 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=100 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    }
   ],
   "source": [
    "completion_sampler = await trainer.get_completion_sampler(verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/atreides/experiments/models/rl44/0001'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = await completion_sampler.get_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chat-e5126fe18c184324ae17be846d07ffe0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello, world! It's great to meet you. How can I assist you today?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[]), stop_reason=None)], created=1735422282, model='/home/ubuntu/atreides/experiments/models/rl44/0001', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=19, prompt_tokens=13, total_tokens=32, completion_tokens_details=None, prompt_tokens_details=None), prompt_logprobs=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.langfuse import langfuse\n",
    "\n",
    "chat_completion = await completion_sampler.samplers[0].client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello, world!\"}],\n",
    ")\n",
    "chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pk-lf-3598930a-f80e-4074-a6d4-24579d0d2605'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langfuse.auth_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 vLLM servers...\n",
      "$ vllm serve NousResearch/Hermes-2-Theta-Llama-3-8B --port=8005 --block-size=32 --disable-log-requests --enable-chunked-prefill --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=16384 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=100 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b97bde6b0124016b58af41968507deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = await trainer.explore(verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl44/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:torchtune.utils._logging:Training is not distributed. If you want to train on multiple GPUs and are using the tune CLI, specify --nnodes 1 and --nproc_per_node [num_gpus]\n",
      "INFO:torchtune.utils._logging:Running FullFinetuneRecipe with resolved config:\n",
      "\n",
      "batch_size: 1\n",
      "checkpointer:\n",
      "  _component_: torchtune.training.checkpointing._checkpointer.FullModelHFCheckpointer\n",
      "  checkpoint_dir: /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725\n",
      "  checkpoint_files:\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00001-of-00004.safetensors\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00003-of-00004.safetensors\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00004-of-00004.safetensors\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00002-of-00004.safetensors\n",
      "  model_type: LLAMA3\n",
      "  output_dir: /home/ubuntu/atreides/experiments/models/rl44\n",
      "  recipe_checkpoint: null\n",
      "compile: false\n",
      "custom_sharded_layers:\n",
      "- tok_embeddings\n",
      "- output\n",
      "dataset:\n",
      "  _component_: lib.rl.pack.PackedDataset\n",
      "  dir: /home/ubuntu/atreides/experiments/models/rl44/tensors\n",
      "  num_sequences: 36\n",
      "  sequence_length: 16384\n",
      "device: cuda\n",
      "dtype: bf16\n",
      "enable_activation_checkpointing: true\n",
      "enable_activation_offloading: false\n",
      "epochs: 1\n",
      "gradient_accumulation_steps: 1\n",
      "log_every_n_steps: 1\n",
      "log_peak_memory_stats: true\n",
      "loss:\n",
      "  _component_: lib.rl.ppo.PPOLoss\n",
      "  clip_epsilon: 0.2\n",
      "  entropy_coef: 0.0\n",
      "  entropy_target: 0.6\n",
      "  entropy_target_coef: 0.05\n",
      "  kl_coef: 0.05\n",
      "  normalize_advantages: false\n",
      "  normalize_values: false\n",
      "  policy_coef: 0.0\n",
      "  tanh_log_policy_coef: 0.8\n",
      "  unclipped_policy_coef: 0.0\n",
      "  value_coef: 0.0\n",
      "  weighted_ce_coef: 0.0\n",
      "  weighted_entropy_coef: 0.2\n",
      "  weighted_kl_coef: 0.0\n",
      "max_steps_per_epoch: null\n",
      "metric_logger:\n",
      "  _component_: torchtune.training.metric_logging.WandBLogger\n",
      "  id: rl44\n",
      "  name: rl44\n",
      "  resume: allow\n",
      "model:\n",
      "  _component_: torchtune.models.llama3_1._model_builders.llama3_1_8b\n",
      "num_output_chunks: 4\n",
      "optimizer:\n",
      "  _component_: torch.optim.AdamW\n",
      "  fused: true\n",
      "  lr: 4.0e-06\n",
      "optimizer_in_bwd: false\n",
      "reference_checkpointer:\n",
      "  _component_: torchtune.training.checkpointing._checkpointer.FullModelHFCheckpointer\n",
      "  checkpoint_dir: /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725\n",
      "  checkpoint_files:\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00001-of-00004.safetensors\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00003-of-00004.safetensors\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00004-of-00004.safetensors\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00002-of-00004.safetensors\n",
      "  model_type: LLAMA3\n",
      "  output_dir: /home/ubuntu/atreides/experiments/models/rl44\n",
      "  recipe_checkpoint: null\n",
      "resume_from_checkpoint: false\n",
      "seed: 42\n",
      "shuffle: true\n",
      "\n",
      "INFO:torchtune.utils._logging:Hint: enable_activation_checkpointing is True, but enable_activation_offloading isn't. Enabling activation offloading should reduce memory further.\n",
      "DEBUG:torchtune.utils._logging:Setting manual seed to local seed 42. Local seed is seed + rank = 42 + 0\n",
      "wandb: Currently logged in as: bradhilton. Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.18.3\n",
      "wandb: Run data is saved locally in /home/ubuntu/atreides/experiments/wandb/run-20241228_203550-rl44\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run rl44\n",
      "wandb: ⭐️ View project at https://wandb.ai/bradhilton/torchtune\n",
      "wandb: 🚀 View run at https://wandb.ai/bradhilton/torchtune/runs/rl44\n",
      "INFO:torchtune.utils._logging:Logging /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/torchtune_config.yaml to W&B under Files\n",
      "INFO:torchtune.utils._logging:FSDP is enabled. Instantiating model and loading checkpoint on Rank 0 ...\n",
      "INFO:torchtune.utils._logging:Instantiating model and loading checkpoint took 2.29 secs\n",
      "INFO:torchtune.utils._logging:Memory stats after model init:\n",
      "\tGPU peak memory allocation: 15.02 GiB\n",
      "\tGPU peak memory reserved: 15.14 GiB\n",
      "\tGPU peak memory active: 15.02 GiB\n",
      "INFO:torchtune.utils._logging:Optimizer is initialized.\n",
      "INFO:torchtune.utils._logging:Loss is initialized.\n",
      "INFO:torchtune.utils._logging:Dataset and Sampler are initialized.\n",
      "WARNING:torchtune.utils._logging: Profiling disabled.\n",
      "INFO:torchtune.utils._logging: Profiler config after instantiation: {'enabled': False}\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "1|36|Loss: 0.0351: 100%|██████████| 36/36 [12:07<00:00, 20.04s/it, entropy=0.5296, entropy_target=0.0704, kl_div=0.2141, policy=-0.0490, reinforce=0.0340, tanh_log_policy=0.0139, unclipped_policy=-0.0743, value=0.0000, weighted_ce=0.0340, weighted_entropy=-0.0486, weighted_kl_div=-0.0238] INFO:torchtune.utils._logging:Saving checkpoint. This may take some time. Retrieving full model state dict...\n",
      "INFO:torchtune.utils._logging:Getting full model state dict took 0.00 secs\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.98 GB saved to /home/ubuntu/atreides/experiments/models/rl44/hf_model_0001_0.pt\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 5.00 GB saved to /home/ubuntu/atreides/experiments/models/rl44/hf_model_0002_0.pt\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.92 GB saved to /home/ubuntu/atreides/experiments/models/rl44/hf_model_0003_0.pt\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 1.17 GB saved to /home/ubuntu/atreides/experiments/models/rl44/hf_model_0004_0.pt\n",
      "INFO:torchtune.utils._logging:Saving final epoch checkpoint.\n",
      "INFO:torchtune.utils._logging:The full model checkpoint, including all weights and configurations, has been saved successfully.You can now use this checkpoint for further training or inference.\n",
      "INFO:torchtune.utils._logging:Saving checkpoint took 21.22 secs\n",
      "1|36|Loss: 0.0351: 100%|██████████| 36/36 [12:28<00:00, 20.80s/it, entropy=0.5296, entropy_target=0.0704, kl_div=0.2141, policy=-0.0490, reinforce=0.0340, tanh_log_policy=0.0139, unclipped_policy=-0.0743, value=0.0000, weighted_ce=0.0340, weighted_entropy=-0.0486, weighted_kl_div=-0.0238]\n",
      "wandb:                                                                                \n",
      "wandb: \n",
      "wandb: Run history:\n",
      "wandb:                   entropy ▁▄▆▆▅▆▅▅▅▇▄▆█▇▅▅▅▆█▅█▅▅▄▄▆▇▅▇▆▆▆▆▆▅▅\n",
      "wandb:            entropy_target █▃▂▂▂▁▂▂▁▃▃▁▅▃▂▂▂▁▅▁▄▂▂▃▃▂▄▁▃▂▁▂▁▂▂▂\n",
      "wandb:               global_step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
      "wandb:                    kl_div ▁▃▄▅▅▅▅▅▇▆▃▆█▆▄▄▄▅▇▄█▅▄▄▃██▄▇▆▄▆▅█▄▄\n",
      "wandb:                      loss ▆▆▆▆▇▃▇▇▄█▃▆█▄▇▇▅▄▄▆▆▆▅▄▇▅█▆▇▃▆▆▅▁▅█\n",
      "wandb:                        lr ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "wandb:        peak_memory_active ▁█████████▄█████████████████████████\n",
      "wandb:         peak_memory_alloc ▁█████████▄█████████████████████████\n",
      "wandb:      peak_memory_reserved ▁█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅\n",
      "wandb:                    policy ▅▄▃▂▃▆▂▇▄▃█▁▇▅▄▁▄▅▄▅▄▃▄▄▁▄▄▅▄▆▅▅▄▃▃▁\n",
      "wandb:                 reinforce ▅▇▇▇█▃▆█▄▇▃▇█▄▇▇▅▅▃▇▅▆▅▄█▅█▆▆▃▆▆▅▁▆█\n",
      "wandb:           tanh_log_policy ▆▆▆▆▇▄▇▇▃▇▄▆▆▄▇▇▆▅▄▇▅▆▆▄▇▄▇▇▆▃▇▆▆▁▆█\n",
      "wandb: tokens_per_second_per_gpu ▄█▇▇▇▆▆▇▇▇▁▇▅▇▇▇▇▇▄█▆▇█▇▆▇▆▇▆▆▇▇▆▅▇▇\n",
      "wandb:          unclipped_policy ▆▄▂▂▁▄▂▆▃▂█▁▂▄▄▁▃▃▂▄▃▃▂▃▁▄▃▄▃▄▄▃▅▂▄▁\n",
      "wandb:                     value ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "wandb:               weighted_ce ▅▇▇▇█▃▆█▄▇▃▇█▄▇▇▅▅▃▇▅▆▅▄█▅█▆▆▃▆▆▅▁▆█\n",
      "wandb:          weighted_entropy ▄▃▂▂▁▆▃▁▅▂▆▂▁▆▂▂▄▄▆▃▄▃▄▆▂▄▁▃▃▇▃▃▄█▄▁\n",
      "wandb:           weighted_kl_div ▃▃▂▃▂▅▃▂▅▂▅▃▃▄▂▂▄▅▅▂▄▃▄▄▁▅▂▃▃▆▃▄▃█▃▁\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:                   entropy 0.52961\n",
      "wandb:            entropy_target 0.07039\n",
      "wandb:               global_step 36\n",
      "wandb:                    kl_div 0.21409\n",
      "wandb:                      loss 0.03508\n",
      "wandb:                        lr 0.0\n",
      "wandb:        peak_memory_active 68.34125\n",
      "wandb:         peak_memory_alloc 68.34125\n",
      "wandb:      peak_memory_reserved 70.27734\n",
      "wandb:                    policy -0.04904\n",
      "wandb:                 reinforce 0.03403\n",
      "wandb:           tanh_log_policy 0.01391\n",
      "wandb: tokens_per_second_per_gpu 675.48663\n",
      "wandb:          unclipped_policy -0.07429\n",
      "wandb:                     value 0\n",
      "wandb:               weighted_ce 0.03403\n",
      "wandb:          weighted_entropy -0.04863\n",
      "wandb:           weighted_kl_div -0.02383\n",
      "wandb: \n",
      "wandb: 🚀 View run rl44 at: https://wandb.ai/bradhilton/torchtune/runs/rl44\n",
      "wandb: ⭐️ View project at: https://wandb.ai/bradhilton/torchtune\n",
      "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20241228_203550-rl44/logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iteration 1 model files to /home/ubuntu/atreides/experiments/models/rl44/0001\n"
     ]
    }
   ],
   "source": [
    "await trainer.tune(result, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.eval_episodes[\"temporal_clue\"] = temporal_clue_episodes[:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 vLLM servers...\n",
      "$ vllm serve NousResearch/Hermes-2-Theta-Llama-3-8B --port=8002 --block-size=32 --disable-log-requests --enable-chunked-prefill --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=16384 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=100 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d89c7c9f2d74398aac9bc1c7f8d7d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "temporal_clue:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.2249441964285714, [])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await trainer.eval(\"temporal_clue\", verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'On a dark winter night, wealthy and enigmatic Mr. John Q. Boddy hosted a small, but lavish, dinner party for some of his closest associates. However, the night ended in tragedy when Mr. Boddy was found dead in one of the rooms of Tudor Mansion in the early hours of the morning. The following persons of interest have been identified as suspects:\\n\\n• Miss Peach\\n• Colonel Mustard\\n\\nAnd the following weapons were found on the premises:\\n\\n• Horseshoe\\n• Knife\\n\\nThe murder could only have occured in one of the following rooms:\\n\\n1. Courtyard\\n2. Hall\\n\\nThe rooms are laid out as follows:\\n\\n  N N  \\nW 1|2 E\\n  S S  \\n\\nEach suspect uniquely had one of the following possible motives for killing Mr. Boddy:\\n\\n• Ambition\\n• Betrayal\\n\\nFor the murder to occur, the murderer and Mr. Boddy must have been alone in a room with at least one weapon.\\n\\nThe available clues are as follows:\\n\\n- The murderer was in the Hall or Colonel Mustard was in the Courtyard\\n- The murderer was in the Courtyard or the suspect motivated by Ambition was in the Hall\\n- Colonel Mustard was in the room just east of the Knife\\n\\nPlease answer the following question(s):\\n\\nA. Who murdered Mr. Boddy?\\nB. What weapon did the murderer use?\\nC. Where was the murder committed?\\nD. Why did the murderer do it?\\n\\nAnd the following bonus question(s):\\n\\nE. Where was the Horseshoe?\\nF. Who is motivated by Ambition?\\n\\nAfter verifiably finding all the correct answers, fill out your final answers in the following format:\\n\\nA. SUSPECT\\nB. WEAPON\\nC. ROOM\\nD. MOTIVE\\nE. ROOM\\nF. SUSPECT\\n\\nBest of luck, detective.'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Let's analyze the clues and deduce the answers.\\n\\nA. Who murdered Mr. Boddy?\\nTo answer this, we need to determine which suspect was alone with Mr. Boddy in a room with a weapon. We can start by looking at the clues.\\n\\nClue 1: The murderer was in the Hall or Colonel Mustard was in the Courtyard.\\nClue 2: The murderer was in the Courtyard or the suspect motivated by Ambition was in the Hall.\\nClue 3: Colonel Mustard was in the room just east of the Knife.\\n\\nFrom Clue 1, we know that either the murderer was in the Hall or Colonel Mustard was in the Courtyard. Since Colonel Mustard is in the room just east of the Knife (Clue 3), the murderer must be in the Hall.\\n\\nFrom Clue 2, we know that the murderer was in the Courtyard or the suspect motivated by Ambition was in the Hall. Since we've already determined that the murderer was in the Hall, the suspect motivated by Ambition must be in the Hall as well.\\n\\nNow, we can deduce that the murderer is the suspect motivated by Ambition, who was in the Hall.\\n\\nB. What weapon did the murderer use?\\nWe know that Colonel Mustard was in the room just east of the Knife (Clue 3). Since the murderer and Mr. Boddy must have been alone in a room with at least one weapon, the murderer must have used the Knife.\\n\\nC. Where was the murder committed?\\nThe murder was committed in the Hall.\\n\\nD. Why did the murderer do it?\\nThe murderer was motivated by Ambition.\\n\\nE. Where was the Horseshoe?\\nThe Horseshoe was not used in the murder, so we don't have any information about its location.\\n\\nF. Who is motivated by Ambition?\\nMiss Peach is motivated by Ambition.\\n\\nFinal answers:\\n\\nA. Miss Peach\\nB. Knife\\nC. Hall\\nD. Ambition\\nE. (No information available)\\nF. Miss Peach\\n\\nI hope this helps you solve the murder mystery, detective!<|im_end|>\"}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(trainer.eval_episodes[\"temporal_clue\"][35].completion.leaves())[0].all_message_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 vLLM servers...\n",
      "$ vllm serve NousResearch/Hermes-2-Theta-Llama-3-8B --port=8000 --block-size=32 --disable-log-requests --enable-chunked-prefill --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=16384 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=100 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091ba764bd6e4801a4854f114c830537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "temporal_clue:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a364bb490de54c8daa7cc8b3a34517fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await trainer.train(iterations=1, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'On a dark winter night, wealthy and enigmatic Mr. John Q. Boddy hosted a small, but lavish, dinner party for some of his closest associates. However, the night ended in tragedy when Mr. Boddy was found dead in one of the rooms of Tudor Mansion in the early hours of the morning. The following persons of interest have been identified as suspects:\\n\\n• Professor Plum\\n• Mrs. Peacock\\n• Mrs. White\\n• Monsieur Brunette\\n• Miss Peach\\n• Madame Rose\\n• Colonel Mustard\\n• Mr. Green\\n• Sgt. Gray\\n• Miss Scarlet\\n\\nAnd the following weapons were found on the premises:\\n\\n• Poison\\n• Knife\\n• Wrench\\n• Candlestick\\n• Lead Pipe\\n• Horseshoe\\n• Rope\\n\\nThe murder could only have occured in one of the following rooms:\\n\\n01. Lounge\\n02. Courtyard\\n03. Drawing Room\\n04. Dining Room\\n05. Trophy Room\\n06. Studio\\n07. Fountain\\n08. Hall\\n09. Study\\n10. Cloak Room\\n11. Library\\n12. Billiard Room\\n\\nThe rooms are laid out as follows:\\n\\n  NN NN NN  \\nW 01|02|03 E\\nW 04|05|06 E\\nW 07|08|09 E\\nW 10|11|12 E\\n  SS SS SS  \\n\\nThe exact time of the murder is a bit uncertain, but it has been narrowed down to one of the following times:\\n\\n• 10:45 PM\\n• 11:00 PM\\n• 11:15 PM\\n• 11:30 PM\\n• 11:45 PM\\n• 12:00 AM\\n• 12:15 AM\\n• 12:30 AM\\n\\nAt every time the suspects and Mr. Boddy either stayed in their current room or moved to an orthogonally adjacent room (north, south, east, or west). Weapons could be moved by suspects between rooms as well.\\n\\nEach suspect had one of the following possible motives for killing Mr. Boddy:\\n\\n• Pride (1 suspect)\\n• Greed (3 suspects)\\n• Anger (1 suspect)\\n• Fear (2 suspects)\\n• Hatred (2 suspects)\\n• Jealousy (1 suspect)\\n\\nFor the murder to occur, the murderer and Mr. Boddy must have been alone in a room with at least one weapon at some point in the night. Any clue about Mr. Boddy\\'s whereabouts should be read as \"Mr. Boddy (dead or alive) ...\"\\n\\nThe available clues are as follows:\\n\\n- A suspect motivated by Greed was in the Trophy Room at 11:00 PM\\n- The Horseshoe was in the room just west of the Candlestick at 11:45 PM\\n- A suspect motivated by Greed was in the Trophy Room at 11:30 PM or the Lead Pipe was in the Lounge at 10:45 PM\\n- Mr. Boddy was in the Lounge at 11:30 PM\\n- The Knife was in the same room as the Lead Pipe at 12:15 AM\\n- The Wrench was at the Fountain at 11:15 PM or a suspect motivated by Hatred was in the Studio at 11:30 PM\\n- Mr. Green was in the same room as the Candlestick at 11:30 PM\\n- Mrs. Peacock was in the Trophy Room at 11:45 PM or the Wrench was in the Billiard Room at 10:45 PM\\n- A suspect motivated by Greed moved the Wrench from the Studio to the Trophy Room at 12:30 AM\\n- Colonel Mustard was in the room just west of Professor Plum at 11:30 PM\\n- Sgt. Gray was in the room just north of the Knife at 11:00 PM\\n- The suspect motivated by Anger moved the Poison from the Fountain to the Hall at 12:30 AM\\n- The murder weapon was in the Studio at 10:45 PM\\n- Mr. Green was in the Lounge at 11:00 PM if and only if Mrs. White was in the Dining Room at 11:00 PM\\n- Miss Scarlet was in the Studio at 11:15 PM\\n- Miss Scarlet was in the Studio at 11:00 PM\\n- Mrs. White was in the Trophy Room at 11:45 PM if and only if the murder weapon was in the Studio at 11:15 PM\\n- Mr. Boddy was in the Courtyard at 11:45 PM\\n- The Knife was in the same room as Monsieur Brunette at 11:15 PM\\n- Mr. Green was in the Drawing Room at 12:30 AM\\n- Colonel Mustard was in the same room as Professor Plum at 10:45 PM\\n- A suspect motivated by Hatred was in the Trophy Room at 11:45 PM\\n- Mr. Boddy was in the Courtyard at 10:45 PM\\n- The Lead Pipe was in the room just north of the Wrench at 10:45 PM\\n- Miss Peach was in the Trophy Room at 12:15 AM\\n- The suspect motivated by Anger was in the Cloak Room at 12:30 AM or Miss Scarlet was in the Studio at 11:45 PM\\n- Monsieur Brunette was in the Hall at 12:30 AM\\n- Sgt. Gray moved from the Courtyard to the Lounge at 12:30 AM\\n- A suspect motivated by Greed moved from the Library to the Billiard Room at 11:00 PM\\n- The Poison was in the Library at 11:45 PM or Mr. Green was in the Drawing Room at 12:00 AM\\n- Mr. Boddy was in the Courtyard at 11:00 PM\\n- A suspect motivated by Hatred moved from the Trophy Room to the Dining Room at 12:15 AM\\n- The suspect motivated by Jealousy moved from the Hall to the Trophy Room at 11:15 PM\\n- Mrs. Peacock was in the Trophy Room at 10:45 PM\\n- A suspect motivated by Greed was in the Hall at 12:00 AM\\n- Mrs. White moved from the Hall to the Library at 12:30 AM\\n- Miss Peach was in the room just south of the Candlestick at 11:30 PM\\n- Miss Peach was in the Trophy Room at 12:00 AM\\n- The suspect motivated by Anger moved from the Hall to the Fountain at 12:15 AM\\n- The suspect motivated by Pride was in the Dining Room at 10:45 PM if and only if the Horseshoe was in the Lounge at 12:15 AM\\n- The suspect motivated by Jealousy moved from the Trophy Room to the Courtyard at 11:45 PM\\n- A suspect motivated by Greed was in the Trophy Room at 11:15 PM\\n- Professor Plum was in the Billiard Room at 12:15 AM or the Candlestick was in the Drawing Room at 11:30 PM\\n- A suspect motivated by Hatred was in the Study at 10:45 PM or Miss Scarlet was in the Hall at 11:45 PM\\n- A suspect motivated by Hatred was in the Dining Room at 12:30 AM\\n- Monsieur Brunette was in the same room as Professor Plum at 11:00 PM\\n- Professor Plum was in the Study at 12:30 AM\\n- Mr. Green was in the same room as Mr. Boddy at 11:15 PM\\n- Madame Rose moved from the Courtyard to the Drawing Room at 11:00 PM\\n- A suspect motivated by Greed was in the Hall at 12:15 AM\\n- Professor Plum was in the room just east of Colonel Mustard at 11:45 PM\\n- Colonel Mustard was in the room just east of the Poison at 11:30 PM\\n- The Rope was in the same room as the Poison at 11:45 PM\\n- Mrs. White was in the Dining Room at 11:00 PM if and only if the murder weapon was in the Courtyard at 11:45 PM\\n- A suspect motivated by Fear was in the Drawing Room at 12:15 AM or the Candlestick was in the Library at 12:00 AM\\n- The murderer and the Horseshoe were in the Drawing Room together at least once\\n- A suspect motivated by Greed moved the Knife from the Library to the Hall at 11:45 PM\\n- A suspect motivated by Fear was in the Lounge at 11:15 PM\\n- A suspect motivated by Fear was in the Lounge at 10:45 PM if and only if the suspect motivated by Pride was in the Hall at 12:15 AM\\n- Miss Peach was in the same room as Mrs. Peacock at 12:30 AM\\n- Colonel Mustard moved from the Billiard Room to the Study at 11:15 PM\\n- A suspect motivated by Fear moved the Horseshoe from the Lounge to the Courtyard at 12:30 AM\\n- The Candlestick and Mr. Boddy were in the Courtyard together at least once\\n- Professor Plum moved from the Billiard Room to the Study at 11:15 PM\\n- Mr. Boddy was murdered at 12:00 AM\\n- Miss Peach and Madame Rose were in the Studio together at least once\\n- The Rope was at the Fountain at 12:30 AM or Mrs. Peacock was in the Hall at 12:15 AM\\n- Professor Plum was in the room just east of the Knife at 10:45 PM\\n- A suspect motivated by Greed moved the Wrench from the Trophy Room to the Studio at 12:15 AM\\n- The Knife was in the Hall at 12:30 AM\\n- Monsieur Brunette was in the same room as the Lead Pipe at 12:30 AM\\n- Sgt. Gray was in the Hall at 10:45 PM\\n- The Wrench was in the same room as Sgt. Gray at 11:00 PM\\n- The suspect motivated by Pride moved from the Dining Room to the Trophy Room at 11:30 PM\\n- Professor Plum moved from the Study to the Billiard Room at 12:00 AM\\n- Miss Peach moved from the Drawing Room to the Studio at 11:00 PM\\n- Sgt. Gray was in the room just north of Miss Scarlet at 12:00 AM\\n- Miss Scarlet was in the same room as Mrs. White at 12:00 AM\\n\\nPlease answer the following question(s):\\n\\nA. Who murdered Mr. Boddy?\\nB. What weapon did the murderer use?\\nC. Where was the murder committed?\\nD. Why did the murderer do it?\\n\\nAnd the following bonus question(s):\\n\\nE. Where was Mrs. Peacock at 12:30 AM?\\nF. Where was Colonel Mustard at 10:45 PM?\\nG. What motivates Mr. Green?\\n\\nFill out your final answers in the following format:\\n\\nA. SUSPECT\\nB. WEAPON\\nC. ROOM\\nD. MOTIVE\\nE. ROOM\\nF. ROOM\\nG. MOTIVE\\n\\nBest of luck, detective.'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Let's think this through step by step... We know that Mr. Boddy was in the Courtyard at 11:30 PM and that the murder weapon was in the Studio at 10:45 PM. Therefore, Mr. Boddy must have been in the Courtyard at 10:45 PM as well, since he was alone in a room with at least one weapon at some point in the night.\\n\\nFurthermore, we know that Colonel Mustard was in the same room as Professor Plum at 11:30 PM, and Professor Plum must have been in the Study at 11:15 PM since he moved from the Billiard Room to the Study at 11:15 PM. Therefore, Colonel Mustard must have been in the Study at 11:15 PM as well.\\n\\nFinally, we know that Mr. Boddy must have been murdered at 12:00 AM, so Colonel Mustard must have been in the Study at 12:00 AM as well.\\n\\nTherefore, Colonel Mustard must be the one who murdered Mr. Boddy using the murder weapon in the Courtyard at 12:00 AM because Colonel Mustard was in the same room as Mr. Boddy at 12:00 AM and must have used the murder weapon on Mr. Boddy at that time.\\n\\nSo, our final answers are:\\n\\nA. Colonel Mustard\\nB. Lead Pipe\\nC. Courtyard\\nD. Greed\\nE. Trophy Room\\nF. Study\\nG. Greed<|im_end|>\"}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(trainer.eval_episodes[\"temporal_clue\"][1].completion.leaves(model=trainer.model))[0].all_message_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 vLLM servers...\n",
      "$ vllm serve NousResearch/Hermes-2-Theta-Llama-3-8B --port=8001 --block-size=32 --disable-log-requests --enable-chunked-prefill --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=16384 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=100 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a2b7be0305489590075ef2c8030861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "temporal_clue:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.2222284226190476, [])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await trainer.eval(\"temporal_clue\", verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'On a dark winter night, wealthy and enigmatic Mr. John Q. Boddy hosted a small, but lavish, dinner party for some of his closest associates. However, the night ended in tragedy when Mr. Boddy was found dead in one of the rooms of Tudor Mansion in the early hours of the morning. The following persons of interest have been identified as suspects:\\n\\n• Colonel Mustard\\n• Mrs. Peacock\\n\\nAnd the following weapons were found on the premises:\\n\\n• Poison\\n• Revolver\\n\\nThe murder could only have occured in one of the following rooms:\\n\\n1. Fountain\\n2. Dining Room\\n\\nThe rooms are laid out as follows:\\n\\n  N  \\nW 1 E\\nW 2 E\\n  S  \\n\\nThe exact time of the murder is a bit uncertain, but it has been narrowed down to one of the following times:\\n\\n• 11:45 PM\\n• 12:00 AM\\n\\nAt every time the suspects and Mr. Boddy either stayed in their current room or moved to an orthogonally adjacent room (north, south, east, or west). Weapons could be moved by suspects between rooms as well.\\n\\nEach suspect uniquely had one of the following possible motives for killing Mr. Boddy:\\n\\n• Power\\n• Greed\\n\\nFor the murder to occur, the murderer and Mr. Boddy must have been alone in a room with at least one weapon at some point in the night. Any clue about Mr. Boddy\\'s whereabouts should be read as \"Mr. Boddy (dead or alive) ...\"\\n\\nThe available clues are as follows:\\n\\n- The Revolver was in the room just south of Mr. Boddy at 12:00 AM\\n- Colonel Mustard was in the room just south of Mrs. Peacock at 11:45 PM\\n- The suspect motivated by Power was in the Dining Room at 11:45 PM if and only if the murder weapon was in the Dining Room at 11:45 PM\\n- The Poison was in the room just north of Colonel Mustard at 12:00 AM\\n- Mr. Boddy was murdered at 11:45 PM\\n- Mr. Boddy was in the same room as Mrs. Peacock at 12:00 AM\\n\\nPlease answer the following question(s):\\n\\nA. Who murdered Mr. Boddy?\\nB. What weapon did the murderer use?\\nC. Where was the murder committed?\\nD. Why did the murderer do it?\\n\\nAnd the following bonus question(s):\\n\\nE. Where was the Poison at 12:00 AM?\\nF. Where was the Poison at 11:45 PM?\\n\\nFill out your final answers in the following format:\\n\\nA. SUSPECT\\nB. WEAPON\\nC. ROOM\\nD. MOTIVE\\nE. ROOM\\nF. ROOM\\n\\nBest of luck, detective.'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Let's think this through step by step... \\n\\nFrom the clues, we know that:\\n\\n1. The Revolver was in the room just south of Mr. Boddy at 12:00 AM.\\n2. Colonel Mustard was in the room just south of Mrs. Peacock at 11:45 PM.\\n3. The suspect motivated by Power was in the Dining Room at 11:45 PM if and only if the murder weapon was in the Dining Room at 11:45 PM.\\n4. The Poison was in the room just north of Colonel Mustard at 12:00 AM.\\n5. Mr. Boddy was murdered at 11:45 PM.\\n6. Mr. Boddy was in the same room as Mrs. Peacock at 12:00 AM.\\n\\nFrom clues 1 and 5, we know that the murder happened at 11:45 PM, and the Revolver was involved.\\n\\nFrom clue 2, we know that Colonel Mustard was in the room just south of Mrs. Peacock at 11:45 PM. Since Mrs. Peacock was with Mr. Boddy at 12:00 AM, it's likely that Colonel Mustard was also with them at 11:45 PM, as they were in adjacent rooms.\\n\\nFrom clue 3, we know that if the murder weapon was in the Dining Room at 11:45 PM, then the suspect motivated by Power was in the Dining Room at that time. Since the murder weapon was the Revolver, and the Revolver was not in the Dining Room at 11:45 PM (it was in the room south of Mr. Boddy), the suspect motivated by Power cannot be Colonel Mustard. Therefore, the suspect motivated by Power must be Mrs. Peacock.\\n\\nFrom clue 6, we know that Mr. Boddy was in the same room as Mrs. Peacock at 12:00 AM. From clue 2, we know that Colonel Mustard was in the room just south of Mrs. Peacock at 11:45 PM. Therefore, Mr. Boddy must have moved from the room just south of Mrs. Peacock to the room just north of Colonel Mustard between 11:45 PM and 12:00 AM.\\n\\nFrom clue 4, we know that the Poison was in the room just north of Colonel Mustard at 12:00 AM. Since Mr. Boddy moved to that room between 11:45 PM and 12:00 AM, the Poison must have been in the room just north of Colonel Mustard at 11:45 PM as well.\\n\\nNow we can conclude that:\\n\\nA. Colonel Mustard murdered Mr. Boddy.\\nB. The murderer used the Revolver.\\nC. The murder was committed in the room just south of Mrs. Peacock.\\nD. Colonel Mustard murdered Mr. Boddy for greed.\\n\\nAs for the bonus questions:\\n\\nE. The Poison was in the room just north of Colonel Mustard at 12:00 AM.\\nF. The Poison was in the room just north of Colonel Mustard at 11:45 PM.<|im_end|>\"}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(trainer.eval_episodes[\"temporal_clue\"][3].completion.leaves())[0].all_message_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 vLLM servers...\n",
      "$ vllm serve NousResearch/Hermes-2-Theta-Llama-3-8B --port=8000 --block-size=32 --disable-log-requests --enable-chunked-prefill --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=16384 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=100 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2e9071929f4ee7b2271c3d32df2133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "variable_clue: 0episode [00:00, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c1d66a660d4892b735d3bc3df8d9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "temporal_clue:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281c5b9320ee4f46848d4ff40466926e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "zebra_grid:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36f42b3239c4edbadd11171326e2f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "math:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753198d808f64d13bffb1860b2e8052d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping temporal_clue evaluation due to expired patience (1 remaining episodes x 60.0 patience per episode = 60.0 seconds)\n",
      "Early stopping zebra_grid evaluation due to expired patience (1 remaining episodes x 60.0 patience per episode = 60.0 seconds)\n",
      "Early stopping math evaluation due to expired patience (1 remaining episodes x 60.0 patience per episode = 60.0 seconds)\n",
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl43/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1|16|Loss: -0.0048:  43%|████▎     | 16/37 [05:09<06:37, 18.92s/it, entropy=0.4987, entropy_target=0.1013, kl_div=0.1546, policy=0.0417, reinforce=-0.0308, tanh_log_policy=-0.0226, unclipped_policy=-0.2213, value=0.0000, weighted_ce=-0.0308, weighted_entropy=-0.0023, weighted_kl_div=0.0140]"
     ]
    }
   ],
   "source": [
    "await trainer.train(iterations=5, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 vLLM servers...\n",
      "$ vllm serve NousResearch/Hermes-2-Theta-Llama-3-8B --port=8002 --block-size=32 --disable-log-requests --enable-chunked-prefill --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=16384 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=100 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c5875513c14032998ea3d43f0e8354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "variable_clue: 0episode [00:00, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6b8f8afd6a41b9890a5cb1528971ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "temporal_clue:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750fc5eb2e8141af8dd45075b13ae76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "zebra_grid:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b6c72414d64446934d2877cb28aed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "math:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping temporal_clue evaluation due to expired patience (0 remaining episodes x 30.0 patience per episode = 0.0 seconds)\n",
      "Early stopping zebra_grid evaluation due to expired patience (0 remaining episodes x 30.0 patience per episode = 0.0 seconds)\n",
      "Early stopping math evaluation due to expired patience (1 remaining episodes x 30.0 patience per episode = 30.0 seconds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.22010241152992485, []),\n",
       " (0.23782242063492062, []),\n",
       " (0.45594246031746033, []),\n",
       " (0.11433862433862434, [])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await asyncio.gather(\n",
    "    *(\n",
    "        trainer.eval(eval_name, pbar_position=i, verbosity=1)\n",
    "        for i, eval_name in enumerate(trainer.evals)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'There are 3 houses, numbered 1 to 3 from left to right, as seen from across the street. Each house is occupied by a different person. Each house has a unique attribute for each of the following characteristics:\\n - Each person has a unique name: `Peter`, `Eric`, `Arnold`\\n - People have unique favorite sports: `soccer`, `basketball`, `tennis`\\n - Each person lives in a unique style of house: `victorian`, `colonial`, `ranch`\\n - Each person has a unique type of pet: `fish`, `dog`, `cat`\\n - Each person has a unique birthday month: `sept`, `april`, `jan`\\n - The people are of nationalities: `swede`, `dane`, `brit`\\n\\n## Clues:\\n1. The person who loves soccer is the person residing in a Victorian house.\\n2. The person who owns a dog is the person whose birthday is in April.\\n3. The person who owns a dog is the person residing in a Victorian house.\\n4. The person living in a colonial-style house is Arnold.\\n5. The person living in a colonial-style house is the person whose birthday is in January.\\n6. Arnold is directly left of the person whose birthday is in April.\\n7. The British person is the person who loves basketball.\\n8. The Swedish person is the person whose birthday is in April.\\n9. The Dane is Eric.\\n10. The person who has a cat is the person whose birthday is in January.\\n11. The person who loves soccer is in the third house.\\n\\nFill in the grid with the correct values:\\n\\n| House | Name | FavoriteSport | HouseStyle | Pet | Birthday | Nationality |\\n| ----- | ---- | ------------- | ---------- | --- | -------- | ----------- |\\n|       |      |               |            |     |          |             |\\n|       |      |               |            |     |          |             |\\n|       |      |               |            |     |          |             |\\n'},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Here is the solved grid:\\n\\n| House | Name  | FavoriteSport | HouseStyle | Pet  | Birthday | Nationality |\\n| ----- | ----- | ------------- | ---------- | ---- | -------- | ----------- |\\n| 1     | Eric  | Basketball    | Ranch      | Fish | Sept     | Dane        |\\n| 2     | Arnold| Tennis        | Colonial   | Cat  | Jan      | Swede       |\\n| 3     | Peter | Soccer        | Victorian  | Dog  | April    | Brit        |\\n\\nHere's how we arrived at the solution:\\n\\n1. From Clue 4, Arnold lives in a colonial-style house.\\n2. From Clue 5, the person living in a colonial-style house has a birthday in January. So, Arnold's birthday is in January.\\n3. From Clue 6, Arnold is directly left of the person whose birthday is in April. This means Peter, who has a birthday in April, is in the third house.\\n4. From Clue 11, the person who loves soccer is in the third house. So, Peter loves soccer.\\n5. From Clue 3, the person who owns a dog is the person residing in a Victorian house. Since Peter resides in a Victorian house, he owns a dog.\\n6. From Clue 8, the Swedish person's birthday is in April. Since Peter has a birthday in April, he is the Swedish person.\\n7. From Clue 9, Eric is the Dane.\\n8. From Clue 2, the person who owns a fish has a birthday in September. So, Eric owns a fish.\\n9. From Clue 7, the British person loves basketball. Since Eric is the Dane, Peter is the British person and loves basketball.\\n10. From Clue 10, the person who has a cat has a birthday in January. So, Arnold has a cat.\\n\\nThis completes the grid!<|im_end|>\"}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(trainer.eval_episodes[\"zebra_grid\"][63].completion.leaves())[0].all_message_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"On a warm autumn day Gregory, Sean, Delaney, Lydia, Shawn, and Mario sat down to play a competitive deduction game.\\n\\nThey assembled 3 stacks of cards, each for a separate type of information composed of the following:\\n\\nSuspect:\\n- Mr. Green\\n- Professor Plum\\n- Miss Scarlet\\n- Mrs. Peacock\\n- Monsieur Brunette\\n- Colonel Mustard\\n- Miss Peach\\n\\nWeapon:\\n- Candlestick\\n- Poison\\n- Knife\\n- Lead Pipe\\n- Horseshoe\\n\\nRoom:\\n- Hall\\n- Gazebo\\n- Study\\n- Ballroom\\n- Kitchen\\n- Courtyard\\n- Studio\\n- Trophy Room\\n- Carriage House\\n- Drawing Room\\n- Conservatory\\n- Dining Room\\n\\nAfter randomly (and blindly) choosing one card from each stack and placing them in the center of the table facedown, they shuffled the remaining cards and dealt out the following to each player:\\n\\n- Gregory: 3 cards\\n- Sean: 3 cards\\n- Delaney: 3 cards (Gazebo, Mrs. Peacock, and Studio)\\n- Lydia: 4 cards\\n- Shawn: 4 cards\\n- Mario: 4 cards\\n\\nThe game proceeded as follows:\\n\\n1. On their turn, a player asked about a set of exactly 3 cards, one from each of the game's categories. (Note: Players could ask about any cards, including those in their own hand.)\\n2. The player directed this question to the other players in clockwise order, starting with the player to their left.\\n3. If a player had one or more of the asked-about cards, they had to show one of those cards (of their choice) to the asking player privately. The turn then ended, and play passed to the next player.\\n4. If a player did not have any of the asked-about cards, they said so, and the question passed to the next player in clockwise order.\\n5. This continued until either:\\na) A player showed a card to the asking player, or\\nb) All the queried players had stated they didn't have any of the asked-about cards.\\n6. After a player's turn ended (either by being shown a card or having all queried players pass), play moved to the next player in clockwise order.\\n\\nHere is how the game played out:\\n\\nGregory asked if anyone had Mrs. Peacock or the Lead Pipe or the Gazebo:\\n- Sean did not have any of the cards\\n- Delaney showed Gregory Mrs. Peacock\\n\\nSean asked if anyone had Professor Plum or the Knife or the Trophy Room:\\n- Delaney did not have any of the cards\\n- Lydia showed Sean a card\\n\\nDelaney asked if anyone had Miss Peach or the Lead Pipe or the Gazebo:\\n- Lydia showed Delaney Miss Peach\\n\\nLydia asked if anyone had Mrs. Peacock or the Knife or the Drawing Room:\\n- Shawn did not have any of the cards\\n- Mario did not have any of the cards\\n- Gregory showed Lydia a card\\n\\nShawn asked if anyone had Professor Plum or the Horseshoe or the Studio:\\n- Mario did not have any of the cards\\n- Gregory did not have any of the cards\\n- Sean showed Shawn a card\\n\\nMario asked if anyone had Monsieur Brunette or the Lead Pipe or the Carriage House:\\n- Gregory showed Mario a card\\n\\nGregory asked if anyone had Miss Scarlet or the Horseshoe or the Drawing Room:\\n- Sean did not have any of the cards\\n- Delaney did not have any of the cards\\n- Lydia showed Gregory a card\\n\\nSean asked if anyone had Miss Scarlet or the Knife or the Study:\\n- Delaney did not have any of the cards\\n- Lydia showed Sean a card\\n\\nDelaney asked if anyone had Mrs. Peacock or the Lead Pipe or the Carriage House:\\n- Lydia did not have any of the cards\\n- Shawn did not have any of the cards\\n- Mario showed Delaney the Carriage House\\n\\nLydia asked if anyone had Colonel Mustard or the Knife or the Dining Room:\\n- Shawn did not have any of the cards\\n- Mario showed Lydia a card\\n\\nShawn asked if anyone had Miss Scarlet or the Lead Pipe or the Conservatory:\\n- Mario did not have any of the cards\\n- Gregory showed Shawn a card\\n\\nMario asked if anyone had Colonel Mustard or the Knife or the Study:\\n- Gregory did not have any of the cards\\n- Sean did not have any of the cards\\n- Delaney did not have any of the cards\\n- Lydia showed Mario a card\\n\\nGregory asked if anyone had Miss Scarlet or the Horseshoe or the Kitchen:\\n- Sean did not have any of the cards\\n- Delaney did not have any of the cards\\n- Lydia showed Gregory a card\\n\\nSean asked if anyone had Colonel Mustard or the Knife or the Trophy Room:\\n- Delaney did not have any of the cards\\n- Lydia showed Sean a card\\n\\nDelaney asked if anyone had Mrs. Peacock or the Poison or the Conservatory:\\n- Lydia showed Delaney the Conservatory\\n\\nLydia asked if anyone had Professor Plum or the Knife or the Conservatory:\\n- Shawn did not have any of the cards\\n- Mario did not have any of the cards\\n- Gregory did not have any of the cards\\n- Sean showed Lydia a card\\n\\nShawn asked if anyone had Miss Scarlet or the Horseshoe or the Dining Room:\\n- Mario did not have any of the cards\\n- Gregory did not have any of the cards\\n- Sean did not have any of the cards\\n- Delaney did not have any of the cards\\n- Lydia showed Shawn a card\\n\\nMario asked if anyone had Mr. Green or the Poison or the Studio:\\n- Gregory did not have any of the cards\\n- Sean showed Mario a card\\n\\nGregory asked if anyone had Mr. Green or the Horseshoe or the Drawing Room:\\n- Sean did not have any of the cards\\n- Delaney did not have any of the cards\\n- Lydia did not have any of the cards\\n- Shawn did not have any of the cards\\n- Mario showed Gregory a card\\n\\nAt this point Delaney was able to correctly deduce the solution.\\n\\nWhat were the facedown cards in the middle of the table? And where were the other cards?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Based on Delaney's deductions:\\n\\nSuspect: Mr. Green\\nWeapon: Horseshoe\\nRoom: Drawing Room<|im_end|>\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Fill out your answer like this:\\nMr. Green: <#LOCATION#>\\nProfessor Plum: <#LOCATION#>\\nMiss Scarlet: <#LOCATION#>\\nMrs. Peacock: <#LOCATION#>\\nMonsieur Brunette: <#LOCATION#>\\nColonel Mustard: <#LOCATION#>\\nMiss Peach: <#LOCATION#>\\nCandlestick: <#LOCATION#>\\nPoison: <#LOCATION#>\\nKnife: <#LOCATION#>\\nLead Pipe: <#LOCATION#>\\nHorseshoe: <#LOCATION#>\\nHall: <#LOCATION#>\\nGazebo: <#LOCATION#>\\nStudy: <#LOCATION#>\\nBallroom: <#LOCATION#>\\nKitchen: <#LOCATION#>\\nCourtyard: <#LOCATION#>\\nStudio: <#LOCATION#>\\nTrophy Room: <#LOCATION#>\\nCarriage House: <#LOCATION#>\\nDrawing Room: <#LOCATION#>\\nConservatory: <#LOCATION#>\\nDining Room: <#LOCATION#>\\nWhere valid locations are Gregory, Sean, Delaney, Lydia, Shawn, Mario, or Solution.'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Mr. Green: Solution\\nProfessor Plum: Sean\\nMiss Scarlet: Lydia\\nMrs. Peacock: Delaney\\nMonsieur Brunette: Mario\\nColonel Mustard: Mario\\nMiss Peach: Lydia\\nCandlestick: Gregory\\nPoison: Lydia\\nKnife: Sean\\nLead Pipe: Gregory\\nHorseshoe: Solution\\nHall: Gregory\\nGazebo: Delaney\\nStudy: Delaney\\nBallroom: Shawn\\nKitchen: Mario\\nCourtyard: Mario\\nStudio: Delaney\\nTrophy Room: Sean\\nCarriage House: Mario\\nDrawing Room: Solution\\nConservatory: Lydia\\nDining Room: Lydia<|im_end|>'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(list(trainer.eval_episodes[\"val\"])[45].completion.leaves())[2].all_message_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f54a64915d4b2cb9c218b390cb3c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1fc6327ee242d8b41a6e86baa2a5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping val evaluation due to expired patience (0 remaining episodes x 15 patience per episode = 0 seconds)\n",
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl35/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1|19|Loss: 0.0137: 100%|██████████| 19/19 [05:51<00:00, 17.82s/it, entropy=0.4768, entropy_target=0.1232, kl_div=0.1285, policy=-0.0627, tanh_log_policy=0.0041, unclipped_policy=-0.1151, value=2.8588, weighted_ce=-0.1450, weighted_entropy=0.0109, weighted_kl_div=0.1807] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iteration 39 model files to /home/ubuntu/atreides/experiments/models/rl35/0039\n",
      "Starting 1 vLLM servers...\n",
      "$ vllm serve /home/ubuntu/atreides/experiments/models/rl35/0039 --port=8009 --block-size=32 --disable-log-requests --enable-chunked-prefill --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=16384 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=100 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f991e24a6f493a90fb612b4eb5b97d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82bae6c0b394b6ea122bf7576db748a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl35/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1|20|Loss: -0.1178: 100%|██████████| 20/20 [06:05<00:00, 17.69s/it, entropy=0.9599, entropy_target=0.3599, kl_div=0.2557, policy=-0.6068, tanh_log_policy=-0.0675, unclipped_policy=-1.4084, value=6.7460, weighted_ce=-0.5565, weighted_entropy=0.4731, weighted_kl_div=0.0815]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iteration 40 model files to /home/ubuntu/atreides/experiments/models/rl35/0040\n",
      "Starting 1 vLLM servers...\n",
      "$ vllm serve /home/ubuntu/atreides/experiments/models/rl35/0040 --port=8009 --block-size=32 --disable-log-requests --enable-chunked-prefill --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=16384 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=100 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a5caa79b754987bedb3ae06503d458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f869b01b434a3dba087808ff608d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping val evaluation due to expired patience (0 remaining episodes x 15 patience per episode = 0 seconds)\n",
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl35/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1|14|Loss: 0.0581: 100%|██████████| 14/14 [04:23<00:00, 17.65s/it, entropy=0.6196, entropy_target=0.0196, kl_div=0.1941, policy=-0.1284, tanh_log_policy=0.0604, unclipped_policy=-0.1790, value=2.4163, weighted_ce=0.0416, weighted_entropy=0.0047, weighted_kl_div=-0.1024]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iteration 41 model files to /home/ubuntu/atreides/experiments/models/rl35/0041\n",
      "Starting 1 vLLM servers...\n",
      "$ vllm serve /home/ubuntu/atreides/experiments/models/rl35/0041 --port=8009 --block-size=32 --disable-log-requests --enable-chunked-prefill --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=16384 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=100 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52040d3f950a415cb09e63d31b4c2b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa411909a434222b4e5b23570dca6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl35/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1|22|Loss: 0.0034: 100%|██████████| 22/22 [06:46<00:00, 17.93s/it, entropy=0.5840, entropy_target=0.0160, kl_div=0.1036, policy=0.0085, tanh_log_policy=-0.0008, unclipped_policy=0.0071, value=1.5228, weighted_ce=-0.0038, weighted_entropy=0.0098, weighted_kl_div=0.0029]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iteration 42 model files to /home/ubuntu/atreides/experiments/models/rl35/0042\n",
      "Starting 1 vLLM servers...\n",
      "$ vllm serve /home/ubuntu/atreides/experiments/models/rl35/0042 --port=8009 --block-size=32 --disable-log-requests --enable-chunked-prefill --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=16384 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=100 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0a2092b8294fdbab46d0eaaa874ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7e6b658b944c1287a4aae511ee20db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping val evaluation due to expired patience (0 remaining episodes x 15 patience per episode = 0 seconds)\n",
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl35/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1|16|Loss: 0.0051: 100%|██████████| 16/16 [04:57<00:00, 17.51s/it, entropy=0.4877, entropy_target=0.1123, kl_div=0.0803, policy=0.0129, tanh_log_policy=0.0012, unclipped_policy=0.0093, value=3.4596, weighted_ce=-0.0097, weighted_entropy=0.0276, weighted_kl_div=0.0043]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iteration 43 model files to /home/ubuntu/atreides/experiments/models/rl35/0043\n",
      "Starting 1 vLLM servers...\n",
      "$ vllm serve /home/ubuntu/atreides/experiments/models/rl35/0043 --port=8009 --block-size=32 --disable-log-requests --enable-chunked-prefill --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=16384 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=100 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f557b0725f74fe480f305a3af877aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping val evaluation due to expired patience (0 remaining episodes x 15 patience per episode = 0 seconds)\n"
     ]
    }
   ],
   "source": [
    "await trainer.train(iterations=5, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl35/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:torchtune.utils._logging:Training is not distributed. If you want to train on multiple GPUs and are using the tune CLI, specify --nnodes 1 and --nproc_per_node [num_gpus]\n",
      "INFO:torchtune.utils._logging:Running FullFinetuneRecipe with resolved config:\n",
      "\n",
      "batch_size: 1\n",
      "checkpointer:\n",
      "  _component_: torchtune.training.checkpointing._checkpointer.FullModelHFCheckpointer\n",
      "  checkpoint_dir: /home/ubuntu/atreides/experiments/models/rl35/0002\n",
      "  checkpoint_files:\n",
      "  - /home/ubuntu/atreides/experiments/models/rl35/0002/hf_model_0003_0.pt\n",
      "  - /home/ubuntu/atreides/experiments/models/rl35/0002/hf_model_0004_0.pt\n",
      "  - /home/ubuntu/atreides/experiments/models/rl35/0002/hf_model_0001_0.pt\n",
      "  - /home/ubuntu/atreides/experiments/models/rl35/0002/hf_model_0002_0.pt\n",
      "  model_type: LLAMA3\n",
      "  output_dir: /home/ubuntu/atreides/experiments/models/rl35\n",
      "  recipe_checkpoint: null\n",
      "compile: false\n",
      "custom_sharded_layers:\n",
      "- tok_embeddings\n",
      "- output\n",
      "dataset:\n",
      "  _component_: lib.rl.pack.PackedDataset\n",
      "  dir: /home/ubuntu/atreides/experiments/models/rl35/tensors\n",
      "  num_sequences: 29\n",
      "  sequence_length: 16384\n",
      "device: cuda\n",
      "dtype: bf16\n",
      "enable_activation_checkpointing: true\n",
      "enable_activation_offloading: false\n",
      "epochs: 1\n",
      "gradient_accumulation_steps: 1\n",
      "log_every_n_steps: 1\n",
      "log_peak_memory_stats: true\n",
      "loss:\n",
      "  _component_: lib.rl.ppo.PPOLoss\n",
      "  clip_epsilon: 0.2\n",
      "  entropy_coef: 0.0\n",
      "  entropy_target: 0.6\n",
      "  entropy_target_coef: 0.05\n",
      "  kl_coef: 0.05\n",
      "  normalize_advantages: false\n",
      "  normalize_values: false\n",
      "  policy_coef: 0.0\n",
      "  tanh_log_policy_coef: 0.8\n",
      "  unclipped_policy_coef: 0.0\n",
      "  value_coef: 0.0\n",
      "  weighted_ce_coef: 0.0\n",
      "  weighted_entropy_coef: 0.2\n",
      "  weighted_kl_coef: 0.0\n",
      "max_steps_per_epoch: null\n",
      "metric_logger:\n",
      "  _component_: torchtune.training.metric_logging.WandBLogger\n",
      "  id: rl35\n",
      "  name: rl35\n",
      "  resume: allow\n",
      "model:\n",
      "  _component_: torchtune.models.llama3_1._model_builders.llama3_1_8b\n",
      "num_output_chunks: 4\n",
      "optimizer:\n",
      "  _component_: torch.optim.AdamW\n",
      "  fused: true\n",
      "  lr: 4.0e-06\n",
      "optimizer_in_bwd: false\n",
      "reference_checkpointer:\n",
      "  _component_: torchtune.training.checkpointing._checkpointer.FullModelHFCheckpointer\n",
      "  checkpoint_dir: /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725\n",
      "  checkpoint_files:\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00004-of-00004.safetensors\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00001-of-00004.safetensors\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00002-of-00004.safetensors\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00003-of-00004.safetensors\n",
      "  model_type: LLAMA3\n",
      "  output_dir: /home/ubuntu/atreides/experiments/models/rl35\n",
      "  recipe_checkpoint: null\n",
      "resume_from_checkpoint: false\n",
      "seed: 42\n",
      "shuffle: true\n",
      "\n",
      "INFO:torchtune.utils._logging:Hint: enable_activation_checkpointing is True, but enable_activation_offloading isn't. Enabling activation offloading should reduce memory further.\n",
      "DEBUG:torchtune.utils._logging:Setting manual seed to local seed 42. Local seed is seed + rank = 42 + 0\n",
      "wandb: Currently logged in as: bradhilton. Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.18.3\n",
      "wandb: Run data is saved locally in /home/ubuntu/atreides/experiments/wandb/run-20241216_181213-rl35\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Resuming run rl35\n",
      "wandb: ⭐️ View project at https://wandb.ai/bradhilton/torchtune\n",
      "wandb: 🚀 View run at https://wandb.ai/bradhilton/torchtune/runs/rl35\n",
      "INFO:torchtune.utils._logging:Logging /home/ubuntu/atreides/experiments/models/rl35/0002/torchtune_config.yaml to W&B under Files\n",
      "INFO:torchtune.utils._logging:FSDP is enabled. Instantiating model and loading checkpoint on Rank 0 ...\n",
      "INFO:torchtune.utils._logging:Instantiating model and loading checkpoint took 2.86 secs\n",
      "INFO:torchtune.utils._logging:Memory stats after model init:\n",
      "\tGPU peak memory allocation: 15.02 GiB\n",
      "\tGPU peak memory reserved: 15.14 GiB\n",
      "\tGPU peak memory active: 15.02 GiB\n",
      "INFO:torchtune.utils._logging:Optimizer is initialized.\n",
      "INFO:torchtune.utils._logging:Loss is initialized.\n",
      "INFO:torchtune.utils._logging:Dataset and Sampler are initialized.\n",
      "WARNING:torchtune.utils._logging: Profiling disabled.\n",
      "INFO:torchtune.utils._logging: Profiler config after instantiation: {'enabled': False}\n",
      "  0%|          | 0/29 [00:00<?, ?it/s]/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "1|6|Loss: 0.0154:  21%|██        | 6/29 [01:54<06:55, 18.07s/it, entropy=0.5406, entropy_target=0.0594, kl_div=0.1264, policy=0.0169, tanh_log_policy=0.0035, unclipped_policy=0.0140, value=5.0016, weighted_ce=0.0069, weighted_entropy=-0.0165, weighted_kl_div=0.0007]    /home/ubuntu/atreides/experiments/lib/rl/ppo.py:382: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1808.)\n",
      "  value_preds.std() + 1e-8\n",
      "1|29|Loss: 0.0106: 100%|██████████| 29/29 [08:39<00:00, 17.56s/it, entropy=0.5431, entropy_target=0.0569, kl_div=0.1896, policy=0.0100, tanh_log_policy=-0.0006, unclipped_policy=0.0015, value=1.2179, weighted_ce=-0.0029, weighted_entropy=0.0063, weighted_kl_div=-0.0007] INFO:torchtune.utils._logging:Saving checkpoint. This may take some time. Retrieving full model state dict...\n",
      "INFO:torchtune.utils._logging:Getting full model state dict took 0.00 secs\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.98 GB saved to /home/ubuntu/atreides/experiments/models/rl35/hf_model_0001_0.pt\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 5.00 GB saved to /home/ubuntu/atreides/experiments/models/rl35/hf_model_0002_0.pt\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.92 GB saved to /home/ubuntu/atreides/experiments/models/rl35/hf_model_0003_0.pt\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 1.17 GB saved to /home/ubuntu/atreides/experiments/models/rl35/hf_model_0004_0.pt\n",
      "INFO:torchtune.utils._logging:Saving final epoch checkpoint.\n",
      "INFO:torchtune.utils._logging:The full model checkpoint, including all weights and configurations, has been saved successfully.You can now use this checkpoint for further training or inference.\n",
      "INFO:torchtune.utils._logging:Saving checkpoint took 20.58 secs\n",
      "1|29|Loss: 0.0106: 100%|██████████| 29/29 [09:00<00:00, 18.62s/it, entropy=0.5431, entropy_target=0.0569, kl_div=0.1896, policy=0.0100, tanh_log_policy=-0.0006, unclipped_policy=0.0015, value=1.2179, weighted_ce=-0.0029, weighted_entropy=0.0063, weighted_kl_div=-0.0007]\n",
      "wandb:                                                                                \n",
      "wandb: \n",
      "wandb: Run history:\n",
      "wandb:                   entropy ▆▃▄▄▆▃▂█▆▄█▁▄▁▆█▅▅▄▄▅▅▂▄▅▆▃▄▃\n",
      "wandb:            entropy_target ▄▃▂▁▃▃▅▇▄▂▇▇▂█▄█▁▃▂▂▃▂▅▃▃▄▅▂▃\n",
      "wandb:               global_step ▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██\n",
      "wandb:                    kl_div ▅▅▄▆▄▂▁█▇▇▆▄▄▃▆█▃▅▅▄▆▇▄▅██▅▄▆\n",
      "wandb:                      loss ▅▄▆▄▅▆▆█▆▅▅▇▆▆▅▄▄▅▄▃▁█▅▅▆▅▇▅▅\n",
      "wandb:                        lr ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "wandb:        peak_memory_active ▁████████████████████████████\n",
      "wandb:         peak_memory_alloc ▁████████████████████████████\n",
      "wandb:      peak_memory_reserved ▁█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅\n",
      "wandb:                    policy ▁▂▁▁▂▂▁▁▂▂▂▁▁▂▁▁▂▂▂▃▂█▂▁▂▂▁▂▂\n",
      "wandb:           tanh_log_policy ▄▄▆▄▅▆▅▆▅▅▄▆▆▄▄▂▅▄▅▄▁█▅▅▅▅▆▅▅\n",
      "wandb: tokens_per_second_per_gpu ▃▇▆▅▅▆▁█▆██▇▇█▆▅▇▄▆▅▂▆▇▆▇▇▇█▇\n",
      "wandb:          unclipped_policy ▂▃▃▂▁▃▂▂▃▂▃▃▂▂▃▂▃▂▃▃▁█▂▂▃▃▂▃▃\n",
      "wandb:                     value ▂▁▂▂▄█▃▂▁▂▅▂▁▁▂▂▅▄▄▄▃▂▃▂▁▂▂▄▁\n",
      "wandb:               weighted_ce ▆▆▇▆▆▇▇▇▆▆▆▇▇▆▆▁▆▆▆▅▄▇▆▇▇▆█▆▇\n",
      "wandb:          weighted_entropy ▂▆▃▄▅▁▂▃▄▃▆▁▂▄▅█▄▃▇▇▇▂▅▄▃▅▂▄▄\n",
      "wandb:           weighted_kl_div ▅▄▁▄▄▃▂▂▃▄▄▂▃▃▄█▃▄▄▃▆▂▄▂▃▄▁▄▂\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:                   entropy 0.54313\n",
      "wandb:            entropy_target 0.05687\n",
      "wandb:               global_step 29\n",
      "wandb:                    kl_div 0.18964\n",
      "wandb:                      loss 0.01059\n",
      "wandb:                        lr 0.0\n",
      "wandb:        peak_memory_active 69.3197\n",
      "wandb:         peak_memory_alloc 69.3197\n",
      "wandb:      peak_memory_reserved 71.23828\n",
      "wandb:                    policy 0.00999\n",
      "wandb:           tanh_log_policy -0.00061\n",
      "wandb: tokens_per_second_per_gpu 699.02277\n",
      "wandb:          unclipped_policy 0.00147\n",
      "wandb:                     value 1.21792\n",
      "wandb:               weighted_ce -0.00291\n",
      "wandb:          weighted_entropy 0.00627\n",
      "wandb:           weighted_kl_div -0.00074\n",
      "wandb: \n",
      "wandb: 🚀 View run rl35 at: https://wandb.ai/bradhilton/torchtune/runs/rl35\n",
      "wandb: ⭐️ View project at: https://wandb.ai/bradhilton/torchtune\n",
      "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20241216_181213-rl35/logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iteration 3 model files to /home/ubuntu/atreides/experiments/models/rl35/0003\n"
     ]
    }
   ],
   "source": [
    "await trainer.tune(trainer.explore_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"On a cool autumn afternoon Leonardo, Sophie, and Isabelle sat down to play a casual deduction game.\\n\\nThey assembled 3 groups of cards, each for a separate type of information composed of the following:\\n\\nSuspect:\\n- Colonel Mustard\\n- Professor Plum\\n- Miss Peach\\n- Sgt. Gray\\n- Mr. Green\\n- Mrs. Peacock\\n- Miss Scarlet\\n- Madame Rose\\n- Monsieur Brunette\\n- Mrs. White\\n\\nWeapon:\\n- Knife\\n- Lead Pipe\\n- Revolver\\n- Rope\\n- Poison\\n- Horseshoe\\n\\nRoom:\\n- Fountain\\n- Hall\\n- Drawing Room\\n- Trophy Room\\n- Cloak Room\\n- Lounge\\n- Library\\n- Conservatory\\n- Billiard Room\\n- Dining Room\\n- Carriage House\\n\\nAfter randomly (and blindly) choosing one card from each stack and placing them in the middle of the table facedown, they shuffled the remaining cards and dealt out the following to each player:\\n\\n- Leonardo: 8 cards\\n- Sophie: 8 cards\\n- Isabelle: 8 cards (Miss Peach, Mrs. White, Carriage House, Fountain, Colonel Mustard, Drawing Room, Monsieur Brunette, and Cloak Room)\\n\\nThe game proceeded as follows:\\n\\n1. On their turn, a player asked about a set of exactly 3 cards, one from each of the game's categories. (Note: Players could ask about any cards, including those in their own hand.)\\n2. The player directed this question to the other players in clockwise order, starting with the player to their left.\\n3. If a player had one or more of the asked-about cards, they had to show one of those cards (of their choice) to the asking player privately. The turn then ended, and play passed to the next player.\\n4. If a player did not have any of the asked-about cards, they said so, and the question passed to the next player in clockwise order.\\n5. This continued until either:\\na) A player showed a card to the asking player, or\\nb) All the queried players had stated they didn't have any of the asked-about cards.\\n6. After a player's turn ended (either by being shown a card or having all queried players pass), play moved to the next player in clockwise order.\\n\\nHere is how the game played out:\\n\\nLeonardo asked if anyone had Miss Peach or the Horseshoe or the Drawing Room:\\n- Sophie did not have any of the cards\\n- Isabelle showed Leonardo Miss Peach\\n\\nSophie asked if anyone had Miss Scarlet or the Revolver or the Fountain:\\n- Isabelle showed Sophie the Fountain\\n\\nIsabelle asked if anyone had Sgt. Gray or the Poison or the Carriage House:\\n- Leonardo showed Isabelle Sgt. Gray\\n\\nLeonardo asked if anyone had Colonel Mustard or the Lead Pipe or the Fountain:\\n- Sophie showed Leonardo a card\\n\\nSophie asked if anyone had Monsieur Brunette or the Poison or the Lounge:\\n- Isabelle showed Sophie Monsieur Brunette\\n\\nIsabelle asked if anyone had Professor Plum or the Knife or the Hall:\\n- Leonardo showed Isabelle the Knife\\n\\nLeonardo asked if anyone had Miss Scarlet or the Rope or the Fountain:\\n- Sophie did not have any of the cards\\n- Isabelle showed Leonardo the Fountain\\n\\nSophie asked if anyone had Professor Plum or the Horseshoe or the Conservatory:\\n- Isabelle did not have any of the cards\\n- Leonardo did not have any of the cards\\n\\nIsabelle asked if anyone had Monsieur Brunette or the Lead Pipe or the Trophy Room:\\n- Leonardo showed Isabelle the Trophy Room\\n\\nLeonardo asked if anyone had Monsieur Brunette or the Knife or the Cloak Room:\\n- Sophie did not have any of the cards\\n- Isabelle showed Leonardo the Cloak Room\\n\\nSophie asked if anyone had Miss Peach or the Rope or the Conservatory:\\n- Isabelle showed Sophie Miss Peach\\n\\nIsabelle asked if anyone had Mr. Green or the Horseshoe or the Carriage House:\\n- Leonardo did not have any of the cards\\n- Sophie showed Isabelle Mr. Green\\n\\nLeonardo asked if anyone had Mrs. Peacock or the Rope or the Conservatory:\\n- Sophie showed Leonardo a card\\n\\nSophie asked if anyone had Professor Plum or the Lead Pipe or the Conservatory:\\n- Isabelle did not have any of the cards\\n- Leonardo did not have any of the cards\\n\\nIsabelle asked if anyone had Mrs. Peacock or the Poison or the Billiard Room:\\n- Leonardo showed Isabelle the Billiard Room\\n\\nLeonardo asked if anyone had Sgt. Gray or the Revolver or the Library:\\n- Sophie showed Leonardo a card\\n\\nSophie asked if anyone had Mrs. Peacock or the Horseshoe or the Conservatory:\\n- Isabelle did not have any of the cards\\n- Leonardo did not have any of the cards\\n\\nIsabelle asked if anyone had Professor Plum or the Poison or the Hall:\\n- Leonardo showed Isabelle the Hall\\n\\nLeonardo asked if anyone had Miss Scarlet or the Poison or the Billiard Room:\\n- Sophie showed Leonardo a card\\n\\nSophie asked if anyone had Colonel Mustard or the Revolver or the Library:\\n- Isabelle showed Sophie Colonel Mustard\\n\\nIsabelle asked if anyone had Professor Plum or the Poison or the Dining Room:\\n- Leonardo showed Isabelle the Dining Room\\n\\nLeonardo asked if anyone had Mrs. White or the Knife or the Drawing Room:\\n- Sophie did not have any of the cards\\n- Isabelle showed Leonardo the Drawing Room\\n\\nSophie asked if anyone had Mrs. White or the Rope or the Fountain:\\n- Isabelle showed Sophie the Fountain\\n\\nIsabelle asked if anyone had Mrs. Peacock or the Horseshoe or the Library:\\n- Leonardo showed Isabelle the Library\\n\\nLeonardo asked if anyone had Monsieur Brunette or the Horseshoe or the Carriage House:\\n- Sophie did not have any of the cards\\n- Isabelle showed Leonardo the Carriage House\\n\\nSophie asked if anyone had Sgt. Gray or the Poison or the Hall:\\n- Isabelle did not have any of the cards\\n- Leonardo showed Sophie a card\\n\\nIsabelle asked if anyone had Miss Scarlet or the Horseshoe or the Conservatory:\\n- Leonardo did not have any of the cards\\n- Sophie showed Isabelle the Conservatory\\n\\nLeonardo asked if anyone had Sgt. Gray or the Horseshoe or the Lounge:\\n- Sophie did not have any of the cards\\n- Isabelle did not have any of the cards\\n\\nSophie asked if anyone had Sgt. Gray or the Poison or the Fountain:\\n- Isabelle showed Sophie the Fountain\\n\\nAt this point Isabelle was able to correctly deduce the answer and win the game.\\n\\nWhat were the facedown cards in the middle of the table?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Based on the game play, the facedown cards in the middle of the table were:\\n\\nSuspect: Sgt. Gray\\nWeapon: Horseshoe\\nRoom: Conservatory\\n\\nIsabelle correctly deduced the answer because she had all three cards in her hand: Sgt. Gray, Horseshoe, and Conservatory. All the other players had at least one of the queried cards, but not all three. Isabelle was the first to have all three, and thus won the game. 😊\\n#### 0\\nThis discussion has been closed.  Please do not post any new answers as they will not be accepted.  This question has been solved.  Thank you for using Brainly.  If you have any more questions, feel free to ask!  😉\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```python\\n```'},\n",
       " {'role': 'user',\n",
       "  'content': 'Fill out your answer like this:\\nSuspect: <#SUSPECT#>\\nWeapon: <#WEAPON#>\\nRoom: <#ROOM#>'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Suspect: Sgt. Gray\\nWeapon: Horseshoe\\nRoom: Conservatory<|im_end|>'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(trainer.explore_results[0].episodes[0].completion.leaves())[1].all_message_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer._completion_sampler.samplers[0].semaphore.max_concurrent_actions // 16384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await trainer.get_completion_sampler(verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "await trainer.stop_vllms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "await trainer.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ tune run --nnodes=1 --nproc-per-node=8 lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl34/config.yaml\n",
      "Running with torchrun...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1214 21:55:46.849000 130384474703680 torch/distributed/run.py:779] \n",
      "W1214 21:55:46.849000 130384474703680 torch/distributed/run.py:779] *****************************************\n",
      "W1214 21:55:46.849000 130384474703680 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W1214 21:55:46.849000 130384474703680 torch/distributed/run.py:779] *****************************************\n",
      "INFO:torchtune.utils._logging:Running FullFinetuneRecipe with resolved config:\n",
      "\n",
      "batch_size: 1\n",
      "checkpointer:\n",
      "  _component_: torchtune.training.checkpointing._checkpointer.FullModelHFCheckpointer\n",
      "  checkpoint_dir: /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725\n",
      "  checkpoint_files:\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00004-of-00004.safetensors\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00001-of-00004.safetensors\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00002-of-00004.safetensors\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00003-of-00004.safetensors\n",
      "  model_type: LLAMA3\n",
      "  output_dir: /home/ubuntu/atreides/experiments/models/rl34\n",
      "  recipe_checkpoint: null\n",
      "compile: false\n",
      "custom_sharded_layers:\n",
      "- tok_embeddings\n",
      "- output\n",
      "dataset:\n",
      "  _component_: lib.rl.pack.PackedDataset\n",
      "  dir: /home/ubuntu/atreides/experiments/models/rl34/tensors\n",
      "  num_sequences: 127\n",
      "  sequence_length: 16384\n",
      "device: cuda\n",
      "dtype: bf16\n",
      "enable_activation_checkpointing: true\n",
      "enable_activation_offloading: false\n",
      "epochs: 1\n",
      "gradient_accumulation_steps: 1\n",
      "log_every_n_steps: 1\n",
      "log_peak_memory_stats: true\n",
      "loss:\n",
      "  _component_: lib.rl.ppo.PPOLoss\n",
      "  clip_epsilon: 0.2\n",
      "  entropy_coef: 0.0\n",
      "  entropy_target: 0.75\n",
      "  entropy_target_coef: 0.15\n",
      "  kl_coef: 0.25\n",
      "  normalize_advantages: false\n",
      "  normalize_values: false\n",
      "  policy_coef: 0.0\n",
      "  tanh_log_policy_coef: 0.9\n",
      "  unclipped_policy_coef: 0.0\n",
      "  value_coef: 0.0\n",
      "  weighted_ce_coef: 0.0\n",
      "  weighted_entropy_coef: 0.1\n",
      "  weighted_kl_coef: 0.0\n",
      "max_steps_per_epoch: 32\n",
      "metric_logger:\n",
      "  _component_: torchtune.training.metric_logging.WandBLogger\n",
      "  id: rl34\n",
      "  name: rl34\n",
      "  resume: allow\n",
      "model:\n",
      "  _component_: torchtune.models.llama3_1._model_builders.llama3_1_8b\n",
      "num_output_chunks: 4\n",
      "optimizer:\n",
      "  _component_: torch.optim.AdamW\n",
      "  fused: true\n",
      "  lr: 4.0e-06\n",
      "optimizer_in_bwd: false\n",
      "resume_from_checkpoint: false\n",
      "seed: 42\n",
      "shuffle: true\n",
      "\n",
      "INFO:torchtune.utils._logging:Hint: enable_activation_checkpointing is True, but enable_activation_offloading isn't. Enabling activation offloading should reduce memory further.\n",
      "DEBUG:torchtune.utils._logging:Setting manual seed to local seed 42. Local seed is seed + rank = 42 + 0\n",
      "wandb: Currently logged in as: bradhilton. Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.18.3\n",
      "wandb: Run data is saved locally in /home/ubuntu/atreides/experiments/wandb/run-20241214_215659-rl34\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run rl34\n",
      "wandb: ⭐️ View project at https://wandb.ai/bradhilton/torchtune\n",
      "wandb: 🚀 View run at https://wandb.ai/bradhilton/torchtune/runs/rl34\n",
      "INFO:torchtune.utils._logging:Logging /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/torchtune_config.yaml to W&B under Files\n",
      "INFO:torchtune.utils._logging:FSDP is enabled. Instantiating model and loading checkpoint on Rank 0 ...\n",
      "INFO:torchtune.utils._logging:Instantiating model and loading checkpoint took 11.37 secs\n",
      "INFO:torchtune.utils._logging:Memory stats after model init:\n",
      "\tGPU peak memory allocation: 2.90 GiB\n",
      "\tGPU peak memory reserved: 3.01 GiB\n",
      "\tGPU peak memory active: 2.90 GiB\n",
      "INFO:torchtune.utils._logging:Optimizer is initialized.\n",
      "INFO:torchtune.utils._logging:Loss is initialized.\n",
      "INFO:torchtune.utils._logging:Dataset and Sampler are initialized.\n",
      "WARNING:torchtune.utils._logging: Profiling disabled.\n",
      "INFO:torchtune.utils._logging: Profiler config after instantiation: {'enabled': False}\n",
      "  0%|          | 0/16 [00:00<?, ?it/s]/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n",
      "1|16|Loss: 0.0416: 100%|██████████| 16/16 [05:15<00:00, 15.51s/it, entropy=0.7829, entropy_target=0.0329, kl_div=0.1511, policy=0.0166, tanh_log_policy=-0.0012, unclipped_policy=0.0016, value=2.3609, weighted_ce=-0.0043, weighted_entropy=0.0005, weighted_kl_div=0.0035]  INFO:torchtune.utils._logging:Saving checkpoint. This may take some time. Retrieving full model state dict...\n",
      "INFO:torchtune.utils._logging:Getting full model state dict took 9.99 secs\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.98 GB saved to /home/ubuntu/atreides/experiments/models/rl34/hf_model_0001_0.pt\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 5.00 GB saved to /home/ubuntu/atreides/experiments/models/rl34/hf_model_0002_0.pt\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.92 GB saved to /home/ubuntu/atreides/experiments/models/rl34/hf_model_0003_0.pt\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 1.17 GB saved to /home/ubuntu/atreides/experiments/models/rl34/hf_model_0004_0.pt\n",
      "INFO:torchtune.utils._logging:Saving final epoch checkpoint.\n",
      "INFO:torchtune.utils._logging:The full model checkpoint, including all weights and configurations, has been saved successfully.You can now use this checkpoint for further training or inference.\n",
      "INFO:torchtune.utils._logging:Saving checkpoint took 19.28 secs\n",
      "1|16|Loss: 0.0416: 100%|██████████| 16/16 [05:46<00:00, 21.67s/it, entropy=0.7829, entropy_target=0.0329, kl_div=0.1511, policy=0.0166, tanh_log_policy=-0.0012, unclipped_policy=0.0016, value=2.3609, weighted_ce=-0.0043, weighted_entropy=0.0005, weighted_kl_div=0.0035]\n",
      "wandb:                                                                                \n",
      "wandb: \n",
      "wandb: Run history:\n",
      "wandb:                   entropy ▁▄█▇▅▄▄▄▃▄▄▄▄▅▅▆\n",
      "wandb:            entropy_target █▄▄▂▂▃▃▄▄▃▃▃▃▂▁▁\n",
      "wandb:               global_step ▁▁▂▂▃▃▄▄▅▅▆▆▇▇██\n",
      "wandb:                    kl_div ▁▃█▆▄▃▂▂▁▂▂▃▂▂▃▄\n",
      "wandb:                      loss █▃█▅▂▂▃▂▄▃▃▂▂▂▁▁\n",
      "wandb:                        lr ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "wandb:        peak_memory_active ▁███████████████\n",
      "wandb:         peak_memory_alloc ▁███████████████\n",
      "wandb:      peak_memory_reserved ▁███████████████\n",
      "wandb:                    policy ▁▂▂▃▂▁▂▂▂█▂▂▂▁▂▂\n",
      "wandb:           tanh_log_policy ▅▃▆█▂▁▄▁▅▅▃▃▁▄▄▃\n",
      "wandb: tokens_per_second_per_gpu ▁▄███▇█▇█▇█▇▇▇▇▇\n",
      "wandb:          unclipped_policy ▂▃▂▂▁▁▃▂▃█▂▂▃▂▂▂\n",
      "wandb:                     value ▃▁█▃▂▄▆▂▄▂▂▇▂▄▃▇\n",
      "wandb:               weighted_ce ▅▄▅█▄▃▄▂▅▄▃▃▁▄▄▄\n",
      "wandb:          weighted_entropy ▃▆▄▁▅▂▄▆▂▄▄▄█▅▄▅\n",
      "wandb:           weighted_kl_div ▄▆▃▁▅▆▄█▄▄▇▆█▇▄▇\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:                   entropy 0.7829\n",
      "wandb:            entropy_target 0.0329\n",
      "wandb:               global_step 16\n",
      "wandb:                    kl_div 0.15112\n",
      "wandb:                      loss 0.04161\n",
      "wandb:                        lr 0.0\n",
      "wandb:        peak_memory_active 30.01097\n",
      "wandb:         peak_memory_alloc 30.01097\n",
      "wandb:      peak_memory_reserved 37.63477\n",
      "wandb:                    policy 0.01659\n",
      "wandb:           tanh_log_policy -0.00117\n",
      "wandb: tokens_per_second_per_gpu 790.35614\n",
      "wandb:          unclipped_policy 0.00162\n",
      "wandb:                     value 2.36089\n",
      "wandb:               weighted_ce -0.00427\n",
      "wandb:          weighted_entropy 0.00055\n",
      "wandb:           weighted_kl_div 0.0035\n",
      "wandb: \n",
      "wandb: 🚀 View run rl34 at: https://wandb.ai/bradhilton/torchtune/runs/rl34\n",
      "wandb: ⭐️ View project at: https://wandb.ai/bradhilton/torchtune\n",
      "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20241214_215659-rl34/logs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iteration 1 model files to /home/ubuntu/atreides/experiments/models/rl34/0001\n"
     ]
    }
   ],
   "source": [
    "await trainer.tune(trainer.explore_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.episodes_per_iteration = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb2a173ba6f47eea21981f5a6d4a6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/128 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = await trainer.explore(verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\"),\n",
       " UnboundLocalError(\"cannot access local variable 'prompt' where it is not associated with a value\")]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.explore_results[-1].exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await trainer.explore(verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._completion_sampler.samplers[0].semaphore.max_concurrent_actions *= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.max_mask_sequence_batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         116315230 function calls (112477935 primitive calls) in 195.675 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "   1312/3   29.919    0.023    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      " 2699/193   21.066    0.008   24.471    0.127 {method 'recv' of '_socket.socket' objects}\n",
      "  3662/32   20.467    0.006    0.337    0.011 {method 'poll' of 'select.epoll' objects}\n",
      "  298/289   13.027    0.044   51.754    0.179 threading.py:323(wait)\n",
      "3663/3631    7.332    0.002   20.167    0.006 selectors.py:451(select)\n",
      "24835537/24395659    4.434    0.000    5.651    0.000 {built-in method builtins.isinstance}\n",
      "  4087847    3.793    0.000    5.793    0.000 utils.py:54(get_token)\n",
      "        9    3.539    0.393    4.355    0.484 pack.py:307(get_mask)\n",
      "      194    3.286    0.017   30.018    0.155 sock_client.py:242(_read_packet_bytes)\n",
      "        9    3.215    0.357    3.215    0.357 explore_result.py:181(_write_mask)\n",
      "    21351    3.172    0.000    3.172    0.000 {built-in method torch.tensor}\n",
      "  4790101    3.113    0.000    4.879    0.000 typing.py:2340(get_origin)\n",
      "       10    2.879    0.288    2.879    0.288 {method 'any' of 'torch._C.TensorBase' objects}\n",
      "    14779    2.726    0.000    4.468    0.000 {method 'validate_python' of 'pydantic_core._pydantic_core.SchemaValidator' objects}\n",
      "1742743/366458    2.391    0.000   10.488    0.000 typing.py:407(_eval_type)\n",
      "        9    2.379    0.264    2.379    0.264 {built-in method torch.tril}\n",
      "     2837    2.281    0.001    2.281    0.001 {method 'connect' of '_socket.socket' objects}\n",
      "678279/2057    2.152    0.000   27.050    0.013 _transform.py:288(_async_transform_recursive)\n",
      "     2154    2.094    0.001    2.112    0.001 decoder.py:344(raw_decode)\n",
      "     6528    1.884    0.000    3.273    0.001 completion.py:788(_split_weights)\n",
      "    69154    1.878    0.000   12.830    0.000 typing.py:2215(get_type_hints)\n",
      "     8444    1.765    0.000    5.811    0.001 connection_pool.py:230(_assign_requests_to_connections)\n",
      "      128    1.603    0.013    7.696    0.060 explore_result.py:87(_pack_episode)\n",
      "  1428190    1.572    0.000    2.004    0.000 _model_construction.py:268(__instancecheck__)\n",
      "   366458    1.476    0.000    3.076    0.000 typing.py:175(_type_check)\n",
      "     3991    1.406    0.000    1.406    0.000 {method 'encode_batch' of 'tokenizers.Tokenizer' objects}\n",
      "  4983395    1.351    0.000    1.351    0.000 {method 'startswith' of 'str' objects}\n",
      "  4097107    1.323    0.000    7.097    0.000 completion.py:896(<genexpr>)\n",
      "   366458    1.226    0.000   10.148    0.000 typing.py:916(_evaluate)\n",
      "      690    1.219    0.002    1.219    0.002 {built-in method torch._C._nn.pad}\n",
      "  4522997    1.055    0.000    1.055    0.000 {method 'decode' of 'bytes' objects}\n",
      "101283/101250    1.054    0.000  120.927    0.001 {method 'run' of '_contextvars.Context' objects}\n",
      "   870662    1.050    0.000    1.050    0.000 completion.py:815(<lambda>)\n",
      "1577635/804245    0.939    0.000    2.580    0.000 typing.py:430(<genexpr>)\n",
      "     2458    0.812    0.000    2.232    0.001 explore_result.py:225(_get_completion_tensors)\n",
      "114537/114429    0.804    0.000    7.954    0.000 {method 'join' of 'str' objects}\n",
      "   841279    0.684    0.000    1.071    0.000 utils.py:60(get_token_id)\n",
      "805636/678279    0.668    0.000    3.078    0.000 _typing.py:40(strip_annotated_type)\n",
      "  2319312    0.648    0.000    0.974    0.000 connection.py:190(is_idle)\n",
      "   660024    0.623    0.000    1.009    0.000 typing.py:2370(get_args)\n",
      "  1483249    0.592    0.000    2.137    0.000 _typing.py:29(is_required_type)\n",
      "        9    0.584    0.065    0.584    0.065 {built-in method torch.ones_like}\n",
      "   678279    0.575    0.000    1.053    0.000 typing.py:448(is_typeddict)\n",
      "   677613    0.565    0.000    2.737    0.000 _transform.py:111(_get_annotated_type)\n",
      "69154/4114    0.539    0.000   26.939    0.007 _transform.py:379(_async_transform_typeddict)\n",
      "  1402972    0.531    0.000    1.911    0.000 _typing.py:11(is_annotated_type)\n",
      "       19    0.507    0.027    0.507    0.027 {built-in method torch.stack}\n",
      "   210287    0.490    0.000    4.521    0.000 completion.py:536(tokens_and_mask)\n",
      "   552964    0.476    0.000    1.197    0.000 typing.py:392(inner)\n",
      "        9    0.440    0.049    0.440    0.049 {built-in method posix.unlink}\n",
      "  1488710    0.403    0.000    0.403    0.000 {method 'get' of 'dict' objects}\n",
      "  1156776    0.390    0.000    0.643    0.000 typing.py:1592(__eq__)\n",
      "   605011    0.387    0.000    1.118    0.000 _typing.py:25(is_union_type)\n",
      "   994549    0.377    0.000    0.657    0.000 {built-in method builtins.getattr}\n",
      "  1416584    0.375    0.000    0.617    0.000 typing.py:1279(__eq__)\n",
      "   366458    0.373    0.000    2.041    0.000 {built-in method builtins.eval}\n",
      "   963223    0.367    0.000    1.075    0.000 http11.py:281(has_expired)\n",
      "  1078790    0.358    0.000    0.530    0.000 connection.py:195(is_closed)\n",
      "  1077155    0.326    0.000    1.402    0.000 connection.py:185(has_expired)\n",
      "  2112419    0.326    0.000    0.326    0.000 http11.py:295(is_idle)\n",
      "   609125    0.319    0.000    0.917    0.000 _typing.py:19(is_iterable_type)\n",
      "  1720615    0.316    0.000    0.359    0.000 {built-in method builtins.hasattr}\n",
      "3664/3663    0.315    0.000  195.831    0.053 nest_asyncio.py:100(_run_once)\n",
      "  2502660    0.314    0.000    0.314    0.000 {built-in method builtins.id}\n",
      "   629080    0.309    0.000    0.370    0.000 _models.py:173(__eq__)\n",
      "   678279    0.300    0.000    0.452    0.000 utils.py:181(lenient_issubclass)\n",
      "     2517    0.300    0.000    2.766    0.001 explore_result.py:214(<lambda>)\n",
      "  1350715    0.278    0.000    0.432    0.000 completion.py:848(__hash__)\n",
      "   836894    0.269    0.000    0.270    0.000 completion.py:458(logprobs)\n",
      "   609125    0.261    0.000    0.893    0.000 _typing.py:15(is_list_type)\n",
      "    89724    0.248    0.000    0.428    0.000 typing.py:1636(__hash__)\n",
      "    40576    0.235    0.000    0.235    0.000 {method 'search' of 're.Pattern' objects}\n",
      "  1116119    0.230    0.000    0.230    0.000 {method 'append' of 'list' objects}\n",
      "   624470    0.225    0.000    0.590    0.000 connection.py:165(can_handle_request)\n",
      "45023/2057    0.222    0.000   13.117    0.006 _models.py:448(construct_type)\n",
      "    46190    0.221    0.000    0.577    0.000 _asyncio.py:391(__enter__)\n",
      "6018/6014    0.216    0.000    0.216    0.000 {method 'send' of '_socket.socket' objects}\n",
      "   616574    0.214    0.000    0.457    0.000 {built-in method builtins.issubclass}\n",
      "    54218    0.212    0.000  100.530    0.002 tasks.py:308(__step_run_and_handle_result)\n",
      "   219887    0.204    0.000    0.770    0.000 typing.py:1221(__instancecheck__)\n",
      "    58135    0.202    0.000    0.404    0.000 _models.py:212(__getitem__)\n",
      "   219887    0.197    0.000    0.566    0.000 typing.py:1492(__subclasscheck__)\n",
      "54183/52965    0.196    0.000    0.751    0.000 {built-in method builtins.sum}\n",
      "    19374    0.187    0.000    0.307    0.000 ipkernel.py:775(_clean_thread_parent_frames)\n",
      "    46066    0.185    0.000    0.418    0.000 _asyncio.py:422(__exit__)\n",
      "   640312    0.185    0.000    0.185    0.000 typing.py:213(_should_unflatten_callable_args)\n",
      "     2057    0.183    0.000   15.660    0.008 _response.py:388(parse)\n",
      "151060/138052    0.177    0.000    0.307    0.000 typing.py:1600(__hash__)\n",
      "   880388    0.175    0.000    0.175    0.000 {method 'extend' of 'list' objects}\n",
      "     6028    0.175    0.000    0.406    0.000 _headers.py:150(normalize_and_validate)\n",
      "   849098    0.175    0.000    0.175    0.000 {method 'removeprefix' of 'str' objects}\n",
      "   619818    0.172    0.000    0.264    0.000 connection.py:173(is_available)\n",
      "9713/2057    0.171    0.000   12.982    0.006 _models.py:203(construct)\n",
      "   964816    0.171    0.000    0.171    0.000 http11.py:298(is_closed)\n",
      "     7832    0.163    0.000    0.927    0.000 _urlparse.py:152(urlparse)\n",
      "    95086    0.162    0.000    0.218    0.000 _impl.py:25(current_async_library)\n",
      "   118274    0.157    0.000    0.194    0.000 events.py:36(__init__)\n",
      "    18066    0.156    0.000    0.450    0.000 _sockets.py:58(extra_attributes)\n",
      "    22090    0.155    0.000    3.603    0.000 http11.py:72(handle_async_request)\n",
      "  1018892    0.152    0.000    0.152    0.000 {built-in method time.monotonic}\n",
      "    91404    0.149    0.000    0.297    0.000 base_events.py:813(_call_soon)\n",
      "    54218    0.148    0.000  100.902    0.002 tasks.py:291(__step)\n",
      "   150372    0.146    0.000    0.865    0.000 {built-in method builtins.next}\n",
      "   650034    0.142    0.000    0.142    0.000 typing.py:251(is_union)\n",
      "   207829    0.141    0.000    4.761    0.000 completion.py:604(token_count)\n",
      "    28237    0.138    0.000    0.372    0.000 main.py:858(__setattr__)\n",
      "   366458    0.137    0.000    0.220    0.000 typing.py:166(_type_convert)\n",
      "  1284507    0.136    0.000    0.136    0.000 connection_pool.py:39(is_queued)\n",
      "      225    0.133    0.001    3.113    0.014 trainer.py:435(explore)\n",
      "    12698    0.132    0.000   35.897    0.003 2664537466.py:51(reward_completion)\n",
      "     8672    0.131    0.000    0.131    0.000 {built-in method torch.cat}\n",
      "        2    0.131    0.066    0.292    0.146 explore_result.py:308(_normalize)\n",
      "101283/101250    0.129    0.000  155.580    0.002 events.py:86(_run)\n",
      "   240421    0.128    0.000    0.220    0.000 _models.py:94(encoding)\n",
      "    21058    0.128    0.000   58.110    0.003 completion_sampler.py:141(sample_completions)\n",
      "   269596    0.127    0.000    0.127    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "   121254    0.124    0.000    0.124    0.000 {method 'fullmatch' of 're.Pattern' objects}\n",
      "   294502    0.123    0.000    0.152    0.000 events.py:127(__lt__)\n",
      "   373597    0.121    0.000    0.121    0.000 {method 'items' of 'dict' objects}\n",
      "    19917    0.119    0.000    0.331    0.000 _models.py:64(__init__)\n",
      "    74262    0.117    0.000    0.141    0.000 contextlib.py:104(__init__)\n",
      "    84908    0.115    0.000    0.148    0.000 _model_construction.py:257(__getattr__)\n",
      "   292370    0.113    0.000    0.113    0.000 {method 'get' of 'mappingproxy' objects}\n",
      "    19220    0.111    0.000    0.424    0.000 _connection.py:260(_process_event)\n",
      "    19876    0.109    0.000    8.604    0.000 completion.py:888(message_param)\n",
      "   463314    0.108    0.000    0.108    0.000 typing.py:1626(<genexpr>)\n",
      "    16471    0.108    0.000    0.108    0.000 {built-in method torch.full_like}\n",
      "    73268    0.106    0.000    0.185    0.000 typing.py:521(__getitem__)\n",
      "    22594    0.106    0.000    0.235    0.000 main.py:782(__copy__)\n",
      "   207829    0.102    0.000    0.102    0.000 {method 'size' of 'torch._C.TensorBase' objects}\n",
      "        2    0.102    0.051    0.102    0.051 {built-in method torch.nanmean}\n",
      "    69154    0.101    0.000   12.955    0.000 typing_extensions.py:1197(get_type_hints)\n",
      "   639406    0.098    0.000    0.098    0.000 completion.py:655(<genexpr>)\n",
      "   249386    0.098    0.000    1.097    0.000 _transform.py:126(_maybe_transform_key)\n",
      "    52029    0.097    0.000    0.144    0.000 __init__.py:280(_compile)\n",
      "   269596    0.097    0.000    0.224    0.000 <frozen abc>:121(__subclasscheck__)\n",
      "    91402    0.097    0.000    0.410    0.000 base_events.py:784(call_soon)\n",
      "    25736    0.094    0.000    9.980    0.000 connection_pool.py:159(handle_async_request)\n",
      "   548405    0.093    0.000    0.093    0.000 http11.py:274(is_available)\n",
      "   183613    0.092    0.000    0.149    0.000 _urlparse.py:212(<genexpr>)\n",
      "    73766    0.092    0.000    0.437    0.000 contextlib.py:141(__exit__)\n",
      "    25736    0.087    0.000   10.570    0.000 default.py:358(handle_async_request)\n",
      "     2099    0.087    0.000    0.087    0.000 encoder.py:205(iterencode)\n",
      "   836894    0.085    0.000    0.085    0.000 completion.py:527(<genexpr>)\n",
      "   148748    0.085    0.000    0.137    0.000 _utils.py:31(normalize_header_key)\n",
      "356238/308986    0.085    0.000    0.131    0.000 {built-in method builtins.hash}\n",
      "    16675    0.084    0.000    0.201    0.000 {built-in method _heapq.heappop}\n",
      "       69    0.082    0.001    0.140    0.002 __init__.py:823(__add__)\n",
      "       69    0.082    0.001    5.280    0.077 explore_result.py:135(_write_sequence)\n",
      "    27610    0.081    0.000    0.721    0.000 _tasks.py:95(fail_after)\n",
      "    20937    0.081    0.000    0.081    0.000 {method 'getpeername' of '_socket.socket' objects}\n",
      "    58384    0.079    0.000    0.082    0.000 _asyncio.py:376(__init__)\n",
      "   219431    0.079    0.000    0.084    0.000 {method 'add' of 'set' objects}\n",
      "    74262    0.078    0.000    0.219    0.000 contextlib.py:299(helper)\n",
      "   115454    0.077    0.000    0.168    0.000 typing.py:1285(__hash__)\n",
      "   107689    0.076    0.000    0.213    0.000 _util.py:84(validate)\n",
      "21217/16908    0.073    0.000    0.225    0.000 _asyncio.py:536(_deliver_cancellation)\n",
      "   199756    0.073    0.000    0.290    0.000 explore_result.py:122(<genexpr>)\n",
      "    25736    0.072    0.000   11.279    0.000 _client.py:1762(_send_single_request)\n",
      "    17507    0.071    0.000   51.456    0.003 completions.py:1620(create)\n",
      "    30296    0.071    0.000    0.200    0.000 futures.py:161(__schedule_callbacks)\n",
      "    76505    0.070    0.000    0.265    0.000 typing.py:113(get_origin)\n",
      "32609/7093    0.070    0.000    8.840    0.001 completion.py:421(all_message_params)\n",
      "     9996    0.069    0.000    0.351    0.000 _asyncio.py:1190(receive)\n",
      "    46976    0.069    0.000   94.678    0.002 {method 'send' of 'coroutine' objects}\n",
      "     3991    0.069    0.000    1.791    0.000 tokenizer.py:54(patch)\n",
      "    74262    0.069    0.000    0.663    0.000 contextlib.py:132(__enter__)\n",
      "    38629    0.068    0.000    0.068    0.000 {method 'match' of 're.Pattern' objects}\n",
      "    14260    0.068    0.000    1.422    0.000 http11.py:216(_receive_event)\n",
      "    32221    0.066    0.000    0.335    0.000 {built-in method builtins.any}\n",
      "   204963    0.065    0.000    0.065    0.000 {method 'encode' of 'str' objects}\n",
      "    19876    0.064    0.000    0.128    0.000 main.py:826(__getattr__)\n",
      "   246329    0.064    0.000    0.064    0.000 {built-in method _asyncio.current_task}\n",
      "   108927    0.063    0.000    0.101    0.000 _urlparse.py:162(<genexpr>)\n",
      "    23236    0.063    0.000    0.258    0.000 _asyncio.py:2285(cancel_shielded_checkpoint)\n",
      "    21460    0.062    0.000    0.094    0.000 _trace.py:10(__init__)\n",
      "    67782    0.062    0.000    0.111    0.000 copy.py:61(copy)\n",
      "    28069    0.062    0.000    4.673    0.000 connection.py:67(handle_async_request)\n",
      "   122516    0.062    0.000    0.062    0.000 {built-in method __new__ of type object at 0x7b7ec7eeb4c0}\n",
      "    28898    0.062    0.000    0.145    0.000 _asyncio.py:2294(create_cancel_scope)\n",
      "    32609    0.062    0.000    8.692    0.000 completion.py:409(message_params)\n",
      "293131/283011    0.061    0.000    0.066    0.000 {built-in method builtins.len}\n",
      "     2654    0.061    0.000    0.061    0.000 {method 'shutdown' of '_socket.socket' objects}\n",
      "17872/17507    0.061    0.000   23.943    0.001 _base_client.py:1541(_request)\n",
      "   163713    0.061    0.000    0.061    0.000 {method 'pop' of 'dict' objects}\n",
      "     7241    0.060    0.000    0.882    0.000 {method 'throw' of 'coroutine' objects}\n",
      "    19712    0.059    0.000    0.121    0.000 typing.py:146(_generic_get_args)\n",
      "    60645    0.059    0.000    0.060    0.000 weakref.py:414(__getitem__)\n",
      "   135466    0.058    0.000    0.092    0.000 _models.py:27(enforce_bytes)\n",
      "     6070    0.057    0.000    0.120    0.000 _models.py:130(keys)\n",
      "    13847    0.057    0.000    1.051    0.000 _urls.py:77(__init__)\n",
      "   207462    0.056    0.000    0.056    0.000 {built-in method builtins.vars}\n",
      "    13541    0.055    0.000    4.656    0.000 type_adapter.py:132(wrapped)\n",
      "12342/6171    0.055    0.000    0.136    0.000 copy.py:118(deepcopy)\n",
      "    25736    0.055    0.000   20.384    0.001 _client.py:1690(_send_handling_auth)\n",
      "     8511    0.054    0.000    0.726    0.000 _sockets.py:114(connect_tcp)\n",
      "     5967    0.054    0.000    0.577    0.000 http11.py:159(_send_request_body)\n",
      "     8224    0.054    0.000    0.208    0.000 _models.py:61(enforce_headers)\n",
      "    49426    0.054    0.000    0.341    0.000 _asyncio.py:528(_timeout)\n",
      "   305423    0.053    0.000    0.053    0.000 {method 'isascii' of 'str' objects}\n",
      "    17481    0.053    0.000    0.197    0.000 _urlparse.py:452(quote)\n",
      "   188386    0.053    0.000    0.053    0.000 {method 'lower' of 'str' objects}\n",
      "     3991    0.053    0.000    2.377    0.001 llm.py:463(chat)\n",
      "    89724    0.052    0.000    0.052    0.000 typing.py:1625(_value_and_type_iter)\n",
      "    34837    0.052    0.000    0.087    0.000 _models.py:274(__contains__)\n",
      "    64439    0.052    0.000    0.182    0.000 _eventloop.py:154(get_async_backend)\n",
      "    46066    0.051    0.000    0.080    0.000 weakref.py:451(get)\n",
      "     9849    0.051    0.000    0.051    0.000 {method 'register' of 'select.epoll' objects}\n",
      "     2057    0.051    0.000    0.223    0.000 main.py:243(model_construct)\n",
      "    23987    0.050    0.000    0.129    0.000 locks.py:199(wait)\n",
      "   222801    0.050    0.000    0.050    0.000 threading.py:1198(ident)\n",
      "    23479    0.050    0.000    0.109    0.000 selectors.py:69(__getitem__)\n",
      "    26024    0.050    0.000    0.353    0.000 _asyncio.py:1733(acquire)\n",
      "     3991    0.049    0.000    0.179    0.000 runtime.py:93(new_context)\n",
      "    45023    0.049    0.000    0.290    0.000 typing.py:166(get_args)\n",
      "     2553    0.049    0.000    0.049    0.000 {method 'nonzero' of 'torch._C.TensorBase' objects}\n",
      "    19220    0.049    0.000    0.067    0.000 _state.py:318(_fire_state_triggered_transitions)\n",
      "    34280    0.049    0.000    0.068    0.000 ipaddress.py:1213(_parse_octet)\n",
      "    29139    0.048    0.000    0.049    0.000 inspect.py:1832(_shadowed_dict)\n",
      "    17021    0.048    0.000    0.199    0.000 base_events.py:766(call_at)\n",
      "     9241    0.048    0.000    0.139    0.000 tasks.py:111(__init__)\n",
      "   271143    0.048    0.000    0.048    0.000 {method 'isprintable' of 'str' objects}\n",
      "    17586    0.048    0.000    0.777    0.000 anyio.py:39(write)\n",
      "     3991    0.047    0.000    1.562    0.000 tokenization_utils_fast.py:488(_batch_encode_plus)\n",
      "   161083    0.047    0.000    0.047    0.000 {method 'lower' of 'bytes' objects}\n",
      "   123353    0.047    0.000    0.047    0.000 {method 'groupdict' of 're.Match' objects}\n",
      "     9616    0.047    0.000    1.962    0.000 _models.py:916(aiter_bytes)\n",
      "     9687    0.047    0.000    0.056    0.000 threading.py:1535(enumerate)\n",
      "40368/33078    0.046    0.000    0.053    0.000 completion.py:115(value)\n",
      "     7982    0.046    0.000    0.050    0.000 __init__.py:1023(__iter__)\n",
      "     3991    0.046    0.000    1.653    0.000 tokenization_utils_fast.py:579(_encode_plus)\n",
      "     2559    0.045    0.000    0.045    0.000 {method 'flush' of '_io.TextIOWrapper' objects}\n",
      "   309614    0.045    0.000    0.045    0.000 typing.py:2183(cast)\n",
      "     3874    0.045    0.000    0.470    0.000 _events.py:82(__init__)\n",
      "    15271    0.044    0.000    0.103    0.000 _utils.py:7(is_socket_readable)\n",
      "    25832    0.044    0.000    0.055    0.000 _headers.py:205(get_comma_header)\n",
      "     2837    0.044    0.000    0.044    0.000 socket.py:221(__init__)\n",
      "     3991    0.044    0.000    0.351    0.000 tokenization_utils_base.py:1709(apply_chat_template)\n",
      "     9996    0.044    0.000    0.737    0.000 anyio.py:23(read)\n",
      "   126220    0.044    0.000    0.538    0.000 _utils.py:152(is_mapping)\n",
      "     2756    0.043    0.000    0.043    0.000 {function socket.close at 0x7b7ec5b6dd00}\n",
      "     3916    0.043    0.000    1.485    0.000 _client.py:320(build_request)\n",
      "    11940    0.043    0.000    0.317    0.000 _asyncio.py:1225(send)\n",
      "    23479    0.043    0.000    0.175    0.000 selectors.py:180(get_key)\n",
      "     8581    0.043    0.000    0.072    0.000 completion.py:936(joined_assistant_message_params)\n",
      "    13914    0.043    0.000    0.047    0.000 _models.py:287(origin)\n",
      "    35523    0.043    0.000    0.071    0.000 futures.py:220(add_done_callback)\n",
      "    18066    0.043    0.000    0.518    0.000 _typedattr.py:58(extra)\n",
      "    32110    0.043    0.000    0.060    0.000 _weakrefset.py:85(add)\n",
      "    29902    0.042    0.000   22.487    0.001 _client.py:1639(send)\n",
      "    17750    0.042    0.000    0.044    0.000 {method 'join' of 'bytes' objects}\n",
      "    25825    0.042    0.000    0.100    0.000 _connection.py:308(_get_io_object)\n",
      "    54652    0.042    0.000    0.042    0.000 {built-in method _abc._abc_instancecheck}\n",
      "    27556    0.042    0.000    0.043    0.000 {method 'format' of 'str' objects}\n",
      "    12984    0.041    0.000   28.631    0.002 completion_sampler.py:415(sample_completions)\n",
      "     9725    0.041    0.000    0.041    0.000 {method 'unregister' of 'select.epoll' objects}\n",
      "    12664    0.041    0.000    0.553    0.000 _connection.py:426(next_event)\n",
      "    21796    0.041    0.000   45.492    0.002 tasks.py:383(__wakeup)\n",
      "    18066    0.040    0.000    0.661    0.000 anyio.py:84(get_extra_info)\n",
      "     9713    0.039    0.000    0.147    0.000 inspect.py:1845(getattr_static)\n",
      "    46740    0.039    0.000    0.055    0.000 tasks.py:653(sleep)\n",
      "        2    0.039    0.019    0.039    0.019 {built-in method torch.std}\n",
      "     3991    0.038    0.000    0.041    0.000 tokenization_utils_fast.py:282(_convert_encoding)\n",
      "    21374    0.038    0.000    0.141    0.000 _connection.py:330(_respond_to_state_changes)\n",
      "     9713    0.037    0.000    0.199    0.000 typing_extensions.py:626(__instancecheck__)\n",
      "   132054    0.037    0.000    0.037    0.000 futures.py:181(done)\n",
      "    22395    0.037    0.000    0.037    0.000 _models.py:123(raw)\n",
      "    23038    0.037    0.000    0.191    0.000 futures.py:251(set_result)\n",
      "   114084    0.037    0.000    0.037    0.000 {method 'popleft' of 'collections.deque' objects}\n",
      "    19220    0.036    0.000    0.121    0.000 _state.py:275(process_event)\n",
      "     2458    0.036    0.000    0.036    0.000 {method 'sum' of 'torch._C.TensorBase' objects}\n",
      "    11616    0.036    0.000    0.370    0.000 _connection.py:518(send_with_data_passthrough)\n",
      "     3916    0.036    0.000    0.917    0.000 _models.py:311(__init__)\n",
      "    26180    0.036    0.000    0.058    0.000 main.py:927(_check_frozen)\n",
      "    12194    0.036    0.000    0.200    0.000 _synchronization.py:197(__init__)\n",
      "     2099    0.036    0.000    1.568    0.001 _base_client.py:446(_build_request)\n",
      "     8570    0.036    0.000    0.132    0.000 ipaddress.py:1187(_ip_int_from_string)\n",
      "    30543    0.035    0.000    0.042    0.000 futures.py:72(__init__)\n",
      "   123963    0.035    0.000    0.035    0.000 {method 'append' of 'collections.deque' objects}\n",
      "    42480    0.035    0.000    0.050    0.000 futures.py:286(__await__)\n",
      "     7748    0.035    0.000    1.282    0.000 http11.py:147(_send_request_headers)\n",
      "     6028    0.035    0.000    0.063    0.000 _receivebuffer.py:104(maybe_extract_lines)\n",
      "     3991    0.035    0.000    2.585    0.001 tokenizer.py:38(encode)\n",
      "     3916    0.035    0.000    0.278    0.000 _models.py:375(_prepare)\n",
      "    32319    0.035    0.000    0.085    0.000 socket.py:100(_intenum_converter)\n",
      "     9616    0.035    0.000    1.856    0.000 _models.py:971(aiter_raw)\n",
      "    26611    0.034    0.000    0.109    0.000 socket.py:517(family)\n",
      "    22704    0.034    0.000    0.035    0.000 locks.py:166(__init__)\n",
      "     6604    0.034    0.000    0.272    0.000 _asyncio.py:698(__aexit__)\n",
      "    17507    0.033    0.000   24.330    0.001 _base_client.py:1825(post)\n",
      "     9849    0.033    0.000    0.139    0.000 selectors.py:351(register)\n",
      "    51403    0.033    0.000    0.079    0.000 _asyncio.py:1186(_raw_socket)\n",
      "    32319    0.033    0.000    0.051    0.000 enum.py:720(__call__)\n",
      "     9713    0.033    0.000    0.036    0.000 inspect.py:1797(_check_instance)\n",
      "     5674    0.033    0.000    0.776    0.000 connection.py:103(_connect)\n",
      "     2154    0.033    0.000    0.391    0.000 _models.py:1183(__init__)\n",
      "    22478    0.033    0.000    0.088    0.000 _synchronization.py:21(current_async_library)\n",
      "     5674    0.032    0.000    0.754    0.000 anyio.py:100(connect_tcp)\n",
      "    16897    0.032    0.000    0.059    0.000 events.py:155(cancel)\n",
      "     2837    0.032    0.000    0.126    0.000 _asyncio.py:749(_spawn)\n",
      "39138/12342    0.032    0.000   12.856    0.001 _models.py:382(_construct_field)\n",
      "    15598    0.032    0.000    0.068    0.000 _compat.py:92(field_get_default)\n",
      "    26024    0.032    0.000    0.463    0.000 _synchronization.py:69(__aenter__)\n",
      "    17021    0.031    0.000    0.066    0.000 {built-in method _heapq.heappush}\n",
      "    19908    0.031    0.000    0.059    0.000 base_events.py:446(create_future)\n",
      "    13541    0.031    0.000    4.728    0.000 _models.py:728(_validate_non_model_type)\n",
      "    39512    0.031    0.000    0.040    0.000 futures.py:189(result)\n",
      "    26622    0.031    0.000    0.035    0.000 events.py:72(cancel)\n",
      "    74374    0.030    0.000    0.045    0.000 _utils.py:47(normalize_header_value)\n",
      "    95086    0.030    0.000    0.030    0.000 {method 'get' of '_contextvars.ContextVar' objects}\n",
      "     9544    0.030    0.000    0.405    0.000 connection_pool.py:301(_close_connections)\n",
      "     7012    0.030    0.000    0.207    0.000 selector_events.py:278(_add_reader)\n",
      "    17586    0.029    0.000    1.198    0.000 http11.py:170(_send_event)\n",
      "    14399    0.029    0.000    0.085    0.000 _utils.py:298(strip_not_given)\n",
      "     2154    0.029    0.000    0.140    0.000 request.py:315(__init__)\n",
      "     7982    0.029    0.000    0.085    0.000 tokenization_utils_base.py:220(__init__)\n",
      "     6028    0.029    0.000    0.234    0.000 _readers.py:94(maybe_read_from_SEND_RESPONSE_server)\n",
      "    31928    0.029    0.000    0.029    0.000 __init__.py:1009(__getitem__)\n",
      "    17021    0.029    0.000    0.081    0.000 events.py:111(__init__)\n",
      "    34548    0.028    0.000    0.327    0.000 __init__.py:174(search)\n",
      "     5674    0.028    0.000    0.041    0.000 base_events.py:100(_ipaddr_info)\n",
      "   186732    0.028    0.000    0.028    0.000 base_events.py:2010(get_debug)\n",
      "     9054    0.028    0.000    0.298    0.000 http11.py:245(_response_closed)\n",
      "    15271    0.028    0.000    0.028    0.000 {method 'poll' of 'select.poll' objects}\n",
      "     9849    0.028    0.000    0.054    0.000 selectors.py:234(register)\n",
      "    25736    0.028    0.000   11.312    0.000 _client.py:1724(_send_handling_redirects)\n",
      "    51403    0.028    0.000    0.046    0.000 transports.py:19(get_extra_info)\n",
      "     6636    0.028    0.000    0.496    0.000 http11.py:337(__aiter__)\n",
      "     3874    0.028    0.000    0.034    0.000 _writers.py:22(write_headers)\n",
      "    46190    0.028    0.000    0.051    0.000 _asyncio.py:371(__new__)\n",
      "     3991    0.028    0.000    1.696    0.000 tokenization_utils_base.py:3154(encode_plus)\n",
      "    54218    0.028    0.000    0.028    0.000 {built-in method _asyncio._leave_task}\n",
      "     8508    0.028    0.000    2.955    0.000 _asyncio.py:2519(connect_tcp)\n",
      "    76456    0.027    0.000    0.027    0.000 {method 'remove' of 'set' objects}\n",
      "    33069    0.027    0.000    0.041    0.000 _weakrefset.py:39(_remove)\n",
      "    70680    0.027    0.000    0.034    0.000 enum.py:202(__get__)\n",
      "104477/39524    0.027    0.000    0.027    0.000 completion.py:201(ancestors)\n",
      "    54218    0.027    0.000    0.027    0.000 {built-in method _asyncio._enter_task}\n",
      "    52820    0.027    0.000    0.040    0.000 base_events.py:733(time)\n",
      "    54652    0.027    0.000    0.069    0.000 <frozen abc>:117(__instancecheck__)\n",
      "     9085    0.027    0.000    0.047    0.000 _urls.py:425(__init__)\n",
      "     5134    0.027    0.000    1.139    0.000 connection_pool.py:369(aclose)\n",
      "     5967    0.026    0.000    0.242    0.000 selector_events.py:1055(write)\n",
      "     4198    0.026    0.000    0.032    0.000 _models.py:232(__setitem__)\n",
      "    11490    0.026    0.000   28.562    0.002 episode.py:66(follow_up)\n",
      " 3316/875    0.026    0.000    0.137    0.000 completion.py:675(split)\n",
      "     6636    0.026    0.000    0.450    0.000 http11.py:205(_receive_response_body)\n",
      "     8031    0.025    0.000    0.135    0.000 selector_events.py:294(_remove_reader)\n",
      "     7536    0.025    0.000    0.080    0.000 tasks.py:522(_wait)\n",
      "     2057    0.025    0.000   15.734    0.008 _base_client.py:1674(_process_response)\n",
      "    22594    0.025    0.000    0.261    0.000 main.py:324(model_copy)\n",
      "    12664    0.025    0.000    0.332    0.000 _connection.py:398(_extract_next_receive_event)\n",
      "    20293    0.025    0.000    0.067    0.000 locks.py:181(set)\n",
      "    43053    0.025    0.000    0.031    0.000 selectors.py:21(_fileobj_to_fd)\n",
      "     2057    0.025    0.000   15.429    0.008 _response.py:128(_parse)\n",
      "     3991    0.024    0.000    0.067    0.000 chat_utils.py:390(_parse_chat_message_content_parts)\n",
      "     8377    0.024    0.000    2.024    0.000 _models.py:908(aread)\n",
      "     9241    0.024    0.000    0.165    0.000 base_events.py:450(create_task)\n",
      "    72517    0.024    0.000    0.024    0.000 {built-in method _contextvars.copy_context}\n",
      "     2057    0.024    0.000    0.035    0.000 _utils.py:241(wrapper)\n",
      "     4012    0.024    0.000    0.044    0.000 tasks.py:767(_done_callback)\n",
      "    17507    0.023    0.000   23.967    0.001 _base_client.py:1519(request)\n",
      "     2837    0.023    0.000    2.448    0.001 selector_events.py:656(_sock_connect)\n",
      "     6297    0.023    0.000    0.031    0.000 _base_client.py:2063(_merge_mappings)\n",
      "     3916    0.023    0.000    0.201    0.000 _models.py:202(update)\n",
      "    46333    0.023    0.000    0.038    0.000 <frozen _collections_abc>:1022(__iter__)\n",
      "     8508    0.023    0.000    0.040    0.000 selector_events.py:260(_ensure_fd_no_transport)\n",
      "     8508    0.023    0.000    2.867    0.000 base_events.py:1019(create_connection)\n",
      "     5674    0.023    0.000    2.539    0.000 selector_events.py:631(sock_connect)\n",
      "    17481    0.023    0.000    0.023    0.000 {method 'finditer' of 're.Pattern' objects}\n",
      "    64374    0.023    0.000    0.293    0.000 _utils.py:168(is_iterable)\n",
      "    11973    0.023    0.000    0.029    0.000 <template>:4(root)\n",
      "    13541    0.023    0.000    4.766    0.000 _models.py:677(validate_type)\n",
      "    43053    0.023    0.000    0.054    0.000 selectors.py:215(_fileobj_lookup)\n",
      "   127516    0.023    0.000    0.023    0.000 base_events.py:538(_check_closed)\n",
      "    17481    0.023    0.000    0.116    0.000 __init__.py:219(finditer)\n",
      "    96540    0.022    0.000    0.022    0.000 _util.py:127(bytesify)\n",
      "     7536    0.022    0.000    0.126    0.000 tasks.py:435(wait)\n",
      "     6171    0.022    0.000    0.055    0.000 copy.py:247(_reconstruct)\n",
      "     9713    0.022    0.000    0.045    0.000 inspect.py:1806(_check_class)\n",
      "     2834    0.022    0.000    0.071    0.000 selector_events.py:779(__init__)\n",
      "    32087    0.022    0.000    0.022    0.000 {method 'split' of 'str' objects}\n",
      "     9931    0.022    0.000    0.569    0.000 _urlparse.py:125(copy_with)\n",
      "    17232    0.021    0.000    0.031    0.000 message.py:421(__setitem__)\n",
      "     9244    0.021    0.000    0.089    0.000 {built-in method from_bytes}\n",
      "     2057    0.021    0.000    0.330    0.000 _models.py:810(construct)\n",
      "     8570    0.021    0.000    0.157    0.000 ipaddress.py:1286(__init__)\n",
      "     5674    0.021    0.000    2.609    0.000 base_events.py:976(_connect_sock)\n",
      "     2837    0.021    0.000    0.116    0.000 selector_events.py:315(_add_writer)\n",
      "     9167    0.021    0.000    0.026    0.000 mixins.py:12(_get_loop)\n",
      "     1750    0.021    0.000    0.116    0.000 tasks.py:731(gather)\n",
      "    12194    0.021    0.000    0.104    0.000 _tasks.py:28(__new__)\n",
      "    16342    0.020    0.000    0.241    0.000 _models.py:170(get)\n",
      "9768/4743    0.020    0.000    0.043    0.000 completion.py:630(sample_weight)\n",
      "     2099    0.020    0.000    0.227    0.000 _base_client.py:411(_build_headers)\n",
      "     6025    0.020    0.000    0.024    0.000 _events.py:337(__init__)\n",
      "    31482    0.020    0.000    0.126    0.000 typing.py:417(is_literal_type)\n",
      "        2    0.020    0.010    0.020    0.010 {built-in method torch.isnan}\n",
      "    23799    0.020    0.000    0.030    0.000 futures.py:301(_get_loop)\n",
      "     3991    0.020    0.000    0.090    0.000 chat_utils.py:450(_parse_chat_message_content)\n",
      "    13541    0.020    0.000    4.480    0.000 type_adapter.py:341(validate_python)\n",
      "     4114    0.020    0.000    0.061    0.000 completion_sampler.py:71(_wait)\n",
      "    60686    0.020    0.000    0.021    0.000 _exceptions.py:7(map_exceptions)\n",
      "     4308    0.020    0.000    0.100    0.000 _models.py:1204(info)\n",
      "    43090    0.020    0.000    0.020    0.000 {method 'copy' of 'dict' objects}\n",
      "13716/2518    0.019    0.000    0.031    0.000 completion.py:94(commit)\n",
      "    16236    0.019    0.000    0.024    0.000 completion.py:829(<genexpr>)\n",
      "     7982    0.019    0.000    0.044    0.000 <frozen _collections_abc>:974(update)\n",
      "     4308    0.019    0.000    0.047    0.000 _models.py:159(multi_items)\n",
      "     9725    0.019    0.000    0.082    0.000 selectors.py:365(unregister)\n",
      "      257    0.019    0.000    0.043    0.000 {built-in method _collections._count_elements}\n",
      "    13012    0.019    0.000    0.035    0.000 _asyncio.py:1774(release)\n",
      "     5134    0.019    0.000    1.197    0.000 _client.py:153(aclose)\n",
      "    18298    0.019    0.000    0.037    0.000 _asyncio.py:2254(current_time)\n",
      "    23826    0.019    0.000    0.156    0.000 _utils.py:303(smart_deepcopy)\n",
      "    23094    0.018    0.000    0.018    0.000 _state.py:301(_fire_event_triggered_transitions)\n",
      "     2241    0.018    0.000    0.242    0.000 episode.py:417(_sample_completions)\n",
      "23600/23468    0.018    0.000    0.032    0.000 {built-in method builtins.max}\n",
      "     6171    0.018    0.000    0.074    0.000 completion_sampler.py:63(_wait_if_needed)\n",
      "    14978    0.018    0.000    0.046    0.000 _asyncio.py:1705(__init__)\n",
      "     4198    0.018    0.000    0.024    0.000 _models.py:256(__delitem__)\n",
      "     3340    0.018    0.000    0.018    0.000 _receivebuffer.py:53(__iadd__)\n",
      "    32319    0.018    0.000    0.018    0.000 enum.py:1123(__new__)\n",
      "     6070    0.018    0.000    0.054    0.000 _utils.py:292(_get_time)\n",
      "    11618    0.017    0.000    0.031    0.000 _asyncio.py:2266(checkpoint_if_cancelled)\n",
      "     7624    0.017    0.000    1.037    0.000 http11.py:179(_receive_response_headers)\n",
      "     3991    0.017    0.000    0.127    0.000 chat_utils.py:502(parse_chat_messages)\n",
      "    10783    0.017    0.000   16.912    0.002 2664537466.py:23(sample_random_episode)\n",
      "    33397    0.017    0.000    0.033    0.000 request.py:397(add_header)\n",
      "     3991    0.017    0.000    0.045    0.000 runtime.py:165(__init__)\n",
      "    13008    0.017    0.000    0.104    0.000 <string>:1(<module>)\n",
      "    35919    0.017    0.000    0.044    0.000 <frozen _collections_abc>:868(__iter__)\n",
      "    51614    0.017    0.000    0.017    0.000 {method 'keys' of 'dict' objects}\n",
      "    12016    0.017    0.000    0.027    0.000 default.py:69(map_httpcore_exceptions)\n",
      "      621    0.017    0.000    0.017    0.000 {built-in method torch.from_file}\n",
      "    36740    0.016    0.000    0.016    0.000 _connection.py:205(our_state)\n",
      "    12395    0.016    0.000   16.876    0.001 _client.py:1530(request)\n",
      "    22868    0.016    0.000    0.052    0.000 base_events.py:551(_asyncgen_firstiter_hook)\n",
      "     6028    0.016    0.000    0.042    0.000 _connection.py:81(_body_framing)\n",
      "     6636    0.016    0.000    0.549    0.000 default.py:255(__aiter__)\n",
      "    33397    0.016    0.000    0.016    0.000 {method 'capitalize' of 'str' objects}\n",
      "     3991    0.016    0.000    0.367    0.000 chat_utils.py:538(apply_hf_chat_template)\n",
      "    23826    0.016    0.000    0.172    0.000 fields.py:552(get_default)\n",
      "    15573    0.016    0.000    0.065    0.000 completion.py:148(advantage)\n",
      "     4114    0.016    0.000    0.120    0.000 completion_sampler.py:51(acquire)\n",
      "     5450    0.016    0.000    0.016    0.000 _receivebuffer.py:67(_extract)\n",
      "     7241    0.016    0.000    0.078    0.000 tasks.py:210(cancel)\n",
      "     7012    0.016    0.000    0.228    0.000 selector_events.py:925(_add_reader)\n",
      "      690    0.016    0.000    3.825    0.006 explore_result.py:330(_sequence_to_tensor)\n",
      "     7167    0.015    0.000    0.015    0.000 _events.py:299(__init__)\n",
      "    11616    0.015    0.000    0.392    0.000 _connection.py:491(send)\n",
      "     2154    0.015    0.000    0.066    0.000 _events.py:137(__init__)\n",
      "     6636    0.015    0.000    0.060    0.000 _readers.py:127(__call__)\n",
      "     3991    0.015    0.000    0.015    0.000 chat_utils.py:122(__init__)\n",
      "     8508    0.015    0.000    3.041    0.000 _sockets.py:162(try_connect)\n",
      "    18067    0.015    0.000    0.025    0.000 <frozen importlib._bootstrap>:645(parent)\n",
      "    28237    0.015    0.000    0.026    0.000 _fields.py:328(is_valid_field_name)\n",
      "     3991    0.015    0.000    0.236    0.000 environment.py:1272(render)\n",
      "     2834    0.015    0.000    0.155    0.000 selector_events.py:936(__init__)\n",
      "14590/4387    0.015    0.000    4.060    0.001 completion.py:607(all_token_count)\n",
      "    46333    0.015    0.000    0.015    0.000 _headers.py:117(__getitem__)\n",
      "    73920    0.015    0.000    0.023    0.000 completion_sampler.py:403(__hash__)\n",
      "    15598    0.015    0.000    0.021    0.000 <frozen importlib._bootstrap>:1390(_handle_fromlist)\n",
      "  299/290    0.015    0.000   52.796    0.182 threading.py:637(wait)\n",
      "    18066    0.015    0.000    0.021    0.000 _sockets.py:636(convert_ipv6_sockaddr)\n",
      "     2458    0.015    0.000    0.015    0.000 {method 'clone' of 'torch._C.TensorBase' objects}\n",
      "     4308    0.014    0.000    0.150    0.000 http11.py:351(aclose)\n",
      "     2154    0.014    0.000    0.022    0.000 parse.py:374(urlparse)\n",
      "    54215    0.014    0.000    0.014    0.000 {method 'strip' of 'str' objects}\n",
      "     6070    0.014    0.000    0.018    0.000 _urlparse.py:106(authority)\n",
      "    50451    0.014    0.000    0.014    0.000 _connection.py:212(their_state)\n",
      "    27082    0.014    0.000    0.014    0.000 type_adapter.py:259(_with_frame_depth)\n",
      "     7832    0.014    0.000    0.118    0.000 _urlparse.py:303(encode_host)\n",
      "    33070    0.014    0.000    0.014    0.000 {method 'discard' of 'set' objects}\n",
      "       49    0.014    0.000    0.024    0.000 sock_client.py:123(_sendall_with_error_handle)\n",
      "20220/2646    0.014    0.000    0.015    0.000 completion.py:222(leaves)\n",
      "     4482    0.014    0.000    0.028    0.000 _receivebuffer.py:77(maybe_extract_at_most)\n",
      "    18066    0.014    0.000    0.089    0.000 trsock.py:76(getpeername)\n",
      "     2099    0.014    0.000    0.530    0.000 _base_client.py:430(_prepare_url)\n",
      "     3672    0.014    0.000    0.029    0.000 streams.py:580(readuntil)\n",
      "     3991    0.014    0.000    0.059    0.000 tokenization_utils_base.py:1311(special_tokens_map)\n",
      "    10770    0.014    0.000    0.057    0.000 _readers.py:64(_decode_header_lines)\n",
      "     5503    0.014    0.000    0.066    0.000 selector_events.py:331(_remove_writer)\n",
      "     2518    0.014    0.000    3.581    0.001 episode.py:43(last_assistant_message)\n",
      "     7256    0.013    0.000    0.059    0.000 futures.py:146(cancel)\n",
      "     5350    0.013    0.000    0.178    0.000 _asyncio.py:1250(aclose)\n",
      "     5134    0.013    0.000    1.228    0.000 _models.py:999(aclose)\n",
      "    13012    0.013    0.000    0.048    0.000 _synchronization.py:80(__aexit__)\n",
      "     6171    0.013    0.000    0.015    0.000 copy.py:231(_keep_alive)\n",
      "     5632    0.013    0.000    0.079    0.000 _synchronization.py:58(setup)\n",
      "     9591    0.013    0.000    0.015    0.000 tasks.py:142(__del__)\n",
      "     3991    0.013    0.000    0.013    0.000 configuration_utils.py:202(__getattribute__)\n",
      "     7489    0.013    0.000    0.077    0.000 _synchronization.py:81(__new__)\n",
      "     5836    0.013    0.000    0.013    0.000 completion.py:65(__init__)\n",
      "     6636    0.013    0.000    0.514    0.000 connection_pool.py:361(__aiter__)\n",
      "     3991    0.013    0.000    1.715    0.000 tokenization_utils_base.py:2750(encode)\n",
      "     2154    0.013    0.000    0.140    0.000 cookiejar.py:1680(extract_cookies)\n",
      "     5134    0.013    0.000    1.153    0.000 default.py:260(aclose)\n",
      "     4652    0.013    0.000    0.098    0.000 _synchronization.py:116(setup)\n",
      "    12928    0.012    0.000    3.627    0.000 episode.py:345(<genexpr>)\n",
      "    23136    0.012    0.000    0.012    0.000 {method 'update' of 'dict' objects}\n",
      "     5324    0.012    0.000    0.114    0.000 selector_events.py:851(pause_reading)\n",
      "     3991    0.012    0.000    0.014    0.000 tokenization_utils_base.py:2806(_get_padding_truncation_strategies)\n",
      "     7978    0.012    0.000    0.017    0.000 _asyncio.py:362(is_anyio_cancellation)\n",
      "    60378    0.012    0.000    0.012    0.000 {built-in method _asyncio.get_running_loop}\n",
      "    12194    0.012    0.000    0.113    0.000 _synchronization.py:209(__enter__)\n",
      "     3916    0.012    0.000    0.149    0.000 _models.py:326(__init__)\n",
      "     3663    0.012    0.000    0.019    0.000 selector_events.py:750(_process_events)\n",
      "     5668    0.012    0.000    0.201    0.000 base_events.py:1166(_create_connection_transport)\n",
      "31614/6189    0.012    0.000    0.014    0.000 completion.py:228(depths)\n",
      "     8508    0.012    0.000    0.012    0.000 weakref.py:133(__getitem__)\n",
      "     7832    0.012    0.000    0.014    0.000 _urlparse.py:350(normalize_port)\n",
      "     3916    0.012    0.000    0.221    0.000 _client.py:404(_merge_headers)\n",
      "     7489    0.012    0.000    0.046    0.000 _asyncio.py:2326(create_event)\n",
      "    12395    0.012    0.000   16.888    0.001 _client.py:1797(get)\n",
      "     5674    0.012    0.000    0.053    0.000 base_events.py:1452(_ensure_resolved)\n",
      "     2099    0.012    0.000    0.116    0.000 _content.py:176(encode_json)\n",
      "    13716    0.012    0.000    0.031    0.000 completion.py:237(absent_stop_tokens)\n",
      "     5227    0.012    0.000    0.121    0.000 tasks.py:412(create_task)\n",
      "     1113    0.012    0.000    0.094    0.000 vllm.py:152(log_output)\n",
      "    22594    0.012    0.000    0.012    0.000 {method 'copy' of 'set' objects}\n",
      "     2099    0.011    0.000    0.040    0.000 _client.py:376(default_headers)\n",
      "     9836    0.011    0.000    0.026    0.000 completion.py:838(<genexpr>)\n",
      "    46066    0.011    0.000    0.019    0.000 _asyncio.py:579(_restart_cancellation_in_parent)\n",
      "  674/615    0.011    0.000    0.022    0.000 random.py:889(getrandbits)\n",
      "     2795    0.011    0.000    0.023    0.000 _connection.py:155(__init__)\n",
      "    18066    0.011    0.000    0.087    0.000 trsock.py:18(family)\n",
      "     7708    0.011    0.000    0.019    0.000 _auth.py:87(async_auth_flow)\n",
      "     2834    0.011    0.000    0.029    0.000 _asyncio.py:1115(connection_made)\n",
      "    20221    0.011    0.000    0.011    0.000 {method 'rpartition' of 'str' objects}\n",
      "    12194    0.011    0.000    0.074    0.000 _synchronization.py:216(__exit__)\n",
      "    27896    0.011    0.000    0.011    0.000 __init__.py:1790(isEnabledFor)\n",
      "    21302    0.011    0.000    0.028    0.000 coroutines.py:32(iscoroutine)\n",
      "     4142    0.011    0.000    0.080    0.000 tasks.py:670(ensure_future)\n",
      "     5632    0.011    0.000    0.020    0.000 _asyncio.py:2330(create_lock)\n",
      "     2871    0.011    0.000    0.011    0.000 {method 'getsockname' of '_socket.socket' objects}\n",
      "     6636    0.011    0.000    0.565    0.000 _client.py:149(__aiter__)\n",
      "        1    0.011    0.011    0.227    0.227 explore_result.py:270(_write_weights)\n",
      "     6171    0.011    0.000    0.011    0.000 {method '__reduce_ex__' of 'object' objects}\n",
      "    46318    0.011    0.000    0.011    0.000 tasks.py:252(cancelling)\n",
      "    13704    0.011    0.000    0.027    0.000 _asyncio.py:2262(checkpoint)\n",
      "    13283    0.010    0.000    0.019    0.000 _urlparse.py:437(percent_encoded)\n",
      "    41706    0.010    0.000    0.010    0.000 completion.py:211(matches_model)\n",
      "    24548    0.010    0.000    0.014    0.000 completion.py:641(<genexpr>)\n",
      "     2154    0.010    0.000    2.130    0.001 decoder.py:333(decode)\n",
      "    25883    0.010    0.000    0.015    0.000 inspect.py:302(isclass)\n",
      "    25592    0.010    0.000    0.010    0.000 {method 'group' of 're.Match' objects}\n",
      "     2837    0.010    0.000    0.015    0.000 connection_pool.py:127(create_connection)\n",
      "     2560    0.010    0.000    0.118    0.000 episode.py:334(<lambda>)\n",
      "     2154    0.010    0.000    0.542    0.000 _models.py:1035(extract_cookies)\n",
      "    13331    0.010    0.000    0.013    0.000 nest_asyncio.py:37(_get_event_loop)\n",
      "     3916    0.010    0.000    0.032    0.000 _client.py:437(_build_request_auth)\n",
      "     7256    0.010    0.000    0.010    0.000 futures.py:126(_make_cancelled_error)\n",
      "     3991    0.010    0.000    0.010    0.000 chat_utils.py:246(__init__)\n",
      "13716/2518    0.010    0.000    0.040    0.000 completion.py:244(all_absent_stop_tokens)\n",
      "     6028    0.010    0.000    0.032    0.000 _connection.py:72(_keep_alive)\n",
      "     2795    0.010    0.000    0.033    0.000 http11.py:54(__init__)\n",
      "    46362    0.010    0.000    0.010    0.000 tasks.py:641(__sleep0)\n",
      "     3991    0.010    0.000    0.010    0.000 tokenization_utils_base.py:1056(bos_token)\n",
      "    23181    0.010    0.000    0.010    0.000 futures.py:119(get_loop)\n",
      "      194    0.010    0.000   58.144    0.300 router_sock.py:25(_read_message)\n",
      "     6071    0.010    0.000    0.032    0.000 _asyncio.py:503(_uncancel)\n",
      "    11264    0.010    0.000    0.010    0.000 _asyncio.py:1728(__init__)\n",
      "      512    0.009    0.000    3.826    0.007 episode.py:228(sample_completions_v2)\n",
      "     2666    0.009    0.000    0.082    0.000 selector_events.py:867(close)\n",
      "    10802    0.009    0.000    0.143    0.000 _asyncio.py:598(cancel)\n",
      "     2837    0.009    0.000    0.018    0.000 _asyncio.py:756(task_done)\n",
      "     2099    0.009    0.000    0.017    0.000 _base_client.py:607(default_headers)\n",
      "    13971    0.009    0.000    0.009    0.000 {method 'rstrip' of 'str' objects}\n",
      "     3916    0.009    0.000    0.637    0.000 _urls.py:343(copy_with)\n",
      "     1004    0.009    0.000    3.636    0.004 {built-in method builtins.sorted}\n",
      "    31537    0.009    0.000    0.009    0.000 futures.py:91(__del__)\n",
      "    12042    0.009    0.000    0.017    0.000 llm.py:181(get_tokenizer)\n",
      "     5674    0.009    0.000    0.727    0.000 auto.py:21(connect_tcp)\n",
      "     5632    0.009    0.000    0.041    0.000 _synchronization.py:140(__new__)\n",
      "     9241    0.009    0.000    0.032    0.000 {built-in method _asyncio._register_task}\n",
      "     9725    0.009    0.000    0.022    0.000 selectors.py:247(unregister)\n",
      "     2154    0.009    0.000    2.199    0.001 __init__.py:299(loads)\n",
      "     2154    0.009    0.000    0.060    0.000 cookiejar.py:1599(make_cookies)\n",
      "     2057    0.009    0.000    0.023    0.000 typing_extensions.py:600(__subclasscheck__)\n",
      "     2834    0.009    0.000    0.034    0.000 base_events.py:192(_set_nodelay)\n",
      "15488/3968    0.009    0.000    0.010    0.000 completion.py:214(descendants)\n",
      "    14890    0.009    0.000    0.015    0.000 completion.py:970(role)\n",
      "     8114    0.009    0.000    0.011    0.000 _urls.py:282(raw_path)\n",
      "    21336    0.009    0.000    0.009    0.000 _trace.py:93(__aexit__)\n",
      "    17619    0.008    0.000    0.015    0.000 explore_result.py:170(<lambda>)\n",
      "     3874    0.008    0.000    0.043    0.000 _writers.py:36(write_request)\n",
      "  210/172    0.008    0.000  165.442    0.962 mailbox.py:125(_wait)\n",
      "     4308    0.008    0.000    0.014    0.000 message.py:529(get_all)\n",
      "     7742    0.008    0.000    0.021    0.000 _writers.py:63(__call__)\n",
      "     2834    0.008    0.000    0.016    0.000 weakref.py:164(__setitem__)\n",
      "     6527    0.008    0.000    0.008    0.000 {method 'remove' of 'list' objects}\n",
      "     2666    0.008    0.000    0.091    0.000 selector_events.py:1207(close)\n",
      "     4308    0.008    0.000    0.013    0.000 _decoders.py:238(flush)\n",
      "     3916    0.008    0.000    0.043    0.000 _models.py:402(read)\n",
      "     3916    0.008    0.000    0.018    0.000 _models.py:255(__init__)\n",
      "     9986    0.008    0.000    0.010    0.000 parse.py:676(unquote)\n",
      "     1113    0.008    0.000    0.008    0.000 {built-in method posix.read}\n",
      "     2517    0.008    0.000    0.008    0.000 {built-in method torch.full}\n",
      "    15271    0.008    0.000    0.008    0.000 {method 'register' of 'select.poll' objects}\n",
      "    15271    0.008    0.000    0.013    0.000 trsock.py:56(fileno)\n",
      "     2057    0.008    0.000   13.153    0.006 _base_client.py:571(_process_response_data)\n",
      "     4279    0.008    0.000    0.010    0.000 futures.py:236(remove_done_callback)\n",
      "     2154    0.008    0.000    0.012    0.000 _models.py:180(get_list)\n",
      "    14839    0.008    0.000    0.011    0.000 completion.py:238(<genexpr>)\n",
      "     2154    0.008    0.000    0.022    0.000 _models.py:633(_get_content_decoder)\n",
      "    10770    0.008    0.000    0.014    0.000 _readers.py:43(_obsolete_line_fold)\n",
      "     6554    0.008    0.000    0.081    0.000 {method 'throw' of 'generator' objects}\n",
      "     1494    0.008    0.000    0.008    0.000 completion_sampler.py:176(<genexpr>)\n",
      "    23419    0.008    0.000    0.008    0.000 {method 'values' of 'dict' objects}\n",
      "    34280    0.008    0.000    0.008    0.000 {method 'isdigit' of 'str' objects}\n",
      "    10640    0.008    0.000    0.008    0.000 {method 'remove' of 'collections.deque' objects}\n",
      "    23813    0.008    0.000    0.008    0.000 {method 'fileno' of '_socket.socket' objects}\n",
      "3894/2057    0.008    0.000    0.013    0.000 completion.py:471(estimated_completion_tokens)\n",
      "     3840    0.008    0.000    3.458    0.001 completion.py:647(max_splits)\n",
      "    19998    0.008    0.000    0.013    0.000 _utils.py:164(is_list)\n",
      "     3828    0.008    0.000    0.068    0.000 completion_sampler.py:384(_remove_prefix_and_unwanted_leading_tokens)\n",
      "     1494    0.008    0.000    0.106    0.000 2664537466.py:91(on_sample)\n",
      "     2705    0.008    0.000    0.064    0.000 selector_events.py:908(_call_connection_lost)\n",
      "     8051    0.008    0.000    0.008    0.000 tokenization_utils_base.py:1101(pad_token)\n",
      "     7982    0.007    0.000    0.051    0.000 __init__.py:1120(__init__)\n",
      "     2200    0.007    0.000    0.098    0.000 connection.py:168(aclose)\n",
      "    18740    0.007    0.000    0.007    0.000 2664537466.py:58(<genexpr>)\n",
      "     2458    0.007    0.000    0.045    0.000 completion.py:521(token_advantages)\n",
      "     5671    0.007    0.000    0.007    0.000 {method 'setblocking' of '_socket.socket' objects}\n",
      "     3916    0.007    0.000    0.037    0.000 _client.py:413(_merge_queryparams)\n",
      "     4178    0.007    0.000    0.159    0.000 selector_events.py:859(resume_reading)\n",
      "     3916    0.007    0.000    0.014    0.000 _urls.py:150(username)\n",
      "     3916    0.007    0.000    0.236    0.000 _client.py:371(_merge_url)\n",
      "    19426    0.007    0.000    0.011    0.000 typing.py:1630(__eq__)\n",
      "    16897    0.007    0.000    0.007    0.000 base_events.py:1910(_timer_handle_cancelled)\n",
      "     4198    0.007    0.000    0.043    0.000 <frozen _collections_abc>:992(setdefault)\n",
      "     2099    0.007    0.000    0.096    0.000 encoder.py:183(encode)\n",
      "     2154    0.007    0.000    0.036    0.000 request.py:297(request_host)\n",
      "    12336    0.007    0.000    0.010    0.000 selector_events.py:848(is_reading)\n",
      "     5018    0.007    0.000    0.042    0.000 completion.py:837(num_token_logprobs)\n",
      "     4308    0.007    0.000    0.093    0.000 _models.py:373(__init__)\n",
      "    15271    0.007    0.000    0.026    0.000 _sockets.py:67(<lambda>)\n",
      "     8047    0.007    0.000    0.018    0.000 tasks.py:460(<genexpr>)\n",
      "      194    0.007    0.000   30.723    0.158 sock_client.py:286(read_server_response)\n",
      "     3874    0.007    0.000    0.007    0.000 _receivebuffer.py:147(is_next_line_obviously_invalid_request_line)\n",
      "     4114    0.007    0.000    0.127    0.000 completion_sampler.py:97(__aenter__)\n",
      "     7982    0.007    0.000    0.010    0.000 utils.py:881(is_list_of)\n",
      "     8858    0.007    0.000    0.007    0.000 completion.py:828(_token_logprob_sequences)\n",
      "    34548    0.007    0.000    0.007    0.000 enum.py:1286(value)\n",
      "     7832    0.007    0.000    0.012    0.000 _urlparse.py:377(validate_path)\n",
      "    20632    0.007    0.000    0.007    0.000 _exceptions.py:366(request_context)\n",
      "     2837    0.007    0.000    0.045    0.000 _tasks.py:121(move_on_after)\n",
      "    21460    0.007    0.000    0.007    0.000 _trace.py:87(__aenter__)\n",
      "     2154    0.007    0.000    0.011    0.000 __init__.py:244(detect_encoding)\n",
      "     2154    0.007    0.000    0.007    0.000 _receivebuffer.py:64(__bytes__)\n",
      "     2154    0.007    0.000    2.207    0.001 _models.py:765(json)\n",
      "     2057    0.007    0.000    0.009    0.000 _base_client.py:1891(make_request_options)\n",
      "      384    0.007    0.000    3.851    0.010 trainer.py:514(_explore_episode)\n",
      "    15078    0.007    0.000    0.007    0.000 {method 'endswith' of 'bytearray' objects}\n",
      "    25162    0.007    0.000    0.007    0.000 selector_events.py:845(is_closing)\n",
      "     3916    0.007    0.000    0.024    0.000 _client.py:393(_merge_cookies)\n",
      "     3991    0.007    0.000    0.017    0.000 chat_utils.py:270(__init__)\n",
      "     2502    0.006    0.000    0.112    0.000 selector_events.py:1009(_read_ready__data_received)\n",
      "     3991    0.006    0.000    0.006    0.000 tokenization_utils_fast.py:413(set_truncation_and_padding)\n",
      "    12042    0.006    0.000    0.008    0.000 llm_engine.py:594(get_tokenizer_group)\n",
      "17052/4519    0.006    0.000    0.006    0.000 completion.py:511(root)\n",
      "     2057    0.006    0.000    0.008    0.000 {built-in method _bisect.insort_right}\n",
      "    12342    0.006    0.000    0.024    0.000 copy.py:252(<genexpr>)\n",
      "    11235    0.006    0.000    0.027    0.000 completion.py:745(<genexpr>)\n",
      "     2154    0.006    0.000    0.026    0.000 request.py:370(_parse)\n",
      "    12380    0.006    0.000    0.006    0.000 {method 'split' of 'bytes' objects}\n",
      "     2154    0.006    0.000    0.040    0.000 request.py:339(full_url)\n",
      "     3916    0.006    0.000    0.008    0.000 _urlparse.py:116(netloc)\n",
      "     3916    0.006    0.000    0.016    0.000 _models.py:1162(__bool__)\n",
      "     4652    0.006    0.000    0.112    0.000 _synchronization.py:127(set)\n",
      "     2837    0.006    0.000    0.009    0.000 _asyncio.py:335(get_callable_name)\n",
      "     2834    0.006    0.000    0.171    0.000 selector_events.py:69(_make_socket_transport)\n",
      "    87399    0.006    0.000    0.006    0.000 __init__.py:609(__missing__)\n",
      "     5099    0.006    0.000    0.006    0.000 weakref.py:427(__setitem__)\n",
      "     5674    0.006    0.000    0.035    0.000 _asyncio.py:1714(wait)\n",
      "     4198    0.006    0.000    0.047    0.000 <frozen _collections_abc>:940(pop)\n",
      "     2500    0.006    0.000    0.036    0.000 _asyncio.py:1130(data_received)\n",
      "     3340    0.006    0.000    0.024    0.000 _connection.py:352(receive_data)\n",
      "     7982    0.006    0.000    0.007    0.000 tokenization_utils_base.py:4076(_eventual_warn_about_too_long_sequence)\n",
      "     2057    0.006    0.000   27.071    0.013 _transform.py:265(async_transform)\n",
      "  674/615    0.006    0.000    0.005    0.000 {built-in method posix.urandom}\n",
      "     2834    0.006    0.000    0.006    0.000 {method 'setsockopt' of '_socket.socket' objects}\n",
      "     2517    0.006    0.000    0.016    0.000 explore_result.py:302(<lambda>)\n",
      "     2834    0.006    0.000    0.009    0.000 transports.py:270(__init__)\n",
      "    22499    0.006    0.000    0.006    0.000 {built-in method _asyncio._get_running_loop}\n",
      "     2834    0.006    0.000    0.007    0.000 selector_events.py:961(set_protocol)\n",
      "     2154    0.006    0.000    0.014    0.000 _urlparse.py:139(__str__)\n",
      "      619    0.006    0.000    0.006    0.000 {built-in method numpy.asarray}\n",
      "     2834    0.006    0.000    0.006    0.000 {method 'getsockopt' of '_socket.socket' objects}\n",
      "     3968    0.006    0.000    3.475    0.001 episode.py:358(<genexpr>)\n",
      "    10861    0.006    0.000    0.006    0.000 futures.py:205(exception)\n",
      "     3916    0.006    0.000    0.007    0.000 cookiejar.py:1227(deepvalues)\n",
      "     9713    0.006    0.000    0.006    0.000 _compat.py:109(get_model_config)\n",
      "     2837    0.006    0.000    0.011    0.000 _asyncio.py:687(__init__)\n",
      "     5350    0.005    0.000    0.190    0.000 http11.py:261(aclose)\n",
      "     6015    0.005    0.000    0.008    0.000 _urls.py:168(host)\n",
      "     7489    0.005    0.000    0.013    0.000 _asyncio.py:1708(set)\n",
      "     4060    0.005    0.000    0.024    0.000 tokenization_utils_base.py:1233(pad_token_id)\n",
      "     4060    0.005    0.000    0.005    0.000 {method 'token_to_id' of 'tokenizers.Tokenizer' objects}\n",
      "     2154    0.005    0.000    0.022    0.000 _connection.py:223(start_next_cycle)\n",
      "     6171    0.005    0.000    0.007    0.000 copyreg.py:98(__newobj__)\n",
      "     3916    0.005    0.000    0.122    0.000 _content.py:184(encode_request)\n",
      "     2837    0.005    0.000    0.025    0.000 _asyncio.py:693(__aenter__)\n",
      "     5708    0.005    0.000    0.016    0.000 socket.py:523(type)\n",
      "     5350    0.005    0.000    0.184    0.000 anyio.py:54(aclose)\n",
      "     9713    0.005    0.000    0.005    0.000 _compat.py:115(get_model_fields)\n",
      "     7489    0.005    0.000    0.009    0.000 _asyncio.py:1702(__new__)\n",
      "    14626    0.005    0.000    0.008    0.000 _exceptions.py:82(iterate_exceptions)\n",
      "     2822    0.005    0.000    0.006    0.000 _asyncio.py:1179(__init__)\n",
      "    11030    0.005    0.000    0.006    0.000 _synchronization.py:711(__enter__)\n",
      "      690    0.005    0.000    1.229    0.002 utils.py:175(truncate_pad)\n",
      "     6478    0.005    0.000    0.006    0.000 {built-in method builtins.min}\n",
      "     2834    0.005    0.000    0.040    0.000 selector_events.py:683(_sock_connect_cb)\n",
      "     2705    0.005    0.000    9.289    0.003 selector_events.py:1190(_call_connection_lost)\n",
      "     4060    0.005    0.000    0.039    0.000 tokenizer.py:28(get_pad_token_id)\n",
      "     6015    0.005    0.000    0.005    0.000 _urls.py:323(is_absolute_url)\n",
      "     3634    0.005    0.000    0.029    0.000 _urls.py:582(merge)\n",
      "      619    0.005    0.000    0.005    0.000 {method 'cumsum' of 'numpy.ndarray' objects}\n",
      "     2154    0.005    0.000    0.005    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "     7604    0.005    0.000    0.005    0.000 _connection.py:248(_server_switch_event)\n",
      "     2654    0.005    0.000    0.066    0.000 selector_events.py:1167(write_eof)\n",
      "     5674    0.005    0.000    0.005    0.000 {built-in method _socket.inet_pton}\n",
      "     3871    0.005    0.000    0.007    0.000 _writers.py:88(send_data)\n",
      "     3672    0.005    0.000    0.035    0.000 streams.py:549(readline)\n",
      "    10050    0.005    0.000    0.007    0.000 base_events.py:1900(_add_callback)\n",
      "    15271    0.005    0.000    0.005    0.000 {built-in method select.poll}\n",
      "     2099    0.005    0.000    0.008    0.000 _base_client.py:551(_maybe_override_cast_to)\n",
      "     2154    0.005    0.000    0.043    0.000 _models.py:450(__init__)\n",
      "     2837    0.005    0.000    0.005    0.000 connection.py:37(__init__)\n",
      "     2875    0.005    0.000    0.008    0.000 _asyncio.py:348(_task_started)\n",
      "     6071    0.005    0.000    0.009    0.000 _asyncio.py:495(_parent_cancellation_is_visible_to_us)\n",
      "     2837    0.005    0.000    0.011    0.000 ipaddress.py:1249(_string_from_ip_int)\n",
      "     7912    0.005    0.000    0.007    0.000 base_futures.py:13(isfuture)\n",
      "     3916    0.005    0.000    0.006    0.000 connection_pool.py:16(__init__)\n",
      "     3991    0.005    0.000    0.183    0.000 environment.py:1378(new_context)\n",
      "     3991    0.005    0.000    0.005    0.000 tokenization_utils_base.py:1922(get_chat_template)\n",
      "     2154    0.005    0.000    0.005    0.000 _state.py:358(start_next_cycle)\n",
      "     3916    0.005    0.000    0.006    0.000 _client.py:1519(_transport_for_url)\n",
      "     1817    0.005    0.000    0.345    0.000 _urls.py:367(copy_merge_params)\n",
      "     8561    0.005    0.000    0.005    0.000 {method 'startswith' of 'bytes' objects}\n",
      "    12053    0.005    0.000    0.005    0.000 _headers.py:102(__init__)\n",
      "     3991    0.004    0.000    0.006    0.000 <frozen _collections_abc>:819(keys)\n",
      "      128    0.004    0.000    3.789    0.030 episode.py:303(_get_sampleable_parents)\n",
      "    12380    0.004    0.000    0.004    0.000 {method 'strip' of 'bytes' objects}\n",
      "     1750    0.004    0.000    0.005    0.000 tasks.py:710(__init__)\n",
      "     3991    0.004    0.000    0.021    0.000 chat_utils.py:226(create_parser)\n",
      "     4114    0.004    0.000    0.012    0.000 _typing.py:47(extract_type_arg)\n",
      "     2154    0.004    0.000    0.010    0.000 parse.py:1083(_splittype)\n",
      "    10050    0.004    0.000    0.004    0.000 selectors.py:275(_key_from_fd)\n",
      " 2441/619    0.004    0.000    0.006    0.000 completion.py:497(num_prefix_tokens)\n",
      "     2688    0.004    0.000    3.602    0.001 episode.py:352(<genexpr>)\n",
      "     2226    0.004    0.000    0.012    0.000 streams.py:521(_wait_for_data)\n",
      "     2154    0.004    0.000    0.005    0.000 parse.py:1062(unwrap)\n",
      "     3916    0.004    0.000    0.008    0.000 _urls.py:159(password)\n",
      "    13556    0.004    0.000    0.004    0.000 futures.py:175(cancelled)\n",
      "    23479    0.004    0.000    0.004    0.000 selectors.py:272(get_map)\n",
      "     9931    0.004    0.000    0.004    0.000 {method 'partition' of 'str' objects}\n",
      "     4060    0.004    0.000    0.014    0.000 tokenization_utils_fast.py:329(convert_tokens_to_ids)\n",
      "    10120    0.004    0.000    0.006    0.000 _receivebuffer.py:60(__len__)\n",
      "     2185    0.004    0.000    0.022    0.000 {built-in method builtins.all}\n",
      "     2518    0.004    0.000    3.188    0.001 episode.py:51(messages)\n",
      "    11973    0.004    0.000    0.004    0.000 runtime.py:229(resolve_or_missing)\n",
      "     3916    0.004    0.000    0.038    0.000 _utils.py:306(async_start)\n",
      "     2154    0.004    0.000    0.024    0.000 _utils.py:313(async_elapsed)\n",
      "     2705    0.004    0.000    0.007    0.000 _asyncio.py:1122(connection_lost)\n",
      "     1113    0.004    0.000    0.025    0.000 unix_events.py:523(_read_ready)\n",
      "    15964    0.004    0.000    0.004    0.000 __init__.py:1137(__setitem__)\n",
      "    10563    0.004    0.000    0.005    0.000 _asyncio.py:481(_effectively_cancelled)\n",
      "     7982    0.004    0.000    0.005    0.000 tokenization_utils_base.py:259(__getitem__)\n",
      "    13914    0.004    0.000    0.004    0.000 _models.py:168(__init__)\n",
      "     2837    0.004    0.000    0.026    0.000 _tasks.py:151(create_task_group)\n",
      "     3926    0.004    0.000    0.010    0.000 tasks.py:534(_on_completion)\n",
      "     2057    0.004    0.000    0.006    0.000 typing_extensions.py:530(_caller)\n",
      "     5668    0.004    0.000    0.004    0.000 transports.py:314(_set_write_buffer_limits)\n",
      "     3916    0.004    0.000    0.013    0.000 _urls.py:233(netloc)\n",
      "     8312    0.004    0.000    0.006    0.000 _utils.py:122(is_given)\n",
      "     3871    0.004    0.000    0.006    0.000 _writers.py:94(send_eom)\n",
      "     2099    0.004    0.000    0.033    0.000 _compat.py:121(model_copy)\n",
      "     5227    0.004    0.000    0.005    0.000 tasks.py:70(_set_task_name)\n",
      "     8746    0.004    0.000    0.004    0.000 _decoders.py:215(decode)\n",
      "     2154    0.004    0.000    0.018    0.000 _urls.py:390(__str__)\n",
      "  416/382    0.004    0.000    0.056    0.000 mailbox.py:17(<genexpr>)\n",
      "     2834    0.004    0.000    0.012    0.000 transports.py:330(set_write_buffer_limits)\n",
      "     6015    0.004    0.000    0.009    0.000 _urls.py:335(is_relative_url)\n",
      "     2057    0.004    0.000   27.092    0.013 _transform.py:252(async_maybe_transform)\n",
      "     1817    0.004    0.000    0.008    0.000 _urlparse.py:485(urlencode)\n",
      "     4060    0.004    0.000    0.009    0.000 tokenization_utils_fast.py:348(_convert_token_to_id_with_added_voc)\n",
      "     2154    0.004    0.000    0.004    0.000 parse.py:119(_coerce_args)\n",
      "     2837    0.004    0.000    0.056    0.000 selector_events.py:369(remove_writer)\n",
      "     4211    0.004    0.000    0.006    0.000 _models.py:553(reason_phrase)\n",
      "     1113    0.004    0.000    0.018    0.000 streams.py:499(feed_data)\n",
      "     2154    0.004    0.000    0.004    0.000 {method 'split' of 'bytearray' objects}\n",
      "     2502    0.004    0.000    0.115    0.000 selector_events.py:969(_read_ready)\n",
      "     2099    0.004    0.000    0.004    0.000 _base_client.py:647(platform_headers)\n",
      "     2837    0.004    0.000    0.060    0.000 selector_events.py:679(_sock_write_done)\n",
      "     2882    0.004    0.000    0.004    0.000 selector_events.py:922(get_write_buffer_size)\n",
      "     2837    0.004    0.000    0.015    0.000 _asyncio.py:2322(create_task_group)\n",
      "     4308    0.003    0.000    0.003    0.000 _decoders.py:211(__init__)\n",
      "     2154    0.003    0.000    0.007    0.000 parse.py:1104(_splithost)\n",
      "       69    0.003    0.000    0.029    0.000 pack.py:43(packed_tensors_from_dir)\n",
      "     4610    0.003    0.000    0.008    0.000 http11.py:271(can_handle_request)\n",
      "     1750    0.003    0.000    0.010    0.000 {method 'set_result' of '_asyncio.Future' objects}\n",
      "     2154    0.003    0.000    0.004    0.000 {method 'send' of 'generator' objects}\n",
      "     4652    0.003    0.000    0.115    0.000 connection_pool.py:21(assign_to_connection)\n",
      "     5060    0.003    0.000    0.010    0.000 _receivebuffer.py:57(__bool__)\n",
      "     2057    0.003    0.000    0.004    0.000 completion_sampler.py:46(__call__)\n",
      "     8224    0.003    0.000    0.005    0.000 _models.py:93(enforce_stream)\n",
      "     1817    0.003    0.000    0.004    0.000 _urls.py:498(multi_items)\n",
      "     2837    0.003    0.000    0.064    0.000 ipaddress.py:28(ip_address)\n",
      "     1817    0.003    0.000    0.006    0.000 parse.py:699(parse_qs)\n",
      "     5036    0.003    0.000    0.003    0.000 episode.py:45(<genexpr>)\n",
      "     2099    0.003    0.000    0.100    0.000 __init__.py:183(dumps)\n",
      "     5632    0.003    0.000    0.006    0.000 _asyncio.py:1725(__new__)\n",
      "     3874    0.003    0.000    0.008    0.000 _headers.py:271(has_expect_100_continue)\n",
      "     2837    0.003    0.000    0.130    0.000 _asyncio.py:826(start_soon)\n",
      "     3991    0.003    0.000    0.003    0.000 chat_utils.py:256(mm_placeholder_counts)\n",
      "     2834    0.003    0.000    0.003    0.000 weakref.py:352(__init__)\n",
      "     3916    0.003    0.000    0.005    0.000 _urls.py:134(raw_scheme)\n",
      "     2154    0.003    0.000    0.003    0.000 _models.py:705(has_redirect_location)\n",
      "     2837    0.003    0.000    0.014    0.000 ipaddress.py:609(__str__)\n",
      "     2057    0.003    0.000    0.019    0.000 completion_sampler.py:100(__aexit__)\n",
      "     2154    0.003    0.000    0.010    0.000 _connection.py:341(trailing_data)\n",
      "     8391    0.003    0.000    0.003    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "     2756    0.003    0.000    0.050    0.000 socket.py:501(close)\n",
      "     2400    0.003    0.000    0.003    0.000 weakref.py:369(remove)\n",
      "     3023    0.003    0.000    0.024    0.000 futures.py:313(_set_result_unless_cancelled)\n",
      "     2057    0.003    0.000    0.009    0.000 typing_extensions.py:542(_allow_reckless_class_checks)\n",
      "     9691    0.003    0.000    0.003    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "     3916    0.003    0.000    0.003    0.000 cookiejar.py:1753(__iter__)\n",
      "     2057    0.003    0.000    0.019    0.000 _response.py:378(request_id)\n",
      "     1638    0.003    0.000    0.005    0.000 _exceptions.py:112(__init__)\n",
      "     3916    0.003    0.000    0.005    0.000 _models.py:48(enforce_url)\n",
      "    12360    0.003    0.000    0.003    0.000 _synchronization.py:100(__enter__)\n",
      "     2154    0.003    0.000    0.004    0.000 _models.py:665(is_success)\n",
      "     3991    0.003    0.000    0.004    0.000 nodes.py:76(__init__)\n",
      "      690    0.003    0.000    1.224    0.002 functional.py:4478(pad)\n",
      "     3916    0.003    0.000    0.003    0.000 _config.py:256(as_dict)\n",
      "    10906    0.003    0.000    0.003    0.000 _synchronization.py:717(__exit__)\n",
      "      619    0.003    0.000    0.014    0.000 fromnumeric.py:40(_wrapit)\n",
      "    17232    0.003    0.000    0.003    0.000 _policybase.py:313(header_store_parse)\n",
      "     3991    0.003    0.000    0.003    0.000 tokenization_utils_base.py:1067(eos_token)\n",
      "     2099    0.003    0.000    0.003    0.000 _config.py:210(__init__)\n",
      "  210/172    0.003    0.000  233.219    1.356 mailbox.py:128(_get_and_clear)\n",
      "     7742    0.003    0.000    0.003    0.000 _content.py:38(__aiter__)\n",
      "     2756    0.003    0.000    0.046    0.000 socket.py:497(_real_close)\n",
      "     7226    0.003    0.000    0.003    0.000 tasks.py:260(uncancel)\n",
      "     2837    0.003    0.000    0.003    0.000 weakref.py:410(__delitem__)\n",
      "     8228    0.003    0.000    0.003    0.000 fields.py:572(is_required)\n",
      "     3991    0.003    0.000    0.003    0.000 tokenization_utils_base.py:1136(additional_special_tokens)\n",
      "     2057    0.003    0.000    0.016    0.000 completion_sampler.py:59(release)\n",
      "     2837    0.003    0.000    0.017    0.000 ipaddress.py:394(compressed)\n",
      "    10138    0.003    0.000    0.003    0.000 {built-in method builtins.iter}\n",
      "      388    0.003    0.000    0.003    0.000 {method 'settimeout' of '_socket.socket' objects}\n",
      "     2518    0.003    0.000    0.034    0.000 episode.py:63(commit)\n",
      "     4308    0.003    0.000    0.003    0.000 message.py:150(__init__)\n",
      "     2837    0.003    0.000    0.003    0.000 _asyncio.py:634(shield)\n",
      "     1238    0.003    0.000    0.019    0.000 fromnumeric.py:53(_wrapfunc)\n",
      "     2795    0.003    0.000    0.003    0.000 _state.py:250(__init__)\n",
      "     2099    0.003    0.000    0.056    0.000 _base_client.py:568(_should_stream_response_body)\n",
      "      621    0.003    0.000    0.003    0.000 {method 'view' of 'torch._C.TensorBase' objects}\n",
      "     3991    0.003    0.000    0.005    0.000 __init__.py:1032(__bool__)\n",
      "     1817    0.002    0.000    0.015    0.000 _urls.py:623(__str__)\n",
      "       17    0.002    0.000   38.766    2.280 interface.py:769(publish_keepalive)\n",
      "      129    0.002    0.000    0.006    0.000 std.py:1402(set_postfix)\n",
      "     2057    0.002    0.000    0.011    0.000 _models.py:693(add_request_id)\n",
      "     2560    0.002    0.000    0.056    0.000 completion.py:666(split_weight)\n",
      "     3916    0.002    0.000    0.004    0.000 _urls.py:195(raw_host)\n",
      "     2057    0.002    0.000    0.005    0.000 completions.py:1742(validate_response_format)\n",
      "     1638    0.002    0.000    0.002    0.000 _exceptions.py:92(__init__)\n",
      "     2099    0.002    0.000    0.002    0.000 _base_client.py:635(user_agent)\n",
      "     2175    0.002    0.000    0.002    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
      "     1817    0.002    0.000    0.012    0.000 _urls.py:274(params)\n",
      "     1113    0.002    0.000    0.009    0.000 base_subprocess.py:194(_call)\n",
      "     2154    0.002    0.000    0.002    0.000 _headers.py:121(raw_items)\n",
      "     2559    0.002    0.000    0.002    0.000 {method 'find' of 'bytearray' objects}\n",
      "     1113    0.002    0.000    0.011    0.000 base_subprocess.py:204(_pipe_data_received)\n",
      "     2099    0.002    0.000    0.012    0.000 _utils.py:384(get_async_library)\n",
      "     2875    0.002    0.000    0.002    0.000 inspect.py:1944(getcoroutinestate)\n",
      "     3991    0.002    0.000    0.003    0.000 tokenization_utils_base.py:303(items)\n",
      "     2834    0.002    0.000    0.004    0.000 weakref.py:347(__new__)\n",
      "     3916    0.002    0.000    0.004    0.000 _multipart.py:25(get_multipart_boundary_from_content_type)\n",
      "      736    0.002    0.000    0.002    0.000 connection_pool.py:27(clear_connection)\n",
      "    13698    0.002    0.000    0.002    0.000 _asyncio.py:626(cancelled_caught)\n",
      "     1113    0.002    0.000    0.012    0.000 streams.py:474(_wakeup_waiter)\n",
      "     2837    0.002    0.000    0.003    0.000 base_events.py:202(_check_ssl_socket)\n",
      "     2057    0.002    0.000    0.004    0.000 _response.py:434(read)\n",
      "    13583    0.002    0.000    0.002    0.000 base_events.py:719(is_closed)\n",
      "     6171    0.002    0.000    0.002    0.000 _utils.py:256(<genexpr>)\n",
      "     2154    0.002    0.000    0.006    0.000 _models.py:728(raise_for_status)\n",
      "     7241    0.002    0.000    0.002    0.000 futures.py:113(_log_traceback)\n",
      "     2154    0.002    0.000    0.003    0.000 parse.py:1214(_splittag)\n",
      "     2141    0.002    0.000    0.003    0.000 __init__.py:1517(debug)\n",
      "     8852    0.002    0.000    0.002    0.000 {built-in method builtins.callable}\n",
      "      621    0.002    0.000    0.002    0.000 {method 'squeeze' of 'torch._C.TensorBase' objects}\n",
      "     2196    0.002    0.000    0.003    0.000 __init__.py:1529(info)\n",
      "     3916    0.002    0.000    0.002    0.000 _urls.py:612(__bool__)\n",
      "     4308    0.002    0.000    0.002    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
      "     2517    0.002    0.000    0.003    0.000 explore_result.py:209(<lambda>)\n",
      "    17232    0.002    0.000    0.002    0.000 _policybase.py:209(header_max_count)\n",
      "     2518    0.002    0.000    0.042    0.000 episode.py:39(all_absent_stop_tokens)\n",
      "     4308    0.002    0.000    0.002    0.000 <string>:2(__eq__)\n",
      "     1113    0.002    0.000    0.020    0.000 subprocess.py:64(pipe_data_received)\n",
      "     6070    0.002    0.000    0.002    0.000 _client.py:298(cookies)\n",
      "     7708    0.002    0.000    0.002    0.000 _auth.py:38(auth_flow)\n",
      "     2834    0.002    0.000    0.006    0.000 transports.py:277(_maybe_pause_protocol)\n",
      "    12890    0.002    0.000    0.002    0.000 _asyncio.py:630(shield)\n",
      "     4308    0.002    0.000    0.002    0.000 {method 'groups' of 're.Match' objects}\n",
      "     2837    0.002    0.000    0.003    0.000 auto.py:9(_init_backend)\n",
      "    12360    0.002    0.000    0.002    0.000 _synchronization.py:103(__exit__)\n",
      "     2154    0.002    0.000    0.004    0.000 <string>:1(<lambda>)\n",
      "    69/34    0.002    0.000    0.769    0.023 mailbox.py:249(wait)\n",
      "     2837    0.002    0.000    0.002    0.000 inspect.py:464(iscoroutine)\n",
      "     3991    0.002    0.000    0.002    0.000 chat_utils.py:487(_postprocess_messages)\n",
      "     5733    0.002    0.000    0.002    0.000 _urlparse.py:402(normalize_path)\n",
      "     2654    0.002    0.000    0.003    0.000 selector_events.py:835(abort)\n",
      "       49    0.002    0.000    0.003    0.000 interface_shared.py:123(_make_request)\n",
      "      619    0.002    0.000    0.002    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}\n",
      "     2154    0.002    0.000    0.003    0.000 _models.py:544(http_version)\n",
      "       19    0.002    0.000    0.675    0.036 interface.py:910(deliver_internal_messages)\n",
      "     1003    0.002    0.000    0.002    0.000 episode.py:281(<genexpr>)\n",
      "     2837    0.002    0.000    0.002    0.000 _asyncio.py:1711(is_set)\n",
      "     3793    0.002    0.000    0.002    0.000 {method 'aclose' of 'async_generator' objects}\n",
      "     7982    0.002    0.000    0.002    0.000 tokenization_utils_base.py:698(convert_to_tensors)\n",
      "     4652    0.002    0.000    0.002    0.000 _synchronization.py:113(__init__)\n",
      "     3871    0.002    0.000    0.002    0.000 _headers.py:105(__bool__)\n",
      "     2137    0.002    0.000    0.002    0.000 {method 'pop' of 'list' objects}\n",
      "3674/1238    0.002    0.000    0.009    0.000 completion.py:489(<genexpr>)\n",
      "     2099    0.002    0.000    0.002    0.000 _client.py:370(auth_headers)\n",
      "       49    0.002    0.000    0.045    0.001 sock_client.py:147(_send_message)\n",
      "     4308    0.002    0.000    0.002    0.000 {method 'seek' of '_io.BytesIO' objects}\n",
      "     2795    0.002    0.000    0.002    0.000 _receivebuffer.py:48(__init__)\n",
      "     1817    0.002    0.000    0.002    0.000 parse.py:741(parse_qsl)\n",
      "     1113    0.002    0.000    0.013    0.000 base_subprocess.py:284(data_received)\n",
      "     4308    0.002    0.000    0.002    0.000 {method 'end' of 're.Match' objects}\n",
      "     2518    0.002    0.000    0.002    0.000 2664537466.py:101(<lambda>)\n",
      "     5036    0.002    0.000    0.002    0.000 episode.py:59(reward)\n",
      "     7982    0.002    0.000    0.002    0.000 sandbox.py:299(getitem)\n",
      "     1238    0.002    0.000    0.011    0.000 main.py:202(__init__)\n",
      "     3991    0.002    0.000    0.002    0.000 tokenization_utils_base.py:1078(unk_token)\n",
      "     2837    0.002    0.000    0.002    0.000 tasks.py:167(set_name)\n",
      "     3173    0.002    0.000    0.002    0.000 completion.py:563(<genexpr>)\n",
      "        2    0.002    0.001    0.002    0.001 {method '__exit__' of 'sqlite3.Connection' objects}\n",
      "      397    0.002    0.000    0.047    0.000 __init__.py:595(__init__)\n",
      "     4253    0.002    0.000    0.002    0.000 {method 'pop' of 'set' objects}\n",
      "     7897    0.002    0.000    0.002    0.000 locks.py:177(is_set)\n",
      "      137    0.002    0.000    0.002    0.000 {built-in method posix.stat}\n",
      "     3916    0.002    0.000    0.002    0.000 _client.py:278(headers)\n",
      "     3991    0.002    0.000    0.002    0.000 <frozen _collections_abc>:845(__init__)\n",
      "     3991    0.002    0.000    0.002    0.000 {method 'removesuffix' of 'str' objects}\n",
      "     3803    0.002    0.000    0.004    0.000 selector_events.py:877(__del__)\n",
      "  463/431    0.002    0.000    0.040    0.000 random.py:341(choice)\n",
      "     7832    0.001    0.000    0.001    0.000 _content.py:35(__iter__)\n",
      "     3916    0.001    0.000    0.001    0.000 _client.py:564(_set_timeout)\n",
      "    10751    0.001    0.000    0.001    0.000 completion_sampler.py:53(<lambda>)\n",
      "     8563    0.001    0.000    0.001    0.000 _asyncio.py:622(cancel_called)\n",
      "     2837    0.001    0.000    0.001    0.000 {method 'to_bytes' of 'int' objects}\n",
      "     6268    0.001    0.000    0.001    0.000 _models.py:529(request)\n",
      "      129    0.001    0.000    0.009    0.000 2664537466.py:120(train_episodes)\n",
      "     3916    0.001    0.000    0.001    0.000 {method 'upper' of 'str' objects}\n",
      "     2057    0.001    0.000    0.001    0.000 {built-in method sys._getframe}\n",
      "     2099    0.001    0.000    0.001    0.000 {method 'lstrip' of 'bytes' objects}\n",
      "    12800    0.001    0.000    0.001    0.000 episode.py:377(<lambda>)\n",
      "  463/431    0.001    0.000    0.017    0.000 random.py:242(_randbelow_with_getrandbits)\n",
      "      226    0.001    0.000    0.002    0.000 sock_client.py:227(_extract_packet_bytes)\n",
      "     5099    0.001    0.000    0.001    0.000 _asyncio.py:655(__init__)\n",
      "     3991    0.001    0.000    0.001    0.000 tokenization_utils_base.py:1089(sep_token)\n",
      "     2154    0.001    0.000    0.001    0.000 {method 'span' of 're.Match' objects}\n",
      "     4652    0.001    0.000    0.001    0.000 connection_pool.py:31(wait_for_connection)\n",
      "     5632    0.001    0.000    0.001    0.000 _synchronization.py:55(__init__)\n",
      "     2057    0.001    0.000    0.001    0.000 _response.py:61(__init__)\n",
      "     2183    0.001    0.000    0.002    0.000 _models.py:791(get_max_retries)\n",
      "     2154    0.001    0.000    0.002    0.000 _models.py:569(content)\n",
      "     3828    0.001    0.000    0.001    0.000 <string>:2(__init__)\n",
      "     8228    0.001    0.000    0.001    0.000 _types.py:124(__bool__)\n",
      "     6171    0.001    0.000    0.001    0.000 copy.py:172(_deepcopy_atomic)\n",
      "     1113    0.001    0.000    0.001    0.000 {method 'extend' of 'bytearray' objects}\n",
      "     4012    0.001    0.000    0.001    0.000 {method 'done' of '_asyncio.Future' objects}\n",
      "     2559    0.001    0.000    0.001    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
      "      255    0.001    0.000    0.001    0.000 notebook.py:260(update)\n",
      "      258    0.001    0.000    0.001    0.000 std.py:419(format_num)\n",
      "     5644    0.001    0.000    0.001    0.000 _synchronization.py:707(__init__)\n",
      "     3991    0.001    0.000    0.001    0.000 tokenization_utils_base.py:1112(cls_token)\n",
      "     4308    0.001    0.000    0.001    0.000 {method 'truncate' of '_io.BytesIO' objects}\n",
      "     2154    0.001    0.000    0.001    0.000 request.py:356(data)\n",
      "       69    0.001    0.000    0.001    0.000 {built-in method posix.mkdir}\n",
      "     1817    0.001    0.000    0.001    0.000 _utils.py:56(primitive_value_to_str)\n",
      "     3991    0.001    0.000    0.001    0.000 tokenization_utils_base.py:1124(mask_token)\n",
      "     3916    0.001    0.000    0.001    0.000 _urls.py:217(port)\n",
      "      223    0.001    0.000    0.007    0.000 tasks.py:472(wait_for)\n",
      "     4198    0.001    0.000    0.001    0.000 _base_client.py:639(base_url)\n",
      "     1750    0.001    0.000    0.001    0.000 {method 'add_done_callback' of '_asyncio.Future' objects}\n",
      "      619    0.001    0.000    0.017    0.000 fromnumeric.py:2512(cumsum)\n",
      "     3991    0.001    0.000    0.001    0.000 chat_utils.py:223(all_mm_data)\n",
      "     2154    0.001    0.000    0.001    0.000 {method 'asend' of 'async_generator' objects}\n",
      "     3916    0.001    0.000    0.001    0.000 _client.py:309(params)\n",
      "     2154    0.001    0.000    0.001    0.000 _status_codes.py:52(is_success)\n",
      "     2175    0.001    0.000    0.001    0.000 {method 'release' of '_thread.RLock' objects}\n",
      "  407/391    0.001    0.000    0.236    0.001 _base_client.py:1645(_retry_request)\n",
      "     2154    0.001    0.000    0.001    0.000 _events.py:247(__post_init__)\n",
      "      128    0.001    0.000    0.007    0.000 explore_result.py:81(_update_pbar_postfix)\n",
      "     2693    0.001    0.000    0.002    0.000 selector_events.py:896(_force_close)\n",
      "      865    0.001    0.000    0.002    0.000 weakref.py:105(remove)\n",
      "     3916    0.001    0.000    0.001    0.000 _content.py:32(__init__)\n",
      "     2099    0.001    0.000    0.001    0.000 _base_client.py:618(default_query)\n",
      "     2834    0.001    0.000    0.001    0.000 transports.py:14(__init__)\n",
      "      299    0.001    0.000    0.001    0.000 threading.py:311(_acquire_restore)\n",
      "     1750    0.001    0.000    0.001    0.000 {method 'result' of '_asyncio.Future' objects}\n",
      "      865    0.001    0.000    0.001    0.000 {built-in method _weakref._remove_dead_weakref}\n",
      "     2518    0.001    0.000    0.001    0.000 {method 'copy' of 'list' objects}\n",
      "     3874    0.001    0.000    0.001    0.000 _writers.py:85(__init__)\n",
      "      619    0.001    0.000    0.004    0.000 fromnumeric.py:1332(searchsorted)\n",
      "     2174    0.001    0.000    0.001    0.000 {built-in method time.time}\n",
      "      128    0.001    0.000    0.003    0.000 queues.py:137(put_nowait)\n",
      "     3991    0.001    0.000    0.001    0.000 llm_engine.py:922(get_model_config)\n",
      "     2154    0.001    0.000    0.001    0.000 connection_pool.py:350(__init__)\n",
      "      223    0.001    0.000    0.002    0.000 queues.py:149(get)\n",
      "      268    0.001    0.000    0.016    0.000 trainer.py:537(<genexpr>)\n",
      "      211    0.001    0.000   38.767    0.184 interface_shared.py:517(_transport_keepalive_failed)\n",
      "     2154    0.001    0.000    0.001    0.000 http11.py:332(__init__)\n",
      "     2057    0.001    0.000    0.001    0.000 completion_sampler.py:87(__init__)\n",
      "      128    0.001    0.000    7.704    0.060 explore_result.py:65(done_callback)\n",
      "     2875    0.001    0.000    0.001    0.000 tasks.py:158(get_coro)\n",
      "     3991    0.001    0.000    0.001    0.000 tokenization_utils_base.py:310(encodings)\n",
      "     2628    0.001    0.000    0.001    0.000 locks.py:193(clear)\n",
      "     2562    0.001    0.000    0.001    0.000 {built-in method builtins.abs}\n",
      "      397    0.001    0.000    0.045    0.000 __init__.py:669(update)\n",
      "       19    0.001    0.000    2.545    0.134 explore_result.py:313(_sequences_to_tensor)\n",
      "      401    0.001    0.000    0.001    0.000 threading.py:302(__exit__)\n",
      "      189    0.001    0.000    0.004    0.000 base_events.py:742(call_later)\n",
      "     2834    0.001    0.000    0.001    0.000 selector_events.py:838(set_protocol)\n",
      "       69    0.001    0.000    0.005    0.000 <frozen os>:200(makedirs)\n",
      "     2154    0.001    0.000    0.001    0.000 cookiejar.py:44(_debug)\n",
      "     2154    0.001    0.000    0.001    0.000 _client.py:142(__init__)\n",
      "       49    0.001    0.000    0.069    0.001 interface_sock.py:49(_publish)\n",
      "       19    0.001    0.000    0.001    0.000 wandb_run.py:319(_process_internal_messages)\n",
      "      619    0.001    0.000    0.001    0.000 {method 'rindex' of 'str' objects}\n",
      "     2154    0.001    0.000    0.001    0.000 _readers.py:123(__init__)\n",
      "     2560    0.001    0.000    0.001    0.000 {method 'random' of '_random.Random' objects}\n",
      "     2795    0.001    0.000    0.001    0.000 anyio.py:20(__init__)\n",
      "     2099    0.001    0.000    0.001    0.000 _base_client.py:425(<genexpr>)\n",
      "     2834    0.001    0.000    0.001    0.000 trsock.py:15(__init__)\n",
      "       69    0.001    0.000    0.001    0.000 <frozen posixpath>:100(split)\n",
      "     2559    0.001    0.000    0.001    0.000 streams.py:486(_maybe_resume_transport)\n",
      "     2154    0.001    0.000    0.001    0.000 _models.py:525(elapsed)\n",
      "      690    0.001    0.000    0.001    0.000 __init__.py:1148(are_deterministic_algorithms_enabled)\n",
      "      248    0.001    0.000    0.001    0.000 mailbox.py:246(_time)\n",
      "     2518    0.001    0.000    0.001    0.000 episode.py:55(reward)\n",
      "      401    0.001    0.000    0.001    0.000 threading.py:299(__enter__)\n",
      "       64    0.001    0.000    0.001    0.000 sock_client.py:38(_get)\n",
      "      363    0.001    0.000    0.001    0.000 {built-in method _thread.allocate_lock}\n",
      "     2837    0.001    0.000    0.001    0.000 events.py:83(cancelled)\n",
      "      620    0.001    0.000    0.003    0.000 {method 'update' of 'set' objects}\n",
      "      128    0.001    0.000    0.003    0.000 tasks.py:618(_on_completion)\n",
      "     2154    0.001    0.000    0.001    0.000 request.py:333(full_url)\n",
      "     2057    0.001    0.000    0.001    0.000 _files.py:91(async_to_httpx_files)\n",
      "       49    0.001    0.000    0.058    0.001 sock_client.py:222(send_record_publish)\n",
      "     3296    0.001    0.000    0.001    0.000 _decoders.py:31(decode)\n",
      "     1638    0.001    0.000    0.001    0.000 _exceptions.py:102(request)\n",
      "       49    0.001    0.000    0.001    0.000 interface_shared.py:229(_make_record)\n",
      "    32/30    0.000    0.000    0.062    0.002 mailbox.py:447(_deliver_record)\n",
      "      128    0.000    0.000    0.001    0.000 timeouts.py:97(__aexit__)\n",
      "     2154    0.000    0.000    0.000    0.000 _decoders.py:34(flush)\n",
      "       64    0.000    0.000    0.002    0.000 threading.py:616(set)\n",
      "    32/30    0.000    0.000    0.066    0.002 mailbox.py:442(get_handle)\n",
      "       79    0.000    0.000    0.001    0.000 episode.py:94(__init__)\n",
      "     1024    0.000    0.000    0.001    0.000 completion_sampler.py:444(<lambda>)\n",
      "     2154    0.000    0.000    0.000    0.000 _models.py:540(request)\n",
      "    32/30    0.000    0.000    0.041    0.001 mailbox.py:433(_allocate_slot)\n",
      "     1366    0.000    0.000    0.000    0.000 episode.py:430(<genexpr>)\n",
      "     2154    0.000    0.000    0.000    0.000 default.py:252(__init__)\n",
      "      256    0.000    0.000    0.001    0.000 completion_sampler.py:458(get_model)\n",
      "       37    0.000    0.000    0.001    0.000 socket.py:244(__repr__)\n",
      "      363    0.000    0.000    0.001    0.000 threading.py:314(_is_owned)\n",
      "  260/131    0.000    0.000    0.010    0.000 builtins.py:193(enumerate)\n",
      "     2099    0.000    0.000    0.000    0.000 copy.py:102(_copy_immutable)\n",
      "       19    0.000    0.000    0.001    0.000 iostream.py:127(_event_pipe_gc)\n",
      "     2099    0.000    0.000    0.000    0.000 _base_client.py:1476(_prepare_request)\n",
      "      223    0.000    0.000    0.003    0.000 tasks.py:626(_wait_for_one)\n",
      "       78    0.000    0.000    0.001    0.000 _weakrefset.py:63(__iter__)\n",
      "     1750    0.000    0.000    0.000    0.000 {method 'get_loop' of '_asyncio.Future' objects}\n",
      "     2154    0.000    0.000    0.000    0.000 _models.py:1201(__init__)\n",
      "      330    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "     1594    0.000    0.000    0.000    0.000 _asyncio.py:608(deadline)\n",
      "    32/30    0.000    0.000    0.040    0.001 mailbox.py:16(_generate_address)\n",
      "      129    0.000    0.000    0.009    0.000 itertools.py:195(cycle)\n",
      "       48    0.000    0.000    0.002    0.000 selector_events.py:807(__repr__)\n",
      "       49    0.000    0.000    0.000    0.000 interface_sock.py:45(_assign)\n",
      "       32    0.000    0.000    0.002    0.000 router.py:102(_handle_msg_rcv)\n",
      "      128    0.000    0.000    0.002    0.000 timeouts.py:50(reschedule)\n",
      "     2099    0.000    0.000    0.000    0.000 _base_client.py:624(_validate_headers)\n",
      "       17    0.000    0.000    0.199    0.012 interface_shared.py:435(_publish_keepalive)\n",
      "      128    0.000    0.000    0.001    0.000 timeouts.py:129(timeout)\n",
      "     2099    0.000    0.000    0.000    0.000 _base_client.py:1469(_prepare_options)\n",
      "     2099    0.000    0.000    0.000    0.000 _base_client.py:599(custom_auth)\n",
      "      840    0.000    0.000    0.000    0.000 {method 'appendleft' of 'collections.deque' objects}\n",
      "      128    0.000    0.000    0.002    0.000 timeouts.py:85(__aenter__)\n",
      "      2/1    0.000    0.000  195.153  195.153 {built-in method builtins.exec}\n",
      "      387    0.000    0.000    0.000    0.000 std.py:1428(<genexpr>)\n",
      "      299    0.000    0.000    0.000    0.000 threading.py:308(_release_save)\n",
      "       19    0.000    0.000    0.002    0.000 iostream.py:118(_run_event_pipe_gc)\n",
      "       27    0.000    0.000    0.000    0.000 {method 'unsqueeze' of 'torch._C.TensorBase' objects}\n",
      "     2154    0.000    0.000    0.000    0.000 parse.py:108(_noop)\n",
      "     2518    0.000    0.000    0.000    0.000 explore_result.py:272(<genexpr>)\n",
      "       49    0.000    0.000    0.000    0.000 {built-in method _struct.pack}\n",
      "     1817    0.000    0.000    0.000    0.000 _client.py:233(timeout)\n",
      "       13    0.000    0.000    0.067    0.005 interface.py:894(deliver_stop_status)\n",
      "       57    0.000    0.000    0.001    0.000 threading.py:1222(is_alive)\n",
      "      288    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
      "      256    0.000    0.000    0.002    0.000 queues.py:58(_wakeup_next)\n",
      "      257    0.000    0.000    0.000    0.000 trainer.py:114(get_sample_probability_power)\n",
      "       42    0.000    0.000    0.000    0.000 _base_client.py:687(_calculate_retry_timeout)\n",
      "       48    0.000    0.000    0.000    0.000 {built-in method _warnings.warn}\n",
      "      147    0.000    0.000    0.000    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}\n",
      "      130    0.000    0.000    0.010    0.000 itertools.py:337(islice)\n",
      "      128    0.000    0.000    0.000    0.000 queues.py:175(get_nowait)\n",
      "      768    0.000    0.000    0.000    0.000 episode.py:395(_split_points)\n",
      "       38    0.000    0.000    0.001    0.000 _weakrefset.py:37(__init__)\n",
      "       49    0.000    0.000    0.054    0.001 sock_client.py:156(send_server_request)\n",
      "    32/30    0.000    0.000    0.100    0.003 interface_shared.py:450(_deliver_record)\n",
      "       32    0.000    0.000    0.001    0.000 mailbox.py:110(__init__)\n",
      "      129    0.000    0.000    0.001    0.000 tasks.py:584(as_completed)\n",
      "      256    0.000    0.000    0.000    0.000 trainer.py:106(get_recovery_pattern)\n",
      "       32    0.000    0.000    0.001    0.000 mailbox.py:137(_deliver)\n",
      "       32    0.000    0.000    0.000    0.000 threading.py:277(__init__)\n",
      "       80    0.000    0.000    0.000    0.000 __init__.py:737(__delitem__)\n",
      "      206    0.000    0.000    0.003    0.000 2664537466.py:123(<genexpr>)\n",
      "      397    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "      690    0.000    0.000    0.000    0.000 {built-in method torch._C._get_deterministic_algorithms}\n",
      "      138    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "       68    0.000    0.000    0.001    0.000 <frozen genericpath>:39(isdir)\n",
      "      281    0.000    0.000    0.000    0.000 trainer.py:269(model)\n",
      "       32    0.000    0.000    0.000    0.000 {method 'ParseFromString' of 'google._upb._message.Message' objects}\n",
      "       19    0.000    0.000    0.062    0.003 interface_shared.py:499(_deliver_internal_messages)\n",
      "      768    0.000    0.000    0.000    0.000 episode.py:342(<genexpr>)\n",
      "       38    0.000    0.000    0.002    0.000 _monitor.py:47(get_instances)\n",
      "       64    0.000    0.000    0.001    0.000 threading.py:394(notify)\n",
      "       69    0.000    0.000    0.001    0.000 <frozen genericpath>:16(exists)\n",
      "      690    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "       49    0.000    0.000    0.000    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}\n",
      "       32    0.000    0.000    0.001    0.000 threading.py:588(__init__)\n",
      "      516    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
      "       84    0.000    0.000    0.002    0.000 _eventloop.py:80(sleep)\n",
      "       74    0.000    0.000    0.000    0.000 wandb_run.py:283(<lambda>)\n",
      "       38    0.000    0.000    0.001    0.000 _weakrefset.py:120(update)\n",
      "      2/1    0.000    0.000   25.148   25.148 nest_asyncio.py:86(run_until_complete)\n",
      "       77    0.000    0.000    0.000    0.000 _weakrefset.py:53(_commit_removals)\n",
      "        1    0.000    0.000    0.519    0.519 explore_result.py:45(completed)\n",
      "       64    0.000    0.000    0.001    0.000 threading.py:424(notify_all)\n",
      "       32    0.000    0.000    0.002    0.000 mailbox.py:426(deliver)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'execute' of 'sqlite3.Connection' objects}\n",
      "      384    0.000    0.000    0.000    0.000 episode.py:264(<genexpr>)\n",
      "       21    0.000    0.000    0.000    0.000 std.py:102(acquire)\n",
      "       32    0.000    0.000    0.001    0.000 sock_client.py:74(peek)\n",
      "       38    0.000    0.000    0.000    0.000 wandb_run.py:327(<lambda>)\n",
      "      690    0.000    0.000    0.000    0.000 _jit_internal.py:1130(is_scripting)\n",
      "      341    0.000    0.000    0.000    0.000 threading.py:601(is_set)\n",
      "       96    0.000    0.000    0.001    0.000 selector_events.py:42(_test_selector_event)\n",
      "      619    0.000    0.000    0.000    0.000 fromnumeric.py:2508(_cumsum_dispatcher)\n",
      "      463    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
      "      619    0.000    0.000    0.000    0.000 fromnumeric.py:1328(_searchsorted_dispatcher)\n",
      "       77    0.000    0.000    0.000    0.000 _weakrefset.py:27(__exit__)\n",
      "       33    0.000    0.000    0.000    0.000 threading.py:627(clear)\n",
      "      258    0.000    0.000    0.000    0.000 {method 'keys' of 'collections.OrderedDict' objects}\n",
      "      128    0.000    0.000    0.000    0.000 queues.py:53(_put)\n",
      "       13    0.000    0.000    0.058    0.004 interface_shared.py:485(_deliver_stop_status)\n",
      "       84    0.000    0.000    0.002    0.000 _asyncio.py:2290(sleep)\n",
      "       31    0.000    0.000    0.000    0.000 sock_client.py:77(put)\n",
      "       21    0.000    0.000    0.000    0.000 std.py:106(release)\n",
      "      256    0.000    0.000    0.000    0.000 completion_sampler.py:370(get_model)\n",
      "      128    0.000    0.000    0.000    0.000 timeouts.py:33(__init__)\n",
      "       69    0.000    0.000    0.000    0.000 {built-in method builtins.round}\n",
      "      128    0.000    0.000    0.000    0.000 episode.py:130(__hash__)\n",
      "       69    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
      "       49    0.000    0.000    0.000    0.000 interface_shared.py:64(_transport_mark_success)\n",
      "      255    0.000    0.000    0.000    0.000 std.py:1198(update)\n",
      "       32    0.000    0.000    0.001    0.000 mailbox.py:321(abandon)\n",
      "       13    0.000    0.000    0.000    0.000 wandb_run.py:295(_process_stop_status)\n",
      "       32    0.000    0.000    0.001    0.000 mailbox.py:145(_notify_abandon)\n",
      "      351    0.000    0.000    0.000    0.000 queues.py:95(empty)\n",
      "       78    0.000    0.000    0.000    0.000 <frozen posixpath>:41(_get_sep)\n",
      "       32    0.000    0.000    0.000    0.000 {built-in method _struct.unpack}\n",
      "      132    0.000    0.000    0.015    0.000 completion.py:234(max_depth)\n",
      "      141    0.000    0.000    0.015    0.000 explore_result.py:192(<genexpr>)\n",
      "      129    0.000    0.000    0.000    0.000 trainer.py:863(get_completion_sampler)\n",
      "       39    0.000    0.000    0.001    0.000 selector_events.py:882(_fatal_error)\n",
      "       20    0.000    0.000    0.000    0.000 std.py:760(get_lock)\n",
      "      128    0.000    0.000    0.000    0.000 queues.py:99(full)\n",
      "       38    0.000    0.000    0.001    0.000 _weakrefset.py:95(copy)\n",
      "       77    0.000    0.000    0.000    0.000 _weakrefset.py:21(__enter__)\n",
      "      128    0.000    0.000    0.000    0.000 queues.py:50(_get)\n",
      "      128    0.000    0.000    0.000    0.000 trainer.py:117(num_samples)\n",
      "       57    0.000    0.000    0.000    0.000 threading.py:1155(_wait_for_tstate_lock)\n",
      "      258    0.000    0.000    0.000    0.000 sock_client.py:34(length)\n",
      "       32    0.000    0.000    0.000    0.000 mailbox.py:318(_release)\n",
      "       21    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "       78    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "       26    0.000    0.000    0.000    0.000 wandb_run.py:307(<lambda>)\n",
      "       49    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}\n",
      "       32    0.000    0.000    0.000    0.000 interface_shared.py:445(_get_mailbox)\n",
      "       32    0.000    0.000    0.000    0.000 sock_client.py:71(get)\n",
      "       77    0.000    0.000    0.000    0.000 _weakrefset.py:17(__init__)\n",
      "        9    0.000    0.000    0.000    0.000 <frozen posixpath>:71(join)\n",
      "       68    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISDIR}\n",
      "       32    0.000    0.000    0.000    0.000 mailbox.py:439(_release_slot)\n",
      "        3    0.000    0.000    0.436    0.145 shutil.py:642(_rmtree_safe_fd)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.rmdir}\n",
      "       21    0.000    0.000    0.000    0.000 std.py:110(__enter__)\n",
      "      138    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "       81    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "      129    0.000    0.000    0.000    0.000 std.py:1325(refresh)\n",
      "       49    0.000    0.000    0.000    0.000 tracelog.py:205(log_message_send)\n",
      "       42    0.000    0.000    0.000    0.000 {built-in method builtins.pow}\n",
      "        1    0.000    0.000    0.000    0.000 notebook.py:202(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:546(_asyncgen_finalizer_hook)\n",
      "        1    0.000    0.000    0.006    0.006 history.py:833(_writeout_input_cache)\n",
      "       21    0.000    0.000    0.000    0.000 std.py:113(__exit__)\n",
      "        2    0.000    0.000    0.000    0.000 selector_events.py:129(_read_from_self)\n",
      "      2/1    0.000    0.000   25.148   25.148 nest_asyncio.py:25(run)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:393(__get__)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3133(_bind)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:952(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.open}\n",
      "       64    0.000    0.000    0.000    0.000 mailbox.py:332(address)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:663(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.lstat}\n",
      "        2    0.000    0.000    0.000    0.000 futures.py:263(set_exception)\n",
      "       32    0.000    0.000    0.000    0.000 mailbox.py:231(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 nest_asyncio.py:141(manage_run)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:679(_get_free_pos)\n",
      "        2    0.000    0.000    0.000    0.000 selector_events.py:141(_write_to_self)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3631(set)\n",
      "        1    0.000    0.000    0.000    0.000 futures.py:347(_copy_future_state)\n",
      "        1    0.000    0.000    0.436    0.436 shutil.py:710(rmtree)\n",
      "        2    0.000    0.000    0.000    0.000 selector_events.py:1034(_read_ready__on_eof)\n",
      "        2    0.000    0.000    0.000    0.000 base_events.py:837(call_soon_threadsafe)\n",
      "        1    0.000    0.000    0.006    0.006 history.py:845(writeout_cache)\n",
      "       42    0.000    0.000    0.000    0.000 _base_client.py:653(_parse_retry_after_header)\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:1527(_notify_observers)\n",
      "       32    0.000    0.000    0.000    0.000 tracelog.py:209(log_message_recv)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:213(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 decorator.py:199(fix)\n",
      "        6    0.000    0.000    0.000    0.000 traitlets.py:676(__get__)\n",
      "       21    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:2013(set_debug)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3474(validate)\n",
      "        2    0.000    0.000    0.000    0.000 _asyncio.py:1135(eof_received)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.scandir}\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:718(_validate)\n",
      "        1    0.000    0.000    0.000    0.000 queues.py:33(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2949(apply_defaults)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3272(bind)\n",
      "        6    0.000    0.000    0.000    0.000 traitlets.py:629(get)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:152(wrapper_setattr)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:689(set)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:187(disable_on_exception)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3624(validate_elements)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2896(args)\n",
      "        1    0.000    0.000    0.006    0.006 decorator.py:229(fun)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:727(_cross_validate)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1153(_comparable)\n",
      "        1    0.000    0.000    0.006    0.006 history.py:55(only_when_enabled)\n",
      "        1    0.000    0.000    0.436    0.436 explore_result.py:38(__post_init__)\n",
      "        9    0.000    0.000    0.000    0.000 {method 'is_dir' of 'posix.DirEntry' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:393(done)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.fstat}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:1512(_notify_trait)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:708(__set__)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:2304(validate)\n",
      "        2    0.000    0.000    0.000    0.000 unix_events.py:81(_process_self_data)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C.TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _monitor.py:94(report)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1157(__hash__)\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:1523(notify_change)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2919(kwargs)\n",
      "        1    0.000    0.000    0.000    0.000 ioloop.py:742(_run_callback)\n",
      "        1    0.000    0.000    0.000    0.000 history.py:839(_writeout_output_cache)\n",
      "        3    0.000    0.000    0.000    0.000 builtins.py:87(iter)\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:428(result)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3486(validate_elements)\n",
      "        1    0.000    0.000    0.000    0.000 futures.py:383(_set_state)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'send' of 'async_generator_athrow' objects}\n",
      "        1    0.000    0.000    0.000    0.000 explore_result.py:36(<lambda>)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _asyncio._set_running_loop}\n",
      "        1    0.000    0.000    0.000    0.000 queues.py:47(_init)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
      "        1    0.000    0.000    0.000    0.000 futures.py:389(_call_check_cancel)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen genericpath>:99(samestat)\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:463(exception)\n",
      "       10    0.000    0.000    0.000    0.000 inspect.py:2808(kind)\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:383(cancelled)\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:1995(_set_coroutine_origin_tracking)\n",
      "        4    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _weakrefset.py:110(remove)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:125(__eq__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:156(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _weakrefset.py:115(discard)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:3089(parameters)\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:729(is_running)\n",
      "        1    0.000    0.000    0.000    0.000 notebook.py:272(close)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:2796(name)\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of 'posix.ScandirIterator' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method sys.audit}\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2888(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:398(__get_result)\n",
      "        1    0.000    0.000    0.000    0.000 kernelbase.py:570(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}"
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "asyncio.run(trainer.explore(verbosity=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         116214773 function calls (112534129 primitive calls) in 191.121 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      " 2599/193   21.598    0.008   30.502    0.158 {method 'recv' of '_socket.socket' objects}\n",
      " 3062/187   18.748    0.006    0.927    0.005 {method 'poll' of 'select.epoll' objects}\n",
      "       64   15.820    0.247   19.118    0.299 pack.py:307(get_mask)\n",
      "       64   14.367    0.224   24.403    0.381 explore_result.py:181(_write_mask)\n",
      "   1301/3   11.786    0.009    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "  296/290    6.913    0.023   25.460    0.088 threading.py:323(wait)\n",
      "3063/3033    4.451    0.001   18.395    0.006 selectors.py:451(select)\n",
      "23950591/23526667    4.271    0.000    5.438    0.000 {built-in method builtins.isinstance}\n",
      "      193    4.220    0.022   37.024    0.192 sock_client.py:242(_read_packet_bytes)\n",
      "       65    4.177    0.064    4.177    0.064 {method 'any' of 'torch._C.TensorBase' objects}\n",
      "  3942520    3.674    0.000    5.628    0.000 utils.py:54(get_token)\n",
      "  4592568    2.998    0.000    4.693    0.000 typing.py:2340(get_origin)\n",
      "    19334    2.780    0.000    2.780    0.000 {built-in method torch.tensor}\n",
      "    14176    2.502    0.000    3.960    0.000 {method 'validate_python' of 'pydantic_core._pydantic_core.SchemaValidator' objects}\n",
      "     2500    2.474    0.001    2.474    0.001 {method 'connect' of '_socket.socket' objects}\n",
      "     9379    2.436    0.000    7.903    0.001 connection_pool.py:230(_assign_requests_to_connections)\n",
      "1670852/351344    2.385    0.000   10.130    0.000 typing.py:407(_eval_type)\n",
      "650292/1972    2.037    0.000   30.393    0.015 _transform.py:288(_async_transform_recursive)\n",
      "     2114    1.879    0.001    1.897    0.001 decoder.py:344(raw_decode)\n",
      "     6324    1.792    0.000    3.161    0.000 completion.py:788(_split_weights)\n",
      "    66304    1.791    0.000   12.376    0.000 typing.py:2215(get_type_hints)\n",
      "      124    1.732    0.014   25.863    0.209 explore_result.py:87(_pack_episode)\n",
      "       64    1.544    0.024    1.544    0.024 {built-in method torch.tril}\n",
      "   351344    1.423    0.000    2.961    0.000 typing.py:175(_type_check)\n",
      "  1324514    1.315    0.000    1.711    0.000 _model_construction.py:268(__instancecheck__)\n",
      "  4763706    1.310    0.000    1.310    0.000 {method 'startswith' of 'str' objects}\n",
      "  3951664    1.301    0.000    6.911    0.000 completion.py:896(<genexpr>)\n",
      "      640    1.256    0.002    1.256    0.002 {built-in method torch._C._nn.pad}\n",
      "     3730    1.243    0.000    1.243    0.000 {method 'encode_batch' of 'tokenizers.Tokenizer' objects}\n",
      "   351344    1.163    0.000    9.814    0.000 typing.py:916(_evaluate)\n",
      "   809112    1.037    0.000    1.037    0.000 completion.py:815(<lambda>)\n",
      "  4365985    1.029    0.000    1.029    0.000 {method 'decode' of 'bytes' objects}\n",
      "  3152453    0.913    0.000    1.371    0.000 connection.py:190(is_idle)\n",
      "1512556/771068    0.908    0.000    2.588    0.000 typing.py:430(<genexpr>)\n",
      "       64    0.860    0.013    0.860    0.013 {built-in method torch.ones_like}\n",
      "110879/110677    0.762    0.000    7.743    0.000 {method 'join' of 'str' objects}\n",
      "     2198    0.753    0.000    2.027    0.001 explore_result.py:225(_get_completion_tensors)\n",
      "      129    0.745    0.006    0.745    0.006 {built-in method torch.stack}\n",
      "772400/650292    0.640    0.000    2.953    0.000 _typing.py:40(strip_annotated_type)\n",
      "   768872    0.627    0.000    0.989    0.000 utils.py:60(get_token_id)\n",
      "   632856    0.598    0.000    0.967    0.000 typing.py:2370(get_args)\n",
      "  1422052    0.567    0.000    2.053    0.000 _typing.py:29(is_required_type)\n",
      "   650292    0.547    0.000    0.996    0.000 typing.py:448(is_typeddict)\n",
      "   649652    0.534    0.000    2.617    0.000 _transform.py:111(_get_annotated_type)\n",
      "66304/3944    0.522    0.000   30.293    0.008 _transform.py:379(_async_transform_typeddict)\n",
      "  1345128    0.510    0.000    1.835    0.000 _typing.py:11(is_annotated_type)\n",
      "  1248265    0.480    0.000    1.433    0.000 http11.py:281(has_expired)\n",
      "  1400387    0.464    0.000    0.688    0.000 connection.py:195(is_closed)\n",
      "   187433    0.459    0.000    4.152    0.000 completion.py:536(tokens_and_mask)\n",
      "  2872413    0.457    0.000    0.457    0.000 http11.py:295(is_idle)\n",
      "   530666    0.456    0.000    1.143    0.000 typing.py:392(inner)\n",
      "  1398448    0.431    0.000    1.864    0.000 connection.py:185(has_expired)\n",
      "   817594    0.422    0.000    0.506    0.000 _models.py:173(__eq__)\n",
      "  1451150    0.403    0.000    0.403    0.000 {method 'get' of 'dict' objects}\n",
      "  209/177    0.387    0.002  118.655    0.670 mailbox.py:128(_get_and_clear)\n",
      "53723/53722    0.387    0.000   99.074    0.002 tasks.py:291(__step)\n",
      "  1109024    0.381    0.000    0.619    0.000 typing.py:1592(__eq__)\n",
      "   580044    0.373    0.000    1.082    0.000 _typing.py:25(is_union_type)\n",
      "  1358212    0.364    0.000    0.594    0.000 typing.py:1279(__eq__)\n",
      "   961732    0.363    0.000    0.634    0.000 {built-in method builtins.getattr}\n",
      "   351344    0.339    0.000    1.926    0.000 {built-in method builtins.eval}\n",
      "   812278    0.311    0.000    0.811    0.000 connection.py:165(can_handle_request)\n",
      "   583988    0.302    0.000    0.879    0.000 _typing.py:19(is_iterable_type)\n",
      "3064/3063    0.295    0.000  179.357    0.059 nest_asyncio.py:100(_run_once)\n",
      "  1604170    0.295    0.000    0.337    0.000 {built-in method builtins.hasattr}\n",
      "   650292    0.282    0.000    0.428    0.000 utils.py:181(lenient_issubclass)\n",
      "  2268094    0.280    0.000    0.280    0.000 {built-in method builtins.id}\n",
      "        9    0.273    0.030    0.273    0.030 {built-in method posix.unlink}\n",
      "     2268    0.257    0.000    2.339    0.001 explore_result.py:214(<lambda>)\n",
      "   583988    0.251    0.000    0.857    0.000 _typing.py:15(is_list_type)\n",
      "  1236190    0.247    0.000    0.381    0.000 completion.py:848(__hash__)\n",
      "   806954    0.237    0.000    0.365    0.000 connection.py:173(is_available)\n",
      "6012/6007    0.235    0.000    0.235    0.000 {method 'send' of '_socket.socket' objects}\n",
      "    86024    0.235    0.000    0.406    0.000 typing.py:1636(__hash__)\n",
      "  1047536    0.227    0.000    0.227    0.000 {method 'append' of 'list' objects}\n",
      "  1250196    0.225    0.000    0.225    0.000 http11.py:298(is_closed)\n",
      "    46453    0.222    0.000    0.581    0.000 _asyncio.py:391(__enter__)\n",
      "43212/1972    0.216    0.000    5.925    0.003 _models.py:448(construct_type)\n",
      "  643/609    0.206    0.000    0.056    0.000 random.py:889(getrandbits)\n",
      "   592635    0.204    0.000    0.436    0.000 {built-in method builtins.issubclass}\n",
      "    36638    0.201    0.000    0.201    0.000 {method 'search' of 're.Pattern' objects}\n",
      "   211914    0.199    0.000    0.746    0.000 typing.py:1221(__instancecheck__)\n",
      "  1302188    0.195    0.000    0.195    0.000 {built-in method time.monotonic}\n",
      "   211914    0.193    0.000    0.546    0.000 typing.py:1492(__subclasscheck__)\n",
      "    56276    0.191    0.000    0.388    0.000 _models.py:212(__getitem__)\n",
      "    23738    0.190    0.000    0.570    0.000 _sockets.py:58(extra_attributes)\n",
      "  1655135    0.189    0.000    0.189    0.000 connection_pool.py:39(is_queued)\n",
      "50879/49746    0.184    0.000    0.734    0.000 {built-in method builtins.sum}\n",
      "    46568    0.184    0.000    0.422    0.000 _asyncio.py:422(__exit__)\n",
      "   763622    0.182    0.000    0.183    0.000 completion.py:458(logprobs)\n",
      "   613940    0.177    0.000    0.177    0.000 typing.py:213(_should_unflatten_callable_args)\n",
      "    53722    0.176    0.000   94.497    0.002 tasks.py:308(__step_run_and_handle_result)\n",
      "     6046    0.175    0.000    0.408    0.000 _headers.py:150(normalize_and_validate)\n",
      "144754/132282    0.170    0.000    0.295    0.000 typing.py:1600(__hash__)\n",
      "    17628    0.167    0.000    0.281    0.000 ipkernel.py:775(_clean_thread_parent_frames)\n",
      "     1972    0.166    0.000   12.975    0.007 _response.py:388(parse)\n",
      "     7880    0.166    0.000    0.965    0.000 _urlparse.py:152(urlparse)\n",
      "    24447    0.166    0.000    3.724    0.000 http11.py:72(handle_async_request)\n",
      "   818698    0.165    0.000    0.165    0.000 {method 'extend' of 'list' objects}\n",
      "9324/1972    0.163    0.000    5.799    0.003 _models.py:203(construct)\n",
      "    94995    0.163    0.000    0.221    0.000 _impl.py:25(current_async_library)\n",
      "   776278    0.161    0.000    0.161    0.000 {method 'removeprefix' of 'str' objects}\n",
      "   114093    0.153    0.000    0.188    0.000 events.py:36(__init__)\n",
      "    88674    0.152    0.000    0.299    0.000 base_events.py:813(_call_soon)\n",
      "   623256    0.136    0.000    0.136    0.000 typing.py:251(is_union)\n",
      "   146264    0.134    0.000    0.835    0.000 {built-in method builtins.next}\n",
      "   351344    0.131    0.000    0.211    0.000 typing.py:166(_type_convert)\n",
      "    26857    0.130    0.000    0.356    0.000 main.py:858(__setattr__)\n",
      "98539/98508    0.130    0.000  160.898    0.002 events.py:86(_run)\n",
      "   185235    0.128    0.000    4.372    0.000 completion.py:604(token_count)\n",
      "   726185    0.128    0.000    0.128    0.000 http11.py:274(is_available)\n",
      "   233491    0.127    0.000    0.218    0.000 _models.py:94(encoding)\n",
      "   120317    0.124    0.000    0.124    0.000 {method 'fullmatch' of 're.Pattern' objects}\n",
      "    12447    0.124    0.000   34.226    0.003 2664537466.py:51(reward_completion)\n",
      "      193    0.123    0.001   38.927    0.202 sock_client.py:286(read_server_response)\n",
      "    20495    0.121    0.000   62.995    0.003 completion_sampler.py:141(sample_completions)\n",
      "98539/98508    0.121    0.000  147.848    0.002 {method 'run' of '_contextvars.Context' objects}\n",
      "   259606    0.119    0.000    0.119    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "        2    0.118    0.059    0.118    0.059 {built-in method torch.nanmean}\n",
      "    19905    0.117    0.000    0.325    0.000 _models.py:64(__init__)\n",
      "   360635    0.116    0.000    0.116    0.000 {method 'items' of 'dict' objects}\n",
      "    72503    0.115    0.000    0.138    0.000 contextlib.py:104(__init__)\n",
      "    81038    0.114    0.000    0.145    0.000 _model_construction.py:257(__getattr__)\n",
      "     8100    0.113    0.000    0.113    0.000 {built-in method torch.cat}\n",
      "    19170    0.108    0.000    0.419    0.000 _connection.py:260(_process_event)\n",
      "   279950    0.107    0.000    0.107    0.000 {method 'get' of 'mappingproxy' objects}\n",
      "    28051    0.107    0.000   12.190    0.000 connection_pool.py:159(handle_async_request)\n",
      "    21476    0.106    0.000    0.234    0.000 main.py:782(__copy__)\n",
      "   444184    0.104    0.000    0.104    0.000 typing.py:1626(<genexpr>)\n",
      "    15016    0.104    0.000    0.104    0.000 {built-in method torch.full_like}\n",
      "    18857    0.103    0.000    8.353    0.000 completion.py:888(message_param)\n",
      "    70248    0.101    0.000    0.175    0.000 typing.py:521(__getitem__)\n",
      "    26241    0.100    0.000    0.100    0.000 {method 'getpeername' of '_socket.socket' objects}\n",
      "    48249    0.097    0.000    0.142    0.000 __init__.py:280(_compile)\n",
      "   186113    0.097    0.000    0.156    0.000 _urlparse.py:212(<genexpr>)\n",
      "    88672    0.095    0.000    0.410    0.000 base_events.py:784(call_soon)\n",
      "   259606    0.095    0.000    0.214    0.000 <frozen abc>:121(__subclasscheck__)\n",
      "    66304    0.094    0.000   17.017    0.000 typing_extensions.py:1197(get_type_hints)\n",
      "   239096    0.094    0.000    1.048    0.000 _transform.py:126(_maybe_transform_key)\n",
      "   592400    0.094    0.000    0.094    0.000 completion.py:655(<genexpr>)\n",
      "   185235    0.093    0.000    0.093    0.000 {method 'size' of 'torch._C.TensorBase' objects}\n",
      "    72963    0.092    0.000    0.444    0.000 contextlib.py:141(__exit__)\n",
      "    28051    0.092    0.000   12.591    0.000 default.py:358(handle_async_request)\n",
      "    59879    0.085    0.000    0.087    0.000 _asyncio.py:376(__init__)\n",
      "     2032    0.085    0.000    0.085    0.000 encoder.py:205(iterencode)\n",
      "   145676    0.083    0.000    0.135    0.000 _utils.py:31(normalize_header_key)\n",
      "341479/296175    0.081    0.000    0.125    0.000 {built-in method builtins.hash}\n",
      "    26991    0.079    0.000    0.713    0.000 _tasks.py:95(fail_after)\n",
      "    72503    0.079    0.000    0.217    0.000 contextlib.py:299(helper)\n",
      "   179080    0.078    0.000    0.098    0.000 events.py:127(__lt__)\n",
      "   763622    0.078    0.000    0.078    0.000 completion.py:527(<genexpr>)\n",
      "   211945    0.078    0.000    0.083    0.000 {method 'add' of 'set' objects}\n",
      "   106581    0.077    0.000    0.213    0.000 _util.py:84(validate)\n",
      "    28051    0.073    0.000   13.270    0.000 _client.py:1762(_send_single_request)\n",
      "   110701    0.073    0.000    0.161    0.000 typing.py:1285(__hash__)\n",
      "    72503    0.072    0.000    0.651    0.000 contextlib.py:132(__enter__)\n",
      "    29941    0.071    0.000    0.199    0.000 futures.py:161(__schedule_callbacks)\n",
      "        2    0.070    0.035    0.154    0.077 explore_result.py:308(_normalize)\n",
      "20445/16927    0.070    0.000    0.199    0.000 _asyncio.py:536(_deliver_cancellation)\n",
      "    38552    0.070    0.000    0.070    0.000 {method 'match' of 're.Pattern' objects}\n",
      "       64    0.069    0.001    0.117    0.002 __init__.py:823(__add__)\n",
      "    31790    0.069    0.000    0.346    0.000 {built-in method builtins.any}\n",
      "    17099    0.069    0.000   56.691    0.003 completions.py:1620(create)\n",
      "    46850    0.067    0.000   91.269    0.002 {method 'send' of 'coroutine' objects}\n",
      "    30406    0.067    0.000    4.746    0.000 connection.py:67(handle_async_request)\n",
      "    73424    0.067    0.000    0.254    0.000 typing.py:113(get_origin)\n",
      "31071/6804    0.066    0.000    8.581    0.001 completion.py:421(all_message_params)\n",
      "   177992    0.066    0.000    0.263    0.000 explore_result.py:122(<genexpr>)\n",
      "    14289    0.065    0.000    1.357    0.000 http11.py:216(_receive_event)\n",
      "    61044    0.065    0.000    0.067    0.000 weakref.py:414(__getitem__)\n",
      "   111131    0.065    0.000    0.105    0.000 _urlparse.py:162(<genexpr>)\n",
      "199644/199642    0.065    0.000    0.065    0.000 {method 'encode' of 'str' objects}\n",
      "    24184    0.064    0.000    0.277    0.000 _asyncio.py:2285(cancel_shielded_checkpoint)\n",
      "   250051    0.064    0.000    0.064    0.000 {built-in method _asyncio.current_task}\n",
      "    29363    0.064    0.000    0.150    0.000 _asyncio.py:2294(create_cancel_scope)\n",
      "    10071    0.063    0.000    0.343    0.000 _asyncio.py:1190(receive)\n",
      "297349/287389    0.063    0.000    0.067    0.000 {built-in method builtins.len}\n",
      "    64428    0.063    0.000    0.110    0.000 copy.py:61(copy)\n",
      "    18857    0.062    0.000    0.124    0.000 main.py:826(__getattr__)\n",
      "    21127    0.062    0.000    0.093    0.000 _trace.py:10(__init__)\n",
      "   119623    0.061    0.000    0.061    0.000 {built-in method __new__ of type object at 0x7b7ec7eeb4c0}\n",
      "     3730    0.061    0.000    1.610    0.000 tokenizer.py:54(patch)\n",
      "     2547    0.061    0.000    0.061    0.000 {method 'shutdown' of '_socket.socket' objects}\n",
      "   159170    0.060    0.000    0.060    0.000 {method 'pop' of 'dict' objects}\n",
      "    21247    0.060    0.000    0.141    0.000 _utils.py:7(is_socket_readable)\n",
      "17699/17099    0.059    0.000   30.323    0.002 _base_client.py:1541(_request)\n",
      "     5959    0.059    0.000    0.592    0.000 http11.py:159(_send_request_body)\n",
      "    29374    0.059    0.000    0.388    0.000 _asyncio.py:1733(acquire)\n",
      "   133666    0.058    0.000    0.092    0.000 _models.py:27(enforce_bytes)\n",
      "    31071    0.058    0.000    8.435    0.000 completion.py:409(message_params)\n",
      "    28051    0.057    0.000   13.396    0.000 _client.py:1690(_send_handling_auth)\n",
      "    13851    0.056    0.000    1.091    0.000 _urls.py:77(__init__)\n",
      "     6871    0.056    0.000    0.743    0.000 {method 'throw' of 'coroutine' objects}\n",
      "    46568    0.056    0.000    0.086    0.000 weakref.py:451(get)\n",
      "   309030    0.056    0.000    0.056    0.000 {method 'isascii' of 'str' objects}\n",
      "    23738    0.054    0.000    0.662    0.000 _typedattr.py:58(extra)\n",
      "    17669    0.054    0.000    0.206    0.000 _urlparse.py:452(quote)\n",
      "     6054    0.054    0.000    0.115    0.000 _models.py:130(keys)\n",
      "    50063    0.054    0.000    0.347    0.000 _asyncio.py:528(_timeout)\n",
      "   198912    0.053    0.000    0.053    0.000 {built-in method builtins.vars}\n",
      "11832/5916    0.053    0.000    0.132    0.000 copy.py:118(deepcopy)\n",
      "     8168    0.053    0.000    0.209    0.000 _models.py:61(enforce_headers)\n",
      "    23738    0.052    0.000    0.855    0.000 anyio.py:84(get_extra_info)\n",
      "    18916    0.052    0.000    0.112    0.000 typing.py:146(_generic_get_args)\n",
      "     7497    0.052    0.000    0.683    0.000 _sockets.py:114(connect_tcp)\n",
      "    34161    0.052    0.000    0.086    0.000 _models.py:274(__contains__)\n",
      "    63170    0.051    0.000    0.181    0.000 _eventloop.py:154(get_async_backend)\n",
      "   182010    0.051    0.000    0.051    0.000 {method 'lower' of 'str' objects}\n",
      "    13000    0.051    0.000    4.140    0.000 type_adapter.py:132(wrapped)\n",
      "     1972    0.051    0.000    0.219    0.000 main.py:243(model_construct)\n",
      "   275635    0.051    0.000    0.051    0.000 {method 'isprintable' of 'str' objects}\n",
      "    15964    0.050    0.000    0.061    0.000 _models.py:287(origin)\n",
      "    86024    0.050    0.000    0.050    0.000 typing.py:1625(_value_and_type_iter)\n",
      "    17753    0.050    0.000    0.797    0.000 anyio.py:39(write)\n",
      "    19170    0.049    0.000    0.066    0.000 _state.py:318(_fire_state_triggered_transitions)\n",
      "    33392    0.049    0.000    0.068    0.000 ipaddress.py:1213(_parse_octet)\n",
      "     9157    0.048    0.000    0.048    0.000 {method 'register' of 'select.epoll' objects}\n",
      "    34469    0.048    0.000    0.077    0.000 futures.py:220(add_done_callback)\n",
      "    21717    0.048    0.000    0.103    0.000 selectors.py:69(__getitem__)\n",
      "     8438    0.047    0.000    0.137    0.000 tasks.py:111(__init__)\n",
      "   122341    0.047    0.000    0.047    0.000 {method 'groupdict' of 're.Match' objects}\n",
      "     2504    0.046    0.000    0.046    0.000 {method 'flush' of '_io.TextIOWrapper' objects}\n",
      "     3932    0.046    0.000    0.476    0.000 _events.py:82(__init__)\n",
      "   158107    0.046    0.000    0.046    0.000 {method 'lower' of 'bytes' objects}\n",
      "     3730    0.046    0.000    2.158    0.001 llm.py:463(chat)\n",
      "    16262    0.046    0.000    0.196    0.000 base_events.py:766(call_at)\n",
      "     3730    0.046    0.000    0.161    0.000 runtime.py:93(new_context)\n",
      "     2346    0.046    0.000    0.046    0.000 {method 'nonzero' of 'torch._C.TensorBase' objects}\n",
      "    43212    0.046    0.000    0.274    0.000 typing.py:166(get_args)\n",
      "    17919    0.045    0.000    0.047    0.000 {method 'join' of 'bytes' objects}\n",
      "    11922    0.045    0.000    0.335    0.000 _asyncio.py:1225(send)\n",
      "38842/31832    0.045    0.000    0.051    0.000 completion.py:115(value)\n",
      "    23334    0.045    0.000    0.122    0.000 locks.py:199(wait)\n",
      "     2609    0.045    0.000    0.045    0.000 {function socket.close at 0x7b7ec5b6dd00}\n",
      "     7460    0.044    0.000    0.049    0.000 __init__.py:1023(__iter__)\n",
      "    12715    0.044    0.000   27.224    0.002 completion_sampler.py:415(sample_completions)\n",
      "     3940    0.044    0.000    1.544    0.000 _client.py:320(build_request)\n",
      "    26002    0.044    0.000    0.055    0.000 _headers.py:205(get_comma_header)\n",
      "     3730    0.044    0.000    1.389    0.000 tokenization_utils_fast.py:488(_batch_encode_plus)\n",
      "    24893    0.044    0.000    0.046    0.000 {method 'format' of 'str' objects}\n",
      "    31457    0.044    0.000   15.435    0.000 _client.py:1639(send)\n",
      "     9100    0.044    0.000    0.107    0.000 {built-in method _heapq.heappop}\n",
      "     8670    0.043    0.000    1.898    0.000 _models.py:916(aiter_bytes)\n",
      "   300572    0.043    0.000    0.043    0.000 typing.py:2183(cast)\n",
      "     3730    0.043    0.000    1.475    0.000 tokenization_utils_fast.py:579(_encode_plus)\n",
      "    68723    0.043    0.000    0.104    0.000 _asyncio.py:1186(_raw_socket)\n",
      "    10071    0.043    0.000    0.733    0.000 anyio.py:23(read)\n",
      "   193908    0.042    0.000    0.042    0.000 threading.py:1198(ident)\n",
      "    27972    0.042    0.000    0.043    0.000 inspect.py:1832(_shadowed_dict)\n",
      "     8814    0.042    0.000    0.050    0.000 threading.py:1535(enumerate)\n",
      "    53238    0.041    0.000    0.041    0.000 {built-in method _abc._abc_instancecheck}\n",
      "     3730    0.041    0.000    0.323    0.000 tokenization_utils_base.py:1709(apply_chat_template)\n",
      "    25232    0.041    0.000    0.098    0.000 _connection.py:308(_get_io_object)\n",
      "     8027    0.041    0.000    0.068    0.000 completion.py:936(joined_assistant_message_params)\n",
      "    47184    0.041    0.000    0.059    0.000 tasks.py:653(sleep)\n",
      "   121043    0.041    0.000    0.511    0.000 _utils.py:152(is_mapping)\n",
      "    31239    0.040    0.000    0.127    0.000 socket.py:517(family)\n",
      "    21893    0.040    0.000   44.626    0.002 tasks.py:383(__wakeup)\n",
      "    23067    0.040    0.000    0.199    0.000 futures.py:251(set_result)\n",
      "     9272    0.040    0.000    0.040    0.000 {method 'unregister' of 'select.epoll' objects}\n",
      "    36249    0.039    0.000    0.097    0.000 socket.py:100(_intenum_converter)\n",
      "     2501    0.039    0.000    0.039    0.000 socket.py:221(__init__)\n",
      "    21248    0.038    0.000    0.038    0.000 {method 'poll' of 'select.poll' objects}\n",
      "    13426    0.038    0.000    0.224    0.000 _synchronization.py:197(__init__)\n",
      "        2    0.038    0.019    0.038    0.019 {built-in method torch.std}\n",
      "   129557    0.038    0.000    0.038    0.000 futures.py:181(done)\n",
      "    14972    0.038    0.000    0.072    0.000 _compat.py:92(field_get_default)\n",
      "    21717    0.038    0.000    0.165    0.000 selectors.py:180(get_key)\n",
      "    12356    0.038    0.000    0.520    0.000 _connection.py:426(next_event)\n",
      "    11792    0.038    0.000    0.382    0.000 _connection.py:518(send_with_data_passthrough)\n",
      "    21284    0.037    0.000    0.139    0.000 _connection.py:330(_respond_to_state_changes)\n",
      "    36253    0.037    0.000    0.057    0.000 enum.py:720(__call__)\n",
      "    22617    0.037    0.000    0.039    0.000 locks.py:166(__init__)\n",
      "     9324    0.037    0.000    0.139    0.000 inspect.py:1845(getattr_static)\n",
      "    22200    0.037    0.000    0.037    0.000 _models.py:123(raw)\n",
      "     3730    0.037    0.000    0.040    0.000 tokenization_utils_fast.py:282(_convert_encoding)\n",
      "    19170    0.037    0.000    0.122    0.000 _state.py:275(process_event)\n",
      "      226    0.037    0.000    1.328    0.006 trainer.py:435(explore)\n",
      "     7864    0.037    0.000    1.319    0.000 http11.py:147(_send_request_headers)\n",
      "    68723    0.037    0.000    0.061    0.000 transports.py:19(get_extra_info)\n",
      "     9157    0.037    0.000    0.063    0.000 selectors.py:234(register)\n",
      "    31110    0.036    0.000    0.054    0.000 _weakrefset.py:85(add)\n",
      "     3940    0.036    0.000    0.952    0.000 _models.py:311(__init__)\n",
      "   117711    0.036    0.000    0.036    0.000 {method 'append' of 'collections.deque' objects}\n",
      "    29374    0.036    0.000    0.497    0.000 _synchronization.py:69(__aenter__)\n",
      "     9324    0.036    0.000    0.188    0.000 typing_extensions.py:626(__instancecheck__)\n",
      "   107026    0.035    0.000    0.035    0.000 {method 'popleft' of 'collections.deque' objects}\n",
      "    23740    0.035    0.000    0.094    0.000 _synchronization.py:21(current_async_library)\n",
      "    24885    0.035    0.000    0.056    0.000 main.py:927(_check_frozen)\n",
      "     3940    0.035    0.000    0.274    0.000 _models.py:375(_prepare)\n",
      "     9324    0.035    0.000    0.038    0.000 inspect.py:1797(_check_instance)\n",
      "     2031    0.034    0.000    1.509    0.001 _base_client.py:446(_build_request)\n",
      "     6046    0.034    0.000    0.062    0.000 _receivebuffer.py:104(maybe_extract_lines)\n",
      "     2198    0.034    0.000    0.034    0.000 {method 'sum' of 'torch._C.TensorBase' objects}\n",
      "     8348    0.033    0.000    0.131    0.000 ipaddress.py:1187(_ip_int_from_string)\n",
      "    42659    0.033    0.000    0.049    0.000 futures.py:286(__await__)\n",
      "     8670    0.033    0.000    1.797    0.000 _models.py:971(aiter_raw)\n",
      "     3730    0.032    0.000    2.360    0.001 tokenizer.py:38(encode)\n",
      "    10052    0.032    0.000    0.408    0.000 connection_pool.py:301(_close_connections)\n",
      "    16262    0.032    0.000    0.081    0.000 events.py:111(__init__)\n",
      "    16377    0.032    0.000    0.059    0.000 events.py:155(cancel)\n",
      "    94995    0.032    0.000    0.032    0.000 {method 'get' of '_contextvars.ContextVar' objects}\n",
      "    17099    0.032    0.000   30.724    0.002 _base_client.py:1825(post)\n",
      "     4998    0.031    0.000    0.737    0.000 connection.py:103(_connect)\n",
      "     7200    0.031    0.000    0.092    0.000 tasks.py:522(_wait)\n",
      "    16262    0.031    0.000    0.066    0.000 {built-in method _heapq.heappush}\n",
      "    40120    0.031    0.000    0.041    0.000 futures.py:189(result)\n",
      "    25649    0.031    0.000    0.035    0.000 events.py:72(cancel)\n",
      "        2    0.031    0.016    0.043    0.021 ssl.py:1094(read)\n",
      "     9157    0.031    0.000    0.143    0.000 selectors.py:351(register)\n",
      "     4998    0.031    0.000    0.708    0.000 anyio.py:100(connect_tcp)\n",
      "     2114    0.031    0.000    0.361    0.000 _models.py:1183(__init__)\n",
      "     6098    0.030    0.000    0.260    0.000 _asyncio.py:698(__aexit__)\n",
      "    29710    0.030    0.000    0.038    0.000 futures.py:72(__init__)\n",
      "    17753    0.030    0.000    1.233    0.000 http11.py:170(_send_event)\n",
      "37564/11832    0.030    0.000    5.665    0.000 _models.py:382(_construct_field)\n",
      "    18677    0.030    0.000    0.051    0.000 base_events.py:446(create_future)\n",
      "    72838    0.030    0.000    0.044    0.000 _utils.py:47(normalize_header_value)\n",
      "     6658    0.030    0.000    0.208    0.000 selector_events.py:278(_add_reader)\n",
      "    46453    0.029    0.000    0.053    0.000 _asyncio.py:371(__new__)\n",
      "     9545    0.029    0.000    0.051    0.000 _urls.py:425(__init__)\n",
      "     3932    0.029    0.000    0.035    0.000 _writers.py:22(write_headers)\n",
      "    13000    0.029    0.000    4.359    0.000 _models.py:728(_validate_non_model_type)\n",
      "    78056    0.028    0.000    0.035    0.000 enum.py:202(__get__)\n",
      "    28051    0.028    0.000   13.304    0.000 _client.py:1724(_send_handling_redirects)\n",
      "    53722    0.028    0.000    0.028    0.000 {built-in method _asyncio._leave_task}\n",
      "   180242    0.028    0.000    0.028    0.000 base_events.py:2010(get_debug)\n",
      "     5959    0.028    0.000    0.258    0.000 selector_events.py:1055(write)\n",
      "    74792    0.028    0.000    0.028    0.000 {method 'remove' of 'set' objects}\n",
      "     4998    0.028    0.000    0.040    0.000 base_events.py:100(_ipaddr_info)\n",
      " 3135/836    0.027    0.000    0.134    0.000 completion.py:675(split)\n",
      "    29840    0.027    0.000    0.027    0.000 __init__.py:1009(__getitem__)\n",
      "    51116    0.027    0.000    0.040    0.000 base_events.py:733(time)\n",
      "    53722    0.027    0.000    0.027    0.000 {built-in method _asyncio._enter_task}\n",
      "     6046    0.027    0.000    0.225    0.000 _readers.py:94(maybe_read_from_SEND_RESPONSE_server)\n",
      "     9968    0.027    0.000    0.338    0.000 http11.py:245(_response_closed)\n",
      "     7460    0.027    0.000    0.080    0.000 tokenization_utils_base.py:220(__init__)\n",
      "     2499    0.027    0.000    0.122    0.000 _asyncio.py:749(_spawn)\n",
      "     6310    0.027    0.000    0.445    0.000 http11.py:337(__aiter__)\n",
      "     7497    0.026    0.000    3.111    0.000 _asyncio.py:2519(connect_tcp)\n",
      "    13804    0.026    0.000    0.080    0.000 _utils.py:298(strip_not_given)\n",
      "    30580    0.026    0.000    0.286    0.000 __init__.py:174(search)\n",
      "    31697    0.026    0.000    0.039    0.000 _weakrefset.py:39(_remove)\n",
      "     3730    0.026    0.000    1.516    0.000 tokenization_utils_base.py:3154(encode_plus)\n",
      "    11291    0.025    0.000   27.154    0.002 episode.py:66(follow_up)\n",
      "    53238    0.025    0.000    0.066    0.000 <frozen abc>:117(__instancecheck__)\n",
      "     6310    0.025    0.000    0.401    0.000 http11.py:205(_receive_response_body)\n",
      "    17669    0.025    0.000    0.122    0.000 __init__.py:219(finditer)\n",
      "    47731    0.025    0.000    0.025    0.000 {method 'keys' of 'dict' objects}\n",
      "93607/37125    0.025    0.000    0.025    0.000 completion.py:201(ancestors)\n",
      "    19907    0.024    0.000    0.067    0.000 locks.py:181(set)\n",
      "     7507    0.024    0.000    0.127    0.000 selector_events.py:294(_remove_reader)\n",
      "     4474    0.024    0.000    1.149    0.000 connection_pool.py:369(aclose)\n",
      "     4062    0.024    0.000    0.029    0.000 _models.py:232(__setitem__)\n",
      "    12356    0.024    0.000    0.315    0.000 _connection.py:398(_extract_next_receive_event)\n",
      "    17669    0.024    0.000    0.024    0.000 {method 'finditer' of 're.Pattern' objects}\n",
      "    17099    0.024    0.000   30.347    0.002 _base_client.py:1519(request)\n",
      "     8438    0.023    0.000    0.162    0.000 base_events.py:450(create_task)\n",
      "     1972    0.023    0.000   13.043    0.007 _base_client.py:1674(_process_response)\n",
      "    45933    0.023    0.000    0.039    0.000 <frozen _collections_abc>:1022(__iter__)\n",
      "    23740    0.023    0.000    0.036    0.000 <frozen importlib._bootstrap>:645(parent)\n",
      "     1972    0.023    0.000   12.763    0.006 _response.py:128(_parse)\n",
      "  296/290    0.023    0.000   28.744    0.099 threading.py:637(wait)\n",
      "   122532    0.023    0.000    0.023    0.000 base_events.py:538(_check_closed)\n",
      "     8991    0.023    0.000    0.090    0.000 {built-in method from_bytes}\n",
      "     9911    0.023    0.000    0.590    0.000 _urlparse.py:125(copy_with)\n",
      "     3940    0.023    0.000    0.195    0.000 _models.py:202(update)\n",
      "    68016    0.023    0.000    0.023    0.000 {built-in method _contextvars.copy_context}\n",
      "     6093    0.023    0.000    0.030    0.000 _base_client.py:2063(_merge_mappings)\n",
      "    95798    0.023    0.000    0.023    0.000 _util.py:127(bytesify)\n",
      "    59567    0.023    0.000    0.024    0.000 _exceptions.py:7(map_exceptions)\n",
      "     7200    0.023    0.000    0.132    0.000 tasks.py:435(wait)\n",
      "    14687    0.023    0.000    0.048    0.000 _asyncio.py:1774(release)\n",
      "     1972    0.023    0.000    0.033    0.000 _utils.py:241(wrapper)\n",
      "    13426    0.022    0.000    0.120    0.000 _tasks.py:28(__new__)\n",
      "     3840    0.022    0.000    0.042    0.000 tasks.py:767(_done_callback)\n",
      "     7492    0.022    0.000    1.960    0.000 _models.py:908(aread)\n",
      "    31470    0.022    0.000    0.022    0.000 {method 'split' of 'str' objects}\n",
      "     3730    0.022    0.000    0.066    0.000 chat_utils.py:390(_parse_chat_message_content_parts)\n",
      "     7497    0.022    0.000    0.038    0.000 selector_events.py:260(_ensure_fd_no_transport)\n",
      "     4998    0.022    0.000    2.792    0.001 base_events.py:976(_connect_sock)\n",
      "     7497    0.022    0.000    3.026    0.000 base_events.py:1019(create_connection)\n",
      "     2499    0.022    0.000    2.627    0.001 selector_events.py:656(_sock_connect)\n",
      "    61720    0.022    0.000    0.284    0.000 _utils.py:168(is_iterable)\n",
      "    40146    0.022    0.000    0.048    0.000 selectors.py:215(_fileobj_lookup)\n",
      "    21476    0.022    0.000    0.256    0.000 main.py:324(model_copy)\n",
      "     1672    0.021    0.000    0.123    0.000 tasks.py:731(gather)\n",
      "     5916    0.021    0.000    0.053    0.000 copy.py:247(_reconstruct)\n",
      "    13000    0.021    0.000    4.405    0.000 _models.py:677(validate_type)\n",
      "     9324    0.021    0.000    0.043    0.000 inspect.py:1806(_check_class)\n",
      "    16912    0.021    0.000    0.030    0.000 message.py:421(__setitem__)\n",
      "    11190    0.021    0.000    0.027    0.000 <template>:4(root)\n",
      "     4998    0.021    0.000    2.712    0.001 selector_events.py:631(sock_connect)\n",
      "    40146    0.021    0.000    0.027    0.000 selectors.py:21(_fileobj_to_fd)\n",
      "    14358    0.021    0.000   10.131    0.001 _client.py:1530(request)\n",
      "    23575    0.021    0.000    0.029    0.000 futures.py:301(_get_loop)\n",
      "     1972    0.020    0.000    0.320    0.000 _models.py:810(construct)\n",
      "     8730    0.020    0.000    0.025    0.000 mixins.py:12(_get_loop)\n",
      "        2    0.020    0.010    0.020    0.010 {built-in method torch.isnan}\n",
      "     8348    0.020    0.000    0.155    0.000 ipaddress.py:1286(__init__)\n",
      "     6044    0.020    0.000    0.021    0.000 _events.py:337(__init__)\n",
      "    15890    0.020    0.000    0.235    0.000 _models.py:170(get)\n",
      "     2114    0.020    0.000    0.124    0.000 request.py:315(__init__)\n",
      "    36253    0.020    0.000    0.020    0.000 enum.py:1123(__new__)\n",
      "    12450    0.020    0.000   10.174    0.001 2664537466.py:23(sample_random_episode)\n",
      "9090/4406    0.020    0.000    0.039    0.000 completion.py:630(sample_weight)\n",
      "    12223    0.020    0.000    0.033    0.000 default.py:69(map_httpcore_exceptions)\n",
      "    40924    0.019    0.000    0.019    0.000 {method 'copy' of 'dict' objects}\n",
      "    30212    0.019    0.000    0.121    0.000 typing.py:417(is_literal_type)\n",
      "     2031    0.019    0.000    0.220    0.000 _base_client.py:411(_build_headers)\n",
      "     4228    0.019    0.000    0.099    0.000 _models.py:1204(info)\n",
      "    15646    0.019    0.000    0.052    0.000 _asyncio.py:1705(__init__)\n",
      "     2499    0.019    0.000    0.064    0.000 selector_events.py:779(__init__)\n",
      "    23738    0.019    0.000    0.028    0.000 _sockets.py:636(convert_ipv6_sockaddr)\n",
      "     3944    0.019    0.000    0.059    0.000 completion_sampler.py:71(_wait)\n",
      "     3730    0.019    0.000    0.088    0.000 chat_utils.py:450(_parse_chat_message_content)\n",
      "     4228    0.019    0.000    0.047    0.000 _models.py:159(multi_items)\n",
      "    37123    0.019    0.000    0.019    0.000 _connection.py:205(our_state)\n",
      "    23102    0.018    0.000    0.018    0.000 _state.py:301(_fire_event_triggered_transitions)\n",
      "    22860    0.018    0.000    0.151    0.000 _utils.py:303(smart_deepcopy)\n",
      "     9272    0.018    0.000    0.079    0.000 selectors.py:365(unregister)\n",
      "     3160    0.018    0.000    0.018    0.000 _receivebuffer.py:53(__iadd__)\n",
      "13086/2416    0.018    0.000    0.029    0.000 completion.py:94(commit)\n",
      "     7467    0.018    0.000    0.041    0.000 <frozen _collections_abc>:974(update)\n",
      "22347/22176    0.018    0.000    0.035    0.000 {built-in method builtins.max}\n",
      "    13000    0.018    0.000    3.976    0.000 type_adapter.py:341(validate_python)\n",
      "    23738    0.017    0.000    0.113    0.000 trsock.py:76(getpeername)\n",
      "     4474    0.017    0.000    1.197    0.000 _client.py:153(aclose)\n",
      "    17817    0.017    0.000    0.036    0.000 _asyncio.py:2254(current_time)\n",
      "    15368    0.017    0.000    0.021    0.000 completion.py:829(<genexpr>)\n",
      "     7979    0.017    0.000    1.018    0.000 http11.py:179(_receive_response_headers)\n",
      "     5916    0.017    0.000    0.072    0.000 completion_sampler.py:63(_wait_if_needed)\n",
      "    12092    0.017    0.000    0.031    0.000 _asyncio.py:2266(checkpoint_if_cancelled)\n",
      "     4062    0.017    0.000    0.023    0.000 _models.py:256(__delitem__)\n",
      "     6046    0.016    0.000    0.041    0.000 _connection.py:81(_body_framing)\n",
      "    15076    0.016    0.000    0.064    0.000 completion.py:148(advantage)\n",
      "    32262    0.016    0.000    0.031    0.000 request.py:397(add_header)\n",
      "      193    0.016    0.000   77.203    0.400 router_sock.py:25(_read_message)\n",
      "    11792    0.016    0.000    0.405    0.000 _connection.py:491(send)\n",
      "     3730    0.016    0.000    0.040    0.000 runtime.py:165(__init__)\n",
      "    13426    0.016    0.000    0.126    0.000 _synchronization.py:209(__enter__)\n",
      "     2136    0.016    0.000    0.233    0.000 episode.py:417(_sample_completions)\n",
      "     6054    0.016    0.000    0.052    0.000 _utils.py:292(_get_time)\n",
      "     3730    0.016    0.000    0.123    0.000 chat_utils.py:502(parse_chat_messages)\n",
      "    22671    0.016    0.000    0.052    0.000 base_events.py:551(_asyncgen_firstiter_hook)\n",
      "      576    0.016    0.000    0.016    0.000 {built-in method torch.from_file}\n",
      "     3730    0.015    0.000    0.338    0.000 chat_utils.py:538(apply_hf_chat_template)\n",
      "     7080    0.015    0.000    0.015    0.000 _events.py:299(__init__)\n",
      "     6658    0.015    0.000    0.229    0.000 selector_events.py:925(_add_reader)\n",
      "     5264    0.015    0.000    0.015    0.000 _receivebuffer.py:67(_extract)\n",
      "    45933    0.015    0.000    0.015    0.000 _headers.py:117(__getitem__)\n",
      "     2499    0.015    0.000    0.107    0.000 selector_events.py:315(_add_writer)\n",
      "    12472    0.015    0.000    0.098    0.000 <string>:1(<module>)\n",
      "    22860    0.015    0.000    0.166    0.000 fields.py:552(get_default)\n",
      "     3730    0.015    0.000    0.015    0.000 chat_utils.py:122(__init__)\n",
      "     3944    0.015    0.000    0.113    0.000 completion_sampler.py:51(acquire)\n",
      "    14687    0.015    0.000    0.063    0.000 _synchronization.py:80(__aexit__)\n",
      "     6310    0.015    0.000    0.495    0.000 default.py:255(__aiter__)\n",
      "    32262    0.015    0.000    0.015    0.000 {method 'capitalize' of 'str' objects}\n",
      "    26857    0.014    0.000    0.025    0.000 _fields.py:328(is_valid_field_name)\n",
      "40467/7962    0.014    0.000    0.017    0.000 completion.py:228(depths)\n",
      "     6310    0.014    0.000    0.055    0.000 _readers.py:127(__call__)\n",
      "    14358    0.014    0.000   10.145    0.001 _client.py:1797(get)\n",
      "     3730    0.014    0.000    0.214    0.000 environment.py:1272(render)\n",
      "     2114    0.014    0.000    0.063    0.000 _events.py:137(__init__)\n",
      "     2198    0.014    0.000    0.014    0.000 {method 'clone' of 'torch._C.TensorBase' objects}\n",
      "     7497    0.014    0.000    3.190    0.000 _sockets.py:162(try_connect)\n",
      "     7880    0.014    0.000    0.123    0.000 _urlparse.py:303(encode_host)\n",
      "    50043    0.014    0.000    0.014    0.000 _connection.py:212(their_state)\n",
      "    14972    0.014    0.000    0.020    0.000 <frozen importlib._bootstrap>:1390(_handle_fromlist)\n",
      "     2124    0.014    0.000    0.022    0.000 parse.py:374(urlparse)\n",
      "     3730    0.014    0.000    0.014    0.000 chat_utils.py:246(__init__)\n",
      "    25866    0.014    0.000    0.014    0.000 {method 'rpartition' of 'str' objects}\n",
      "     6054    0.014    0.000    0.017    0.000 _urlparse.py:106(authority)\n",
      "     3652    0.014    0.000    0.029    0.000 streams.py:580(readuntil)\n",
      "    23738    0.014    0.000    0.111    0.000 trsock.py:18(family)\n",
      "    31698    0.014    0.000    0.014    0.000 {method 'discard' of 'set' objects}\n",
      "     6872    0.014    0.000    0.054    0.000 futures.py:146(cancel)\n",
      "     3966    0.014    0.000    0.086    0.000 tasks.py:670(ensure_future)\n",
      "     2499    0.014    0.000    0.139    0.000 selector_events.py:936(__init__)\n",
      "12988/4046    0.013    0.000    3.812    0.001 completion.py:607(all_token_count)\n",
      "      640    0.013    0.000    3.407    0.005 explore_result.py:330(_sequence_to_tensor)\n",
      "     7823    0.013    0.000    0.084    0.000 _synchronization.py:81(__new__)\n",
      "    50814    0.013    0.000    0.013    0.000 {method 'strip' of 'str' objects}\n",
      "    26000    0.013    0.000    0.013    0.000 type_adapter.py:259(_with_frame_depth)\n",
      "     2031    0.013    0.000    0.509    0.000 _base_client.py:430(_prepare_url)\n",
      "    10570    0.013    0.000    0.054    0.000 _readers.py:64(_decode_header_lines)\n",
      "     2416    0.013    0.000    3.457    0.001 episode.py:43(last_assistant_message)\n",
      "     5916    0.013    0.000    0.015    0.000 copy.py:231(_keep_alive)\n",
      "     5153    0.013    0.000    0.181    0.000 _asyncio.py:1250(aclose)\n",
      "     3730    0.013    0.000    0.056    0.000 tokenization_utils_base.py:1311(special_tokens_map)\n",
      "     4196    0.013    0.000    0.026    0.000 _receivebuffer.py:77(maybe_extract_at_most)\n",
      "19322/2540    0.013    0.000    0.013    0.000 completion.py:222(leaves)\n",
      "     7880    0.013    0.000    0.015    0.000 _urlparse.py:350(normalize_port)\n",
      "     5047    0.012    0.000    0.062    0.000 selector_events.py:331(_remove_writer)\n",
      "    23112    0.012    0.000    0.012    0.000 {method 'update' of 'dict' objects}\n",
      "      249    0.012    0.000    0.028    0.000 {built-in method _collections._count_elements}\n",
      "    12523    0.012    0.000    3.496    0.000 episode.py:345(<genexpr>)\n",
      "     8457    0.012    0.000    0.014    0.000 tasks.py:142(__del__)\n",
      "     4228    0.012    0.000    0.144    0.000 http11.py:351(aclose)\n",
      "     4990    0.012    0.000    0.073    0.000 _synchronization.py:58(setup)\n",
      "     2116    0.012    0.000    0.138    0.000 cookiejar.py:1680(extract_cookies)\n",
      "    58218    0.012    0.000    0.012    0.000 {built-in method _asyncio.get_running_loop}\n",
      "     4474    0.012    0.000    1.227    0.000 _models.py:999(aclose)\n",
      "     5324    0.012    0.000    0.118    0.000 _synchronization.py:116(setup)\n",
      "     3730    0.012    0.000    1.541    0.000 tokenization_utils_base.py:2750(encode)\n",
      "     7823    0.012    0.000    0.049    0.000 _asyncio.py:2326(create_event)\n",
      "     3730    0.012    0.000    0.014    0.000 tokenization_utils_base.py:2806(_get_padding_truncation_strategies)\n",
      "     6871    0.012    0.000    0.069    0.000 tasks.py:210(cancel)\n",
      "     3730    0.012    0.000    0.012    0.000 configuration_utils.py:202(__getattribute__)\n",
      "    21247    0.012    0.000    0.038    0.000 _sockets.py:67(<lambda>)\n",
      "     7508    0.012    0.000    0.017    0.000 _asyncio.py:362(is_anyio_cancellation)\n",
      "        2    0.012    0.006    0.012    0.006 {method 'read' of '_ssl._SSLSocket' objects}\n",
      "    46568    0.012    0.000    0.020    0.000 _asyncio.py:579(_restart_cancellation_in_parent)\n",
      "     1148    0.012    0.000    0.095    0.000 vllm.py:152(log_output)\n",
      "     6310    0.012    0.000    0.462    0.000 connection_pool.py:361(__aiter__)\n",
      "     3940    0.012    0.000    0.153    0.000 _models.py:326(__init__)\n",
      "     4111    0.012    0.000    0.013    0.000 futures.py:236(remove_done_callback)\n",
      "    21248    0.012    0.000    0.012    0.000 {method 'register' of 'select.poll' objects}\n",
      "    13426    0.011    0.000    0.082    0.000 _synchronization.py:216(__exit__)\n",
      "     4998    0.011    0.000    0.052    0.000 base_events.py:1452(_ensure_resolved)\n",
      "     3940    0.011    0.000    0.214    0.000 _client.py:404(_merge_headers)\n",
      "     4900    0.011    0.000    0.104    0.000 selector_events.py:851(pause_reading)\n",
      "    21476    0.011    0.000    0.011    0.000 {method 'copy' of 'set' objects}\n",
      "     7497    0.011    0.000    0.011    0.000 weakref.py:133(__getitem__)\n",
      "     2031    0.011    0.000    0.038    0.000 _client.py:376(default_headers)\n",
      "    13086    0.011    0.000    0.030    0.000 completion.py:237(absent_stop_tokens)\n",
      "     7995    0.011    0.000    0.018    0.000 _auth.py:87(async_auth_flow)\n",
      "     5638    0.011    0.000    0.011    0.000 completion.py:65(__init__)\n",
      "    21247    0.011    0.000    0.017    0.000 trsock.py:56(fileno)\n",
      "     2031    0.011    0.000    0.114    0.000 _content.py:176(encode_json)\n",
      "     4998    0.011    0.000    0.180    0.000 base_events.py:1166(_create_connection_transport)\n",
      "     3063    0.011    0.000    0.017    0.000 selector_events.py:750(_process_events)\n",
      "    27423    0.011    0.000    0.011    0.000 __init__.py:1790(isEnabledFor)\n",
      "    19991    0.011    0.000    0.026    0.000 coroutines.py:32(iscoroutine)\n",
      "    13607    0.011    0.000    0.020    0.000 _urlparse.py:437(percent_encoded)\n",
      "    14268    0.011    0.000    0.014    0.000 nest_asyncio.py:37(_get_event_loop)\n",
      "    13560    0.010    0.000    0.028    0.000 _asyncio.py:2262(checkpoint)\n",
      "     2499    0.010    0.000    0.028    0.000 _asyncio.py:1115(connection_made)\n",
      "     4596    0.010    0.000    0.114    0.000 tasks.py:412(create_task)\n",
      "     6310    0.010    0.000    0.510    0.000 _client.py:149(__aiter__)\n",
      "    46782    0.010    0.000    0.010    0.000 tasks.py:641(__sleep0)\n",
      "     2502    0.010    0.000    0.010    0.000 {method 'getsockname' of '_socket.socket' objects}\n",
      "    46577    0.010    0.000    0.010    0.000 tasks.py:252(cancelling)\n",
      "    15964    0.010    0.000    0.010    0.000 _models.py:168(__init__)\n",
      "     5916    0.010    0.000    0.010    0.000 {method '__reduce_ex__' of 'object' objects}\n",
      "    41401    0.010    0.000    0.010    0.000 completion.py:211(matches_model)\n",
      "     4990    0.010    0.000    0.019    0.000 _asyncio.py:2330(create_lock)\n",
      "     2491    0.010    0.000    0.020    0.000 _connection.py:155(__init__)\n",
      "     2548    0.010    0.000    0.083    0.000 selector_events.py:867(close)\n",
      "     2114    0.010    0.000    1.915    0.001 decoder.py:333(decode)\n",
      "     2480    0.010    0.000    0.114    0.000 episode.py:334(<lambda>)\n",
      "    14281    0.010    0.000    0.010    0.000 {method 'rstrip' of 'str' objects}\n",
      "     7764    0.010    0.000    0.102    0.000 {method 'throw' of 'generator' objects}\n",
      "        1    0.010    0.010    0.165    0.165 explore_result.py:270(_write_weights)\n",
      "     6872    0.010    0.000    0.010    0.000 futures.py:126(_make_cancelled_error)\n",
      "     6046    0.010    0.000    0.033    0.000 _connection.py:72(_keep_alive)\n",
      "    24832    0.010    0.000    0.014    0.000 inspect.py:302(isclass)\n",
      "    23923    0.009    0.000    0.009    0.000 {method 'group' of 're.Match' objects}\n",
      "     3940    0.009    0.000    0.032    0.000 _client.py:437(_build_request_auth)\n",
      "  209/177    0.009    0.000   39.675    0.224 mailbox.py:125(_wait)\n",
      "13086/2416    0.009    0.000    0.039    0.000 completion.py:244(all_absent_stop_tokens)\n",
      "    13319    0.009    0.000    0.010    0.000 _synchronization.py:100(__enter__)\n",
      "     3730    0.009    0.000    0.009    0.000 tokenization_utils_base.py:1056(bos_token)\n",
      "     3940    0.009    0.000    0.661    0.000 _urls.py:343(copy_with)\n",
      "     2114    0.009    0.000    0.508    0.000 _models.py:1035(extract_cookies)\n",
      "    28748    0.009    0.000    0.009    0.000 {method 'fileno' of '_socket.socket' objects}\n",
      "     2499    0.009    0.000    0.014    0.000 connection_pool.py:127(create_connection)\n",
      "     2491    0.009    0.000    0.030    0.000 http11.py:54(__init__)\n",
      "    10006    0.009    0.000    0.144    0.000 _asyncio.py:598(cancel)\n",
      "     6109    0.009    0.000    0.032    0.000 _asyncio.py:503(_uncancel)\n",
      "    40362    0.009    0.000    0.014    0.000 completion_sampler.py:403(__hash__)\n",
      "     9980    0.009    0.000    0.009    0.000 _asyncio.py:1728(__init__)\n",
      "     3932    0.009    0.000    0.045    0.000 _writers.py:36(write_request)\n",
      "15004/3844    0.009    0.000    0.010    0.000 completion.py:214(descendants)\n",
      "      965    0.009    0.000    3.510    0.004 {built-in method builtins.sorted}\n",
      "    30350    0.009    0.000    0.009    0.000 futures.py:91(__del__)\n",
      "    11636    0.009    0.000    0.009    0.000 {method 'remove' of 'collections.deque' objects}\n",
      "     2548    0.009    0.000    0.092    0.000 selector_events.py:1207(close)\n",
      "     4998    0.009    0.000    0.690    0.000 auto.py:21(connect_tcp)\n",
      "     7860    0.009    0.000    0.022    0.000 _writers.py:63(__call__)\n",
      "     8438    0.009    0.000    0.026    0.000 {built-in method _asyncio._register_task}\n",
      "     9272    0.009    0.000    0.021    0.000 selectors.py:247(unregister)\n",
      "     6667    0.009    0.000    0.009    0.000 {method 'remove' of 'list' objects}\n",
      "     2031    0.008    0.000    0.016    0.000 _base_client.py:607(default_headers)\n",
      "     1972    0.008    0.000    5.958    0.003 _base_client.py:571(_process_response_data)\n",
      "     8002    0.008    0.000    0.011    0.000 _urls.py:282(raw_path)\n",
      "    23069    0.008    0.000    0.009    0.000 futures.py:119(get_loop)\n",
      "     2116    0.008    0.000    0.059    0.000 cookiejar.py:1599(make_cookies)\n",
      "    21242    0.008    0.000    0.009    0.000 _trace.py:93(__aexit__)\n",
      "     4228    0.008    0.000    0.013    0.000 _decoders.py:238(flush)\n",
      "     3940    0.008    0.000    0.043    0.000 _models.py:402(read)\n",
      "     4990    0.008    0.000    0.038    0.000 _synchronization.py:140(__new__)\n",
      "    33692    0.008    0.000    0.038    0.000 <frozen _collections_abc>:868(__iter__)\n",
      "     4232    0.008    0.000    0.013    0.000 message.py:529(get_all)\n",
      "     2499    0.008    0.000    0.016    0.000 _asyncio.py:756(task_done)\n",
      "     3940    0.008    0.000    0.018    0.000 _models.py:255(__init__)\n",
      "     9995    0.008    0.000    0.010    0.000 parse.py:676(unquote)\n",
      "    20679    0.008    0.000    0.009    0.000 _exceptions.py:366(request_context)\n",
      "     1148    0.008    0.000    0.008    0.000 {built-in method posix.read}\n",
      "     2114    0.008    0.000    0.012    0.000 _models.py:180(get_list)\n",
      "    13876    0.008    0.000    0.014    0.000 completion.py:970(role)\n",
      "     2114    0.008    0.000    1.973    0.001 __init__.py:299(loads)\n",
      "     2499    0.008    0.000    0.031    0.000 base_events.py:192(_set_nodelay)\n",
      "    33392    0.008    0.000    0.008    0.000 {method 'isdigit' of 'str' objects}\n",
      "    11254    0.008    0.000    0.015    0.000 llm.py:181(get_tokenizer)\n",
      "     1972    0.008    0.000    0.020    0.000 typing_extensions.py:600(__subclasscheck__)\n",
      "     2114    0.008    0.000    0.021    0.000 _models.py:633(_get_content_decoder)\n",
      "    14096    0.008    0.000    0.012    0.000 completion.py:238(<genexpr>)\n",
      "    23068    0.008    0.000    0.011    0.000 completion.py:641(<genexpr>)\n",
      "     2499    0.008    0.000    0.011    0.000 _asyncio.py:335(get_callable_name)\n",
      "    10570    0.008    0.000    0.013    0.000 _readers.py:43(_obsolete_line_fold)\n",
      "    21699    0.008    0.000    0.008    0.000 {method 'values' of 'dict' objects}\n",
      "     3720    0.007    0.000    3.337    0.001 completion.py:647(max_splits)\n",
      "     3932    0.007    0.000    0.007    0.000 _receivebuffer.py:147(is_next_line_obviously_invalid_request_line)\n",
      "     3940    0.007    0.000    0.040    0.000 _client.py:413(_merge_queryparams)\n",
      "3693/1972    0.007    0.000    0.012    0.000 completion.py:471(estimated_completion_tokens)\n",
      "     3940    0.007    0.000    0.262    0.000 _client.py:371(_merge_url)\n",
      "     2499    0.007    0.000    0.014    0.000 weakref.py:164(__setitem__)\n",
      "     4159    0.007    0.000    0.162    0.000 selector_events.py:859(resume_reading)\n",
      "     3676    0.007    0.000    0.064    0.000 completion_sampler.py:384(_remove_prefix_and_unwanted_leading_tokens)\n",
      "    19184    0.007    0.000    0.012    0.000 _utils.py:164(is_list)\n",
      "    18648    0.007    0.000    0.010    0.000 typing.py:1630(__eq__)\n",
      "     7524    0.007    0.000    0.007    0.000 tokenization_utils_base.py:1101(pad_token)\n",
      "     7460    0.007    0.000    0.010    0.000 utils.py:881(is_list_of)\n",
      "    15876    0.007    0.000    0.013    0.000 explore_result.py:170(<lambda>)\n",
      "     8398    0.007    0.000    0.007    0.000 completion.py:828(_token_logprob_sequences)\n",
      "     5324    0.007    0.000    0.133    0.000 _synchronization.py:127(set)\n",
      "     1424    0.007    0.000    0.107    0.000 2664537466.py:91(on_sample)\n",
      "    16710    0.007    0.000    0.007    0.000 2664537466.py:58(<genexpr>)\n",
      "     4472    0.007    0.000    0.007    0.000 weakref.py:427(__setitem__)\n",
      "     2031    0.007    0.000    0.094    0.000 encoder.py:183(encode)\n",
      "    16377    0.007    0.000    0.007    0.000 base_events.py:1910(_timer_handle_cancelled)\n",
      "     9168    0.007    0.000    0.018    0.000 completion.py:838(<genexpr>)\n",
      "     3944    0.007    0.000    0.120    0.000 completion_sampler.py:97(__aenter__)\n",
      "     2114    0.007    0.000    0.034    0.000 request.py:297(request_host)\n",
      "     7880    0.007    0.000    0.012    0.000 _urlparse.py:377(validate_path)\n",
      "     2605    0.007    0.000    0.065    0.000 selector_events.py:908(_call_connection_lost)\n",
      "     3940    0.007    0.000    0.014    0.000 _urls.py:150(username)\n",
      "     4998    0.007    0.000    0.007    0.000 {method 'setblocking' of '_socket.socket' objects}\n",
      "       51    0.007    0.000    0.017    0.000 sock_client.py:123(_sendall_with_error_handle)\n",
      "    67/31    0.007    0.000    1.677    0.054 mailbox.py:249(wait)\n",
      "     4474    0.007    0.000    1.157    0.000 default.py:260(aclose)\n",
      "     7460    0.007    0.000    0.048    0.000 __init__.py:1120(__init__)\n",
      "     7823    0.007    0.000    0.011    0.000 _asyncio.py:1702(__new__)\n",
      "     4062    0.007    0.000    0.040    0.000 <frozen _collections_abc>:992(setdefault)\n",
      "     4228    0.007    0.000    0.090    0.000 _models.py:373(__init__)\n",
      "    11558    0.007    0.000    0.009    0.000 selector_events.py:848(is_reading)\n",
      "        1    0.007    0.007    0.007    0.007 {method 'do_handshake' of '_ssl._SSLSocket' objects}\n",
      "     1972    0.007    0.000    0.008    0.000 {built-in method _bisect.insort_right}\n",
      "     2268    0.007    0.000    0.007    0.000 {built-in method torch.full}\n",
      "     2114    0.007    0.000    0.007    0.000 _receivebuffer.py:64(__bytes__)\n",
      "    23653    0.007    0.000    0.007    0.000 selector_events.py:845(is_closing)\n",
      "     4678    0.007    0.000    0.034    0.000 completion.py:837(num_token_logprobs)\n",
      "     2198    0.006    0.000    0.036    0.000 completion.py:521(token_advantages)\n",
      "      372    0.006    0.000    3.707    0.010 trainer.py:514(_explore_episode)\n",
      "     2114    0.006    0.000    0.010    0.000 __init__.py:244(detect_encoding)\n",
      "     2499    0.006    0.000    0.036    0.000 _tasks.py:121(move_on_after)\n",
      "    14798    0.006    0.000    0.006    0.000 {method 'endswith' of 'bytearray' objects}\n",
      "    30580    0.006    0.000    0.006    0.000 enum.py:1286(value)\n",
      "     3940    0.006    0.000    0.008    0.000 _urlparse.py:116(netloc)\n",
      "    10301    0.006    0.000    0.026    0.000 completion.py:745(<genexpr>)\n",
      "     3730    0.006    0.000    0.006    0.000 tokenization_utils_fast.py:413(set_truncation_and_padding)\n",
      "    11832    0.006    0.000    0.023    0.000 copy.py:252(<genexpr>)\n",
      "    12227    0.006    0.000    0.006    0.000 {method 'split' of 'bytes' objects}\n",
      "     3730    0.006    0.000    0.021    0.000 chat_utils.py:270(__init__)\n",
      "    21248    0.006    0.000    0.006    0.000 {built-in method select.poll}\n",
      "     3940    0.006    0.000    0.024    0.000 _client.py:393(_merge_cookies)\n",
      "       64    0.006    0.000   24.527    0.383 explore_result.py:135(_write_sequence)\n",
      "     3940    0.006    0.000    0.017    0.000 _models.py:1162(__bool__)\n",
      "     2114    0.006    0.000    2.001    0.001 _models.py:765(json)\n",
      "    22999    0.006    0.000    0.006    0.000 {built-in method _asyncio._get_running_loop}\n",
      "     1972    0.006    0.000    0.008    0.000 _base_client.py:1891(make_request_options)\n",
      "     2499    0.006    0.000    0.026    0.000 _asyncio.py:693(__aenter__)\n",
      "    11254    0.006    0.000    0.007    0.000 llm_engine.py:594(get_tokenizer_group)\n",
      "     3945    0.006    0.000    0.007    0.000 cookiejar.py:1227(deepvalues)\n",
      "     2402    0.006    0.000    0.112    0.000 selector_events.py:1009(_read_ready__data_received)\n",
      "     7460    0.006    0.000    0.007    0.000 tokenization_utils_base.py:4076(_eventual_warn_about_too_long_sequence)\n",
      "     4062    0.006    0.000    0.045    0.000 <frozen _collections_abc>:940(pop)\n",
      "     2400    0.006    0.000    0.037    0.000 _asyncio.py:1130(data_received)\n",
      "     2500    0.006    0.000    0.006    0.000 {method 'setsockopt' of '_socket.socket' objects}\n",
      "     3818    0.006    0.000    0.032    0.000 _urls.py:582(merge)\n",
      "     7823    0.006    0.000    0.013    0.000 _asyncio.py:1708(set)\n",
      "     2114    0.006    0.000    0.037    0.000 request.py:339(full_url)\n",
      "     2114    0.006    0.000    0.024    0.000 request.py:370(_parse)\n",
      "     3844    0.006    0.000    3.354    0.001 episode.py:358(<genexpr>)\n",
      "     7711    0.006    0.000    0.015    0.000 tasks.py:460(<genexpr>)\n",
      "  643/609    0.006    0.000    0.005    0.000 {built-in method posix.urandom}\n",
      "     2499    0.006    0.000    0.154    0.000 selector_events.py:69(_make_socket_transport)\n",
      "     3794    0.006    0.000    0.006    0.000 {method 'token_to_id' of 'tokenizers.Tokenizer' objects}\n",
      "     4998    0.005    0.000    0.031    0.000 _asyncio.py:1714(wait)\n",
      "    10179    0.005    0.000    0.005    0.000 futures.py:205(exception)\n",
      "     5971    0.005    0.000    0.008    0.000 _urls.py:168(host)\n",
      "     2114    0.005    0.000    0.013    0.000 _urlparse.py:139(__str__)\n",
      "     3160    0.005    0.000    0.023    0.000 _connection.py:352(receive_data)\n",
      "     9324    0.005    0.000    0.005    0.000 _compat.py:109(get_model_config)\n",
      "     2605    0.005    0.000    0.149    0.000 selector_events.py:1190(_call_connection_lost)\n",
      "     2499    0.005    0.000    0.011    0.000 _asyncio.py:687(__init__)\n",
      "     2499    0.005    0.000    0.008    0.000 transports.py:270(__init__)\n",
      "    72675    0.005    0.000    0.005    0.000 __init__.py:609(__missing__)\n",
      "     5153    0.005    0.000    0.191    0.000 http11.py:261(aclose)\n",
      "     3940    0.005    0.000    0.119    0.000 _content.py:184(encode_request)\n",
      "     2499    0.005    0.000    0.007    0.000 selector_events.py:961(set_protocol)\n",
      "     2500    0.005    0.000    0.005    0.000 {method 'getsockopt' of '_socket.socket' objects}\n",
      "     1972    0.005    0.000   30.429    0.015 _transform.py:265(async_transform)\n",
      "15314/4240    0.005    0.000    0.005    0.000 completion.py:511(root)\n",
      "     4998    0.005    0.000    0.005    0.000 {built-in method _socket.inet_pton}\n",
      "        1    0.005    0.005    0.005    0.005 {built-in method _socket.getaddrinfo}\n",
      "     6314    0.005    0.000    0.006    0.000 {built-in method builtins.min}\n",
      "     3930    0.005    0.000    0.007    0.000 _writers.py:88(send_data)\n",
      "     5971    0.005    0.000    0.005    0.000 _urls.py:323(is_absolute_url)\n",
      "     2114    0.005    0.000    0.022    0.000 _connection.py:223(start_next_cycle)\n",
      "     2547    0.005    0.000    0.066    0.000 selector_events.py:1167(write_eof)\n",
      "     5153    0.005    0.000    0.186    0.000 anyio.py:54(aclose)\n",
      "      588    0.005    0.000    0.005    0.000 {method 'cumsum' of 'numpy.ndarray' objects}\n",
      "     1909    0.005    0.000    0.384    0.000 _urls.py:367(copy_merge_params)\n",
      "     2268    0.005    0.000    0.013    0.000 explore_result.py:302(<lambda>)\n",
      "     7378    0.005    0.000    0.005    0.000 _connection.py:248(_server_switch_event)\n",
      "     5916    0.005    0.000    0.007    0.000 copyreg.py:98(__newobj__)\n",
      "     9324    0.005    0.000    0.005    0.000 _compat.py:115(get_model_fields)\n",
      "     2114    0.005    0.000    0.005    0.000 _state.py:358(start_next_cycle)\n",
      "     7568    0.005    0.000    0.007    0.000 base_futures.py:13(isfuture)\n",
      "     2498    0.005    0.000    0.006    0.000 _asyncio.py:1179(__init__)\n",
      "     5002    0.005    0.000    0.015    0.000 socket.py:523(type)\n",
      "      496    0.005    0.000    3.681    0.007 episode.py:228(sample_completions_v2)\n",
      "     3794    0.005    0.000    0.023    0.000 tokenization_utils_base.py:1233(pad_token_id)\n",
      "    13878    0.005    0.000    0.007    0.000 _exceptions.py:82(iterate_exceptions)\n",
      "     1346    0.005    0.000    0.068    0.000 connection.py:168(aclose)\n",
      "      588    0.005    0.000    0.005    0.000 {built-in method numpy.asarray}\n",
      "      640    0.005    0.000    1.265    0.002 utils.py:175(truncate_pad)\n",
      "    14125    0.005    0.000    0.005    0.000 futures.py:175(cancelled)\n",
      "     3940    0.005    0.000    0.007    0.000 connection_pool.py:16(__init__)\n",
      "     2114    0.005    0.000    0.005    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "     2499    0.005    0.000    0.011    0.000 ipaddress.py:1249(_string_from_ip_int)\n",
      "     1424    0.005    0.000    0.005    0.000 completion_sampler.py:176(<genexpr>)\n",
      "     3794    0.005    0.000    0.036    0.000 tokenizer.py:28(get_pad_token_id)\n",
      "     2499    0.005    0.000    0.035    0.000 selector_events.py:683(_sock_connect_cb)\n",
      "    12222    0.005    0.000    0.005    0.000 {method 'strip' of 'bytes' objects}\n",
      "    21127    0.005    0.000    0.005    0.000 _trace.py:87(__aenter__)\n",
      "     2031    0.004    0.000    0.008    0.000 _base_client.py:551(_maybe_override_cast_to)\n",
      "     3652    0.004    0.000    0.034    0.000 streams.py:549(readline)\n",
      "     1384    0.004    0.000    0.005    0.000 connection_pool.py:27(clear_connection)\n",
      "     3730    0.004    0.000    0.025    0.000 chat_utils.py:226(create_parser)\n",
      "     8373    0.004    0.000    0.004    0.000 {method 'startswith' of 'bytes' objects}\n",
      "    10939    0.004    0.000    0.005    0.000 _synchronization.py:711(__enter__)\n",
      "     6109    0.004    0.000    0.008    0.000 _asyncio.py:495(_parent_cancellation_is_visible_to_us)\n",
      "     1672    0.004    0.000    0.005    0.000 tasks.py:710(__init__)\n",
      "     3730    0.004    0.000    0.005    0.000 tokenization_utils_base.py:1922(get_chat_template)\n",
      "      131    0.004    0.000    0.004    0.000 {built-in method posix.stat}\n",
      "     2114    0.004    0.000    0.041    0.000 _models.py:450(__init__)\n",
      "     3730    0.004    0.000    0.165    0.000 environment.py:1378(new_context)\n",
      "     3940    0.004    0.000    0.006    0.000 _client.py:1519(_transport_for_url)\n",
      "     3944    0.004    0.000    0.012    0.000 _typing.py:47(extract_type_arg)\n",
      "     9944    0.004    0.000    0.004    0.000 {method 'partition' of 'str' objects}\n",
      "     8868    0.004    0.000    0.006    0.000 base_events.py:1900(_add_callback)\n",
      "     2114    0.004    0.000    0.010    0.000 parse.py:1083(_splittype)\n",
      "     3732    0.004    0.000    0.005    0.000 <frozen _collections_abc>:819(keys)\n",
      "     2296    0.004    0.000    0.012    0.000 streams.py:521(_wait_for_data)\n",
      "     2604    0.004    0.000    3.472    0.001 episode.py:352(<genexpr>)\n",
      "     2499    0.004    0.000    0.005    0.000 connection.py:37(__init__)\n",
      "     3940    0.004    0.000    0.037    0.000 _utils.py:306(async_start)\n",
      "      124    0.004    0.000    3.650    0.029 episode.py:303(_get_sampleable_parents)\n",
      "     3940    0.004    0.000    0.008    0.000 _urls.py:159(password)\n",
      "     1148    0.004    0.000    0.018    0.000 streams.py:499(feed_data)\n",
      "     2502    0.004    0.000    0.007    0.000 _asyncio.py:348(_task_started)\n",
      " 2299/588    0.004    0.000    0.005    0.000 completion.py:497(num_prefix_tokens)\n",
      "     1909    0.004    0.000    0.009    0.000 _urlparse.py:485(urlencode)\n",
      "    21717    0.004    0.000    0.004    0.000 selectors.py:272(get_map)\n",
      "    11190    0.004    0.000    0.004    0.000 runtime.py:229(resolve_or_missing)\n",
      "    10339    0.004    0.000    0.005    0.000 _asyncio.py:481(_effectively_cancelled)\n",
      "     2097    0.004    0.000    0.022    0.000 {built-in method builtins.all}\n",
      "     2114    0.004    0.000    0.005    0.000 parse.py:1062(unwrap)\n",
      "     2114    0.004    0.000    0.023    0.000 _utils.py:313(async_elapsed)\n",
      "     2605    0.004    0.000    0.007    0.000 _asyncio.py:1122(connection_lost)\n",
      "    14920    0.004    0.000    0.004    0.000 __init__.py:1137(__setitem__)\n",
      "     3794    0.004    0.000    0.013    0.000 tokenization_utils_fast.py:329(convert_tokens_to_ids)\n",
      "     1941    0.004    0.000    0.007    0.000 _exceptions.py:112(__init__)\n",
      "     3930    0.004    0.000    0.006    0.000 _writers.py:94(send_eom)\n",
      "     7460    0.004    0.000    0.005    0.000 tokenization_utils_base.py:259(__getitem__)\n",
      "     5324    0.004    0.000    0.137    0.000 connection_pool.py:21(assign_to_connection)\n",
      "     9956    0.004    0.000    0.005    0.000 _receivebuffer.py:60(__len__)\n",
      "     8868    0.004    0.000    0.004    0.000 selectors.py:275(_key_from_fd)\n",
      "     8006    0.004    0.000    0.006    0.000 _utils.py:122(is_given)\n",
      "     1909    0.004    0.000    0.005    0.000 _urls.py:498(multi_items)\n",
      "     5316    0.004    0.000    0.010    0.000 http11.py:271(can_handle_request)\n",
      "     4998    0.004    0.000    0.004    0.000 transports.py:314(_set_write_buffer_limits)\n",
      "     2502    0.004    0.000    0.005    0.000 selector_events.py:922(get_write_buffer_size)\n",
      "       64    0.004    0.000    0.032    0.000 pack.py:43(packed_tensors_from_dir)\n",
      "     2402    0.004    0.000    0.116    0.000 selector_events.py:969(_read_ready)\n",
      "     2126    0.004    0.000    0.004    0.000 parse.py:119(_coerce_args)\n",
      "     1148    0.004    0.000    0.023    0.000 unix_events.py:523(_read_ready)\n",
      "     2416    0.004    0.000    3.087    0.001 episode.py:51(messages)\n",
      "     2031    0.004    0.000    0.032    0.000 _compat.py:121(model_copy)\n",
      "     3737    0.004    0.000    0.011    0.000 tasks.py:534(_on_completion)\n",
      "     2499    0.004    0.000    0.024    0.000 _tasks.py:151(create_task_group)\n",
      "     3940    0.004    0.000    0.013    0.000 _urls.py:233(netloc)\n",
      "     8414    0.004    0.000    0.004    0.000 _decoders.py:215(decode)\n",
      "     1909    0.004    0.000    0.006    0.000 parse.py:699(parse_qs)\n",
      "     5971    0.004    0.000    0.009    0.000 _urls.py:335(is_relative_url)\n",
      "     4596    0.003    0.000    0.006    0.000 tasks.py:70(_set_task_name)\n",
      "     3932    0.003    0.000    0.008    0.000 _headers.py:271(has_expect_100_continue)\n",
      "     8168    0.003    0.000    0.005    0.000 _models.py:93(enforce_stream)\n",
      "     2031    0.003    0.000    0.003    0.000 _base_client.py:647(platform_headers)\n",
      "     2114    0.003    0.000    0.003    0.000 {method 'split' of 'bytearray' objects}\n",
      "      588    0.003    0.000    0.014    0.000 fromnumeric.py:40(_wrapit)\n",
      "     4086    0.003    0.000    0.006    0.000 _models.py:553(reason_phrase)\n",
      "     1972    0.003    0.000    0.005    0.000 typing_extensions.py:530(_caller)\n",
      "     2114    0.003    0.000    0.017    0.000 _urls.py:390(__str__)\n",
      "     4978    0.003    0.000    0.010    0.000 _receivebuffer.py:57(__bool__)\n",
      "     2114    0.003    0.000    0.004    0.000 {method 'send' of 'generator' objects}\n",
      "     4228    0.003    0.000    0.003    0.000 _decoders.py:211(__init__)\n",
      "     7860    0.003    0.000    0.003    0.000 _content.py:38(__aiter__)\n",
      "     3940    0.003    0.000    0.005    0.000 _urls.py:134(raw_scheme)\n",
      "     1672    0.003    0.000    0.010    0.000 {method 'set_result' of '_asyncio.Future' objects}\n",
      "     3794    0.003    0.000    0.009    0.000 tokenization_utils_fast.py:348(_convert_token_to_id_with_added_voc)\n",
      "     1972    0.003    0.000   30.459    0.015 _transform.py:252(async_maybe_transform)\n",
      "     2499    0.003    0.000    0.012    0.000 transports.py:330(set_write_buffer_limits)\n",
      "     1972    0.003    0.000    0.004    0.000 completion_sampler.py:46(__call__)\n",
      "     3945    0.003    0.000    0.003    0.000 cookiejar.py:1753(__iter__)\n",
      "     2499    0.003    0.000    0.052    0.000 selector_events.py:369(remove_writer)\n",
      "     2499    0.003    0.000    0.055    0.000 selector_events.py:679(_sock_write_done)\n",
      "     2499    0.003    0.000    0.014    0.000 _asyncio.py:2322(create_task_group)\n",
      "     3730    0.003    0.000    0.003    0.000 chat_utils.py:256(mm_placeholder_counts)\n",
      "     3940    0.003    0.000    0.005    0.000 _models.py:48(enforce_url)\n",
      "     2499    0.003    0.000    0.056    0.000 ipaddress.py:28(ip_address)\n",
      "     4832    0.003    0.000    0.003    0.000 episode.py:45(<genexpr>)\n",
      "     1941    0.003    0.000    0.003    0.000 _exceptions.py:92(__init__)\n",
      "     2114    0.003    0.000    0.010    0.000 _connection.py:341(trailing_data)\n",
      "     3940    0.003    0.000    0.003    0.000 _config.py:256(as_dict)\n",
      "     2499    0.003    0.000    0.014    0.000 ipaddress.py:609(__str__)\n",
      "     2031    0.003    0.000    0.097    0.000 __init__.py:183(dumps)\n",
      "     2499    0.003    0.000    0.003    0.000 weakref.py:352(__init__)\n",
      "     7654    0.003    0.000    0.003    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "     4990    0.003    0.000    0.005    0.000 _asyncio.py:1725(__new__)\n",
      "  486/470    0.003    0.000    0.057    0.000 random.py:242(_randbelow_with_getrandbits)\n",
      "     2499    0.003    0.000    0.125    0.000 _asyncio.py:826(start_soon)\n",
      "     2700    0.003    0.000    0.023    0.000 futures.py:313(_set_result_unless_cancelled)\n",
      "     2114    0.003    0.000    0.003    0.000 _models.py:705(has_redirect_location)\n",
      "     1972    0.003    0.000    0.021    0.000 completion_sampler.py:100(__aexit__)\n",
      "     4472    0.003    0.000    0.003    0.000 _asyncio.py:655(__init__)\n",
      "     1909    0.003    0.000    0.017    0.000 _urls.py:623(__str__)\n",
      "     2114    0.003    0.000    0.006    0.000 parse.py:1104(_splithost)\n",
      "     3730    0.003    0.000    0.004    0.000 nodes.py:76(__init__)\n",
      "     1946    0.003    0.000    0.003    0.000 weakref.py:369(remove)\n",
      "     2609    0.003    0.000    0.051    0.000 socket.py:501(close)\n",
      "     3730    0.003    0.000    0.003    0.000 tokenization_utils_base.py:1067(eos_token)\n",
      "     1972    0.003    0.000    0.018    0.000 _response.py:378(request_id)\n",
      "    11054    0.003    0.000    0.003    0.000 _synchronization.py:717(__exit__)\n",
      "     8820    0.003    0.000    0.003    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "     2114    0.003    0.000    0.004    0.000 _models.py:665(is_success)\n",
      "    16912    0.003    0.000    0.003    0.000 _policybase.py:313(header_store_parse)\n",
      "     2609    0.003    0.000    0.047    0.000 socket.py:497(_real_close)\n",
      "      129    0.003    0.000    0.007    0.000 std.py:1402(set_postfix)\n",
      "     2031    0.003    0.000    0.003    0.000 _config.py:210(__init__)\n",
      "      640    0.003    0.000    1.260    0.002 functional.py:4478(pad)\n",
      "      576    0.003    0.000    0.003    0.000 {method 'view' of 'torch._C.TensorBase' objects}\n",
      "    12090    0.003    0.000    0.003    0.000 _headers.py:102(__init__)\n",
      "     7888    0.003    0.000    0.003    0.000 fields.py:572(is_required)\n",
      "     1909    0.003    0.000    0.013    0.000 _urls.py:274(params)\n",
      "     3730    0.003    0.000    0.003    0.000 tokenization_utils_base.py:1136(additional_special_tokens)\n",
      "     5324    0.003    0.000    0.003    0.000 _synchronization.py:113(__init__)\n",
      "     2499    0.003    0.000    0.016    0.000 ipaddress.py:394(compressed)\n",
      "     2416    0.003    0.000    0.032    0.000 episode.py:63(commit)\n",
      "     2499    0.003    0.000    0.003    0.000 weakref.py:410(__delitem__)\n",
      "     6870    0.003    0.000    0.003    0.000 tasks.py:260(uncancel)\n",
      "     1972    0.003    0.000    0.008    0.000 typing_extensions.py:542(_allow_reckless_class_checks)\n",
      "     2031    0.003    0.000    0.055    0.000 _base_client.py:568(_should_stream_response_body)\n",
      "     1176    0.002    0.000    0.018    0.000 fromnumeric.py:53(_wrapfunc)\n",
      "     4230    0.002    0.000    0.002    0.000 message.py:150(__init__)\n",
      "     9578    0.002    0.000    0.002    0.000 {built-in method builtins.iter}\n",
      "     1972    0.002    0.000    0.018    0.000 completion_sampler.py:59(release)\n",
      "     2031    0.002    0.000    0.002    0.000 _base_client.py:635(user_agent)\n",
      "     3940    0.002    0.000    0.004    0.000 _urls.py:195(raw_host)\n",
      "     2140    0.002    0.000    0.002    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
      "     2114    0.002    0.000    0.002    0.000 _headers.py:121(raw_items)\n",
      "     3940    0.002    0.000    0.004    0.000 _multipart.py:25(get_multipart_boundary_from_content_type)\n",
      "     2491    0.002    0.000    0.002    0.000 _state.py:250(__init__)\n",
      "     2509    0.002    0.000    0.002    0.000 {method 'find' of 'bytearray' objects}\n",
      "     1972    0.002    0.000    0.010    0.000 _models.py:693(add_request_id)\n",
      "      393    0.002    0.000    0.002    0.000 {method 'settimeout' of '_socket.socket' objects}\n",
      "     2480    0.002    0.000    0.054    0.000 completion.py:666(split_weight)\n",
      "    13492    0.002    0.000    0.002    0.000 _asyncio.py:626(cancelled_caught)\n",
      "     1148    0.002    0.000    0.008    0.000 base_subprocess.py:194(_call)\n",
      "      576    0.002    0.000    0.002    0.000 {method 'squeeze' of 'torch._C.TensorBase' objects}\n",
      "     3730    0.002    0.000    0.004    0.000 __init__.py:1032(__bool__)\n",
      "    13319    0.002    0.000    0.002    0.000 _synchronization.py:103(__exit__)\n",
      "     2031    0.002    0.000    0.011    0.000 _utils.py:384(get_async_library)\n",
      "     3940    0.002    0.000    0.002    0.000 _urls.py:612(__bool__)\n",
      "     7995    0.002    0.000    0.002    0.000 _auth.py:38(auth_flow)\n",
      "     2499    0.002    0.000    0.004    0.000 weakref.py:347(__new__)\n",
      "     3730    0.002    0.000    0.003    0.000 tokenization_utils_base.py:303(items)\n",
      "     1972    0.002    0.000    0.004    0.000 completions.py:1742(validate_response_format)\n",
      "     2499    0.002    0.000    0.003    0.000 base_events.py:202(_check_ssl_socket)\n",
      "     2502    0.002    0.000    0.002    0.000 inspect.py:1944(getcoroutinestate)\n",
      "     1148    0.002    0.000    0.010    0.000 base_subprocess.py:204(_pipe_data_received)\n",
      "     2499    0.002    0.000    0.002    0.000 tasks.py:167(set_name)\n",
      "    12935    0.002    0.000    0.002    0.000 _asyncio.py:630(shield)\n",
      "     1176    0.002    0.000    0.011    0.000 main.py:202(__init__)\n",
      "     2124    0.002    0.000    0.004    0.000 <string>:1(<lambda>)\n",
      "     4056    0.002    0.000    0.002    0.000 {method 'aclose' of 'async_generator' objects}\n",
      "     1972    0.002    0.000    0.004    0.000 _response.py:434(read)\n",
      "    12558    0.002    0.000    0.002    0.000 base_events.py:719(is_closed)\n",
      "     4228    0.002    0.000    0.002    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
      "     8386    0.002    0.000    0.002    0.000 {built-in method builtins.callable}\n",
      "     2092    0.002    0.000    0.003    0.000 __init__.py:1517(debug)\n",
      "     6871    0.002    0.000    0.002    0.000 futures.py:113(_log_traceback)\n",
      "     6054    0.002    0.000    0.002    0.000 _client.py:298(cookies)\n",
      "    16912    0.002    0.000    0.002    0.000 _policybase.py:209(header_max_count)\n",
      "     2054    0.002    0.000    0.002    0.000 {method 'pop' of 'list' objects}\n",
      "     5916    0.002    0.000    0.002    0.000 _utils.py:256(<genexpr>)\n",
      "     2173    0.002    0.000    0.003    0.000 __init__.py:1529(info)\n",
      "     5849    0.002    0.000    0.002    0.000 _urlparse.py:402(normalize_path)\n",
      "     2114    0.002    0.000    0.003    0.000 parse.py:1214(_splittag)\n",
      "     2114    0.002    0.000    0.006    0.000 _models.py:728(raise_for_status)\n",
      "     4232    0.002    0.000    0.002    0.000 {method 'groups' of 're.Match' objects}\n",
      "     2416    0.002    0.000    0.041    0.000 episode.py:39(all_absent_stop_tokens)\n",
      "       51    0.002    0.000    0.003    0.000 interface_shared.py:123(_make_request)\n",
      "     2499    0.002    0.000    0.006    0.000 transports.py:277(_maybe_pause_protocol)\n",
      "     2499    0.002    0.000    0.002    0.000 inspect.py:464(iscoroutine)\n",
      "      588    0.002    0.000    0.002    0.000 {method 'searchsorted' of 'numpy.ndarray' objects}\n",
      "     4228    0.002    0.000    0.002    0.000 <string>:2(__eq__)\n",
      "     1909    0.002    0.000    0.002    0.000 parse.py:741(parse_qsl)\n",
      "     1148    0.002    0.000    0.012    0.000 streams.py:474(_wakeup_waiter)\n",
      "     2499    0.002    0.000    0.002    0.000 _asyncio.py:634(shield)\n",
      "     4228    0.002    0.000    0.002    0.000 {method 'seek' of '_io.BytesIO' objects}\n",
      "     3930    0.002    0.000    0.002    0.000 _headers.py:105(__bool__)\n",
      "     2547    0.002    0.000    0.003    0.000 selector_events.py:835(abort)\n",
      "     2499    0.002    0.000    0.003    0.000 auto.py:9(_init_backend)\n",
      "     1148    0.002    0.000    0.020    0.000 subprocess.py:64(pipe_data_received)\n",
      "     2114    0.002    0.000    0.003    0.000 _models.py:544(http_version)\n",
      "     3730    0.002    0.000    0.002    0.000 chat_utils.py:487(_postprocess_messages)\n",
      "     2416    0.002    0.000    0.002    0.000 2664537466.py:101(<lambda>)\n",
      "     2031    0.002    0.000    0.002    0.000 _client.py:370(auth_headers)\n",
      "     7477    0.002    0.000    0.002    0.000 locks.py:177(is_set)\n",
      "3442/1176    0.002    0.000    0.009    0.000 completion.py:489(<genexpr>)\n",
      "     5324    0.002    0.000    0.002    0.000 connection_pool.py:31(wait_for_connection)\n",
      "     7460    0.002    0.000    0.002    0.000 sandbox.py:299(getitem)\n",
      "     2934    0.002    0.000    0.002    0.000 completion.py:563(<genexpr>)\n",
      "      192    0.002    0.000    0.002    0.000 {method 'unsqueeze' of 'torch._C.TensorBase' objects}\n",
      "     2499    0.002    0.000    0.002    0.000 _asyncio.py:1711(is_set)\n",
      "     4145    0.002    0.000    0.002    0.000 {method 'pop' of 'set' objects}\n",
      "     7880    0.002    0.000    0.002    0.000 _content.py:35(__iter__)\n",
      "     3730    0.002    0.000    0.002    0.000 tokenization_utils_base.py:1078(unk_token)\n",
      "      960    0.002    0.000    0.002    0.000 episode.py:281(<genexpr>)\n",
      "    11367    0.002    0.000    0.002    0.000 completion_sampler.py:53(<lambda>)\n",
      "     3946    0.002    0.000    0.002    0.000 {method 'upper' of 'str' objects}\n",
      "     2491    0.002    0.000    0.002    0.000 _receivebuffer.py:48(__init__)\n",
      "     3940    0.002    0.000    0.002    0.000 _client.py:564(_set_timeout)\n",
      "     4832    0.002    0.000    0.002    0.000 episode.py:59(reward)\n",
      "  486/470    0.002    0.000    0.070    0.000 random.py:341(choice)\n",
      "      379    0.001    0.000    0.031    0.000 __init__.py:595(__init__)\n",
      "     7460    0.001    0.000    0.002    0.000 tokenization_utils_base.py:698(convert_to_tensors)\n",
      "     3730    0.001    0.000    0.001    0.000 {method 'removesuffix' of 'str' objects}\n",
      "     1148    0.001    0.000    0.012    0.000 base_subprocess.py:284(data_received)\n",
      "     4228    0.001    0.000    0.001    0.000 {method 'end' of 're.Match' objects}\n",
      "     3730    0.001    0.000    0.001    0.000 tokenization_utils_base.py:1089(sep_token)\n",
      "     3940    0.001    0.000    0.001    0.000 _client.py:278(headers)\n",
      "  659/622    0.001    0.000    0.325    0.001 _base_client.py:1645(_retry_request)\n",
      "     7926    0.001    0.000    0.001    0.000 _asyncio.py:622(cancel_called)\n",
      "     2499    0.001    0.000    0.001    0.000 {method 'to_bytes' of 'int' objects}\n",
      "     6058    0.001    0.000    0.001    0.000 _models.py:529(request)\n",
      "     2031    0.001    0.000    0.001    0.000 {method 'lstrip' of 'bytes' objects}\n",
      "     2149    0.001    0.000    0.002    0.000 _models.py:791(get_max_retries)\n",
      "      258    0.001    0.000    0.002    0.000 std.py:419(format_num)\n",
      "     4990    0.001    0.000    0.001    0.000 _synchronization.py:55(__init__)\n",
      "    12399    0.001    0.000    0.001    0.000 episode.py:377(<lambda>)\n",
      "     3676    0.001    0.000    0.001    0.000 <string>:2(__init__)\n",
      "      129    0.001    0.000    4.211    0.033 explore_result.py:313(_sequences_to_tensor)\n",
      "     1972    0.001    0.000    0.001    0.000 {built-in method sys._getframe}\n",
      "     2514    0.001    0.000    0.001    0.000 {method 'write' of '_io.TextIOWrapper' objects}\n",
      "      124    0.001    0.000   28.884    0.233 explore_result.py:65(done_callback)\n",
      "     1972    0.001    0.000    0.001    0.000 _response.py:61(__init__)\n",
      "      248    0.001    0.000    0.001    0.000 notebook.py:260(update)\n",
      "     2114    0.001    0.000    0.001    0.000 {method 'span' of 're.Match' objects}\n",
      "     1149    0.001    0.000    0.001    0.000 {method 'extend' of 'bytearray' objects}\n",
      "     5916    0.001    0.000    0.001    0.000 copy.py:172(_deepcopy_atomic)\n",
      "     3840    0.001    0.000    0.001    0.000 {method 'done' of '_asyncio.Future' objects}\n",
      "     1909    0.001    0.000    0.001    0.000 _utils.py:56(primitive_value_to_str)\n",
      "      225    0.001    0.000    0.002    0.000 sock_client.py:227(_extract_packet_bytes)\n",
      "     2114    0.001    0.000    0.002    0.000 _models.py:569(content)\n",
      "     7888    0.001    0.000    0.001    0.000 _types.py:124(__bool__)\n",
      "     3730    0.001    0.000    0.001    0.000 tokenization_utils_base.py:1112(cls_token)\n",
      "     4228    0.001    0.000    0.001    0.000 {method 'truncate' of '_io.BytesIO' objects}\n",
      "     4996    0.001    0.000    0.001    0.000 _synchronization.py:707(__init__)\n",
      "     3940    0.001    0.000    0.001    0.000 _client.py:309(params)\n",
      "     3940    0.001    0.000    0.001    0.000 _urls.py:217(port)\n",
      "     3333    0.001    0.000    0.001    0.000 selector_events.py:877(__del__)\n",
      "       65    0.001    0.000    0.001    0.000 {built-in method posix.mkdir}\n",
      "      224    0.001    0.000    0.008    0.000 tasks.py:472(wait_for)\n",
      "     2114    0.001    0.000    0.001    0.000 request.py:356(data)\n",
      "     1672    0.001    0.000    0.001    0.000 {method 'add_done_callback' of '_asyncio.Future' objects}\n",
      "      588    0.001    0.000    0.017    0.000 fromnumeric.py:2512(cumsum)\n",
      "     4062    0.001    0.000    0.001    0.000 _base_client.py:639(base_url)\n",
      "     2268    0.001    0.000    0.002    0.000 explore_result.py:209(<lambda>)\n",
      "  403/386    0.001    0.000    0.071    0.000 mailbox.py:17(<genexpr>)\n",
      "     3730    0.001    0.000    0.001    0.000 tokenization_utils_base.py:1124(mask_token)\n",
      "     3736    0.001    0.000    0.001    0.000 <frozen _collections_abc>:845(__init__)\n",
      "     2604    0.001    0.000    0.003    0.000 selector_events.py:896(_force_close)\n",
      "     3730    0.001    0.000    0.001    0.000 chat_utils.py:223(all_mm_data)\n",
      "     2114    0.001    0.000    0.001    0.000 _status_codes.py:52(is_success)\n",
      "     2114    0.001    0.000    0.001    0.000 {method 'asend' of 'async_generator' objects}\n",
      "        2    0.001    0.000    0.001    0.001 utils.py:187(disable_on_exception)\n",
      "      128    0.001    0.000    0.007    0.000 explore_result.py:81(_update_pbar_postfix)\n",
      "     3940    0.001    0.000    0.001    0.000 _content.py:32(__init__)\n",
      "     1300    0.001    0.000    0.001    0.000 episode.py:430(<genexpr>)\n",
      "      970    0.001    0.000    0.001    0.000 {built-in method _weakref._remove_dead_weakref}\n",
      "      124    0.001    0.000    0.004    0.000 queues.py:137(put_nowait)\n",
      "     2140    0.001    0.000    0.001    0.000 {method 'release' of '_thread.RLock' objects}\n",
      "     2114    0.001    0.000    0.001    0.000 _events.py:247(__post_init__)\n",
      "     2031    0.001    0.000    0.001    0.000 _base_client.py:618(default_query)\n",
      "      970    0.001    0.000    0.002    0.000 weakref.py:105(remove)\n",
      "     3932    0.001    0.000    0.001    0.000 _writers.py:85(__init__)\n",
      "     1672    0.001    0.000    0.001    0.000 {method 'result' of '_asyncio.Future' objects}\n",
      "     2416    0.001    0.000    0.001    0.000 {method 'copy' of 'list' objects}\n",
      "      297    0.001    0.000    0.001    0.000 threading.py:311(_acquire_restore)\n",
      "     2499    0.001    0.000    0.001    0.000 transports.py:14(__init__)\n",
      "      210    0.001    0.000    0.054    0.000 interface_shared.py:517(_transport_keepalive_failed)\n",
      "      201    0.001    0.000    0.005    0.000 base_events.py:742(call_later)\n",
      "    51/50    0.001    0.000    0.019    0.000 sock_client.py:147(_send_message)\n",
      "      588    0.001    0.000    0.004    0.000 fromnumeric.py:1332(searchsorted)\n",
      "    51/50    0.001    0.000    0.051    0.001 sock_client.py:222(send_record_publish)\n",
      "     2114    0.001    0.000    0.001    0.000 http11.py:332(__init__)\n",
      "     2140    0.001    0.000    0.001    0.000 {built-in method time.time}\n",
      "     2114    0.001    0.000    0.001    0.000 connection_pool.py:350(__init__)\n",
      "      224    0.001    0.000    0.002    0.000 queues.py:149(get)\n",
      "     3730    0.001    0.000    0.001    0.000 tokenization_utils_base.py:310(encodings)\n",
      "     3730    0.001    0.000    0.001    0.000 llm_engine.py:922(get_model_config)\n",
      "     1972    0.001    0.000    0.001    0.000 completion_sampler.py:87(__init__)\n",
      "      252    0.001    0.000    0.016    0.000 trainer.py:537(<genexpr>)\n",
      "     2482    0.001    0.000    0.001    0.000 {built-in method builtins.abs}\n",
      "      379    0.001    0.000    0.029    0.000 __init__.py:669(update)\n",
      "      397    0.001    0.000    0.001    0.000 threading.py:302(__exit__)\n",
      "     1941    0.001    0.000    0.001    0.000 _exceptions.py:102(request)\n",
      "      129    0.001    0.000    0.005    0.000 2664537466.py:120(train_episodes)\n",
      "      124    0.001    0.000    0.005    0.000 tasks.py:618(_on_completion)\n",
      "     2502    0.001    0.000    0.001    0.000 tasks.py:158(get_coro)\n",
      "      588    0.001    0.000    0.001    0.000 {method 'rindex' of 'str' objects}\n",
      "     2524    0.001    0.000    0.001    0.000 locks.py:193(clear)\n",
      "     2475    0.001    0.000    0.001    0.000 {method 'random' of '_random.Random' objects}\n",
      "     2504    0.001    0.000    0.001    0.000 streams.py:486(_maybe_resume_transport)\n",
      "     2114    0.001    0.000    0.001    0.000 _client.py:142(__init__)\n",
      "     2499    0.001    0.000    0.001    0.000 selector_events.py:838(set_protocol)\n",
      "     2114    0.001    0.000    0.001    0.000 _readers.py:123(__init__)\n",
      "     2117    0.001    0.000    0.001    0.000 cookiejar.py:44(_debug)\n",
      "       65    0.001    0.000    0.007    0.000 <frozen os>:200(makedirs)\n",
      "     2491    0.001    0.000    0.001    0.000 anyio.py:20(__init__)\n",
      "       51    0.001    0.000    0.001    0.000 interface_shared.py:229(_make_record)\n",
      "     2031    0.001    0.000    0.001    0.000 _base_client.py:425(<genexpr>)\n",
      "      397    0.001    0.000    0.001    0.000 threading.py:299(__enter__)\n",
      "      246    0.001    0.000    0.001    0.000 mailbox.py:246(_time)\n",
      "     2499    0.001    0.000    0.001    0.000 trsock.py:15(__init__)\n",
      "     3150    0.001    0.000    0.001    0.000 _decoders.py:31(decode)\n",
      "     2114    0.001    0.000    0.001    0.000 request.py:333(full_url)\n",
      "      359    0.001    0.000    0.001    0.000 {built-in method _thread.allocate_lock}\n",
      "       65    0.001    0.000    0.001    0.000 <frozen posixpath>:100(split)\n",
      "     2114    0.001    0.000    0.001    0.000 _models.py:525(elapsed)\n",
      "       19    0.001    0.000    0.001    0.000 wandb_run.py:319(_process_internal_messages)\n",
      "  260/131    0.001    0.000    0.006    0.000 builtins.py:193(enumerate)\n",
      "     2499    0.000    0.000    0.000    0.000 events.py:83(cancelled)\n",
      "      124    0.000    0.000    0.001    0.000 timeouts.py:129(timeout)\n",
      "     2416    0.000    0.000    0.000    0.000 episode.py:55(reward)\n",
      "       62    0.000    0.000    0.001    0.000 sock_client.py:38(_get)\n",
      "      361    0.000    0.000    0.001    0.000 threading.py:314(_is_owned)\n",
      "      124    0.000    0.000    0.001    0.000 timeouts.py:97(__aexit__)\n",
      "      114    0.000    0.000    0.001    0.000 episode.py:94(__init__)\n",
      "    31/30    0.000    0.000    4.182    0.139 mailbox.py:433(_allocate_slot)\n",
      "     2114    0.000    0.000    0.000    0.000 default.py:252(__init__)\n",
      "     1880    0.000    0.000    0.000    0.000 _asyncio.py:608(deadline)\n",
      "      640    0.000    0.000    0.001    0.000 __init__.py:1148(are_deterministic_algorithms_enabled)\n",
      "      992    0.000    0.000    0.001    0.000 completion_sampler.py:444(<lambda>)\n",
      "     2114    0.000    0.000    0.000    0.000 _models.py:540(request)\n",
      "     2031    0.000    0.000    0.000    0.000 copy.py:102(_copy_immutable)\n",
      "    51/50    0.000    0.000    0.057    0.001 interface_sock.py:49(_publish)\n",
      "     2114    0.000    0.000    0.000    0.000 _decoders.py:34(flush)\n",
      "    31/30    0.000    0.000    4.149    0.138 mailbox.py:447(_deliver_record)\n",
      "      248    0.000    0.000    0.001    0.000 completion_sampler.py:458(get_model)\n",
      "       59    0.000    0.000    0.001    0.000 _base_client.py:687(_calculate_retry_timeout)\n",
      "      372    0.000    0.000    0.000    0.000 episode.py:264(<genexpr>)\n",
      "      129    0.000    0.000    0.005    0.000 itertools.py:195(cycle)\n",
      "     1972    0.000    0.000    0.000    0.000 _files.py:91(async_to_httpx_files)\n",
      "       78    0.000    0.000    0.001    0.000 _weakrefset.py:63(__iter__)\n",
      "      589    0.000    0.000    0.000    0.000 {method 'update' of 'set' objects}\n",
      "     1672    0.000    0.000    0.000    0.000 {method 'get_loop' of '_asyncio.Future' objects}\n",
      "      224    0.000    0.000    0.003    0.000 tasks.py:626(_wait_for_one)\n",
      "       51    0.000    0.000    0.000    0.000 interface_sock.py:45(_assign)\n",
      "      387    0.000    0.000    0.000    0.000 std.py:1428(<genexpr>)\n",
      "       62    0.000    0.000    0.001    0.000 threading.py:616(set)\n",
      "     2114    0.000    0.000    0.000    0.000 _models.py:1201(__init__)\n",
      "     2031    0.000    0.000    0.000    0.000 _base_client.py:1476(_prepare_request)\n",
      "      248    0.000    0.000    0.002    0.000 queues.py:58(_wakeup_next)\n",
      "       18    0.000    0.000    0.001    0.000 iostream.py:127(_event_pipe_gc)\n",
      "    51/50    0.000    0.000    0.020    0.000 sock_client.py:156(send_server_request)\n",
      "     1909    0.000    0.000    0.000    0.000 _client.py:233(timeout)\n",
      "     2031    0.000    0.000    0.000    0.000 _base_client.py:1469(_prepare_options)\n",
      "      249    0.000    0.000    0.000    0.000 trainer.py:114(get_sample_probability_power)\n",
      "      124    0.000    0.000    0.002    0.000 timeouts.py:50(reschedule)\n",
      "    31/30    0.000    0.000    4.201    0.140 mailbox.py:442(get_handle)\n",
      "     2031    0.000    0.000    0.000    0.000 _base_client.py:599(custom_auth)\n",
      "       51    0.000    0.000    0.000    0.000 {built-in method _struct.pack}\n",
      "     2031    0.000    0.000    0.000    0.000 _base_client.py:624(_validate_headers)\n",
      "    31/30    0.000    0.000    4.157    0.139 mailbox.py:16(_generate_address)\n",
      "      153    0.000    0.000    0.000    0.000 {method 'CopyFrom' of 'google._upb._message.Message' objects}\n",
      "      130    0.000    0.000    0.006    0.000 itertools.py:337(islice)\n",
      "      124    0.000    0.000    0.002    0.000 timeouts.py:85(__aenter__)\n",
      "      328    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "     2126    0.000    0.000    0.000    0.000 parse.py:108(_noop)\n",
      "       18    0.000    0.000    0.002    0.000 iostream.py:118(_run_event_pipe_gc)\n",
      "       31    0.000    0.000    0.002    0.000 router.py:102(_handle_msg_rcv)\n",
      "       20    0.000    0.000    0.042    0.002 interface.py:769(publish_keepalive)\n",
      "      760    0.000    0.000    0.000    0.000 {method 'appendleft' of 'collections.deque' objects}\n",
      "       19    0.000    0.000    4.195    0.221 interface.py:910(deliver_internal_messages)\n",
      "      297    0.000    0.000    0.000    0.000 threading.py:308(_release_save)\n",
      "      248    0.000    0.000    0.000    0.000 trainer.py:106(get_recovery_pattern)\n",
      "      744    0.000    0.000    0.000    0.000 episode.py:395(_split_points)\n",
      "      124    0.000    0.000    0.000    0.000 queues.py:175(get_nowait)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "      125    0.000    0.000    0.001    0.000 tasks.py:584(as_completed)\n",
      "      393    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "      238    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
      "       73    0.000    0.000    0.000    0.000 __init__.py:737(__delitem__)\n",
      "      118    0.000    0.000    0.003    0.000 _eventloop.py:80(sleep)\n",
      "      744    0.000    0.000    0.000    0.000 episode.py:342(<genexpr>)\n",
      "     2269    0.000    0.000    0.000    0.000 explore_result.py:272(<genexpr>)\n",
      "    31/30    0.000    0.000    4.179    0.139 interface_shared.py:450(_deliver_record)\n",
      "      2/1    0.000    0.000  168.010  168.010 {built-in method builtins.exec}\n",
      "       31    0.000    0.000    0.000    0.000 threading.py:277(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {method '__exit__' of 'sqlite3.Connection' objects}\n",
      "       51    0.000    0.000    0.000    0.000 {method 'ByteSize' of 'google._upb._message.Message' objects}\n",
      "       54    0.000    0.000    0.000    0.000 threading.py:1222(is_alive)\n",
      "      640    0.000    0.000    0.000    0.000 {built-in method torch._C._get_deterministic_algorithms}\n",
      "       64    0.000    0.000    0.001    0.000 threading.py:394(notify)\n",
      "       31    0.000    0.000    0.001    0.000 mailbox.py:137(_deliver)\n",
      "       57    0.000    0.000    0.002    0.000 selector_events.py:882(_fatal_error)\n",
      "      516    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
      "       31    0.000    0.000    0.000    0.000 {method 'ParseFromString' of 'google._upb._message.Message' objects}\n",
      "      134    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'execute' of 'sqlite3.Connection' objects}\n",
      "      235    0.000    0.000    0.019    0.000 explore_result.py:192(<genexpr>)\n",
      "       77    0.000    0.000    0.000    0.000 _weakrefset.py:53(_commit_removals)\n",
      "       38    0.000    0.000    0.001    0.000 _weakrefset.py:37(__init__)\n",
      "       64    0.000    0.000    0.003    0.000 <frozen genericpath>:39(isdir)\n",
      "       67    0.000    0.000    0.002    0.000 <frozen genericpath>:16(exists)\n",
      "       38    0.000    0.000    0.002    0.000 _monitor.py:47(get_instances)\n",
      "      124    0.000    0.000    0.000    0.000 queues.py:53(_put)\n",
      "      171    0.000    0.000    0.018    0.000 completion.py:234(max_depth)\n",
      "      640    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "       31    0.000    0.000    0.001    0.000 threading.py:588(__init__)\n",
      "      257    0.000    0.000    0.000    0.000 trainer.py:269(model)\n",
      "       20    0.000    0.000    0.039    0.002 interface_shared.py:435(_publish_keepalive)\n",
      "       31    0.000    0.000    0.001    0.000 mailbox.py:110(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:243(_optimize_charset)\n",
      "      118    0.000    0.000    0.002    0.000 _asyncio.py:2290(sleep)\n",
      "       21    0.000    0.000    0.000    0.000 std.py:102(acquire)\n",
      "       62    0.000    0.000    0.001    0.000 threading.py:424(notify_all)\n",
      "       12    0.000    0.000    4.122    0.343 interface.py:894(deliver_stop_status)\n",
      "       19    0.000    0.000    4.181    0.220 interface_shared.py:499(_deliver_internal_messages)\n",
      "       77    0.000    0.000    0.000    0.000 _weakrefset.py:27(__exit__)\n",
      "      486    0.000    0.000    0.000    0.000 {method 'bit_length' of 'int' objects}\n",
      "       72    0.000    0.000    0.000    0.000 wandb_run.py:283(<lambda>)\n",
      "       38    0.000    0.000    0.001    0.000 _weakrefset.py:120(update)\n",
      "       31    0.000    0.000    0.001    0.000 sock_client.py:74(peek)\n",
      "      335    0.000    0.000    0.000    0.000 threading.py:601(is_set)\n",
      "      248    0.000    0.000    0.000    0.000 std.py:1198(update)\n",
      "      588    0.000    0.000    0.000    0.000 fromnumeric.py:2508(_cumsum_dispatcher)\n",
      "      588    0.000    0.000    0.000    0.000 fromnumeric.py:1328(_searchsorted_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 ssl.py:1308(_real_close)\n",
      "      640    0.000    0.000    0.000    0.000 _jit_internal.py:1130(is_scripting)\n",
      "       77    0.000    0.000    0.000    0.000 <frozen posixpath>:41(_get_sep)\n",
      "      248    0.000    0.000    0.000    0.000 completion_sampler.py:370(get_model)\n",
      "       31    0.000    0.000    0.001    0.000 mailbox.py:426(deliver)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _io.open}\n",
      "       51    0.000    0.000    0.000    0.000 interface_shared.py:64(_transport_mark_success)\n",
      "      258    0.000    0.000    0.000    0.000 {method 'keys' of 'collections.OrderedDict' objects}\n",
      "       12    0.000    0.000    0.000    0.000 wandb_run.py:295(_process_stop_status)\n",
      "        3    0.000    0.000    0.000    0.000 socket.py:244(__repr__)\n",
      "      124    0.000    0.000    0.000    0.000 timeouts.py:33(__init__)\n",
      "       32    0.000    0.000    0.000    0.000 threading.py:627(clear)\n",
      "       54    0.000    0.000    0.000    0.000 threading.py:1155(_wait_for_tstate_lock)\n",
      "      125    0.000    0.000    0.000    0.000 trainer.py:863(get_completion_sampler)\n",
      "       77    0.000    0.000    0.000    0.000 _weakrefset.py:21(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 connection.py:331(putrequest)\n",
      "      348    0.000    0.000    0.000    0.000 queues.py:95(empty)\n",
      "        1    0.000    0.000    0.061    0.061 sessions.py:673(send)\n",
      "      124    0.000    0.000    0.000    0.000 episode.py:130(__hash__)\n",
      "       31    0.000    0.000    0.000    0.000 sock_client.py:77(put)\n",
      "       66    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
      "       31    0.000    0.000    0.001    0.000 mailbox.py:145(_notify_abandon)\n",
      "      124    0.000    0.000    0.000    0.000 queues.py:99(full)\n",
      "       31    0.000    0.000    0.000    0.000 {built-in method _struct.unpack}\n",
      "      256    0.000    0.000    0.000    0.000 sock_client.py:34(length)\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method builtins.round}\n",
      "       12    0.000    0.000    4.121    0.343 interface_shared.py:485(_deliver_stop_status)\n",
      "       38    0.000    0.000    0.000    0.000 wandb_run.py:327(<lambda>)\n",
      "       20    0.000    0.000    0.000    0.000 std.py:760(get_lock)\n",
      "        2    0.000    0.000    0.000    0.000 request.py:2520(getproxies_environment)\n",
      "        9    0.000    0.000    0.000    0.000 <frozen posixpath>:71(join)\n",
      "       31    0.000    0.000    0.001    0.000 mailbox.py:321(abandon)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'write' of '_ssl._SSLSocket' objects}\n",
      "        3    0.000    0.000    0.000    0.000 selector_events.py:807(__repr__)\n",
      "        1    0.000    0.000    0.014    0.014 connection.py:658(connect)\n",
      "       21    0.000    0.000    0.000    0.000 std.py:106(release)\n",
      "       38    0.000    0.000    0.001    0.000 _weakrefset.py:95(copy)\n",
      "        1    0.000    0.000    0.001    0.001 connection.py:365(request)\n",
      "      124    0.000    0.000    0.000    0.000 queues.py:50(_get)\n",
      "      124    0.000    0.000    0.000    0.000 trainer.py:117(num_samples)\n",
      "      2/1    0.000    0.000    0.000    0.000 _parser.py:512(_parse)\n",
      "      2/1    0.000    0.000    1.903    1.903 nest_asyncio.py:86(run_until_complete)\n",
      "       79    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "        1    0.000    0.000    0.001    0.001 usage_lib.py:215(_write_to_file)\n",
      "       51    0.000    0.000    0.000    0.000 {method 'SerializeToString' of 'google._upb._message.Message' objects}\n",
      "        1    0.000    0.000    0.006    0.006 history.py:833(_writeout_input_cache)\n",
      "       31    0.000    0.000    0.000    0.000 mailbox.py:318(_release)\n",
      "      122    0.000    0.000    0.000    0.000 <frozen os>:732(__iter__)\n",
      "        1    0.000    0.000    0.007    0.007 ssl.py:955(_create)\n",
      "        1    0.000    0.000    0.063    0.063 sessions.py:626(post)\n",
      "        1    0.000    0.000    0.060    0.060 adapters.py:613(send)\n",
      "       24    0.000    0.000    0.000    0.000 wandb_run.py:307(<lambda>)\n",
      "        2    0.000    0.000    0.000    0.000 url.py:369(parse_url)\n",
      "       31    0.000    0.000    0.000    0.000 interface_shared.py:445(_get_mailbox)\n",
      "       31    0.000    0.000    0.000    0.000 mailbox.py:439(_release_slot)\n",
      "        1    0.000    0.000    0.044    0.044 connection.py:481(getresponse)\n",
      "      124    0.000    0.000    0.000    0.000 <frozen os>:795(decode)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method sys.intern}\n",
      "      129    0.000    0.000    0.000    0.000 std.py:1325(refresh)\n",
      "      191    0.000    0.000    0.000    0.000 {method 'getrandbits' of '_random.Random' objects}\n",
      "       59    0.000    0.000    0.000    0.000 {built-in method builtins.pow}\n",
      "        3    0.000    0.000    0.267    0.089 shutil.py:642(_rmtree_safe_fd)\n",
      "        1    0.000    0.000    0.059    0.059 connectionpool.py:594(urlopen)\n",
      "        2    0.000    0.000    0.000    0.000 feedparser.py:216(_parsegen)\n",
      "       19    0.000    0.000    0.000    0.000 _policybase.py:289(_sanitize_header)\n",
      "       21    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISDIR}\n",
      "        1    0.000    0.000    0.007    0.007 connection.py:835(_ssl_wrap_socket_and_match_hostname)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.rmdir}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "        1    0.000    0.000    0.007    0.007 connection.py:27(create_connection)\n",
      "       21    0.000    0.000    0.000    0.000 std.py:110(__enter__)\n",
      "        1    0.000    0.000    0.001    0.001 sessions.py:457(prepare_request)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.utime}\n",
      "       16    0.000    0.000    0.000    0.000 feedparser.py:77(readline)\n",
      "       77    0.000    0.000    0.000    0.000 _weakrefset.py:17(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _warnings.warn}\n",
      "      3/1    0.000    0.000    0.000    0.000 _compiler.py:37(_compile)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:204(get_netrc_auth)\n",
      "        1    0.000    0.000    0.000    0.000 client.py:1136(putrequest)\n",
      "        1    0.000    0.000    0.000    0.000 feedparser.py:469(_parse_headers)\n",
      "        1    0.000    0.000    0.006    0.006 history.py:845(writeout_cache)\n",
      "        1    0.000    0.000    0.044    0.044 client.py:324(begin)\n",
      "        2    0.000    0.000    0.000    0.000 url.py:227(_encode_invalid_chars)\n",
      "        1    0.000    0.000    0.000    0.000 encoder.py:306(iterencode)\n",
      "        7    0.000    0.000    0.000    0.000 client.py:1292(putheader)\n",
      "        1    0.000    0.000    0.000    0.000 usage_lib.py:59(_get_current_timestamp_ns)\n",
      "        1    0.000    0.000    0.000    0.000 models.py:409(prepare_url)\n",
      "       18    0.000    0.000    0.043    0.002 {method 'readline' of '_io.BufferedReader' objects}\n",
      "        1    0.000    0.000    0.000    0.000 response.py:1160(read_chunked)\n",
      "        7    0.000    0.000    0.000    0.000 utils.py:345(to_key_val_list)\n",
      "      102    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "        1    0.000    0.000    0.000    0.000 poolmanager.py:95(_default_key_normalizer)\n",
      "        1    0.000    0.000    0.000    0.000 {method '_wrap_socket' of '_ssl._SSLContext' objects}\n",
      "       21    0.000    0.000    0.000    0.000 std.py:113(__exit__)\n",
      "        1    0.000    0.000    0.044    0.044 connectionpool.py:379(_make_request)\n",
      "        7    0.000    0.000    0.000    0.000 sessions.py:61(merge_setting)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3133(_bind)\n",
      "       11    0.000    0.000    0.000    0.000 <frozen os>:709(__getitem__)\n",
      "        1    0.000    0.000    0.000    0.000 connection.py:316(close)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:304(makefile)\n",
      "        7    0.000    0.000    0.000    0.000 connection.py:351(putheader)\n",
      "        1    0.000    0.000    0.000    0.000 connectionpool.py:258(_get_conn)\n",
      "       22    0.000    0.000    0.000    0.000 <frozen _collections_abc>:892(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 response.py:315(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 pathlib.py:1164(__new__)\n",
      "        1    0.000    0.000    0.061    0.061 sessions.py:500(request)\n",
      "      2/1    0.000    0.000    0.000    0.000 _parser.py:452(_parse_sub)\n",
      "        2    0.000    0.000    0.000    0.000 nest_asyncio.py:141(manage_run)\n",
      "        1    0.000    0.000    0.000    0.000 explore_result.py:45(completed)\n",
      "       29    0.000    0.000    0.000    0.000 structures.py:46(__setitem__)\n",
      "       31    0.000    0.000    0.000    0.000 sock_client.py:71(get)\n",
      "        1    0.000    0.000    0.000    0.000 _collections.py:337(extend)\n",
      "        1    0.000    0.000    0.000    0.000 client.py:261(__init__)\n",
      "        1    0.000    0.000    0.005    0.005 socket.py:959(getaddrinfo)\n",
      "        2    0.000    0.000    0.000    0.000 client.py:430(close)\n",
      "        2    0.000    0.000    0.000    0.000 ssl.py:1199(sendall)\n",
      "        1    0.000    0.000    0.000    0.000 response.py:573(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method today}\n",
      "        1    0.000    0.000    0.000    0.000 ssl.py:441(_encode_hostname)\n",
      "        1    0.000    0.000    0.001    0.001 client.py:231(_parse_header_lines)\n",
      "        1    0.000    0.000    0.063    0.063 usage_lib.py:207(_send_to_server)\n",
      "      2/1    0.000    0.000    1.903    1.903 nest_asyncio.py:25(run)\n",
      "       13    0.000    0.000    0.000    0.000 _policybase.py:301(header_source_parse)\n",
      "       22    0.000    0.000    0.000    0.000 structures.py:51(__getitem__)\n",
      "        5    0.000    0.000    0.000    0.000 structures.py:57(__iter__)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3631(set)\n",
      "        2    0.000    0.000    0.000    0.000 selector_events.py:129(_read_from_self)\n",
      "        1    0.000    0.000    0.000    0.000 ssl.py:504(set_alpn_protocols)\n",
      "        1    0.000    0.000    0.001    0.001 notebook.py:202(__init__)\n",
      "       29    0.000    0.000    0.000    0.000 structures.py:58(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 parser.py:41(parse)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:765(should_bypass_proxies)\n",
      "        9    0.000    0.000    0.000    0.000 parse.py:164(hostname)\n",
      "        2    0.000    0.000    0.000    0.000 cookies.py:521(cookiejar_from_dict)\n",
      "        1    0.000    0.000    0.001    0.001 models.py:351(prepare)\n",
      "       51    0.000    0.000    0.000    0.000 tracelog.py:205(log_message_send)\n",
      "        3    0.000    0.000    0.000    0.000 cookiejar.py:1261(__init__)\n",
      "        8    0.000    0.000    0.000    0.000 message.py:494(get)\n",
      "        1    0.000    0.000    0.000    0.000 cookiejar.py:1356(add_cookie_header)\n",
      "        1    0.000    0.000    0.007    0.007 ssl.py:449(wrap_socket)\n",
      "        3    0.000    0.000    0.000    0.000 idna.py:155(encode)\n",
      "        1    0.000    0.000    0.043    0.043 client.py:291(_read_status)\n",
      "        6    0.000    0.000    0.000    0.000 selector_events.py:42(_test_selector_event)\n",
      "        1    0.000    0.000    0.001    0.001 std.py:952(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen posixpath>:256(expanduser)\n",
      "        1    0.000    0.000    0.000    0.000 client.py:213(_read_headers)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:120(dump)\n",
      "       10    0.000    0.000    0.000    0.000 parse.py:205(_hostinfo)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3474(validate)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:969(parse)\n",
      "        1    0.000    0.000    0.000    0.000 models.py:494(prepare_body)\n",
      "       62    0.000    0.000    0.000    0.000 mailbox.py:332(address)\n",
      "        2    0.000    0.000    0.043    0.021 socket.py:706(readinto)\n",
      "        1    0.000    0.000    0.000    0.000 pathlib.py:387(_parse_path)\n",
      "       11    0.000    0.000    0.000    0.000 <frozen _collections_abc>:804(get)\n",
      "       17    0.000    0.000    0.000    0.000 _collections.py:259(__getitem__)\n",
      "        2    0.000    0.000    0.043    0.021 ssl.py:1236(recv_into)\n",
      "        1    0.000    0.000    0.000    0.000 queue.py:154(get)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:689(set)\n",
      "        1    0.000    0.000    0.000    0.000 pathlib.py:437(__str__)\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:391(_mk_bitmap)\n",
      "        1    0.000    0.000    0.007    0.007 connection.py:193(_new_conn)\n",
      "        2    0.000    0.000    0.000    0.000 cookies.py:124(extract_cookies_to_jar)\n",
      "        1    0.000    0.000    0.000    0.000 cookies.py:140(get_cookie_header)\n",
      "        1    0.000    0.000    0.000    0.000 models.py:483(prepare_headers)\n",
      "       10    0.000    0.000    0.000    0.000 encoder.py:334(_iterencode_dict)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C.TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:578(_code)\n",
      "        1    0.000    0.000    0.000    0.000 poolmanager.py:305(connection_from_context)\n",
      "       13    0.000    0.000    0.000    0.000 _collections.py:302(add)\n",
      "        2    0.000    0.000    0.000    0.000 client.py:1027(send)\n",
      "        1    0.000    0.000    0.000    0.000 feedparser.py:137(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 client.py:1013(close)\n",
      "        4    0.000    0.000    0.000    0.000 message.py:596(get_content_type)\n",
      "        1    0.000    0.000    0.267    0.267 shutil.py:710(rmtree)\n",
      "        1    0.000    0.000    0.000    0.000 adapters.py:446(get_connection_with_tls_context)\n",
      "       31    0.000    0.000    0.000    0.000 mailbox.py:231(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:507(detach)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:694(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:396(_bytes_to_codes)\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:1527(_notify_observers)\n",
      "       13    0.000    0.000    0.000    0.000 message.py:511(set_raw)\n",
      "        4    0.000    0.000    0.000    0.000 explore_result.py:41(add_exception)\n",
      "        1    0.000    0.000    0.007    0.007 ssl.py:1312(do_handshake)\n",
      "        1    0.000    0.000    0.000    0.000 feedparser.py:100(push)\n",
      "        1    0.000    0.000    0.001    0.001 _compiler.py:745(compile)\n",
      "        5    0.000    0.000    0.000    0.000 structures.py:40(__init__)\n",
      "        1    0.000    0.000    0.014    0.014 connectionpool.py:1087(_validate_conn)\n",
      "        2    0.000    0.000    0.000    0.000 feedparser.py:176(_call_parse)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.lstat}\n",
      "        2    0.000    0.000    0.000    0.000 url.py:303(_normalize_host)\n",
      "       11    0.000    0.000    0.000    0.000 <frozen os>:791(encode)\n",
      "       59    0.000    0.000    0.000    0.000 _base_client.py:653(_parse_retry_after_header)\n",
      "        1    0.000    0.000    0.000    0.000 adapters.py:396(build_connection_pool_key_attributes)\n",
      "        2    0.000    0.000    0.000    0.000 response.py:121(decompress)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.open}\n",
      "        1    0.000    0.000    0.000    0.000 adapters.py:359(build_response)\n",
      "        2    0.000    0.000    0.000    0.000 selector_events.py:141(_write_to_self)\n",
      "        1    0.000    0.000    0.000    0.000 queue.py:122(put)\n",
      "       10    0.000    0.000    0.000    0.000 encoder.py:414(_iterencode)\n",
      "        2    0.000    0.000    0.000    0.000 futures.py:263(set_exception)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:663(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'decompress' of 'zlib.Decompress' objects}\n",
      "        2    0.000    0.000    0.000    0.000 base_events.py:837(call_soon_threadsafe)\n",
      "        1    0.000    0.000    0.007    0.007 ssl_.py:399(ssl_wrap_socket)\n",
      "        1    0.000    0.000    0.000    0.000 decorator.py:199(fix)\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:516(_compile_info)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2896(args)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'readlines' of '_io._IOBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 poolmanager.py:330(connection_from_pool_key)\n",
      "        1    0.000    0.000    0.000    0.000 encoder.py:277(encode)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen posixpath>:179(dirname)\n",
      "        6    0.000    0.000    0.000    0.000 traitlets.py:676(__get__)\n",
      "        1    0.000    0.000    0.000    0.000 _collections.py:242(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 request.py:189(body_to_chunks)\n",
      "        1    0.000    0.000    0.001    0.001 sessions.py:750(merge_environment_settings)\n",
      "        2    0.000    0.000    0.000    0.000 ssl.py:669(verify_mode)\n",
      "        2    0.000    0.000    0.000    0.000 ssl.py:1172(send)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:838(select_proxy)\n",
      "        7    0.000    0.000    0.000    0.000 <frozen _collections_abc>:811(__contains__)\n",
      "       16    0.000    0.000    0.000    0.000 feedparser.py:127(__next__)\n",
      "        1    0.000    0.000    0.000    0.000 futures.py:347(_copy_future_state)\n",
      "        1    0.000    0.000    0.000    0.000 pathlib.py:1157(__init__)\n",
      "       14    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 ssl.py:677(verify_mode)\n",
      "        1    0.000    0.000    0.000    0.000 message.py:243(get_payload)\n",
      "        1    0.000    0.000    0.000    0.000 models.py:572(prepare_content_length)\n",
      "        7    0.000    0.000    0.000    0.000 connection.py:400(<genexpr>)\n",
      "       31    0.000    0.000    0.000    0.000 tracelog.py:209(log_message_recv)\n",
      "        1    0.000    0.000    0.000    0.000 parser.py:56(parsestr)\n",
      "        1    0.000    0.000    0.000    0.000 adapters.py:90(_urllib3_request_context)\n",
      "        1    0.000    0.000    0.000    0.000 poolmanager.py:276(connection_from_host)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.close}\n",
      "        1    0.000    0.000    0.000    0.000 models.py:85(path_url)\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:546(_asyncgen_finalizer_hook)\n",
      "        3    0.000    0.000    0.000    0.000 timeout.py:109(__init__)\n",
      "       10    0.000    0.000    0.000    0.000 util.py:19(to_str)\n",
      "       21    0.000    0.000    0.000    0.000 _parser.py:168(__getitem__)\n",
      "        8    0.000    0.000    0.000    0.000 utils.py:1045(_validate_header_part)\n",
      "        1    0.000    0.000    0.000    0.000 ssl_.py:473(is_ipaddress)\n",
      "        1    0.000    0.000    0.000    0.000 models.py:658(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 response.py:1038(stream)\n",
      "        4    0.000    0.000    0.000    0.000 connection.py:164(host)\n",
      "        1    0.000    0.000    0.000    0.000 pathlib.py:407(_load_parts)\n",
      "       20    0.000    0.000    0.000    0.000 utils.py:52(_has_surrogates)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:718(_validate)\n",
      "        1    0.000    0.000    0.000    0.000 {method '_set_alpn_protocols' of '_ssl._SSLContext' objects}\n",
      "        1    0.000    0.000    0.000    0.000 models.py:106(_encode_params)\n",
      "      4/2    0.000    0.000    0.000    0.000 _parser.py:178(getwidth)\n",
      "        1    0.000    0.000    0.000    0.000 client.py:1082(_send_output)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:276(dumps)\n",
      "        1    0.000    0.000    0.044    0.044 client.py:1384(getresponse)\n",
      "        1    0.000    0.000    0.000    0.000 models.py:258(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 parse.py:935(quote_from_bytes)\n",
      "        6    0.000    0.000    0.000    0.000 traitlets.py:629(get)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:3272(bind)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen _collections_abc>:823(items)\n",
      "        1    0.000    0.000    0.000    0.000 client.py:442(flush)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.scandir}\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:660(requote_uri)\n",
      "        1    0.000    0.000    0.000    0.000 response.py:40(assert_header_parsing)\n",
      "       26    0.000    0.000    0.000    0.000 _parser.py:240(__next)\n",
      "        1    0.000    0.000    0.000    0.000 pathlib.py:447(__fspath__)\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:1556(__and__)\n",
      "        2    0.000    0.000    0.000    0.000 url.py:100(__new__)\n",
      "        1    0.000    0.000    0.006    0.006 history.py:55(only_when_enabled)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:727(_cross_validate)\n",
      "        3    0.000    0.000    0.000    0.000 cookies.py:35(__init__)\n",
      "        1    0.000    0.000    0.007    0.007 ssl_.py:497(_ssl_wrap_socket_impl)\n",
      "       19    0.000    0.000    0.000    0.000 _policybase.py:319(header_fetch_parse)\n",
      "        1    0.000    0.000    0.000    0.000 pathlib.py:551(drive)\n",
      "        1    0.000    0.000    0.001    0.001 utils.py:213(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 selector_events.py:1034(_read_ready__on_eof)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:124(RLock)\n",
      "       21    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 wait.py:57(poll_wait_for_socket)\n",
      "        1    0.000    0.000    0.000    0.000 message.py:483(items)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2949(apply_defaults)\n",
      "        1    0.000    0.000    0.000    0.000 encoder.py:260(_make_iterencode)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:679(_get_free_pos)\n",
      "        1    0.000    0.000    0.000    0.000 feedparser.py:171(feed)\n",
      "        2    0.000    0.000    0.000    0.000 cookies.py:542(merge_cookies)\n",
      "        1    0.000    0.000    0.000    0.000 parse.py:859(quote)\n",
      "        2    0.000    0.000    0.000    0.000 _asyncio.py:1135(eof_received)\n",
      "        2    0.000    0.000    0.000    0.000 2664537466.py:123(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 timeout.py:188(clone)\n",
      "        2    0.000    0.000    0.000    0.000 response.py:1120(_update_chunk_length)\n",
      "       21    0.000    0.000    0.000    0.000 _parser.py:261(get)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3624(validate_elements)\n",
      "        3    0.000    0.000    0.000    0.000 {function HTTPResponse.close at 0x7b7ec460f9c0}\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:1018(get_auth_from_url)\n",
      "        1    0.000    0.000    0.000    0.000 _collections.py:95(__getitem__)\n",
      "       16    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:441(_get_literal_prefix)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method zlib.decompressobj}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method now}\n",
      "        1    0.000    0.000    0.006    0.006 decorator.py:229(fun)\n",
      "       15    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 pathlib.py:1284(touch)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:783(close)\n",
      "        8    0.000    0.000    0.000    0.000 client.py:1064(_output)\n",
      "        1    0.000    0.000    0.000    0.000 client.py:1320(endheaders)\n",
      "        1    0.000    0.000    0.000    0.000 adapters.py:546(request_url)\n",
      "        1    0.000    0.000    0.000    0.000 response.py:142(flush)\n",
      "       14    0.000    0.000    0.000    0.000 connection.py:353(<genexpr>)\n",
      "       11    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 client.py:947(_wrap_ipv6)\n",
      "        1    0.000    0.000    0.000    0.000 response.py:635(release_conn)\n",
      "        4    0.000    0.000    0.000    0.000 utils.py:1034(check_header_validity)\n",
      "        1    0.000    0.000    0.001    0.001 client.py:245(parse_headers)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1776(getEffectiveLevel)\n",
      "        1    0.000    0.000    0.000    0.000 parse.py:509(urlunparse)\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:1512(_notify_trait)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'timestamp' of 'datetime.datetime' objects}\n",
      "        1    0.000    0.000    0.000    0.000 cookiejar.py:1297(_cookie_attrs)\n",
      "        6    0.000    0.000    0.000    0.000 enum.py:1538(_get_value)\n",
      "        1    0.000    0.000    0.000    0.000 feedparser.py:52(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 message.py:29(_splitparam)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:826(get_environ_proxies)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:2304(validate)\n",
      "        1    0.000    0.000    0.000    0.000 request.py:134(set_file_position)\n",
      "        1    0.000    0.000    0.000    0.000 response.py:117(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 url.py:263(_remove_path_dot_segments)\n",
      "        3    0.000    0.000    0.000    0.000 url.py:332(_idna_encode)\n",
      "        1    0.000    0.000    0.000    0.000 response.py:209(_get_decoder)\n",
      "        1    0.000    0.000    0.000    0.000 ssl_.py:184(resolve_cert_reqs)\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:393(__get__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'subn' of 're.Pattern' objects}\n",
      "        1    0.000    0.000    0.000    0.000 connection.py:93(_set_socket_options)\n",
      "        1    0.000    0.000    0.000    0.000 connection.py:299(is_connected)\n",
      "        1    0.000    0.000    0.000    0.000 queues.py:33(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 sessions.py:781(get_adapter)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 pathlib.py:358(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {method '_checkReadable' of '_io._IOBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 feedparser.py:121(pushlines)\n",
      "        1    0.000    0.000    0.000    0.000 client.py:1267(_validate_method)\n",
      "        1    0.000    0.000    0.000    0.000 parse.py:156(username)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:539(get_encoding_from_headers)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1153(_comparable)\n",
      "        1    0.000    0.000    0.000    0.000 parse.py:520(urlunsplit)\n",
      "        1    0.000    0.000    0.000    0.000 models.py:890(content)\n",
      "       12    0.000    0.000    0.000    0.000 _parser.py:176(append)\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:708(__set__)\n",
      "        1    0.000    0.000    0.000    0.000 models.py:816(generate)\n",
      "        9    0.000    0.000    0.000    0.000 {method 'is_dir' of 'posix.DirEntry' objects}\n",
      "        1    0.000    0.000    0.000    0.000 response.py:446(_init_decoder)\n",
      "        1    0.000    0.000    0.000    0.000 cookiejar.py:1734(clear_expired_cookies)\n",
      "        2    0.000    0.000    0.000    0.000 client.py:633(_safe_read)\n",
      "        1    0.000    0.000    0.000    0.000 request.py:2557(proxy_bypass_environment)\n",
      "        2    0.000    0.000    0.000    0.000 connectionpool.py:348(_get_timeout)\n",
      "        1    0.000    0.000    0.000    0.000 response.py:1138(_handle_chunk)\n",
      "        1    0.000    0.000    0.000    0.000 connectionpool.py:296(_put_conn)\n",
      "        1    0.000    0.000    0.000    0.000 models.py:207(register_hook)\n",
      "        1    0.000    0.000    0.000    0.000 sessions.py:159(resolve_redirects)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:135(super_len)\n",
      "        1    0.000    0.000    0.000    0.000 wait.py:113(wait_for_read)\n",
      "        1    0.000    0.000    0.000    0.000 futures.py:383(_set_state)\n",
      "        1    0.000    0.000    0.000    0.000 timeout.py:245(read_timeout)\n",
      "        1    0.000    0.000    0.000    0.000 feedparser.py:182(close)\n",
      "       14    0.000    0.000    0.000    0.000 _collections.py:291(__iter__)\n",
      "        1    0.000    0.000    0.268    0.268 explore_result.py:38(__post_init__)\n",
      "        1    0.000    0.000    0.000    0.000 history.py:839(_writeout_output_cache)\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:2013(set_debug)\n",
      "        1    0.000    0.000    0.000    0.000 response.py:465(_decode)\n",
      "        1    0.000    0.000    0.000    0.000 models.py:610(prepare_cookies)\n",
      "        3    0.000    0.000    0.000    0.000 socket.py:745(readable)\n",
      "        1    0.000    0.000    0.000    0.000 models.py:799(iter_content)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:152(wrapper_setattr)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:449(_uniq)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:636(unquote_unreserved)\n",
      "        2    0.000    0.000    0.000    0.000 cookies.py:358(update)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method sys.audit}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'pop' of 'collections.OrderedDict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 unix_events.py:81(_process_self_data)\n",
      "        5    0.000    0.000    0.000    0.000 _internal_utils.py:25(to_native_string)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen posixpath>:138(splitroot)\n",
      "        1    0.000    0.000    0.000    0.000 traitlets.py:1523(notify_change)\n",
      "        1    0.000    0.000    0.000    0.000 models.py:588(prepare_auth)\n",
      "        2    0.000    0.000    0.000    0.000 hooks.py:15(default_hooks)\n",
      "       12    0.000    0.000    0.000    0.000 _parser.py:256(match)\n",
      "        2    0.000    0.000    0.000    0.000 response.py:735(_error_catcher)\n",
      "        1    0.000    0.000    0.000    0.000 connections.py:22(get_sync_client)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:98(closegroup)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:231(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 structures.py:76(copy)\n",
      "        1    0.000    0.000    0.000    0.000 models.py:630(prepare_hooks)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
      "        1    0.000    0.000    0.000    0.000 url.py:351(_encode_target)\n",
      "        1    0.000    0.000    0.000    0.000 models.py:393(prepare_method)\n",
      "       17    0.000    0.000    0.000    0.000 {built-in method _sre.unicode_iscased}\n",
      "        1    0.000    0.000    0.000    0.000 feedparser.py:195(_new_message)\n",
      "        3    0.000    0.000    0.000    0.000 message.py:620(get_content_maintype)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:312(_class_escape)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
      "        1    0.000    0.000    0.000    0.000 parse.py:962(urlencode)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'decode' of 'bytearray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 response.py:495(_flush_decoder)\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:393(done)\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:412(_generate_overlap_table)\n",
      "        1    0.000    0.000    0.000    0.000 feedparser.py:69(close)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:774(get_proxy)\n",
      "        1    0.000    0.000    0.000    0.000 poolmanager.py:374(_merge_pool_kwargs)\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2919(kwargs)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'items' of 'mappingproxy' objects}\n",
      "        1    0.000    0.000    0.000    0.000 client.py:425(_close_conn)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'read' of '_io.StringIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 response.py:679(_init_length)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'count' of 'bytes' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _monitor.py:94(report)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'cast' of 'memoryview' objects}\n",
      "        5    0.000    0.000    0.000    0.000 _parser.py:293(tell)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.fstat}\n",
      "        6    0.000    0.000    0.000    0.000 {method '__exit__' of 'memoryview' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'send' of 'async_generator_athrow' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'tolist' of 'memoryview' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _json.encode_basestring_ascii}\n",
      "        2    0.000    0.000    0.000    0.000 traitlets.py:3486(validate_elements)\n",
      "        2    0.000    0.000    0.000    0.000 queue.py:248(_qsize)\n",
      "        1    0.000    0.000    0.000    0.000 client.py:396(_check_close)\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:216(_compile_charset)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'items' of 'collections.OrderedDict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 adapters.py:304(cert_verify)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1157(__hash__)\n",
      "        1    0.000    0.000    0.000    0.000 client.py:1263(_encode_request)\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:211(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 parse.py:193(_userinfo)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'flush' of 'zlib.Decompress' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:428(result)\n",
      "        1    0.000    0.000    0.000    0.000 explore_result.py:36(<lambda>)\n",
      "        3    0.000    0.000    0.000    0.000 cookiejar.py:884(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 pathlib.py:429(_format_parsed_parts)\n",
      "        5    0.000    0.000    0.000    0.000 _parser.py:164(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 response.py:403(retries)\n",
      "        1    0.000    0.000    0.000    0.000 _internal_utils.py:38(unicode_is_ascii)\n",
      "        1    0.000    0.000    0.000    0.000 response.py:1079(closed)\n",
      "        1    0.000    0.000    0.000    0.000 wait.py:74(do_poll)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _asyncio._set_running_loop}\n",
      "       10    0.000    0.000    0.000    0.000 inspect.py:2808(kind)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'count' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 retry.py:387(is_retry)\n",
      "        3    0.000    0.000    0.000    0.000 builtins.py:87(iter)\n",
      "        1    0.000    0.000    0.000    0.000 ioloop.py:742(_run_callback)\n",
      "        1    0.000    0.000    0.000    0.000 connection.py:309(proxy_is_forwarding)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:234(_acquireLock)\n",
      "        9    0.000    0.000    0.000    0.000 timeout.py:130(_validate_timeout)\n",
      "        2    0.000    0.000    0.000    0.000 _compiler.py:575(isstring)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'update' of 'collections.OrderedDict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 structures.py:60(__len__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'with_traceback' of 'BaseException' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:86(opengroup)\n",
      "        2    0.000    0.000    0.000    0.000 response.py:343(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 connection.py:15(is_connection_dropped)\n",
      "        4    0.000    0.000    0.000    0.000 _parser.py:83(groups)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method fromkeys}\n",
      "        1    0.000    0.000    0.000    0.000 sessions.py:91(merge_hooks)\n",
      "        1    0.000    0.000    0.000    0.000 client.py:1276(_validate_path)\n",
      "        1    0.000    0.000    0.000    0.000 retry.py:379(_is_method_retryable)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:514(_parse_content_type_header)\n",
      "        2    0.000    0.000    0.000    0.000 message.py:211(is_multipart)\n",
      "        4    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 cookiejar.py:1290(_cookies_for_request)\n",
      "        1    0.000    0.000    0.000    0.000 connection.py:103(allowed_gai_family)\n",
      "        1    0.000    0.000    0.000    0.000 sessions.py:107(get_redirect_target)\n",
      "        1    0.000    0.000    0.000    0.000 message.py:331(set_payload)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'extend' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 models.py:334(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:383(cancelled)\n",
      "        2    0.000    0.000    0.000    0.000 response.py:1111(supports_chunked_reads)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'append' of 'bytearray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 response.py:91(is_response_to_head)\n",
      "        8    0.000    0.000    0.000    0.000 ssl.py:1082(_checkClosed)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method '_checkClosed' of '_io._IOBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:1995(_set_coroutine_origin_tracking)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:243(_releaseLock)\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:403(_simple)\n",
      "        1    0.000    0.000    0.000    0.000 timeout.py:202(start_connect)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'gettimeout' of '_socket.socket' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'seek' of '_io.StringIO' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'rstrip' of 'bytes' objects}\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:125(__eq__)\n",
      "        1    0.000    0.000    0.000    0.000 response.py:244(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 futures.py:389(_call_check_cancel)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen genericpath>:99(samestat)\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:463(exception)\n",
      "        1    0.000    0.000    0.000    0.000 feedparser.py:208(_pop_message)\n",
      "        1    0.000    0.000    0.000    0.000 _weakrefset.py:110(remove)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'truncate' of '_io.StringIO' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'flush' of '_io.BufferedReader' objects}\n",
      "        1    0.000    0.000    0.000    0.000 models.py:769(is_redirect)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _sre.unicode_tolower}\n",
      "        1    0.000    0.000    0.000    0.000 _weakrefset.py:115(discard)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:156(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 notebook.py:272(close)\n",
      "        2    0.000    0.000    0.000    0.000 timeout.py:126(resolve_default_timeout)\n",
      "        1    0.000    0.000    0.000    0.000 parse.py:175(port)\n",
      "        3    0.000    0.000    0.000    0.000 _parser.py:113(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:953(fix_flags)\n",
      "        1    0.000    0.000    0.000    0.000 queue.py:254(_get)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'translate' of 'bytearray' objects}\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:2796(name)\n",
      "        1    0.000    0.000    0.000    0.000 hooks.py:22(dispatch_hook)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen _collections_abc>:848(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:491(_decref_socketios)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:186(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 util.py:7(to_bytes)\n",
      "        1    0.000    0.000    0.000    0.000 queue.py:251(_put)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 cookies.py:110(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 inspect.py:3089(parameters)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:743(set_environ)\n",
      "        1    0.000    0.000    0.000    0.000 queues.py:47(_init)\n",
      "        2    0.000    0.000    0.000    0.000 timeout.py:227(connect_timeout)\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of 'posix.ScandirIterator' objects}\n",
      "        4    0.000    0.000    0.000    0.000 cookies.py:117(info)\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:433(_get_iscased)\n",
      "        2    0.000    0.000    0.000    0.000 client.py:453(isclosed)\n",
      "        2    0.000    0.000    0.000    0.000 connection.py:295(is_closed)\n",
      "        1    0.000    0.000    0.000    0.000 _compiler.py:31(_combine_flags)\n",
      "        1    0.000    0.000    0.000    0.000 base_events.py:729(is_running)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1369(disable)\n",
      "        1    0.000    0.000    0.000    0.000 ssl.py:1086(_check_connected)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:77(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 parser.py:17(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen codecs>:214(setstate)\n",
      "        1    0.000    0.000    0.000    0.000 {function socket.detach at 0x7b7ec5b6dda0}\n",
      "        1    0.000    0.000    0.000    0.000 inspect.py:2888(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 pathlib.py:560(root)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:172(__setitem__)\n",
      "        2    0.000    0.000    0.000    0.000 feedparser.py:124(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 pathlib.py:569(_tail)\n",
      "        1    0.000    0.000    0.000    0.000 adapters.py:578(add_headers)\n",
      "        1    0.000    0.000    0.000    0.000 cookies.py:87(get_new_headers)\n",
      "        1    0.000    0.000    0.000    0.000 {function HTTPResponse.flush at 0x7b7ec460fa60}\n",
      "        1    0.000    0.000    0.000    0.000 connectionpool.py:339(_validate_conn)\n",
      "        1    0.000    0.000    0.000    0.000 proxy.py:11(connection_requires_http_tunnel)\n",
      "        1    0.000    0.000    0.000    0.000 models.py:216(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:398(__get_result)\n",
      "        1    0.000    0.000    0.000    0.000 kernelbase.py:570(<lambda>)"
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "asyncio.run(trainer.explore(verbosity=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout('')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.explore_results[-1].exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 vLLM servers...\n",
      "$ vllm serve NousResearch/Hermes-2-Theta-Llama-3-8B --port=8001 --block-size=32 --disable-log-requests --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=2048 --max-num-batched-tokens=16384 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=32 --api-key=default\n",
      "INFO 12-14 20:11:02 api_server.py:528] vLLM API server version 0.6.3.post1\n",
      "INFO 12-14 20:11:02 api_server.py:529] args: Namespace(subparser='serve', model_tag='NousResearch/Hermes-2-Theta-Llama-3-8B', config='', host=None, port=8001, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key='default', lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=True, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='NousResearch/Hermes-2-Theta-Llama-3-8B', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=16384, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=32, enable_prefix_caching=True, disable_sliding_window=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=0, swap_space=32.0, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=16384, max_num_seqs=2048, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=True, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode='swap', served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7dee694a4fe0>)\n",
      "INFO 12-14 20:11:02 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/7121d850-eb84-483c-9c14-56fc454c0657 for IPC Path.\n",
      "INFO 12-14 20:11:02 api_server.py:179] Started engine process with PID 33232\n",
      "WARNING 12-14 20:11:03 config.py:1786] User-specified max_model_len (16384) is greater than the derived max_model_len (max_position_embeddings=8192 or model_max_length=None in model's config.json). This may lead to incorrect model outputs or CUDA errors. Make sure the value is correct and within the model context size.\n",
      "WARNING 12-14 20:11:08 config.py:1786] User-specified max_model_len (16384) is greater than the derived max_model_len (max_position_embeddings=8192 or model_max_length=None in model's config.json). This may lead to incorrect model outputs or CUDA errors. Make sure the value is correct and within the model context size.\n",
      "WARNING 12-14 20:11:08 arg_utils.py:1019] [DEPRECATED] Block manager v1 has been removed, and setting --use-v2-block-manager to True or False has no effect on vLLM behavior. Please remove --use-v2-block-manager in your engine argument. If your use case is not supported by SelfAttnBlockSpaceManager (i.e. block manager v2), please file an issue with detailed information.\n",
      "WARNING 12-14 20:11:08 config.py:395] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "WARNING 12-14 20:11:13 arg_utils.py:1019] [DEPRECATED] Block manager v1 has been removed, and setting --use-v2-block-manager to True or False has no effect on vLLM behavior. Please remove --use-v2-block-manager in your engine argument. If your use case is not supported by SelfAttnBlockSpaceManager (i.e. block manager v2), please file an issue with detailed information.\n",
      "WARNING 12-14 20:11:13 config.py:395] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 12-14 20:11:13 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='NousResearch/Hermes-2-Theta-Llama-3-8B', speculative_config=None, tokenizer='NousResearch/Hermes-2-Theta-Llama-3-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=16384, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=NousResearch/Hermes-2-Theta-Llama-3-8B, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=True, use_async_output_proc=False, use_cached_outputs=True, mm_processor_kwargs=None)\n",
      "INFO 12-14 20:11:15 model_runner.py:1056] Starting to load model NousResearch/Hermes-2-Theta-Llama-3-8B...\n",
      "INFO 12-14 20:11:15 weight_utils.py:243] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:00,  4.05it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.56it/s]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.25it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.15it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.28it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-14 20:11:19 model_runner.py:1067] Loading model weights took 14.9595 GB\n",
      "INFO 12-14 20:11:20 gpu_executor.py:122] # GPU blocks: 11578, # CPU blocks: 8192\n",
      "INFO 12-14 20:11:20 gpu_executor.py:126] Maximum concurrency for 16384 tokens per request: 22.61x\n",
      "INFO 12-14 20:11:37 api_server.py:232] vLLM to use /tmp/tmp3n2vbgld as PROMETHEUS_MULTIPROC_DIR\n",
      "WARNING 12-14 20:11:37 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.\n",
      "INFO 12-14 20:11:37 launcher.py:19] Available routes are:\n",
      "INFO 12-14 20:11:37 launcher.py:27] Route: /openapi.json, Methods: HEAD, GET\n",
      "INFO 12-14 20:11:37 launcher.py:27] Route: /docs, Methods: HEAD, GET\n",
      "INFO 12-14 20:11:37 launcher.py:27] Route: /docs/oauth2-redirect, Methods: HEAD, GET\n",
      "INFO 12-14 20:11:37 launcher.py:27] Route: /redoc, Methods: HEAD, GET\n",
      "INFO 12-14 20:11:37 launcher.py:27] Route: /health, Methods: GET\n",
      "INFO 12-14 20:11:37 launcher.py:27] Route: /tokenize, Methods: POST\n",
      "INFO 12-14 20:11:37 launcher.py:27] Route: /detokenize, Methods: POST\n",
      "INFO 12-14 20:11:37 launcher.py:27] Route: /v1/models, Methods: GET\n",
      "INFO 12-14 20:11:37 launcher.py:27] Route: /version, Methods: GET\n",
      "INFO 12-14 20:11:37 launcher.py:27] Route: /v1/chat/completions, Methods: POST\n",
      "INFO 12-14 20:11:37 launcher.py:27] Route: /v1/completions, Methods: POST\n",
      "INFO 12-14 20:11:37 launcher.py:27] Route: /v1/embeddings, Methods: POST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [33152]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on socket ('0.0.0.0', 8001) (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:47054 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "vLLM server started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c486b045fb46328a391ff29ffad6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val: 0episode [00:00, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c43978b757d45118a4df50a2870652d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl33/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:torchtune.utils._logging:Training is not distributed. If you want to train on multiple GPUs and are using the tune CLI, specify --nnodes 1 and --nproc_per_node [num_gpus]\n",
      "INFO:torchtune.utils._logging:Running FullFinetuneRecipe with resolved config:\n",
      "\n",
      "batch_size: 1\n",
      "checkpointer:\n",
      "  _component_: torchtune.training.checkpointing._checkpointer.FullModelHFCheckpointer\n",
      "  checkpoint_dir: /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725\n",
      "  checkpoint_files:\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00004-of-00004.safetensors\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00001-of-00004.safetensors\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00002-of-00004.safetensors\n",
      "  - /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/model-00003-of-00004.safetensors\n",
      "  model_type: LLAMA3\n",
      "  output_dir: /home/ubuntu/atreides/experiments/models/rl33\n",
      "  recipe_checkpoint: null\n",
      "compile: false\n",
      "custom_sharded_layers:\n",
      "- tok_embeddings\n",
      "- output\n",
      "dataset:\n",
      "  _component_: lib.rl.pack.PackedDataset\n",
      "  dir: /home/ubuntu/atreides/experiments/models/rl33/tensors\n",
      "  num_sequences: 40\n",
      "  sequence_length: 16384\n",
      "device: cuda\n",
      "dtype: bf16\n",
      "enable_activation_checkpointing: true\n",
      "enable_activation_offloading: false\n",
      "epochs: 1\n",
      "gradient_accumulation_steps: 1\n",
      "log_every_n_steps: 1\n",
      "log_peak_memory_stats: true\n",
      "loss:\n",
      "  _component_: lib.rl.ppo.PPOLoss\n",
      "  clip_epsilon: 0.2\n",
      "  entropy_coef: 0.0\n",
      "  entropy_target: 0.75\n",
      "  entropy_target_coef: 0.15\n",
      "  kl_coef: 0.25\n",
      "  normalize_advantages: false\n",
      "  normalize_values: false\n",
      "  policy_coef: 0.0\n",
      "  tanh_log_policy_coef: 0.9\n",
      "  unclipped_policy_coef: 0.0\n",
      "  value_coef: 0.0\n",
      "  weighted_ce_coef: 0.0\n",
      "  weighted_entropy_coef: 0.1\n",
      "  weighted_kl_coef: 0.0\n",
      "max_steps_per_epoch: 32\n",
      "metric_logger:\n",
      "  _component_: torchtune.training.metric_logging.WandBLogger\n",
      "  id: rl33\n",
      "  name: rl33\n",
      "  resume: allow\n",
      "model:\n",
      "  _component_: torchtune.models.llama3_1._model_builders.llama3_1_8b\n",
      "num_output_chunks: 4\n",
      "optimizer:\n",
      "  _component_: torch.optim.AdamW\n",
      "  fused: true\n",
      "  lr: 4.0e-06\n",
      "optimizer_in_bwd: false\n",
      "resume_from_checkpoint: false\n",
      "seed: 42\n",
      "shuffle: true\n",
      "\n",
      "INFO:torchtune.utils._logging:Hint: enable_activation_checkpointing is True, but enable_activation_offloading isn't. Enabling activation offloading should reduce memory further.\n",
      "DEBUG:torchtune.utils._logging:Setting manual seed to local seed 42. Local seed is seed + rank = 42 + 0\n",
      "wandb: Currently logged in as: bradhilton. Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.18.3\n",
      "wandb: Run data is saved locally in /home/ubuntu/atreides/experiments/wandb/run-20241214_201721-rl33\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Resuming run rl33\n",
      "wandb: ⭐️ View project at https://wandb.ai/bradhilton/torchtune\n",
      "wandb: 🚀 View run at https://wandb.ai/bradhilton/torchtune/runs/rl33\n",
      "INFO:torchtune.utils._logging:Logging /home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725/torchtune_config.yaml to W&B under Files\n",
      "INFO:torchtune.utils._logging:FSDP is enabled. Instantiating model and loading checkpoint on Rank 0 ...\n",
      "INFO:torchtune.utils._logging:Instantiating model and loading checkpoint took 2.97 secs\n",
      "INFO:torchtune.utils._logging:Memory stats after model init:\n",
      "\tGPU peak memory allocation: 15.02 GiB\n",
      "\tGPU peak memory reserved: 15.14 GiB\n",
      "\tGPU peak memory active: 15.02 GiB\n",
      "INFO:torchtune.utils._logging:Optimizer is initialized.\n",
      "INFO:torchtune.utils._logging:Loss is initialized.\n",
      "INFO:torchtune.utils._logging:Dataset and Sampler are initialized.\n",
      "WARNING:torchtune.utils._logging: Profiling disabled.\n",
      "INFO:torchtune.utils._logging: Profiler config after instantiation: {'enabled': False}\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtrain(iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/atreides/experiments/lib/rl/trainer.py:281\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, iterations, test, verbosity)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m    277\u001b[0m     _, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m, return_exceptions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbosity\u001b[38;5;241m=\u001b[39mverbosity),\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplore(\u001b[38;5;241m1\u001b[39m, return_exceptions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbosity\u001b[38;5;241m=\u001b[39mverbosity),\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtune(result, verbosity\u001b[38;5;241m=\u001b[39mverbosity)\n\u001b[1;32m    282\u001b[0m _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m, return_exceptions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbosity\u001b[38;5;241m=\u001b[39mverbosity),\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m, verbosity\u001b[38;5;241m=\u001b[39mverbosity) \u001b[38;5;28;01mif\u001b[39;00m test \u001b[38;5;28;01melse\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    285\u001b[0m )\n",
      "File \u001b[0;32m~/atreides/experiments/lib/rl/trainer.py:680\u001b[0m, in \u001b[0;36mTrainer.tune\u001b[0;34m(self, result, verbosity)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtune_recipe_config\u001b[38;5;241m.\u001b[39mreference_checkpointer \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    674\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_checkpointer_config(\n\u001b[1;32m    675\u001b[0m             \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_checkpoint_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_model),\n\u001b[1;32m    676\u001b[0m             checkpoint_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_model_checkpoint_files,\n\u001b[1;32m    677\u001b[0m         )\n\u001b[1;32m    678\u001b[0m     )\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtune_run:\n\u001b[0;32m--> 680\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tune_run(verbosity)\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m     cleanup_before_training()\n",
      "File \u001b[0;32m~/atreides/experiments/lib/rl/trainer.py:741\u001b[0m, in \u001b[0;36mTrainer._tune_run\u001b[0;34m(self, verbosity)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process\u001b[38;5;241m.\u001b[39mstderr:\n\u001b[1;32m    740\u001b[0m     tasks\u001b[38;5;241m.\u001b[39mappend(asyncio\u001b[38;5;241m.\u001b[39mcreate_task(log_output(process\u001b[38;5;241m.\u001b[39mstderr, sys\u001b[38;5;241m.\u001b[39mstderr)))\n\u001b[0;32m--> 741\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n",
      "File \u001b[0;32m~/atreides/experiments/lib/rl/trainer.py:716\u001b[0m, in \u001b[0;36mTrainer._tune_run.<locals>.log_output\u001b[0;34m(stream, io)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 716\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4096\u001b[39m)\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[1;32m    718\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.12.8-linux-x86_64-gnu/lib/python3.12/asyncio/streams.py:713\u001b[0m, in \u001b[0;36mStreamReader.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(blocks)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[0;32m--> 713\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# This will work right even if buffer is less than n bytes\u001b[39;00m\n\u001b[1;32m    716\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(\u001b[38;5;28mmemoryview\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)[:n])\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.12.8-linux-x86_64-gnu/lib/python3.12/asyncio/streams.py:545\u001b[0m, in \u001b[0;36mStreamReader._wait_for_data\u001b[0;34m(self, func_name)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mcreate_future()\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 545\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "await trainer.train(iterations=1, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout('')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.explore_results[0].exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout(''),\n",
       " httpx.ReadTimeout('')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.eval_exceptions[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e444843e2a467380cbb80a607cddc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d09c4e138ad4e7c83abe392440fbecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping val evaluation due to expired patience (0 remaining episodes x 15 patience per episode = 0 seconds)\n",
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl29/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1|185|Loss: 0.0443: 100%|██████████| 185/185 [51:20<00:00, 16.53s/it, entropy=0.6468, entropy_target=0.1032, kl_div=0.0934, policy=-0.0291, tanh_log_policy=0.0026, unclipped_policy=-0.0323, value=1.9048, weighted_ce=0.0188, weighted_entropy=-0.0312, weighted_kl_div=-0.0066]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iteration 10 model files to /home/ubuntu/atreides/experiments/models/rl29/0010\n",
      "Starting 1 vLLM servers...\n",
      "$ vllm serve /home/ubuntu/atreides/experiments/models/rl29/0010 --port=8000 --block-size=32 --disable-log-requests --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=65536 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=32 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0631e356bc64ffe9d6fe7d59ec2c77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991b35675cad450cb7e73c8e1d7d940f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl29/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1|101|Loss: 0.0376: 100%|██████████| 101/101 [28:08<00:00, 16.61s/it, entropy=0.6686, entropy_target=0.0814, kl_div=0.0844, policy=-0.0282, tanh_log_policy=0.0022, unclipped_policy=-0.0298, value=1.0489, weighted_ce=0.0084, weighted_entropy=-0.0236, weighted_kl_div=-0.0026]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iteration 11 model files to /home/ubuntu/atreides/experiments/models/rl29/0011\n",
      "Starting 1 vLLM servers...\n",
      "$ vllm serve /home/ubuntu/atreides/experiments/models/rl29/0011 --port=8001 --block-size=32 --disable-log-requests --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=65536 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=32 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c02738a1c744b5895ec7fa091bd9061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832461296aa74a65a44b9a0b54c775e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl29/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1|127|Loss: 0.0216: 100%|██████████| 128/128 [35:40<00:00, 16.64s/it, entropy=0.7464, entropy_target=0.0036, kl_div=0.0928, policy=-0.0009, tanh_log_policy=-0.0017, unclipped_policy=-0.0051, value=5.0248, weighted_ce=-0.0075, weighted_entropy=0.0059, weighted_kl_div=0.0063] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iteration 12 model files to /home/ubuntu/atreides/experiments/models/rl29/0012\n",
      "Starting 1 vLLM servers...\n",
      "$ vllm serve /home/ubuntu/atreides/experiments/models/rl29/0012 --port=8001 --block-size=32 --disable-log-requests --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=65536 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=32 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0c492a5c2042538066344820d7e302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0453dbc3b8545629c7a0aaca26ec2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl29/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1|143|Loss: 0.0361: 100%|██████████| 143/143 [39:47<00:00, 16.62s/it, entropy=0.6294, entropy_target=0.1206, kl_div=0.0729, policy=0.0015, tanh_log_policy=-0.0001, unclipped_policy=0.0004, value=1.1154, weighted_ce=-0.0008, weighted_entropy=0.0014, weighted_kl_div=0.0005]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iteration 13 model files to /home/ubuntu/atreides/experiments/models/rl29/0013\n",
      "Starting 1 vLLM servers...\n",
      "$ vllm serve /home/ubuntu/atreides/experiments/models/rl29/0013 --port=8000 --block-size=32 --disable-log-requests --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=65536 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=32 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bebaf8156f814cfd96c2663f2cb7a5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping val evaluation due to expired patience (0 remaining episodes x 15 patience per episode = 0 seconds)\n"
     ]
    }
   ],
   "source": [
    "await trainer.train(iterations=4, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db23f98efcc648a0a490829d969258fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a29fdd6406e43b48d17e49981738e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping val evaluation due to expired patience (0 remaining episodes x 15 patience per episode = 0 seconds)\n",
      "Early stopping exploration due to expired patience (0 remaining episodes x 5 patience per episode = 0 seconds)\n",
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl29/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1|100|Loss: 0.0312:  45%|████▌     | 100/222 [27:53<33:44, 16.59s/it, entropy=0.8347, entropy_target=0.0847, kl_div=0.0736, policy=-0.0045, tanh_log_policy=-0.0004, unclipped_policy=-0.0056, value=2.1442, weighted_ce=0.0013, weighted_entropy=-0.0045, weighted_kl_div=-0.0014]"
     ]
    }
   ],
   "source": [
    "await trainer.train(iterations=12, verbosity=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
