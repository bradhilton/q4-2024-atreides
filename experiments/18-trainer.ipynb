{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8 * 5 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-13 20:04:35 config.py:451] This model supports multiple tasks: {'embed', 'score', 'reward', 'generate', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 12-13 20:04:35 llm_engine.py:250] Initializing an LLM engine (v0.1.dev3782+gf9e303a) with config: model='NousResearch/Hermes-2-Theta-Llama-3-8B', speculative_config=None, tokenizer='NousResearch/Hermes-2-Theta-Llama-3-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=NousResearch/Hermes-2-Theta-Llama-3-8B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, mm_cache_preprocessor=False, mm_processor_kwargs=None, pooler_config=None, compilation_config=CompilationConfig(level=0, debug_dump_path='', backend='', custom_ops=[], splitting_ops=['vllm.unified_attention', 'vllm.unified_attention_with_output'], use_inductor=True, candidate_compile_sizes=[], inductor_compile_config={}, inductor_passes={}, use_cudagraph=False, cudagraph_num_of_warmups=0, cudagraph_capture_sizes=None, cudagraph_copy_inputs=False, pass_config=PassConfig(dump_graph_stages=[], dump_graph_dir=PosixPath('.'), enable_fusion=True, enable_reshape=True), compile_sizes=[], capture_sizes=[256, 248, 240, 232, 224, 216, 208, 200, 192, 184, 176, 168, 160, 152, 144, 136, 128, 120, 112, 104, 96, 88, 80, 72, 64, 56, 48, 40, 32, 24, 16, 8, 4, 2, 1], enabled_custom_ops=Counter(), disabled_custom_ops=Counter(), compilation_time=0.0, static_forward_context={}), use_cached_outputs=False, \n",
      "INFO 12-13 20:04:36 llm_engine.py:447] init engine (profile, create kv cache, warmup model) took 0.00 seconds\n",
      "INFO 12-13 20:04:36 chat_utils.py:331] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbradhilton\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/atreides/experiments/wandb/run-20241213_200437-rl29</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bradhilton/atreides-experiments/runs/rl29' target=\"_blank\">rl29</a></strong> to <a href='https://wandb.ai/bradhilton/atreides-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bradhilton/atreides-experiments' target=\"_blank\">https://wandb.ai/bradhilton/atreides-experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bradhilton/atreides-experiments/runs/rl29' target=\"_blank\">https://wandb.ai/bradhilton/atreides-experiments/runs/rl29</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from lib.clue import Clue, DeductiveSolver\n",
    "from lib.rl.episode import Episode, EpisodeCompletion\n",
    "from lib.rl.ppo import PPOLoss\n",
    "from lib.rl.recipe import ComponentConfig, TuneRecipeConfig\n",
    "from lib.rl.trainer import ExploreOptions, Trainer, vLLMConfig\n",
    "from lib.utils import return_exception\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "from torchtune.models.llama3_1 import llama3_1_8b\n",
    "from typing import Literal, Optional\n",
    "\n",
    "with open(\"./data/chain-of-thought-examples.json\") as f:\n",
    "    chain_of_thought_examples: list[dict[str, str]] = json.load(f)\n",
    "\n",
    "\n",
    "def get_variable_difficulty_game(\n",
    "    return_first_solver_as_winner: Optional[bool] = None,\n",
    ") -> Clue:\n",
    "    num_players = random.randint(3, 6)\n",
    "    num_weapons = max(\n",
    "        3,\n",
    "        min(\n",
    "            num_players + random.randint(-1, 5),\n",
    "            len(Clue.weapons),\n",
    "        ),\n",
    "    )\n",
    "    num_suspects = min(\n",
    "        num_weapons + random.randint(0, num_weapons - 1), len(Clue.suspects)\n",
    "    )\n",
    "    num_rooms = min(num_suspects + random.randint(0, num_suspects - 2), len(Clue.rooms))\n",
    "    elements = {\n",
    "        \"suspect\": random.sample(Clue.suspects, k=num_suspects),\n",
    "        \"weapon\": random.sample(Clue.weapons, k=num_weapons),\n",
    "        \"room\": random.sample(Clue.rooms, k=num_rooms),\n",
    "    }\n",
    "    if random.random() < 0.1:\n",
    "        elements[\"motive\"] = random.sample(\n",
    "            Clue.motives,\n",
    "            k=max(3, min(num_weapons + random.randint(-1, 3), len(Clue.motives))),\n",
    "        )\n",
    "    if random.random() < 0.1:\n",
    "        frequency = random.choice([0.25, 0.5, 1.0])\n",
    "        start = 24.0 - frequency\n",
    "        end = 0.0\n",
    "        for _ in range(random.randint(1, num_weapons + 1)):\n",
    "            if random.randint(0, 1):\n",
    "                end += frequency\n",
    "            else:\n",
    "                start -= frequency\n",
    "\n",
    "        def format_time(time: float) -> str:\n",
    "            return f\"{int(time):02d}:{int(60 * (time - int(time))):02d}\"\n",
    "\n",
    "        elements[\"time\"] = Clue.get_times(\n",
    "            format_time(start), format_time(end), f\"{int(frequency * 60)}min\"\n",
    "        )\n",
    "    game = Clue(\n",
    "        num_players=num_players,\n",
    "        elements=elements,\n",
    "    )\n",
    "    difficulty_level = num_players + random.randint(-2, 3)\n",
    "    # print(f\"Players: {num_players}\")\n",
    "    # for element in elements:\n",
    "    #     print(f\"{element.capitalize()}: {len(elements[element])}\")\n",
    "    # print(f\"Difficulty level: {difficulty_level}\")\n",
    "    return game.play(\n",
    "        deductive_solver=DeductiveSolver(\n",
    "            # note_cards_in_hand=False,\n",
    "            # note_responses_to_suggestions=False,\n",
    "            # note_cards_that_players_do_not_have=False,\n",
    "            # check_unique_card_placement_constraints=False,\n",
    "            # check_player_hand_size_constraints=False,\n",
    "            check_solution_has_one_and_only_one_card_per_element=difficulty_level > 1,\n",
    "            check_one_of_constraints=difficulty_level > 2,\n",
    "            check_inverse_one_of_constraints=difficulty_level > 3,\n",
    "            merge_and_check_disjoint_inverse_one_of_constraints=difficulty_level > 4,\n",
    "            exhaustively_test_possible_assignments=False,\n",
    "        ),\n",
    "        cp_solver_max_solve_time_per_turn=0.01,\n",
    "        check_cp_solver_grid=False,\n",
    "        check_if_deductive_solver_and_cp_solver_grids_match=False,\n",
    "        return_first_solver_as_winner=(\n",
    "            bool(random.randint(0, 1))\n",
    "            if return_first_solver_as_winner is None\n",
    "            else return_first_solver_as_winner\n",
    "        ),\n",
    "        print_playthrough=False,\n",
    "        max_turns=100,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_easy_game(return_first_solver_as_winner: Optional[bool] = None) -> Clue:\n",
    "    game = Clue(\n",
    "        num_players=3,\n",
    "        elements={\n",
    "            \"suspect\": random.sample(Clue.suspects, k=3),\n",
    "            \"weapon\": random.sample(Clue.weapons, k=3),\n",
    "            \"room\": random.sample(Clue.rooms, k=3),\n",
    "            # \"motive\": random.sample(Clue.motives, k=3),\n",
    "            # \"time\": Clue.get_times(\"21:00\", \"03:00\", \"1h\"),\n",
    "        },\n",
    "    )\n",
    "    game.play(\n",
    "        deductive_solver=DeductiveSolver(\n",
    "            # note_cards_in_hand=False,\n",
    "            # note_responses_to_suggestions=False,\n",
    "            # note_cards_that_players_do_not_have=False,\n",
    "            # check_unique_card_placement_constraints=False,\n",
    "            # check_player_hand_size_constraints=False,\n",
    "            check_solution_has_one_and_only_one_card_per_element=False,\n",
    "            check_one_of_constraints=False,\n",
    "            check_inverse_one_of_constraints=False,\n",
    "            merge_and_check_disjoint_inverse_one_of_constraints=False,\n",
    "            exhaustively_test_possible_assignments=False,\n",
    "        ),\n",
    "        cp_solver_max_solve_time_per_turn=0.01,\n",
    "        check_cp_solver_grid=False,\n",
    "        check_if_deductive_solver_and_cp_solver_grids_match=False,\n",
    "        return_first_solver_as_winner=return_first_solver_as_winner or False,\n",
    "        print_playthrough=False,\n",
    "        max_turns=100,\n",
    "    )\n",
    "    return game\n",
    "\n",
    "\n",
    "@return_exception\n",
    "def sample_random_episode(\n",
    "    difficulty: Literal[\"easy\", \"variable\"] = \"variable\",\n",
    "    example_probability: float = 0.0,\n",
    "    max_prompt_characters: int = 8192,\n",
    "    reward_follow_up_completion: bool = True,\n",
    "    return_first_solver_as_winner: Optional[bool] = None,\n",
    ") -> Episode:\n",
    "    while True:\n",
    "        try:\n",
    "            game = (\n",
    "                get_easy_game if difficulty == \"easy\" else get_variable_difficulty_game\n",
    "            )(return_first_solver_as_winner=return_first_solver_as_winner)\n",
    "            prompt, follow_up, solution = game.get_prompt_and_follow_up_and_solution()\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if len(prompt) <= max_prompt_characters:\n",
    "            break\n",
    "\n",
    "    async def reward_completion(completion: EpisodeCompletion) -> EpisodeCompletion:\n",
    "        if len(completion.messages) == 2:\n",
    "            follow_up_completion = await completion.follow_up(\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": follow_up},\n",
    "                ],\n",
    "                max_tokens=10\n",
    "                + len(\"\\n\".join(f\"{key}: {value}\" for key, value in solution.items()))\n",
    "                // 2,\n",
    "            )\n",
    "        else:\n",
    "            follow_up_completion = completion\n",
    "        answer = follow_up_completion.last_assistant_message.get(\"content\")\n",
    "        assert isinstance(answer, str)\n",
    "        if reward_follow_up_completion:\n",
    "            completion = follow_up_completion\n",
    "        completion.reward = sum(\n",
    "            [\n",
    "                bool(\n",
    "                    # Find first match of key followed by colon and capture following text\n",
    "                    (\n",
    "                        match := re.search(\n",
    "                            rf\"{key}: ([A-Za-z \\.:-]+)\",\n",
    "                            answer,\n",
    "                            re.IGNORECASE,\n",
    "                        )\n",
    "                    )\n",
    "                    # Check if captured group matches expected value\n",
    "                    and match.group(1).strip().lower() == value.strip().lower()\n",
    "                )\n",
    "                for key, value in solution.items()\n",
    "            ]\n",
    "        ) / len(solution)\n",
    "        completion.reward -= (\n",
    "            completion.all_absent_stop_tokens\n",
    "            / (3 if reward_follow_up_completion else 2)\n",
    "            / len(solution)\n",
    "        )\n",
    "        return completion\n",
    "\n",
    "    async def on_sample(completions: list[EpisodeCompletion]) -> None:\n",
    "        for completion in await asyncio.gather(\n",
    "            *[reward_completion(completion) for completion in completions]\n",
    "        ):\n",
    "            completion.commit()\n",
    "\n",
    "    example = random.choice(chain_of_thought_examples)\n",
    "\n",
    "    return Episode(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        examples=lambda: (\n",
    "            [\n",
    "                {\"role\": \"user\", \"content\": example[\"prompt\"]},\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": example[\"chain_of_thought\"]\n",
    "                    + (example[\"answer\"] and f\"\\n\\n---\\n\\n{example['answer']}\"),\n",
    "                },\n",
    "            ]\n",
    "            if random.random() < example_probability\n",
    "            else []\n",
    "        ),\n",
    "        on_sample=on_sample,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_episodes():\n",
    "    while True:\n",
    "        yield sample_random_episode()\n",
    "\n",
    "\n",
    "model_name = \"rl29\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    base_model=\"NousResearch/Hermes-2-Theta-Llama-3-8B\",\n",
    "    output_dir=f\"./models/{model_name}\",\n",
    "    explore_options=ExploreOptions(\n",
    "        iterations=8,\n",
    "        num_parents=5,\n",
    "        branch_factor=3,\n",
    "        patience=5,\n",
    "        sample_probability_power=None,\n",
    "        sampling_kwargs={\"max_tokens\": 1024},\n",
    "        split_method=\"prob\",\n",
    "        split_point_std_deviation=0.5,\n",
    "    ),\n",
    "    train_episodes=train_episodes(),\n",
    "    episodes_per_iteration=64 * torch.cuda.device_count(),\n",
    "    max_mask_sequence_batch_size=1,\n",
    "    val_episodes=(\n",
    "        sample_random_episode() for _ in range(64 * torch.cuda.device_count())\n",
    "    ),\n",
    "    val_patience=15,\n",
    "    val_samples_per_episode=3,\n",
    "    val_sampling_kwargs={\"max_tokens\": 1024},\n",
    "    tune_model=llama3_1_8b,\n",
    "    tune_model_type=\"LLAMA3\",\n",
    "    tune_recipe_config=TuneRecipeConfig(\n",
    "        seed=42,\n",
    "        shuffle=False,\n",
    "        num_output_chunks=4,\n",
    "        resume_from_checkpoint=False,\n",
    "        batch_size=1,\n",
    "        epochs=1,\n",
    "        optimizer=ComponentConfig(\n",
    "            \"torch.optim.AdamW\",\n",
    "            # \"bitsandbytes.optim.PagedAdamW8bit\",\n",
    "            # \"bitsandbytes.optim.AdamW\",\n",
    "            # params=PLACEHOLDER,\n",
    "            lr=4e-6,\n",
    "            fused=True,\n",
    "        ),\n",
    "        loss=ComponentConfig(\n",
    "            PPOLoss,\n",
    "            policy_coef=0.0,\n",
    "            clip_epsilon=0.2,\n",
    "            unclipped_policy_coef=0.0,\n",
    "            tanh_log_policy_coef=0.9,\n",
    "            value_coef=0.0,\n",
    "            entropy_coef=0.0,\n",
    "            entropy_target=0.75,\n",
    "            entropy_target_coef=0.15,\n",
    "            kl_coef=0.25,\n",
    "            weighted_entropy_coef=0.1,\n",
    "            weighted_kl_coef=0.0,\n",
    "            weighted_ce_coef=0.0,\n",
    "            normalize_values=False,\n",
    "            normalize_advantages=False,\n",
    "        ),\n",
    "        compile=False,\n",
    "        optimizer_in_bwd=False,\n",
    "        gradient_accumulation_steps=1,\n",
    "        enable_activation_checkpointing=True,\n",
    "        enable_activation_offloading=False,\n",
    "        custom_sharded_layers=[\"tok_embeddings\", \"output\"],\n",
    "        log_every_n_steps=1,\n",
    "        log_peak_memory_stats=True,\n",
    "    ),\n",
    "    # tune_run=False,\n",
    "    tune_sequence_length=16384,\n",
    "    vllm_config=vLLMConfig(\n",
    "        env={\"VLLM_ALLOW_LONG_MAX_MODEL_LEN\": \"1\"},\n",
    "        kwargs=dict(\n",
    "            block_size=32,\n",
    "            disable_log_requests=True,\n",
    "            enable_prefix_caching=True,\n",
    "            enforce_eager=True,\n",
    "            gpu_memory_utilization=0.9,\n",
    "            max_model_len=16384,\n",
    "            max_num_seqs=512,\n",
    "            max_num_batched_tokens=16384 * 4,\n",
    "            preemption_mode=\"swap\",\n",
    "            return_tokens_as_token_ids=True,\n",
    "            swap_space=32,\n",
    "        ),\n",
    "        max_concurrent_samples=512,\n",
    "        timeout=120 + 15 * torch.cuda.device_count(),\n",
    "    ),\n",
    "    wandb_kwargs=dict(\n",
    "        name=model_name,\n",
    "        id=model_name,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 vLLM servers...\n",
      "$ vllm serve /home/ubuntu/atreides/experiments/models/rl29/0001 --port=8000 --block-size=32 --disable-log-requests --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=65536 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=32 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe2cb5d6211b48978542bb8712b2a2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325c9536569445b59d2e67204634e8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl29/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1|19|Loss: 0.0591:  59%|█████▉    | 19/32 [05:24<03:35, 16.60s/it, entropy=0.5678, entropy_target=0.1822, kl_div=0.1324, policy=0.0104, tanh_log_policy=-0.0005, unclipped_policy=0.0040, value=1.2318, weighted_ce=-0.0205, weighted_entropy=0.0085, weighted_kl_div=0.0192]   "
     ]
    }
   ],
   "source": [
    "await trainer.train(iterations=4, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainer.explore_results[0].episodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
