{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:\n",
      "No module named 'vllm._version'\n",
      "  from vllm.version import __version__ as VLLM_VERSION\n",
      "/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:\n",
      "No module named 'vllm._version'\n",
      "  from vllm.version import __version__ as VLLM_VERSION\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.43it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.37it/s]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.00it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.69it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.66it/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.vllm import start_vllm_server, vllm_server_metrics\n",
    "\n",
    "model = \"NousResearch/Hermes-2-Theta-Llama-3-8B\"\n",
    "\n",
    "shutdown_server, client = await start_vllm_server(\n",
    "    disable_log_requests=True,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutdown_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.rl.sampler import CompletionSampler\n",
    "\n",
    "completion_sampler = CompletionSampler(\n",
    "    client,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from lib.rl.completion import Completion\n",
    "from openai.types.chat.chat_completion_message_param import ChatCompletionMessageParam\n",
    "from typing import Callable, Coroutine, Optional\n",
    "\n",
    "\n",
    "class Episode:\n",
    "    def __init__(\n",
    "        self,\n",
    "        messages: list[ChatCompletionMessageParam],\n",
    "        on_sample: Callable[[list[Completion]], None | Coroutine[None, None, None]],\n",
    "        get_easier_episode: Optional[\n",
    "            tuple[float, Callable[[], \"Episode\" | Coroutine[None, None, \"Episode\"]]]\n",
    "        ] = None,\n",
    "        get_similar_episode: Optional[\n",
    "            Callable[[], \"Episode\" | Coroutine[None, None, \"Episode\"]]\n",
    "        ] = None,\n",
    "        get_harder_episode: Optional[\n",
    "            tuple[float, Callable[[], \"Episode\" | Coroutine[None, None, \"Episode\"]]]\n",
    "        ] = None,\n",
    "    ) -> None:\n",
    "        self.completion = Completion(messages=messages)  # type: ignore\n",
    "        self.on_sample = on_sample\n",
    "        self.min_value = (get_easier_episode or [None])[0]\n",
    "        self.max_value = (get_harder_episode or [None])[0]\n",
    "        self.get_easier_episode = (get_easier_episode or [None, None])[1]\n",
    "        self.get_similar_episode = get_similar_episode\n",
    "        self.get_harder_episode = (get_harder_episode or [None, None])[1]\n",
    "        self.weight = 1.0\n",
    "        self.task = asyncio.create_task(asyncio.sleep(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.clue import Clue, DeductiveSolver\n",
    "import re\n",
    "\n",
    "\n",
    "def sample_random_episode() -> Episode:\n",
    "    game = Clue(\n",
    "        num_players=3,\n",
    "        elements={\n",
    "            \"suspect\": Clue.suspects[:3],\n",
    "            \"weapon\": Clue.weapons[:3],\n",
    "            \"room\": Clue.rooms[:3],\n",
    "            # \"motive\": Clue.motives[:6],\n",
    "            # \"time\": Clue.get_times(\"21:00\", \"03:00\", \"1h\"),\n",
    "        },\n",
    "    )\n",
    "    game.play(\n",
    "        deductive_solver=DeductiveSolver(\n",
    "            # note_cards_in_hand=False,\n",
    "            # note_responses_to_suggestions=False,\n",
    "            # note_cards_that_players_do_not_have=False,\n",
    "            # check_unique_card_placement_constraints=False,\n",
    "            # check_player_hand_size_constraints=False,\n",
    "            check_solution_has_one_and_only_one_card_per_element=False,\n",
    "            check_one_of_constraints=False,\n",
    "            check_inverse_one_of_constraints=False,\n",
    "            merge_and_check_disjoint_inverse_one_of_constraints=False,\n",
    "            exhaustively_test_possible_assignments=False,\n",
    "        ),\n",
    "        cp_solver_max_solve_time_per_turn=0.05,\n",
    "        check_cp_solver_grid=False,\n",
    "        check_if_deductive_solver_and_cp_solver_grids_match=False,\n",
    "        print_playthrough=False,\n",
    "    )\n",
    "    prompt = game.get_prompt()\n",
    "    follow_up = \"Fill out your answer like this:\\n\" + \"\\n\".join(\n",
    "        f\"{element.capitalize()}: <#{element.upper()}#>\" for element in game.elements\n",
    "    )\n",
    "\n",
    "    async def reward_completion(completion: Completion) -> None:\n",
    "        chat_completion = await client.chat.completions.create(\n",
    "            messages=completion.all_message_params()\n",
    "            + [\n",
    "                {\"role\": \"user\", \"content\": follow_up},\n",
    "            ],\n",
    "            model=model,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        answer = chat_completion.choices[0].message.content\n",
    "        assert answer\n",
    "        completion.reward = sum(\n",
    "            [\n",
    "                bool(\n",
    "                    re.search(\n",
    "                        f\"{element}: {solution}\",\n",
    "                        answer,\n",
    "                        re.IGNORECASE,\n",
    "                    )\n",
    "                )\n",
    "                for element, solution in game.solution.items()\n",
    "            ]\n",
    "        ) / len(game.solution)\n",
    "\n",
    "    async def on_sample(completions: list[Completion]) -> None:\n",
    "        await asyncio.gather(\n",
    "            *[reward_completion(completion) for completion in completions]\n",
    "        )\n",
    "        for completion in completions:\n",
    "            completion.commit()\n",
    "\n",
    "    return Episode(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        on_sample=on_sample,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.get_token_id(\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class EpisodeSampler:\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample: Callable[[], Episode | Coroutine[None, None, Episode]],\n",
    "    ) -> None:\n",
    "        self.sample = sample\n",
    "        self.num_samples = 0\n",
    "        self.num_goldilocks = 0\n",
    "\n",
    "    def goldilocks_rate(self, prior: float, effective_sample_size: float) -> float:\n",
    "        return (self.num_goldilocks + prior * effective_sample_size) / (\n",
    "            self.num_samples + effective_sample_size\n",
    "        )\n",
    "\n",
    "\n",
    "branch_factor = 2\n",
    "min_requests = 5\n",
    "abs_buffer_size = 40\n",
    "weighted_buffer_size = 80\n",
    "buffer: list[Episode] = []\n",
    "min_random_episode_sample_probability_half_life = 80\n",
    "exploitation_factor = 1.0\n",
    "random_sampler = EpisodeSampler(sample_random_episode)\n",
    "other_samplers: list[EpisodeSampler] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goldilocks_rate_prior_and_effective_sample_size() -> tuple[float, float]:\n",
    "    num_goldilocks = random_sampler.num_goldilocks + sum(\n",
    "        s.num_goldilocks for s in other_samplers\n",
    "    )\n",
    "    num_samples = random_sampler.num_samples + sum(\n",
    "        s.num_samples for s in other_samplers\n",
    "    )\n",
    "    return (\n",
    "        num_goldilocks / num_samples\n",
    "        if num_goldilocks != 0 and num_samples != 0\n",
    "        else 1.0\n",
    "    ), max(num_samples / (len(other_samplers) + 1), 1)\n",
    "\n",
    "\n",
    "async def sample_completions(episode: Episode) -> None:\n",
    "    if episode.completion.children:\n",
    "        try:\n",
    "            leaf = max(\n",
    "                (\n",
    "                    completion\n",
    "                    for completion in episode.completion.leaves()\n",
    "                    if any(\n",
    "                        c.can_split() for c in completion.ancestors(including_self=True)\n",
    "                    )\n",
    "                ),\n",
    "                key=lambda c: c.all_abs_advantage() / c.all_token_count(tokenizer),\n",
    "            )\n",
    "            parent = max(\n",
    "                (c for c in leaf.ancestors(including_self=True) if c.can_split()),\n",
    "                key=lambda c: abs(c.advantage()) * c.token_count(tokenizer),\n",
    "            )\n",
    "            assert parent.split(by=\"count\"), \"Unable to split completion\"\n",
    "        except BaseException as e:\n",
    "            print(type(e), e)\n",
    "            episode.task = asyncio.create_task(asyncio.sleep(float(\"inf\")))\n",
    "            return\n",
    "    else:\n",
    "        parent = episode.completion\n",
    "    completions = await completion_sampler.sample_completions(\n",
    "        parent,\n",
    "        n=branch_factor,\n",
    "    )\n",
    "    on_sample = episode.on_sample(completions)\n",
    "    if isinstance(on_sample, Coroutine):\n",
    "        await on_sample\n",
    "\n",
    "\n",
    "async def get_episode() -> None:\n",
    "    if not other_samplers:\n",
    "        sampler = random_sampler\n",
    "    else:\n",
    "        prior, effective_sample_size = goldilocks_rate_prior_and_effective_sample_size()\n",
    "        min_random_goldilocks_rate = 1.0 * np.exp(\n",
    "            -np.log(2)\n",
    "            / min_random_episode_sample_probability_half_life\n",
    "            * random_sampler.num_samples\n",
    "        )\n",
    "        random_goldilocks_rate = max(\n",
    "            random_sampler.goldilocks_rate(prior, effective_sample_size),\n",
    "            min_random_goldilocks_rate,\n",
    "        )\n",
    "        other_goldilocks_rates = np.array(\n",
    "            [\n",
    "                sampler.goldilocks_rate(prior, effective_sample_size)\n",
    "                for sampler in other_samplers\n",
    "            ]\n",
    "        )\n",
    "        other_sampler_weights = other_goldilocks_rates**exploitation_factor\n",
    "        other_sampler_weights /= other_sampler_weights.sum()\n",
    "        other_expected_goldilocks_rate = other_goldilocks_rates @ other_sampler_weights\n",
    "        hierachical_weights = (\n",
    "            np.array([random_goldilocks_rate, other_expected_goldilocks_rate])\n",
    "            ** exploitation_factor\n",
    "        )\n",
    "        hierachical_weights /= hierachical_weights.sum()\n",
    "        if random.random() < hierachical_weights[0]:\n",
    "            sampler = random_sampler\n",
    "        else:\n",
    "            sampler = random.choices(other_samplers, weights=other_sampler_weights)[0]\n",
    "    episode = sampler.sample()\n",
    "    if isinstance(episode, Coroutine):\n",
    "        placeholder = Episode(\n",
    "            messages=[],\n",
    "            on_sample=lambda _: None,\n",
    "        )\n",
    "        buffer.append(\n",
    "            placeholder,\n",
    "        )\n",
    "        try:\n",
    "            episode = await episode\n",
    "        finally:\n",
    "            buffer.remove(placeholder)\n",
    "    episode.task = asyncio.create_task(sample_completions(episode))\n",
    "    buffer.append(episode)\n",
    "    try:\n",
    "        await episode.task\n",
    "    except BaseException as e:\n",
    "        buffer.remove(episode)\n",
    "        raise e\n",
    "    if not episode.completion.children:\n",
    "        return buffer.remove(episode)\n",
    "    sampler.num_samples += 1\n",
    "\n",
    "    if (\n",
    "        episode.get_easier_episode\n",
    "        and episode.min_value is not None\n",
    "        and episode.completion.value() <= episode.min_value\n",
    "    ):\n",
    "        other_samplers.append(\n",
    "            EpisodeSampler(\n",
    "                episode.get_easier_episode,\n",
    "            )\n",
    "        )\n",
    "        return buffer.remove(episode)\n",
    "    elif (\n",
    "        episode.get_harder_episode\n",
    "        and episode.max_value is not None\n",
    "        and episode.completion.value() >= episode.max_value\n",
    "    ):\n",
    "        other_samplers.append(\n",
    "            EpisodeSampler(\n",
    "                episode.get_harder_episode,\n",
    "            )\n",
    "        )\n",
    "        return buffer.remove(episode)\n",
    "    elif all(c.advantage() == 0 for c in episode.completion.children):\n",
    "        return buffer.remove(episode)\n",
    "    elif episode.get_similar_episode:\n",
    "        other_samplers.append(\n",
    "            EpisodeSampler(\n",
    "                episode.get_similar_episode,\n",
    "            )\n",
    "        )\n",
    "    sampler.num_goldilocks += 1\n",
    "\n",
    "\n",
    "async def enrich_episode() -> None:\n",
    "    try:\n",
    "        episode = min(\n",
    "            (episode for episode in buffer if episode.task.done()),\n",
    "            key=lambda episode: len(list(episode.completion.descendants())),\n",
    "        )\n",
    "        episode.task = asyncio.create_task(sample_completions(episode))\n",
    "    except ValueError:\n",
    "        await get_episode()\n",
    "\n",
    "\n",
    "async def prepare_episodes() -> None:\n",
    "    while True:\n",
    "        await asyncio.sleep(5)\n",
    "        running, pending = vllm_server_metrics()\n",
    "        for _ in range(0, running - pending + min_requests, branch_factor * 2):\n",
    "            if (\n",
    "                len(buffer) < abs_buffer_size\n",
    "                or sum(e.weight for e in buffer) < weighted_buffer_size\n",
    "            ):\n",
    "                asyncio.create_task(get_episode())\n",
    "            else:\n",
    "                asyncio.create_task(enrich_episode())\n",
    "\n",
    "\n",
    "prepare_episodes_task = asyncio.create_task(prepare_episodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_episodes_task.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vllm_server_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buffer) < abs_buffer_size or sum(e.weight for e in buffer) < weighted_buffer_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.120481927710845"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(list(episode.completion.descendants())) for episode in buffer]) / len(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([episode for episode in buffer if episode.task.done()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await prepare_episodes_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class Trajectory:\n",
    "    episode: Episode\n",
    "    terminus: Completion\n",
    "    abs_advantage: float\n",
    "    token_count: int\n",
    "\n",
    "    def score(self) -> float:\n",
    "        return self.episode.weight * self.abs_advantage / self.token_count\n",
    "\n",
    "\n",
    "def best_trajectory(episode: Episode) -> Trajectory:\n",
    "    return max(\n",
    "        (\n",
    "            Trajectory(\n",
    "                episode=episode,\n",
    "                terminus=completion,\n",
    "                abs_advantage=completion.all_abs_advantage(),\n",
    "                token_count=completion.all_token_count(tokenizer),\n",
    "            )\n",
    "            for completion in episode.completion.leaves()\n",
    "        ),\n",
    "        key=lambda t: t.abs_advantage / t.token_count,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = sorted(\n",
    "    (best_trajectory(episode) for episode in buffer),\n",
    "    key=lambda t: t.score(),\n",
    "    reverse=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = trajectories[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5555555555555556,\n",
       " -0.37037037037037046,\n",
       " 0.5432098765432098,\n",
       " -0.36419753086419754,\n",
       " 0.0]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c.advantage() for c in trajectory.terminus.ancestors(including_self=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<|begin_of_text|>': 128000,\n",
       " '<|end_of_text|>': 128001,\n",
       " '<|im_start|>': 128002,\n",
       " '<|im_end|>': 128003,\n",
       " '<tool_call>': 128004,\n",
       " '<|reserved_special_token_3|>': 128005,\n",
       " '<|start_header_id|>': 128006,\n",
       " '<|end_header_id|>': 128007,\n",
       " '<tools>': 128008,\n",
       " '<|eot_id|>': 128009,\n",
       " '</tools>': 128010,\n",
       " '</tool_call>': 128011,\n",
       " '</tool_response>': 128012,\n",
       " '<|reserved_special_token_8|>': 128013,\n",
       " '<|reserved_special_token_9|>': 128014,\n",
       " '<|reserved_special_token_10|>': 128015,\n",
       " '<|reserved_special_token_11|>': 128016,\n",
       " '<|reserved_special_token_12|>': 128017,\n",
       " '<|reserved_special_token_13|>': 128018,\n",
       " '<|reserved_special_token_14|>': 128019,\n",
       " '<|reserved_special_token_15|>': 128020,\n",
       " '<|reserved_special_token_16|>': 128021,\n",
       " '<|reserved_special_token_17|>': 128022,\n",
       " '<|reserved_special_token_18|>': 128023,\n",
       " '<|reserved_special_token_19|>': 128024,\n",
       " '<|reserved_special_token_20|>': 128025,\n",
       " '<|reserved_special_token_21|>': 128026,\n",
       " '<|reserved_special_token_22|>': 128027,\n",
       " '<|reserved_special_token_23|>': 128028,\n",
       " '<|reserved_special_token_24|>': 128029,\n",
       " '<|reserved_special_token_25|>': 128030,\n",
       " '<|reserved_special_token_26|>': 128031,\n",
       " '<|reserved_special_token_27|>': 128032,\n",
       " '<|reserved_special_token_28|>': 128033,\n",
       " '<|reserved_special_token_29|>': 128034,\n",
       " '<|reserved_special_token_30|>': 128035,\n",
       " '<|reserved_special_token_31|>': 128036,\n",
       " '<|reserved_special_token_32|>': 128037,\n",
       " '<|reserved_special_token_33|>': 128038,\n",
       " '<|reserved_special_token_34|>': 128039,\n",
       " '<|reserved_special_token_35|>': 128040,\n",
       " '<|reserved_special_token_36|>': 128041,\n",
       " '<|reserved_special_token_37|>': 128042,\n",
       " '<|reserved_special_token_38|>': 128043,\n",
       " '<|reserved_special_token_39|>': 128044,\n",
       " '<|reserved_special_token_40|>': 128045,\n",
       " '<|reserved_special_token_41|>': 128046,\n",
       " '<|reserved_special_token_42|>': 128047,\n",
       " '<|reserved_special_token_43|>': 128048,\n",
       " '<|reserved_special_token_44|>': 128049,\n",
       " '<|reserved_special_token_45|>': 128050,\n",
       " '<|reserved_special_token_46|>': 128051,\n",
       " '<|reserved_special_token_47|>': 128052,\n",
       " '<|reserved_special_token_48|>': 128053,\n",
       " '<|reserved_special_token_49|>': 128054,\n",
       " '<|reserved_special_token_50|>': 128055,\n",
       " '<|reserved_special_token_51|>': 128056,\n",
       " '<|reserved_special_token_52|>': 128057,\n",
       " '<|reserved_special_token_53|>': 128058,\n",
       " '<|reserved_special_token_54|>': 128059,\n",
       " '<|reserved_special_token_55|>': 128060,\n",
       " '<|reserved_special_token_56|>': 128061,\n",
       " '<|reserved_special_token_57|>': 128062,\n",
       " '<|reserved_special_token_58|>': 128063,\n",
       " '<|reserved_special_token_59|>': 128064,\n",
       " '<|reserved_special_token_60|>': 128065,\n",
       " '<|reserved_special_token_61|>': 128066,\n",
       " '<|reserved_special_token_62|>': 128067,\n",
       " '<|reserved_special_token_63|>': 128068,\n",
       " '<|reserved_special_token_64|>': 128069,\n",
       " '<|reserved_special_token_65|>': 128070,\n",
       " '<|reserved_special_token_66|>': 128071,\n",
       " '<|reserved_special_token_67|>': 128072,\n",
       " '<|reserved_special_token_68|>': 128073,\n",
       " '<|reserved_special_token_69|>': 128074,\n",
       " '<|reserved_special_token_70|>': 128075,\n",
       " '<|reserved_special_token_71|>': 128076,\n",
       " '<|reserved_special_token_72|>': 128077,\n",
       " '<|reserved_special_token_73|>': 128078,\n",
       " '<|reserved_special_token_74|>': 128079,\n",
       " '<|reserved_special_token_75|>': 128080,\n",
       " '<|reserved_special_token_76|>': 128081,\n",
       " '<|reserved_special_token_77|>': 128082,\n",
       " '<|reserved_special_token_78|>': 128083,\n",
       " '<|reserved_special_token_79|>': 128084,\n",
       " '<|reserved_special_token_80|>': 128085,\n",
       " '<|reserved_special_token_81|>': 128086,\n",
       " '<|reserved_special_token_82|>': 128087,\n",
       " '<|reserved_special_token_83|>': 128088,\n",
       " '<|reserved_special_token_84|>': 128089,\n",
       " '<|reserved_special_token_85|>': 128090,\n",
       " '<|reserved_special_token_86|>': 128091,\n",
       " '<|reserved_special_token_87|>': 128092,\n",
       " '<|reserved_special_token_88|>': 128093,\n",
       " '<|reserved_special_token_89|>': 128094,\n",
       " '<|reserved_special_token_90|>': 128095,\n",
       " '<|reserved_special_token_91|>': 128096,\n",
       " '<|reserved_special_token_92|>': 128097,\n",
       " '<|reserved_special_token_93|>': 128098,\n",
       " '<|reserved_special_token_94|>': 128099,\n",
       " '<|reserved_special_token_95|>': 128100,\n",
       " '<|reserved_special_token_96|>': 128101,\n",
       " '<|reserved_special_token_97|>': 128102,\n",
       " '<|reserved_special_token_98|>': 128103,\n",
       " '<|reserved_special_token_99|>': 128104,\n",
       " '<|reserved_special_token_100|>': 128105,\n",
       " '<|reserved_special_token_101|>': 128106,\n",
       " '<|reserved_special_token_102|>': 128107,\n",
       " '<|reserved_special_token_103|>': 128108,\n",
       " '<|reserved_special_token_104|>': 128109,\n",
       " '<|reserved_special_token_105|>': 128110,\n",
       " '<|reserved_special_token_106|>': 128111,\n",
       " '<|reserved_special_token_107|>': 128112,\n",
       " '<|reserved_special_token_108|>': 128113,\n",
       " '<|reserved_special_token_109|>': 128114,\n",
       " '<|reserved_special_token_110|>': 128115,\n",
       " '<|reserved_special_token_111|>': 128116,\n",
       " '<|reserved_special_token_112|>': 128117,\n",
       " '<|reserved_special_token_113|>': 128118,\n",
       " '<|reserved_special_token_114|>': 128119,\n",
       " '<|reserved_special_token_115|>': 128120,\n",
       " '<|reserved_special_token_116|>': 128121,\n",
       " '<|reserved_special_token_117|>': 128122,\n",
       " '<|reserved_special_token_118|>': 128123,\n",
       " '<|reserved_special_token_119|>': 128124,\n",
       " '<|reserved_special_token_120|>': 128125,\n",
       " '<|reserved_special_token_121|>': 128126,\n",
       " '<|reserved_special_token_122|>': 128127,\n",
       " '<|reserved_special_token_123|>': 128128,\n",
       " '<|reserved_special_token_124|>': 128129,\n",
       " '<|reserved_special_token_125|>': 128130,\n",
       " '<|reserved_special_token_126|>': 128131,\n",
       " '<|reserved_special_token_127|>': 128132,\n",
       " '<|reserved_special_token_128|>': 128133,\n",
       " '<|reserved_special_token_129|>': 128134,\n",
       " '<|reserved_special_token_130|>': 128135,\n",
       " '<|reserved_special_token_131|>': 128136,\n",
       " '<|reserved_special_token_132|>': 128137,\n",
       " '<|reserved_special_token_133|>': 128138,\n",
       " '<|reserved_special_token_134|>': 128139,\n",
       " '<|reserved_special_token_135|>': 128140,\n",
       " '<|reserved_special_token_136|>': 128141,\n",
       " '<|reserved_special_token_137|>': 128142,\n",
       " '<|reserved_special_token_138|>': 128143,\n",
       " '<|reserved_special_token_139|>': 128144,\n",
       " '<|reserved_special_token_140|>': 128145,\n",
       " '<|reserved_special_token_141|>': 128146,\n",
       " '<|reserved_special_token_142|>': 128147,\n",
       " '<|reserved_special_token_143|>': 128148,\n",
       " '<|reserved_special_token_144|>': 128149,\n",
       " '<|reserved_special_token_145|>': 128150,\n",
       " '<|reserved_special_token_146|>': 128151,\n",
       " '<|reserved_special_token_147|>': 128152,\n",
       " '<|reserved_special_token_148|>': 128153,\n",
       " '<|reserved_special_token_149|>': 128154,\n",
       " '<|reserved_special_token_150|>': 128155,\n",
       " '<|reserved_special_token_151|>': 128156,\n",
       " '<|reserved_special_token_152|>': 128157,\n",
       " '<|reserved_special_token_153|>': 128158,\n",
       " '<|reserved_special_token_154|>': 128159,\n",
       " '<|reserved_special_token_155|>': 128160,\n",
       " '<|reserved_special_token_156|>': 128161,\n",
       " '<|reserved_special_token_157|>': 128162,\n",
       " '<|reserved_special_token_158|>': 128163,\n",
       " '<|reserved_special_token_159|>': 128164,\n",
       " '<|reserved_special_token_160|>': 128165,\n",
       " '<|reserved_special_token_161|>': 128166,\n",
       " '<|reserved_special_token_162|>': 128167,\n",
       " '<|reserved_special_token_163|>': 128168,\n",
       " '<|reserved_special_token_164|>': 128169,\n",
       " '<|reserved_special_token_165|>': 128170,\n",
       " '<|reserved_special_token_166|>': 128171,\n",
       " '<|reserved_special_token_167|>': 128172,\n",
       " '<|reserved_special_token_168|>': 128173,\n",
       " '<|reserved_special_token_169|>': 128174,\n",
       " '<|reserved_special_token_170|>': 128175,\n",
       " '<|reserved_special_token_171|>': 128176,\n",
       " '<|reserved_special_token_172|>': 128177,\n",
       " '<|reserved_special_token_173|>': 128178,\n",
       " '<|reserved_special_token_174|>': 128179,\n",
       " '<|reserved_special_token_175|>': 128180,\n",
       " '<|reserved_special_token_176|>': 128181,\n",
       " '<|reserved_special_token_177|>': 128182,\n",
       " '<|reserved_special_token_178|>': 128183,\n",
       " '<|reserved_special_token_179|>': 128184,\n",
       " '<|reserved_special_token_180|>': 128185,\n",
       " '<|reserved_special_token_181|>': 128186,\n",
       " '<|reserved_special_token_182|>': 128187,\n",
       " '<|reserved_special_token_183|>': 128188,\n",
       " '<|reserved_special_token_184|>': 128189,\n",
       " '<|reserved_special_token_185|>': 128190,\n",
       " '<|reserved_special_token_186|>': 128191,\n",
       " '<|reserved_special_token_187|>': 128192,\n",
       " '<|reserved_special_token_188|>': 128193,\n",
       " '<|reserved_special_token_189|>': 128194,\n",
       " '<|reserved_special_token_190|>': 128195,\n",
       " '<|reserved_special_token_191|>': 128196,\n",
       " '<|reserved_special_token_192|>': 128197,\n",
       " '<|reserved_special_token_193|>': 128198,\n",
       " '<|reserved_special_token_194|>': 128199,\n",
       " '<|reserved_special_token_195|>': 128200,\n",
       " '<|reserved_special_token_196|>': 128201,\n",
       " '<|reserved_special_token_197|>': 128202,\n",
       " '<|reserved_special_token_198|>': 128203,\n",
       " '<|reserved_special_token_199|>': 128204,\n",
       " '<|reserved_special_token_200|>': 128205,\n",
       " '<|reserved_special_token_201|>': 128206,\n",
       " '<|reserved_special_token_202|>': 128207,\n",
       " '<|reserved_special_token_203|>': 128208,\n",
       " '<|reserved_special_token_204|>': 128209,\n",
       " '<|reserved_special_token_205|>': 128210,\n",
       " '<|reserved_special_token_206|>': 128211,\n",
       " '<|reserved_special_token_207|>': 128212,\n",
       " '<|reserved_special_token_208|>': 128213,\n",
       " '<|reserved_special_token_209|>': 128214,\n",
       " '<|reserved_special_token_210|>': 128215,\n",
       " '<|reserved_special_token_211|>': 128216,\n",
       " '<|reserved_special_token_212|>': 128217,\n",
       " '<|reserved_special_token_213|>': 128218,\n",
       " '<|reserved_special_token_214|>': 128219,\n",
       " '<|reserved_special_token_215|>': 128220,\n",
       " '<|reserved_special_token_216|>': 128221,\n",
       " '<|reserved_special_token_217|>': 128222,\n",
       " '<|reserved_special_token_218|>': 128223,\n",
       " '<|reserved_special_token_219|>': 128224,\n",
       " '<|reserved_special_token_220|>': 128225,\n",
       " '<|reserved_special_token_221|>': 128226,\n",
       " '<|reserved_special_token_222|>': 128227,\n",
       " '<|reserved_special_token_223|>': 128228,\n",
       " '<|reserved_special_token_224|>': 128229,\n",
       " '<|reserved_special_token_225|>': 128230,\n",
       " '<|reserved_special_token_226|>': 128231,\n",
       " '<|reserved_special_token_227|>': 128232,\n",
       " '<|reserved_special_token_228|>': 128233,\n",
       " '<|reserved_special_token_229|>': 128234,\n",
       " '<|reserved_special_token_230|>': 128235,\n",
       " '<|reserved_special_token_231|>': 128236,\n",
       " '<|reserved_special_token_232|>': 128237,\n",
       " '<|reserved_special_token_233|>': 128238,\n",
       " '<|reserved_special_token_234|>': 128239,\n",
       " '<|reserved_special_token_235|>': 128240,\n",
       " '<|reserved_special_token_236|>': 128241,\n",
       " '<|reserved_special_token_237|>': 128242,\n",
       " '<|reserved_special_token_238|>': 128243,\n",
       " '<|reserved_special_token_239|>': 128244,\n",
       " '<|reserved_special_token_240|>': 128245,\n",
       " '<|reserved_special_token_241|>': 128246,\n",
       " '<|reserved_special_token_242|>': 128247,\n",
       " '<|reserved_special_token_243|>': 128248,\n",
       " '<|reserved_special_token_244|>': 128249,\n",
       " '<|reserved_special_token_245|>': 128250,\n",
       " '<|reserved_special_token_246|>': 128251,\n",
       " '<|reserved_special_token_247|>': 128252,\n",
       " '<|reserved_special_token_248|>': 128253,\n",
       " '<|reserved_special_token_249|>': 128254,\n",
       " '<|reserved_special_token_250|>': 128255,\n",
       " '<tool_response>': 128256}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.llm.get_tokenizer().added_tokens_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([        nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan,         nan,         nan,         nan,         nan,\n",
       "                nan, -3.6497e+00, -3.1466e-04, -9.6563e-02, -2.7550e-01,\n",
       "        -1.2978e-03, -3.5010e-01, -1.6010e-01, -8.9407e-06, -2.2817e-03,\n",
       "        -6.4924e-04, -2.8570e-01, -5.8760e-01, -1.5901e-01, -2.3262e+00,\n",
       "        -4.0812e-02, -8.0962e-02, -1.7855e-02, -1.0729e-05, -1.1056e+00,\n",
       "        -3.6298e-02, -7.1526e-07,  0.0000e+00, -3.3480e-04, -5.7025e-04,\n",
       "        -2.7774e-03, -2.1465e-01, -2.1096e-01, -2.9802e-06, -1.3161e-02,\n",
       "        -8.1914e-03, -6.3780e-04, -5.3653e-03, -1.8225e-02,  0.0000e+00,\n",
       "        -7.0080e-01, -2.5186e-02, -4.7684e-07, -3.5763e-07, -2.8345e-03,\n",
       "        -1.7881e-06, -2.5005e-02, -1.6956e-01, -3.4811e-01, -1.6212e-05,\n",
       "        -4.2954e-04, -1.2890e-02, -6.6472e-02, -6.3477e-03, -9.2013e-01,\n",
       "         0.0000e+00, -5.2194e-01, -3.1747e-02, -1.1921e-07,  0.0000e+00,\n",
       "        -3.0163e-03, -3.1740e-01, -8.1440e-01, -4.2530e-01, -4.7331e-01,\n",
       "        -2.2542e-01, -6.2432e-02, -1.6398e-01, -2.4278e+00, -8.5454e-01,\n",
       "        -4.3186e-01, -9.9878e-02, -3.0380e-01, -8.0101e-02, -1.2917e-01,\n",
       "        -1.5770e-04, -3.9845e-01, -7.9468e-01,  0.0000e+00,  0.0000e+00,\n",
       "        -1.3926e-01, -2.3036e-02, -5.5334e-01, -4.7684e-07, -2.3842e-07,\n",
       "        -9.2667e-01, -1.1158e+00, -4.5322e-01, -3.1069e-01, -1.0262e-02,\n",
       "        -1.0577e-02,  0.0000e+00,  0.0000e+00, -1.2587e-01, -2.8614e+00,\n",
       "        -2.3955e-01, -1.2391e+00, -6.5511e-01, -1.6609e-03, -1.9742e+00,\n",
       "        -8.3683e-01, -1.2511e+00, -6.1070e-01,  0.0000e+00, -1.9551e-02,\n",
       "        -7.2906e-04, -1.9415e-01, -1.1921e-07, -4.0186e-01, -9.2290e-01,\n",
       "        -4.7684e-07, -1.1427e-02, -2.9067e-01, -3.5763e-06, -9.4655e-04,\n",
       "        -6.6649e-02, -7.8793e-02,  0.0000e+00, -6.6238e-02, -2.0984e+00,\n",
       "        -2.2094e-01,  0.0000e+00, -1.7991e-02, -7.3251e-04,  0.0000e+00,\n",
       "        -5.5512e-04, -1.2664e-03,  0.0000e+00,  0.0000e+00, -3.9959e+00,\n",
       "        -1.0030e+00, -1.9451e-02, -3.4362e-01, -2.2553e-01, -1.8226e-01,\n",
       "        -2.4848e-03, -4.3491e-01, -6.7176e-04, -4.8843e-03, -6.5019e-04,\n",
       "        -4.6815e-02,  0.0000e+00, -6.5827e-03, -4.8080e-02, -4.7506e-04,\n",
       "        -1.1439e-02, -1.0108e-04,  0.0000e+00, -1.0154e-03, -5.9524e-02,\n",
       "        -1.1957e-02, -3.2361e-02, -8.0589e-01,  0.0000e+00, -1.3696e-04,\n",
       "        -7.2623e-02, -1.4429e-02, -1.0065e-03, -1.4452e+00,  0.0000e+00,\n",
       "        -8.4513e-03, -5.0039e-03, -3.0441e-04, -2.0299e-04, -5.9866e-02,\n",
       "         0.0000e+00,  0.0000e+00, -1.5500e-01, -1.5944e-01, -9.1594e-04,\n",
       "        -1.1921e-07,  0.0000e+00, -1.8358e-05, -1.9631e-03,  0.0000e+00,\n",
       "        -1.6212e-05, -6.8424e-05,  0.0000e+00,  0.0000e+00, -2.2359e-01,\n",
       "        -3.9255e-03, -2.6866e-04, -3.6785e-01, -8.6071e-01, -4.7004e-02,\n",
       "        -2.4199e-05, -2.4153e-01, -2.4626e-04, -1.7643e-05, -9.3857e-04,\n",
       "         0.0000e+00,  0.0000e+00, -3.7376e-03, -2.0955e-04, -1.2230e-04,\n",
       "        -1.6189e-03, -1.0133e-05,  0.0000e+00,  0.0000e+00, -2.1458e-06,\n",
       "        -5.8497e-03, -2.7532e-03, -2.0867e-02, -1.5606e+00,  0.0000e+00,\n",
       "        -1.3613e-04, -8.7734e-05, -8.3466e-03, -8.1161e-04, -2.1387e+00,\n",
       "         0.0000e+00, -2.3872e-01, -3.5481e-01, -8.0616e-03, -9.4587e-02,\n",
       "        -2.8805e-01, -2.4654e-01, -8.8458e-03, -5.1901e+00, -8.3348e-02,\n",
       "        -1.9465e-02, -2.1676e+00,  0.0000e+00, -5.4034e-02, -7.9638e-01,\n",
       "        -1.6495e+00, -1.2564e-04, -1.2236e-01,  0.0000e+00, -8.0386e-04,\n",
       "        -4.7684e-07, -3.5643e-05, -1.7804e-02, -8.3446e-07, -2.2650e-06,\n",
       "        -1.4608e-01, -2.2650e-06, -1.5974e-05, -5.6008e-03,  0.0000e+00,\n",
       "        -2.5163e-01,  0.0000e+00, -6.9258e-05, -3.6114e-04, -1.6457e+00,\n",
       "         0.0000e+00, -6.7568e-03,  0.0000e+00, -4.5895e-05, -5.8412e-06,\n",
       "        -1.1921e-07,  0.0000e+00, -1.7881e-06, -1.2278e-05, -3.5763e-07,\n",
       "        -8.3446e-07, -8.7700e-04,  0.0000e+00, -2.3842e-07, -5.9605e-07,\n",
       "        -5.3643e-05, -9.5410e-03, -1.2476e+00, -2.3304e-03, -1.0436e+00,\n",
       "        -5.5768e-02, -5.4424e-03, -9.4428e-02, -8.6158e-03, -4.4702e-05,\n",
       "        -4.3375e-02, -3.6902e-02, -5.0129e-02,  0.0000e+00, -2.6146e-02,\n",
       "        -9.3392e-02,  0.0000e+00, -9.7692e-04,  0.0000e+00, -4.6785e-03,\n",
       "        -1.1921e-07, -1.3165e-01,  0.0000e+00, -1.0087e-03,  0.0000e+00])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_token = \"<|reserved_special_token_250|>\"\n",
    "seqlen = 1000\n",
    "mask = tokenizer.encode(\n",
    "    [trajectory.terminus.all_message_params(replacement_token=replacement_token)],  # type: ignore\n",
    "    concatenate=True,\n",
    "    seqlen=seqlen,\n",
    ") == tokenizer.get_token_id(replacement_token)\n",
    "logprobs = torch.full_like(mask, fill_value=torch.nan, dtype=torch.float32)\n",
    "logprobs[mask] = torch.tensor(list(trajectory.terminus.all_logprobs())[:mask.sum()])\n",
    "logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(315)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([316])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(list(trajectory.terminus.all_logprobs())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{128000: AddedToken(\"<|begin_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128001: AddedToken(\"<|end_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128002: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128003: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128004: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " 128005: AddedToken(\"<|reserved_special_token_3|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " 128006: AddedToken(\"<|start_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128007: AddedToken(\"<|end_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128008: AddedToken(\"<tools>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " 128009: AddedToken(\"<|eot_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128010: AddedToken(\"</tools>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " 128011: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " 128012: AddedToken(\"</tool_response>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       " 128013: AddedToken(\"<|reserved_special_token_8|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128014: AddedToken(\"<|reserved_special_token_9|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128015: AddedToken(\"<|reserved_special_token_10|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128016: AddedToken(\"<|reserved_special_token_11|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128017: AddedToken(\"<|reserved_special_token_12|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128018: AddedToken(\"<|reserved_special_token_13|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128019: AddedToken(\"<|reserved_special_token_14|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128020: AddedToken(\"<|reserved_special_token_15|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128021: AddedToken(\"<|reserved_special_token_16|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128022: AddedToken(\"<|reserved_special_token_17|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128023: AddedToken(\"<|reserved_special_token_18|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128024: AddedToken(\"<|reserved_special_token_19|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128025: AddedToken(\"<|reserved_special_token_20|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128026: AddedToken(\"<|reserved_special_token_21|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128027: AddedToken(\"<|reserved_special_token_22|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128028: AddedToken(\"<|reserved_special_token_23|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128029: AddedToken(\"<|reserved_special_token_24|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128030: AddedToken(\"<|reserved_special_token_25|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128031: AddedToken(\"<|reserved_special_token_26|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128032: AddedToken(\"<|reserved_special_token_27|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128033: AddedToken(\"<|reserved_special_token_28|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128034: AddedToken(\"<|reserved_special_token_29|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128035: AddedToken(\"<|reserved_special_token_30|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128036: AddedToken(\"<|reserved_special_token_31|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128037: AddedToken(\"<|reserved_special_token_32|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128038: AddedToken(\"<|reserved_special_token_33|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128039: AddedToken(\"<|reserved_special_token_34|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128040: AddedToken(\"<|reserved_special_token_35|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128041: AddedToken(\"<|reserved_special_token_36|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128042: AddedToken(\"<|reserved_special_token_37|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128043: AddedToken(\"<|reserved_special_token_38|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128044: AddedToken(\"<|reserved_special_token_39|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128045: AddedToken(\"<|reserved_special_token_40|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128046: AddedToken(\"<|reserved_special_token_41|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128047: AddedToken(\"<|reserved_special_token_42|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128048: AddedToken(\"<|reserved_special_token_43|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128049: AddedToken(\"<|reserved_special_token_44|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128050: AddedToken(\"<|reserved_special_token_45|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128051: AddedToken(\"<|reserved_special_token_46|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128052: AddedToken(\"<|reserved_special_token_47|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128053: AddedToken(\"<|reserved_special_token_48|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128054: AddedToken(\"<|reserved_special_token_49|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128055: AddedToken(\"<|reserved_special_token_50|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128056: AddedToken(\"<|reserved_special_token_51|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128057: AddedToken(\"<|reserved_special_token_52|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128058: AddedToken(\"<|reserved_special_token_53|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128059: AddedToken(\"<|reserved_special_token_54|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128060: AddedToken(\"<|reserved_special_token_55|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128061: AddedToken(\"<|reserved_special_token_56|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128062: AddedToken(\"<|reserved_special_token_57|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128063: AddedToken(\"<|reserved_special_token_58|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128064: AddedToken(\"<|reserved_special_token_59|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128065: AddedToken(\"<|reserved_special_token_60|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128066: AddedToken(\"<|reserved_special_token_61|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128067: AddedToken(\"<|reserved_special_token_62|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128068: AddedToken(\"<|reserved_special_token_63|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128069: AddedToken(\"<|reserved_special_token_64|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128070: AddedToken(\"<|reserved_special_token_65|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128071: AddedToken(\"<|reserved_special_token_66|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128072: AddedToken(\"<|reserved_special_token_67|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128073: AddedToken(\"<|reserved_special_token_68|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128074: AddedToken(\"<|reserved_special_token_69|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128075: AddedToken(\"<|reserved_special_token_70|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128076: AddedToken(\"<|reserved_special_token_71|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128077: AddedToken(\"<|reserved_special_token_72|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128078: AddedToken(\"<|reserved_special_token_73|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128079: AddedToken(\"<|reserved_special_token_74|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128080: AddedToken(\"<|reserved_special_token_75|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128081: AddedToken(\"<|reserved_special_token_76|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128082: AddedToken(\"<|reserved_special_token_77|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128083: AddedToken(\"<|reserved_special_token_78|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128084: AddedToken(\"<|reserved_special_token_79|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128085: AddedToken(\"<|reserved_special_token_80|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128086: AddedToken(\"<|reserved_special_token_81|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128087: AddedToken(\"<|reserved_special_token_82|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128088: AddedToken(\"<|reserved_special_token_83|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128089: AddedToken(\"<|reserved_special_token_84|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128090: AddedToken(\"<|reserved_special_token_85|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128091: AddedToken(\"<|reserved_special_token_86|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128092: AddedToken(\"<|reserved_special_token_87|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128093: AddedToken(\"<|reserved_special_token_88|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128094: AddedToken(\"<|reserved_special_token_89|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128095: AddedToken(\"<|reserved_special_token_90|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128096: AddedToken(\"<|reserved_special_token_91|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128097: AddedToken(\"<|reserved_special_token_92|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128098: AddedToken(\"<|reserved_special_token_93|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128099: AddedToken(\"<|reserved_special_token_94|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128100: AddedToken(\"<|reserved_special_token_95|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128101: AddedToken(\"<|reserved_special_token_96|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128102: AddedToken(\"<|reserved_special_token_97|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128103: AddedToken(\"<|reserved_special_token_98|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128104: AddedToken(\"<|reserved_special_token_99|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128105: AddedToken(\"<|reserved_special_token_100|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128106: AddedToken(\"<|reserved_special_token_101|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128107: AddedToken(\"<|reserved_special_token_102|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128108: AddedToken(\"<|reserved_special_token_103|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128109: AddedToken(\"<|reserved_special_token_104|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128110: AddedToken(\"<|reserved_special_token_105|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128111: AddedToken(\"<|reserved_special_token_106|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128112: AddedToken(\"<|reserved_special_token_107|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128113: AddedToken(\"<|reserved_special_token_108|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128114: AddedToken(\"<|reserved_special_token_109|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128115: AddedToken(\"<|reserved_special_token_110|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128116: AddedToken(\"<|reserved_special_token_111|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128117: AddedToken(\"<|reserved_special_token_112|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128118: AddedToken(\"<|reserved_special_token_113|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128119: AddedToken(\"<|reserved_special_token_114|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128120: AddedToken(\"<|reserved_special_token_115|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128121: AddedToken(\"<|reserved_special_token_116|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128122: AddedToken(\"<|reserved_special_token_117|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128123: AddedToken(\"<|reserved_special_token_118|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128124: AddedToken(\"<|reserved_special_token_119|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128125: AddedToken(\"<|reserved_special_token_120|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128126: AddedToken(\"<|reserved_special_token_121|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128127: AddedToken(\"<|reserved_special_token_122|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128128: AddedToken(\"<|reserved_special_token_123|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128129: AddedToken(\"<|reserved_special_token_124|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128130: AddedToken(\"<|reserved_special_token_125|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128131: AddedToken(\"<|reserved_special_token_126|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128132: AddedToken(\"<|reserved_special_token_127|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128133: AddedToken(\"<|reserved_special_token_128|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128134: AddedToken(\"<|reserved_special_token_129|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128135: AddedToken(\"<|reserved_special_token_130|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128136: AddedToken(\"<|reserved_special_token_131|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128137: AddedToken(\"<|reserved_special_token_132|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128138: AddedToken(\"<|reserved_special_token_133|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128139: AddedToken(\"<|reserved_special_token_134|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128140: AddedToken(\"<|reserved_special_token_135|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128141: AddedToken(\"<|reserved_special_token_136|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128142: AddedToken(\"<|reserved_special_token_137|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128143: AddedToken(\"<|reserved_special_token_138|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128144: AddedToken(\"<|reserved_special_token_139|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128145: AddedToken(\"<|reserved_special_token_140|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128146: AddedToken(\"<|reserved_special_token_141|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128147: AddedToken(\"<|reserved_special_token_142|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128148: AddedToken(\"<|reserved_special_token_143|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128149: AddedToken(\"<|reserved_special_token_144|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128150: AddedToken(\"<|reserved_special_token_145|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128151: AddedToken(\"<|reserved_special_token_146|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128152: AddedToken(\"<|reserved_special_token_147|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128153: AddedToken(\"<|reserved_special_token_148|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128154: AddedToken(\"<|reserved_special_token_149|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128155: AddedToken(\"<|reserved_special_token_150|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128156: AddedToken(\"<|reserved_special_token_151|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128157: AddedToken(\"<|reserved_special_token_152|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128158: AddedToken(\"<|reserved_special_token_153|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128159: AddedToken(\"<|reserved_special_token_154|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128160: AddedToken(\"<|reserved_special_token_155|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128161: AddedToken(\"<|reserved_special_token_156|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128162: AddedToken(\"<|reserved_special_token_157|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128163: AddedToken(\"<|reserved_special_token_158|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128164: AddedToken(\"<|reserved_special_token_159|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128165: AddedToken(\"<|reserved_special_token_160|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128166: AddedToken(\"<|reserved_special_token_161|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128167: AddedToken(\"<|reserved_special_token_162|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128168: AddedToken(\"<|reserved_special_token_163|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128169: AddedToken(\"<|reserved_special_token_164|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128170: AddedToken(\"<|reserved_special_token_165|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128171: AddedToken(\"<|reserved_special_token_166|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128172: AddedToken(\"<|reserved_special_token_167|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128173: AddedToken(\"<|reserved_special_token_168|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128174: AddedToken(\"<|reserved_special_token_169|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128175: AddedToken(\"<|reserved_special_token_170|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128176: AddedToken(\"<|reserved_special_token_171|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128177: AddedToken(\"<|reserved_special_token_172|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128178: AddedToken(\"<|reserved_special_token_173|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128179: AddedToken(\"<|reserved_special_token_174|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128180: AddedToken(\"<|reserved_special_token_175|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128181: AddedToken(\"<|reserved_special_token_176|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128182: AddedToken(\"<|reserved_special_token_177|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128183: AddedToken(\"<|reserved_special_token_178|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128184: AddedToken(\"<|reserved_special_token_179|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128185: AddedToken(\"<|reserved_special_token_180|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128186: AddedToken(\"<|reserved_special_token_181|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128187: AddedToken(\"<|reserved_special_token_182|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128188: AddedToken(\"<|reserved_special_token_183|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128189: AddedToken(\"<|reserved_special_token_184|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128190: AddedToken(\"<|reserved_special_token_185|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128191: AddedToken(\"<|reserved_special_token_186|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128192: AddedToken(\"<|reserved_special_token_187|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128193: AddedToken(\"<|reserved_special_token_188|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128194: AddedToken(\"<|reserved_special_token_189|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128195: AddedToken(\"<|reserved_special_token_190|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128196: AddedToken(\"<|reserved_special_token_191|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128197: AddedToken(\"<|reserved_special_token_192|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128198: AddedToken(\"<|reserved_special_token_193|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128199: AddedToken(\"<|reserved_special_token_194|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128200: AddedToken(\"<|reserved_special_token_195|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128201: AddedToken(\"<|reserved_special_token_196|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128202: AddedToken(\"<|reserved_special_token_197|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128203: AddedToken(\"<|reserved_special_token_198|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128204: AddedToken(\"<|reserved_special_token_199|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128205: AddedToken(\"<|reserved_special_token_200|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128206: AddedToken(\"<|reserved_special_token_201|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128207: AddedToken(\"<|reserved_special_token_202|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128208: AddedToken(\"<|reserved_special_token_203|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128209: AddedToken(\"<|reserved_special_token_204|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128210: AddedToken(\"<|reserved_special_token_205|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128211: AddedToken(\"<|reserved_special_token_206|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128212: AddedToken(\"<|reserved_special_token_207|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128213: AddedToken(\"<|reserved_special_token_208|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128214: AddedToken(\"<|reserved_special_token_209|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128215: AddedToken(\"<|reserved_special_token_210|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128216: AddedToken(\"<|reserved_special_token_211|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128217: AddedToken(\"<|reserved_special_token_212|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128218: AddedToken(\"<|reserved_special_token_213|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128219: AddedToken(\"<|reserved_special_token_214|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128220: AddedToken(\"<|reserved_special_token_215|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128221: AddedToken(\"<|reserved_special_token_216|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128222: AddedToken(\"<|reserved_special_token_217|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128223: AddedToken(\"<|reserved_special_token_218|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128224: AddedToken(\"<|reserved_special_token_219|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128225: AddedToken(\"<|reserved_special_token_220|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128226: AddedToken(\"<|reserved_special_token_221|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128227: AddedToken(\"<|reserved_special_token_222|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128228: AddedToken(\"<|reserved_special_token_223|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128229: AddedToken(\"<|reserved_special_token_224|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128230: AddedToken(\"<|reserved_special_token_225|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128231: AddedToken(\"<|reserved_special_token_226|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128232: AddedToken(\"<|reserved_special_token_227|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128233: AddedToken(\"<|reserved_special_token_228|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128234: AddedToken(\"<|reserved_special_token_229|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128235: AddedToken(\"<|reserved_special_token_230|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128236: AddedToken(\"<|reserved_special_token_231|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128237: AddedToken(\"<|reserved_special_token_232|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128238: AddedToken(\"<|reserved_special_token_233|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128239: AddedToken(\"<|reserved_special_token_234|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128240: AddedToken(\"<|reserved_special_token_235|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128241: AddedToken(\"<|reserved_special_token_236|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128242: AddedToken(\"<|reserved_special_token_237|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128243: AddedToken(\"<|reserved_special_token_238|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128244: AddedToken(\"<|reserved_special_token_239|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128245: AddedToken(\"<|reserved_special_token_240|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128246: AddedToken(\"<|reserved_special_token_241|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128247: AddedToken(\"<|reserved_special_token_242|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128248: AddedToken(\"<|reserved_special_token_243|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128249: AddedToken(\"<|reserved_special_token_244|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128250: AddedToken(\"<|reserved_special_token_245|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128251: AddedToken(\"<|reserved_special_token_246|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128252: AddedToken(\"<|reserved_special_token_247|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128253: AddedToken(\"<|reserved_special_token_248|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128254: AddedToken(\"<|reserved_special_token_249|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128255: AddedToken(\"<|reserved_special_token_250|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       " 128256: AddedToken(\"<tool_response>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False)}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.llm.get_tokenizer().added_tokens_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128255]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.llm.get_tokenizer().encode(\"<|reserved_special_token_250|>\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335 ns ± 6.33 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\"<|reserved_special_token_250|>\" * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([128000, 128000, 128002,    882,    198, 128255,  66294,     11])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode([{\"role\": param[\"role\"], \"content\": param[\"content\"].replace(\"On a cool spring day\", \"<|reserved_special_token_250|>\")} for param in trajectory.terminus.all_message_params()])[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><|begin_of_text|><|im_start|>user\\n'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(trajectory.terminus.all_message_params(), continue_final_message=False)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Request(BaseModel):\n",
    "    tokens_filename: str\n",
    "    advantages_filename: str\n",
    "    logprobs_filename: str\n",
    "    rows: int\n",
    "    seqlen: int\n",
    "    start: int\n",
    "    stop: int\n",
    "\n",
    "\n",
    "def handle_request(request: Request) -> None:\n",
    "    tokens = torch.from_file(\n",
    "        request.tokens_filename,\n",
    "        shared=True,\n",
    "        size=request.rows * request.seqlen,\n",
    "        dtype=torch.int64,\n",
    "    ).view(-1, request.seqlen)\n",
    "    advantages = torch.from_file(\n",
    "        request.advantages_filename,\n",
    "        shared=True,\n",
    "        size=request.rows * request.seqlen,\n",
    "        dtype=torch.float32,\n",
    "    ).view(-1, request.seqlen)\n",
    "    logprobs = torch.from_file(\n",
    "        request.logprobs_filename,\n",
    "        shared=True,\n",
    "        size=request.rows * request.seqlen,\n",
    "        dtype=torch.float32,\n",
    "    ).view(-1, request.seqlen)\n",
    "    trajectories = sorted(\n",
    "        (best_trajectory(episode) for episode in buffer),\n",
    "        key=lambda t: t.score(),\n",
    "        reverse=True,\n",
    "    )\n",
    "    for row in range(request.start, request.stop):\n",
    "        selected_trajectories: list[Trajectory] = []\n",
    "        for i in range(0, len(trajectories), -1):\n",
    "            if (\n",
    "                trajectories[i].token_count\n",
    "                + sum(t.token_count for t in selected_trajectories)\n",
    "                > request.seqlen\n",
    "            ):\n",
    "                continue\n",
    "            selected_trajectories.append(trajectories.pop(i))\n",
    "        tokens[row] = tokenizer.encode(\n",
    "            [\n",
    "                trajectory.terminus.all_message_params()\n",
    "                for trajectory in selected_trajectories\n",
    "            ],  # type: ignore\n",
    "            concatenate=True,\n",
    "            seqlen=request.seqlen,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
