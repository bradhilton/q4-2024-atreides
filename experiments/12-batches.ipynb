{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:\n",
      "No module named 'vllm._version'\n",
      "  from vllm.version import __version__ as VLLM_VERSION\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b7f7b418914e1a960fd650bcd12ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/716 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:\n",
      "No module named 'vllm._version'\n",
      "  from vllm.version import __version__ as VLLM_VERSION\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f17d4afdf3421380b36042d7cd4aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/56.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d618402bbbe4ba9a8fe88c032786ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a95ec4020a044e3a8634f4e1fcdb1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/444 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  1.56it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.29it/s]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.69it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.56it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.54it/s]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.vllm import start_vllm_server, vllm_server_metrics\n",
    "\n",
    "model = \"NousResearch/Hermes-2-Theta-Llama-3-8B\"\n",
    "\n",
    "shutdown_server, client = await start_vllm_server(\n",
    "    disable_log_requests=True,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m black_print\n\u001b[1;32m      3\u001b[0m black_print(\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      5\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      6\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      7\u001b[0m             {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMy favorite color is\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      8\u001b[0m         ],\n\u001b[1;32m      9\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     10\u001b[0m         extra_body\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd_generation_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinue_final_message\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;66;03m# \"guided_regex\": r\" blue\",\u001b[39;00m\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;66;03m# \"guided_decoding_backend\": \"lm-format-enforcer\",\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         },\n\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py:1633\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1594\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1595\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1630\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m   1631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m AsyncStream[ChatCompletionChunk]:\n\u001b[1;32m   1632\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m   1634\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1635\u001b[0m         body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[1;32m   1636\u001b[0m             {\n\u001b[1;32m   1637\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m   1638\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m   1639\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[1;32m   1640\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[1;32m   1641\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[1;32m   1642\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[1;32m   1643\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[1;32m   1644\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[1;32m   1645\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[1;32m   1646\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[1;32m   1647\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m   1648\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[1;32m   1649\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[1;32m   1650\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[1;32m   1651\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[1;32m   1652\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m   1653\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[1;32m   1654\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[1;32m   1655\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[1;32m   1656\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[1;32m   1657\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[1;32m   1658\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[1;32m   1659\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m   1660\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[1;32m   1661\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m   1662\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[1;32m   1663\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m   1664\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[1;32m   1665\u001b[0m             },\n\u001b[1;32m   1666\u001b[0m             completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[1;32m   1667\u001b[0m         ),\n\u001b[1;32m   1668\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m   1669\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1670\u001b[0m         ),\n\u001b[1;32m   1671\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[1;32m   1672\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1673\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n\u001b[1;32m   1674\u001b[0m     )\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/openai/_base_client.py:1838\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1824\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1825\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1826\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1833\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1834\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[1;32m   1835\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1836\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1837\u001b[0m     )\n\u001b[0;32m-> 1838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/openai/_base_client.py:1532\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1533\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1534\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1535\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1536\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1537\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1538\u001b[0m )\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/openai/_base_client.py:1571\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[0;34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[0m\n\u001b[1;32m   1568\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_auth\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1571\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[1;32m   1572\u001b[0m         request,\n\u001b[1;32m   1573\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1575\u001b[0m     )\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1577\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/httpx/_client.py:1674\u001b[0m, in \u001b[0;36mAsyncClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m   1672\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m-> 1674\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[1;32m   1675\u001b[0m     request,\n\u001b[1;32m   1676\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[1;32m   1677\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1678\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[1;32m   1679\u001b[0m )\n\u001b[1;32m   1680\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/httpx/_client.py:1702\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m   1699\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m auth_flow\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__anext__\u001b[39m()\n\u001b[1;32m   1701\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1702\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[1;32m   1703\u001b[0m         request,\n\u001b[1;32m   1704\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[1;32m   1705\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m   1706\u001b[0m     )\n\u001b[1;32m   1707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/httpx/_client.py:1739\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m   1736\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[0;32m-> 1739\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[1;32m   1740\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1741\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/httpx/_client.py:1776\u001b[0m, in \u001b[0;36mAsyncClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1772\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1773\u001b[0m     )\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1776\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m transport\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, AsyncByteStream)\n\u001b[1;32m   1779\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:377\u001b[0m, in \u001b[0;36mAsyncHTTPTransport.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    364\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    365\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    366\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    375\u001b[0m )\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 377\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_async_request(req)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mAsyncIterable)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    382\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    383\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    384\u001b[0m     stream\u001b[38;5;241m=\u001b[39mAsyncResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    385\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    386\u001b[0m )\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py:216\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, AsyncIterable)\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py:196\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mhandle_async_request(\n\u001b[1;32m    197\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py:101\u001b[0m, in \u001b[0;36mAsyncHTTPConnection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:143\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:113\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection.handle_async_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:186\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_event(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py:224\u001b[0m, in \u001b[0;36mAsyncHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\u001b[38;5;241m.\u001b[39mread(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREAD_NUM_BYTES, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/httpcore/_backends/anyio.py:35\u001b[0m, in \u001b[0;36mAnyIOStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39mfail_after(timeout):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39mreceive(max_bytes\u001b[38;5;241m=\u001b[39mmax_bytes)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39mEndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py:1198\u001b[0m, in \u001b[0;36mSocketStream.receive\u001b[0;34m(self, max_bytes)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mread_event\u001b[38;5;241m.\u001b[39mis_set()\n\u001b[1;32m   1194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mis_closing()\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mis_at_eof\n\u001b[1;32m   1196\u001b[0m ):\n\u001b[1;32m   1197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mresume_reading()\n\u001b[0;32m-> 1198\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\u001b[38;5;241m.\u001b[39mread_event\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m   1199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport\u001b[38;5;241m.\u001b[39mpause_reading()\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.12.7-linux-x86_64-gnu/lib/python3.12/asyncio/locks.py:212\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiters\u001b[38;5;241m.\u001b[39mappend(fut)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.12.7-linux-x86_64-gnu/lib/python3.12/asyncio/futures.py:291\u001b[0m, in \u001b[0;36mFuture.__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_asyncio_future_blocking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawait wasn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt used with future\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.12.7-linux-x86_64-gnu/lib/python3.12/asyncio/tasks.py:385\u001b[0m, in \u001b[0;36mTask.__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 385\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__step(exc)\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.12.7-linux-x86_64-gnu/lib/python3.12/asyncio/futures.py:198\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m _CANCELLED:\n\u001b[1;32m    197\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_cancelled_error()\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m!=\u001b[39m _FINISHED:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mInvalidStateError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResult is not ready.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from lib.utils import black_print\n",
    "\n",
    "black_print(\n",
    "    await client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"My favorite color is\"},\n",
    "        ],\n",
    "        model=model,\n",
    "        extra_body={\n",
    "            \"add_generation_prompt\": False,\n",
    "            \"continue_final_message\": True,\n",
    "            # \"guided_regex\": r\" blue\",\n",
    "            # \"guided_decoding_backend\": \"lm-format-enforcer\",\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from lib.clue import Clue, DeductiveSolver\n",
    "from lib.rl import (\n",
    "    Completion,\n",
    "    CompletionSampler,\n",
    "    Episode,\n",
    "    EpisodeBuffer,\n",
    "    EpisodeSampler,\n",
    "    EpisodeSamplerRouter,\n",
    ")\n",
    "from lib.tokenizer import Tokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shutdown_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random_episode() -> Episode:\n",
    "    game = Clue(\n",
    "        num_players=3,\n",
    "        elements={\n",
    "            \"suspect\": Clue.suspects[:3],\n",
    "            \"weapon\": Clue.weapons[:3],\n",
    "            \"room\": Clue.rooms[:3],\n",
    "            # \"motive\": Clue.motives[:6],\n",
    "            # \"time\": Clue.get_times(\"21:00\", \"03:00\", \"1h\"),\n",
    "        },\n",
    "    )\n",
    "    game.play(\n",
    "        deductive_solver=DeductiveSolver(\n",
    "            # note_cards_in_hand=False,\n",
    "            # note_responses_to_suggestions=False,\n",
    "            # note_cards_that_players_do_not_have=False,\n",
    "            # check_unique_card_placement_constraints=False,\n",
    "            # check_player_hand_size_constraints=False,\n",
    "            check_solution_has_one_and_only_one_card_per_element=False,\n",
    "            check_one_of_constraints=False,\n",
    "            check_inverse_one_of_constraints=False,\n",
    "            merge_and_check_disjoint_inverse_one_of_constraints=False,\n",
    "            exhaustively_test_possible_assignments=False,\n",
    "        ),\n",
    "        cp_solver_max_solve_time_per_turn=0.05,\n",
    "        check_cp_solver_grid=False,\n",
    "        check_if_deductive_solver_and_cp_solver_grids_match=False,\n",
    "        print_playthrough=False,\n",
    "    )\n",
    "    prompt = game.get_prompt()\n",
    "    follow_up = \"Fill out your answer like this:\\n\" + \"\\n\".join(\n",
    "        f\"{element.capitalize()}: <#{element.upper()}#>\" for element in game.elements\n",
    "    )\n",
    "\n",
    "    async def reward_completion(completion: Completion) -> None:\n",
    "        chat_completion = await client.chat.completions.create(\n",
    "            messages=completion.all_message_params()\n",
    "            + [\n",
    "                {\"role\": \"user\", \"content\": follow_up},\n",
    "            ],\n",
    "            model=model,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        answer = chat_completion.choices[0].message.content\n",
    "        assert answer\n",
    "        completion.reward = sum(\n",
    "            [\n",
    "                bool(\n",
    "                    re.search(\n",
    "                        f\"{element}: {solution}\",\n",
    "                        answer,\n",
    "                        re.IGNORECASE,\n",
    "                    )\n",
    "                )\n",
    "                for element, solution in game.solution.items()\n",
    "            ]\n",
    "        ) / len(game.solution)\n",
    "\n",
    "    async def on_sample(completions: list[Completion]) -> None:\n",
    "        await asyncio.gather(\n",
    "            *[reward_completion(completion) for completion in completions]\n",
    "        )\n",
    "        for completion in completions:\n",
    "            completion.commit()\n",
    "\n",
    "    return Episode(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        on_sample=on_sample,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n",
      "<class 'ValueError'> max() iterable argument is empty\n"
     ]
    }
   ],
   "source": [
    "completion_sampler = CompletionSampler(\n",
    "    client,\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "tokenizer = Tokenizer(model)\n",
    "\n",
    "episode_buffer = EpisodeBuffer(\n",
    "    episode_sampler_router=EpisodeSamplerRouter(\n",
    "        EpisodeSampler(sample_random_episode),\n",
    "        exploitation_factor=1.0,\n",
    "        min_random_episode_sample_probability_half_life=40,\n",
    "    ),\n",
    "    completion_sampler=completion_sampler,\n",
    "    tokenizer=tokenizer,\n",
    "    branch_factor=5,\n",
    "    split_method=\"prob\",\n",
    "    split_separators={\"\\n\"},\n",
    "    size=64,\n",
    "    episode_decay=0.7,\n",
    "    completion_decay=0.7,\n",
    "    fork_decay=1.0,\n",
    "    start_buffering=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4, 0, 0, 0, 2, 0], array([4, 4, 4, 4, 6, 6]), 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "def _split_weights(separators: set[str]):\n",
    "    weight = 0\n",
    "    n = 0\n",
    "    for sequence in [\"Hi\\n\\nSo\"]:\n",
    "        separator = True\n",
    "        for char in sequence:\n",
    "            if (\n",
    "                separator\n",
    "                and n\n",
    "                and (separators is None or not char in separators)\n",
    "            ):\n",
    "                yield weight\n",
    "                yield from (0 for _ in range(n - 1))\n",
    "                weight = 0\n",
    "                n = 0\n",
    "            weight += 1\n",
    "            n += 1\n",
    "            separator = separators is None or char in separators\n",
    "    if n:\n",
    "        yield weight\n",
    "        yield from (0 for _ in range(n - 1))\n",
    "\n",
    "weights = list(_split_weights({\"\\n\"}))\n",
    "cumsum = numpy.cumsum(weights)\n",
    "split = numpy.searchsorted(cumsum, max(cumsum[-1] / 2, cumsum[0]), side=\"right\")\n",
    "weights, cumsum, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_buffer.split_method = \"prob\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_buffer.start_buffering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_buffer.stop_buffering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running/Pending/HWM vLLM Requests: 83/10/130\n",
      "Number of Episodes: 64\n",
      "Pending Tasks: 63\n",
      "Sampled Completions: 2668\n",
      "Average Absolute Advantage Per Token: 0.0006680232327741218\n"
     ]
    }
   ],
   "source": [
    "running, pending = vllm_server_metrics()\n",
    "print(f\"Running/Pending/HWM vLLM Requests: {running}/{pending}/{episode_buffer.max_running_requests}\")\n",
    "print(\"Number of Episodes:\", len(episode_buffer.episodes))\n",
    "print(\n",
    "    \"Pending Tasks:\",\n",
    "    sum(task._state == \"PENDING\" for task in episode_buffer.tasks.values()),\n",
    ")\n",
    "print(\n",
    "    \"Sampled Completions:\",\n",
    "    sum(episode.num_samples() for episode in episode_buffer.episodes),\n",
    ")\n",
    "print(\n",
    "    \"Average Absolute Advantage Per Token:\",\n",
    "    sum(\n",
    "        episode.best_leaf(tokenizer, split_method=\"count\").all_abs_advantage_per_token(tokenizer)\n",
    "        for episode in episode_buffer.episodes\n",
    "    )\n",
    "    / max(len(episode_buffer.episodes), 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"white-space: pre-wrap\"><b>User</b>:\n",
       "On a warm autumn morning Melissa, Brady, and Jordyn and sat down to play a casual sleuthing game.\n",
       "\n",
       "They assembled 3 decks of cards, each for a different type of information composed of the following:\n",
       "\n",
       "Suspect:\n",
       "- Miss Scarlet\n",
       "- Mr. Green\n",
       "- Mrs. White\n",
       "\n",
       "Weapon:\n",
       "- Candlestick\n",
       "- Knife\n",
       "- Lead Pipe\n",
       "\n",
       "Room:\n",
       "- Hall\n",
       "- Lounge\n",
       "- Dining Room\n",
       "\n",
       "After randomly (and blindly) choosing one card from each deck and placing them in the middle of the table facedown, they shuffled the remaining cards and dealt out the following to each player:\n",
       "\n",
       "- Melissa: 2 cards (Lounge and Candlestick)\n",
       "- Brady: 2 cards\n",
       "- Jordyn: 2 cards\n",
       "\n",
       "The game proceeded as follows:\n",
       "\n",
       "1. On their turn, a player asked about a set of exactly 3 cards, one from each of the game's categories. (Note: Players could ask about any cards, including those in their own hand.)\n",
       "2. The player directed this question to the other players in clockwise order, starting with the player to their left.\n",
       "3. If a player had one or more of the asked-about cards, they had to show one of those cards (of their choice) to the asking player privately. The turn then ended, and play passed to the next player.\n",
       "4. If a player did not have any of the asked-about cards, they said so, and the question passed to the next player in clockwise order.\n",
       "5. This continued until either:\n",
       "a) A player showed a card to the asking player, or\n",
       "b) All the queried players had stated they didn't have any of the asked-about cards.\n",
       "6. After a player's turn ended (either by being shown a card or having all queried players pass), play moved to the next player in clockwise order.\n",
       "\n",
       "Here is how the game played out:\n",
       "\n",
       "Melissa asked if anyone had Mr. Green or the Candlestick or the Lounge:\n",
       "- Brady did not have any of the cards\n",
       "- Jordyn showed Melissa Mr. Green\n",
       "\n",
       "Brady asked if anyone had Mrs. White or the Candlestick or the Lounge:\n",
       "- Jordyn did not have any of the cards\n",
       "- Melissa showed Brady the Lounge\n",
       "\n",
       "Jordyn asked if anyone had Miss Scarlet or the Lead Pipe or the Lounge:\n",
       "- Melissa showed Jordyn the Lounge\n",
       "\n",
       "Melissa asked if anyone had Miss Scarlet or the Lead Pipe or the Hall:\n",
       "- Brady showed Melissa Miss Scarlet\n",
       "\n",
       "Brady asked if anyone had Mrs. White or the Knife or the Dining Room:\n",
       "- Jordyn did not have any of the cards\n",
       "- Melissa did not have any of the cards\n",
       "\n",
       "Jordyn asked if anyone had Mrs. White or the Knife or the Dining Room:\n",
       "- Melissa did not have any of the cards\n",
       "- Brady did not have any of the cards\n",
       "\n",
       "At this point, Melissa was able to correctly deduce the solution and win the game.\n",
       "\n",
       "What were the facedown cards in the center of the table?\n",
       "\n",
       "<b>Assistant</b>:\n",
       "<span style='background-color: rgba(255,0,0, 0.07852043010752689);'>Let's analyze the information we have:\n",
       "\n",
       "1. Melissa saw Mr. Green. Since she has the Lounge and Candlestick, she doesn't have the third card, which must be either the Hall or the Lead Pipe. If she had the Hall, Brady would have shown it when asked about Miss Scarlet, Knife, and Dining Room. So, Melissa has the Lead Pipe.\n",
       "\n",
       "2. Brady saw Melissa's Lounge. Since he has two cards left, and Melissa has shown the Lead Pipe, Brady must have the Knife and the third card, which is the Dining Room.\n",
       "\n",
       "3. Jordyn saw Melissa's Lounge and Brady's Miss Scarlet. Since Jordyn has two cards left, and Melissa has shown the Lead Pipe, and Brady has shown the Dining Room, Jordyn must have Mrs. White and the Candlestick.\n",
       "\n",
       "Now, let's reveal the facedown cards in the center of the table:\n",
       "\n",
       "Suspect: Miss Scarlet\n",
       "</span><span style='background-color: rgba(0,0,255, 0.21139393939393938);'> (Brady)\n",
       "Weapon: Knife (Brady)\n",
       "Room: Hall (Melissa)\n",
       "\n",
       "The final layout of the cards:\n",
       "\n",
       "Melissa: Lead Pipe, Lounge\n",
       "</span><span style='background-color: rgba(255,0,0, 0.12444444444444441);'>Brady: Miss Scarlet, Dining Room\n",
       "</span><span style='background-color: rgba(255,0,0, 0.10666666666666663);'>Jordyn: Mrs. White, Candlestick\n",
       "\n",
       "The facedown cards in the center of the table are:\n",
       "\n",
       "Suspect: Mr. Green\n",
       "</span><span style='background-color: rgba(0,0,255, 0.72);'>Weapon: Candlestick\n",
       "</span><span style='background-color: rgba(255,0,0, 2.0);'>Room: Hall</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Trajectory:\n",
    "    episode: Episode\n",
    "    terminus: Completion\n",
    "    abs_advantage: float\n",
    "    token_count: int\n",
    "\n",
    "    def __init__(\n",
    "        self, episode: Episode, terminus: Completion, tokenizer: Tokenizer\n",
    "    ) -> None:\n",
    "        self.episode = episode\n",
    "        self.terminus = terminus\n",
    "        self.abs_advantage = self.terminus.all_abs_advantage()\n",
    "        self.token_count = self.terminus.all_token_count(tokenizer)\n",
    "\n",
    "    def score(self) -> float:\n",
    "        return self.episode.weight * self.abs_advantage / self.token_count\n",
    "\n",
    "\n",
    "def sorted_trajectories() -> list[Trajectory]:\n",
    "    return sorted(\n",
    "        (\n",
    "            Trajectory(\n",
    "                episode=episode,\n",
    "                terminus=episode.best_leaf(\n",
    "                    tokenizer, split_method=episode_buffer.split_method\n",
    "                ),\n",
    "                tokenizer=tokenizer,\n",
    "            )\n",
    "            for episode in episode_buffer.episodes\n",
    "        ),\n",
    "        key=lambda trajectory: trajectory.score(),\n",
    "    )\n",
    "\n",
    "\n",
    "best_trajectory = sorted_trajectories()[-3]\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML(f'<div style=\"white-space: pre-wrap\">{best_trajectory.terminus.html(30.0)}</div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the game play:\n",
      "\n",
      "1. Skylar asked about Miss Scarlet, Knife, and Dining Room. Jeremy showed a card, so he must have had one of these cards.\n",
      "2. Jeremy asked about Miss Scarlet, Lead Pipe, and Dining Room. Alex did not have any of these cards, so he cannot have the Dining Room card. Skylar showed a card, so he must have had the Dining Room card.\n",
      "3. Alex asked about Miss Scarlet, Candlestick, and Hall. Skylar did not have any of these cards, so he cannot have the Miss Scarlet or Candlestick cards. Jeremy showed Miss Scarlet, so he must have had Miss Scarlet and Candlestick cards.\n",
      "4. Skylar asked about Mr. Green, Knife, and Dining Room. Jeremy showed a card, so he must have had one of these cards.\n",
      "5. Jeremy asked about Mr. Green, Knife, and Dining Room. Alex and Skylar did not have any of these cards, so they cannot have the Dining Room card. Since Skylar already had the Dining Room card, Jeremy must have had Mr. Green and Knife.\n",
      "6. Alex asked about Miss Scarlet, Candlestick, and Hall. Skylar did not have any of these cards, so he cannot have the Candlestick card. Jeremy showed the Candlestick, so he must have had the Candlestick and Hall cards.\n",
      "\n",
      "So, the facedown cards in the middle of the table were:\n",
      "- Suspect: Mr. Green\n",
      "- Weapon: Knife\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- Room: Hall\n",
      "\n",
      "Jeremy had the Miss Scarlet, Candlestick, and Mr. Green cards, while Alex had the Lounge card.\n"
     ]
    }
   ],
   "source": [
    "print(best_trajectory.terminus.all_message_params()[-1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def max_abs_token_advantage(completion: Completion) -> float:\n",
    "#     if completion.parent:\n",
    "#         return max(abs(completion.token_advantage()), max_abs_token_advantage(completion.parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"best_trajectory.json\", \"w\") as f:\n",
    "    f.write(best_trajectory.episode.completion.model_dump_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"white-space: pre-wrap\"><b>User</b>:\n",
       "On a cool spring evening Brendan, Martin, and Vanessa and sat down to play a casual deduction game.\n",
       "\n",
       "They gathered 3 decks of cards, each for a different type of information composed of the following:\n",
       "\n",
       "Suspect:\n",
       "- Miss Scarlet\n",
       "- Mr. Green\n",
       "- Mrs. White\n",
       "\n",
       "Weapon:\n",
       "- Candlestick\n",
       "- Knife\n",
       "- Lead Pipe\n",
       "\n",
       "Room:\n",
       "- Hall\n",
       "- Lounge\n",
       "- Dining Room\n",
       "\n",
       "After randomly (and blindly) choosing one card from each stack and placing them in the center of the table facedown, they shuffled the remaining cards and dealt out the following to each player:\n",
       "\n",
       "- Brendan: 2 cards (Lounge and Mr. Green)\n",
       "- Martin: 2 cards\n",
       "- Vanessa: 2 cards\n",
       "\n",
       "The game proceeded as follows:\n",
       "\n",
       "1. On their turn, a player asked about a set of exactly 3 cards, one from each of the game's categories. (Note: Players could ask about any cards, including those in their own hand.)\n",
       "2. The player directed this question to the other players in clockwise order, starting with the player to their left.\n",
       "3. If a player had one or more of the asked-about cards, they had to show one of those cards (of their choice) to the asking player privately. The turn then ended, and play passed to the next player.\n",
       "4. If a player did not have any of the asked-about cards, they said so, and the question passed to the next player in clockwise order.\n",
       "5. This continued until either:\n",
       "a) A player showed a card to the asking player, or\n",
       "b) All the queried players had stated they didn't have any of the asked-about cards.\n",
       "6. After a player's turn ended (either by being shown a card or having all queried players pass), play moved to the next player in clockwise order.\n",
       "\n",
       "Here is how the game played out:\n",
       "\n",
       "Brendan asked if anyone had Mrs. White or the Lead Pipe or the Hall:\n",
       "- Martin showed Brendan the Hall\n",
       "\n",
       "Martin asked if anyone had Mr. Green or the Candlestick or the Lounge:\n",
       "- Vanessa did not have any of the cards\n",
       "- Brendan showed Martin Mr. Green\n",
       "\n",
       "Vanessa asked if anyone had Miss Scarlet or the Knife or the Hall:\n",
       "- Brendan did not have any of the cards\n",
       "- Martin showed Vanessa a card\n",
       "\n",
       "Brendan asked if anyone had Mr. Green or the Knife or the Lounge:\n",
       "- Martin did not have any of the cards\n",
       "- Vanessa showed Brendan the Knife\n",
       "\n",
       "Martin asked if anyone had Mrs. White or the Candlestick or the Dining Room:\n",
       "- Vanessa did not have any of the cards\n",
       "- Brendan did not have any of the cards\n",
       "\n",
       "Vanessa asked if anyone had Mrs. White or the Knife or the Dining Room:\n",
       "- Brendan did not have any of the cards\n",
       "- Martin did not have any of the cards\n",
       "\n",
       "Brendan asked if anyone had Mr. Green or the Candlestick or the Dining Room:\n",
       "- Martin showed Brendan the Candlestick\n",
       "\n",
       "Martin asked if anyone had Mrs. White or the Candlestick or the Dining Room:\n",
       "- Vanessa did not have any of the cards\n",
       "- Brendan did not have any of the cards\n",
       "\n",
       "Vanessa asked if anyone had Mrs. White or the Lead Pipe or the Hall:\n",
       "- Brendan did not have any of the cards\n",
       "- Martin showed Vanessa a card\n",
       "\n",
       "Brendan asked if anyone had Miss Scarlet or the Knife or the Lounge:\n",
       "- Martin did not have any of the cards\n",
       "- Vanessa showed Brendan Miss Scarlet\n",
       "\n",
       "Martin asked if anyone had Miss Scarlet or the Candlestick or the Hall:\n",
       "- Vanessa showed Martin a card\n",
       "\n",
       "Vanessa asked if anyone had Mrs. White or the Candlestick or the Dining Room:\n",
       "- Brendan did not have any of the cards\n",
       "- Martin showed Vanessa a card\n",
       "\n",
       "At this point, Brendan was able to correctly deduce the answer and win the game.\n",
       "\n",
       "What were the facedown cards in the middle of the table?\n",
       "\n",
       "<b>Assistant</b>:\n",
       "<span style='background-color: rgba(0,0,255, 0.027664476634998613);'>From the game play, we can deduce the following information:\n",
       "\n",
       "1. Mrs. White is not in the Hall (Martin showed the Hall to Brendan)\n",
       "2. Mr. Green is in the Lounge (Brendan showed</span><span style='background-color: rgba(255,0,0, 0.054988371348913795);'> Mr. Green to Martin)\n",
       "3. The Knife is in the Lounge (Vanessa showed Brendan the Knife)\n",
       "4. The Candlestick is in the Dining Room (Martin showed Brendan the Candlestick)\n",
       "5. Miss Scarlet is in the Lounge (Vanessa showed Brendan Miss Scarlet)\n",
       "6. The Lead Pipe is in the Hall (Martin showed Vanessa a card)\n",
       "7. Mrs. White is not in the Dining Room (</span><span style='background-color: rgba(0,0,255, 0.05556505445400138);'>Vanessa asked about Mrs. White and the Dining Room multiple times with no matches)\n",
       "\n",
       "Since</span><span style='background-color: rgba(0,0,255, 0.03041183586704597);'> the remaining possibilities are Mrs. White in the Dining Room</span><span style='background-color: rgba(255,0,0, 0.3931777549912852);'> and the Room of the Lead Pipe, and the game</span><span style='background-color: rgba(255,0,0, 0.3006683723051902);'> states that a player can only have at most one card,</span><span style='background-color: rgba(0,0,255, 0.0361672664879662);'> we can conclude that Mrs. White is in the Dining Room and the Lead Pipe is in the Hall.\n",
       "\n",
       "Therefore, the facedown cards in the middle of the table are:\n",
       "\n",
       "* Suspect:</span><span style='background-color: rgba(255,0,0, 0.24711925586561156);'> Miss Scarlet\n",
       "* Weapon: Knife\n",
       "* Room: Lounge\n",
       "\n",
       "And</span><span style='background-color: rgba(0,0,255, 2.4489795918367347);'></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(f'<div style=\"white-space: pre-wrap\">{best_trajectory.terminus.html(20.0)}</div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"white-space: pre-wrap\"><b>Assistant:\n",
       "</b><span style=\"background-color: rgba(0, \"0\", 255, 0.21875)\"> White.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def html(completion: Completion) -> HTML:\n",
    "    advantage = completion.advantage(cache=True) / completion.token_count(tokenizer) * 2\n",
    "    print(advantage)\n",
    "    html = \"\"\n",
    "    for message in completion.messages:\n",
    "        if isinstance(message, dict):\n",
    "            html += f'<b>{message[\"role\"].capitalize()}:</b>\\n<span style=\"background-color: rgba({\"255\" if advantage < 0 else \"0\"}, \"0\", {\"255\" if advantage > 0 else \"0\"}, {abs(advantage)})\">{message.get(\"content\")}</span>'\n",
    "        else:\n",
    "            html += f'<b>{message.message.role.capitalize()}:\\n</b><span style=\"background-color: rgba({\"255\" if advantage < 0 else \"0\"}, \"0\", {\"255\" if advantage > 0 else \"0\"}, {abs(advantage)})\">{message.message.content}</span>'\n",
    "    return HTML(f'<div style=\"white-space: pre-wrap\">{html}</div>')\n",
    "\n",
    "\n",
    "html(best_trajectory.terminus.parent.parent.parent.parent.parent.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the conversation, we can deduce the following:\n",
      "\n",
      "1. Dominic initially had the Dining Room and the Lounge. After Kathryn's turn, he was left with only the Lounge. Therefore, he must have played the Dining Room when Kathryn asked about Mr. Green, the Lead Pipe, and the Dining Room.\n",
      "2. Taylor did not have any of the cards Dominic asked about, so Taylor must not have the Lead Pipe or the Hall. Since Taylor didn't play any cards, they must have had both the Candlestick and the Lounge, which were not mentioned.\n",
      "3. Kathryn did not have any of the cards Taylor asked about, so Kathryn must not have the Lead Pipe or the Hall. When Kathryn asked about Mr. Green, the Lead Pipe, and the Dining Room, Dominic showed her the Dining Room. This means Kathryn must have had the Miss Scarlet and the Hall.\n",
      "\n",
      "Now, let's put the cards together:\n",
      "\n",
      "- Suspect: Miss Scarlet (Kathryn) and Mr. Green (unknown)\n",
      "- Weapon: Lead Pipe (unknown) and Candlestick (Taylor)\n",
      "- Room: Dining Room (Dominic), Lounge (Dominic), and Hall (Kathryn)\n",
      "\n",
      "The facedown cards in the center of the table are:\n",
      "\n",
      "- Mr. Green (Suspect)\n",
      "- Candlestick (Weapon)\n",
      "- Lounge (Room)\n"
     ]
    }
   ],
   "source": [
    "print(best_trajectory.terminus.all_message_params()[-1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import torch\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "class Request(BaseModel):\n",
    "    tokens_filename: str\n",
    "    advantages_filename: str\n",
    "    logprobs_filename: str\n",
    "    rows: int\n",
    "    seqlen: int\n",
    "    start: int\n",
    "    stop: int\n",
    "\n",
    "\n",
    "@app.post(\"/write-trajectories\")\n",
    "def write_trajectories(request: Request) -> None:\n",
    "    tokens = torch.from_file(\n",
    "        request.tokens_filename,\n",
    "        shared=True,\n",
    "        size=request.rows * request.seqlen,\n",
    "        dtype=torch.int64,\n",
    "    ).view(-1, request.seqlen)\n",
    "    advantages = torch.from_file(\n",
    "        request.advantages_filename,\n",
    "        shared=True,\n",
    "        size=request.rows * request.seqlen,\n",
    "        dtype=torch.float32,\n",
    "    ).view(-1, request.seqlen)\n",
    "    logprobs = torch.from_file(\n",
    "        request.logprobs_filename,\n",
    "        shared=True,\n",
    "        size=request.rows * request.seqlen,\n",
    "        dtype=torch.float32,\n",
    "    ).view(-1, request.seqlen)\n",
    "    trajectories: list[Trajectory] = []\n",
    "    for row in range(request.start, request.stop):\n",
    "        if not trajectories:\n",
    "            trajectories = sorted_trajectories()\n",
    "        selected_trajectories: list[Trajectory] = []\n",
    "        for i in range(0, len(trajectories), -1):\n",
    "            if (\n",
    "                trajectories[i].token_count\n",
    "                + sum(t.token_count for t in selected_trajectories)\n",
    "                > request.seqlen\n",
    "            ):\n",
    "                continue\n",
    "            selected_trajectories.append(trajectories.pop(i))\n",
    "        for trajectory in selected_trajectories:\n",
    "            trajectory.episode.weight *= episode_buffer.episode_decay\n",
    "            for completion in trajectory.terminus.ancestors(including_self=True):\n",
    "                completion.weight *= episode_buffer.completion_decay\n",
    "        tokens[row] = tokenizer.encode(\n",
    "            [\n",
    "                trajectory.terminus.all_message_params()\n",
    "                for trajectory in selected_trajectories\n",
    "            ],  # type: ignore\n",
    "            concatenate=True,\n",
    "            seqlen=request.seqlen,\n",
    "        )\n",
    "        replacement_token = \"<|reserved_special_token_250|>\"\n",
    "        mask = tokenizer.encode(\n",
    "            [trajectory.terminus.all_message_params(replacement_token=replacement_token) for trajectory in selected_trajectories],  # type: ignore\n",
    "            concatenate=True,\n",
    "            seqlen=request.seqlen,\n",
    "        ) == tokenizer.get_token_id(replacement_token)\n",
    "        mask_size = mask.sum()\n",
    "        advantages[row] = torch.full_like(\n",
    "            mask, fill_value=torch.nan, dtype=torch.float32\n",
    "        )\n",
    "        advantages[row][mask] = torch.tensor(\n",
    "            list(\n",
    "                advantage\n",
    "                for trajectory in selected_trajectories\n",
    "                for advantage in trajectory.terminus.all_token_advantages()\n",
    "            )[:mask_size]\n",
    "        )\n",
    "        logprobs[row] = torch.full_like(mask, fill_value=torch.nan, dtype=torch.float32)\n",
    "        logprobs[row][mask] = torch.tensor(\n",
    "            list(\n",
    "                advantage\n",
    "                for trajectory in selected_trajectories\n",
    "                for advantage in trajectory.terminus.all_logprobs()\n",
    "            )[:mask_size]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in episode_buffer.episodes:\n",
    "    for descendent in episode.completion.descendants(including_self=True):\n",
    "        descendent._cached_value = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(\n",
    "    uncached is cached\n",
    "    for uncached, cached in zip(\n",
    "        *(\n",
    "            [\n",
    "                episode.best_leaf(tokenizer, split_method=\"count\", cache=cache)\n",
    "                for episode in episode_buffer.episodes\n",
    "            ]\n",
    "            for cache in [False, True]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "best_leaves = [episode.best_leaf(tokenizer, split_method=\"count\", cache=True) for episode in episode_buffer.episodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [leaf.all_abs_advantage_per_token(tokenizer, cache=True) for leaf in best_leaves]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Absolute Advantage Per Token: 0.0043192790392456125\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Average Absolute Advantage Per Token:\",\n",
    "    sum(\n",
    "        episode.best_leaf(tokenizer, split_method=\"count\").all_abs_advantage_per_token(tokenizer)\n",
    "        for episode in episode_buffer.episodes\n",
    "    )\n",
    "    / len(episode_buffer.episodes),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(1 for _ in episode_buffer.episodes[0].completion.descendants())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00029788501638367595"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf = episode_buffer.episodes[0].best_leaf(tokenizer, split_method=\"count\")\n",
    "leaf.all_abs_advantage() / leaf.all_token_count(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the cards shown to each player:\n",
      "\n",
      "1. Blake shows the Lounge to Robert.\n",
      "2. Robert shows the Knife to Blake.\n",
      "3. Joel shows the Knife to Blake.\n",
      "4. Blake shows the Candlestick to Robert.\n",
      "5. Joel shows a card to Blake (must be Mrs. White or the Lead Pipe).\n",
      "6. Blake shows a card to Joel (must be Mr. Green or the Dining Room).\n",
      "7. Joel shows the Dining Room to Robert.\n",
      "8. Joel shows a card to Blake (must be the Lead Pipe).\n",
      "9. Blake shows a card to Robert (must be Mr. Green).\n",
      "\n",
      "From the information above, we can determine the following:\n",
      "\n",
      "- Robert has Miss Scarlet and the Knife.\n",
      "- Joel has Mrs. White and the Dining Room.\n",
      "- Blake has Mr. Green and the Candlestick.\n",
      "\n",
      "Since Blake showed the Candlestick to Robert, and Robert has the Knife, we know that the Candlestick is not the Knife. Therefore, the Candlestick must be the weapon in the Lounge.\n",
      "\n",
      "Similarly, since Blake showed a card to Joel (the Lead Pipe), and Joel has the Dining Room, we know that the Lead Pipe is not the Dining Room. Therefore, the Lead Pipe must be the weapon in the Hall.\n",
      "\n",
      "The only remaining card is the Mr. Green in the Dining Room.\n",
      "\n",
      "So, the facedown cards in the middle of the table are:\n",
      "\n",
      "Suspect: Miss Scarlet\n",
      "Weapon: Candlestick\n",
      "Room: Lounge\n",
      "\n",
      "The other two cards, Mr. Green and the Lead Pipe, were revealed during the game. The remaining card, Mrs. White, must be the suspect in the Dining Room.\n"
     ]
    }
   ],
   "source": [
    "print(completion.all_message_params()[-1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class Trajectory:\n",
    "    episode: Episode\n",
    "    terminus: Completion\n",
    "    abs_advantage: float\n",
    "    token_count: int\n",
    "\n",
    "    def score(self) -> float:\n",
    "        return self.episode.weight * self.abs_advantage / self.token_count\n",
    "\n",
    "\n",
    "def best_trajectory(episode: Episode) -> Trajectory:\n",
    "    return max(\n",
    "        (\n",
    "            Trajectory(\n",
    "                episode=episode,\n",
    "                terminus=completion,\n",
    "                abs_advantage=completion.all_abs_advantage(),\n",
    "                token_count=completion.all_token_count(tokenizer),\n",
    "            )\n",
    "            for completion in episode.completion.leaves()\n",
    "        ),\n",
    "        key=lambda t: t.abs_advantage / t.token_count,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 ** 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = 8192\n",
    "rows = 64\n",
    "\n",
    "tokens_file = torch.empty(rows * seqlen, dtype=torch.int64)\n",
    "tokens_file.numpy().tofile(\"/tmp/tokens.bin\")\n",
    "\n",
    "advantages_file = torch.empty(rows * seqlen, dtype=torch.float32)\n",
    "advantages_file.numpy().tofile(\"/tmp/advantages.bin\")\n",
    "\n",
    "logprobs_file = torch.empty(rows * seqlen, dtype=torch.float32)\n",
    "logprobs_file.numpy().tofile(\"/tmp/logprobs.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[157], line 76\u001b[0m\n\u001b[1;32m     67\u001b[0m         logprobs[row] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull_like(mask, fill_value\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnan, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     68\u001b[0m         logprobs[row][mask] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m     69\u001b[0m             \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m     70\u001b[0m                 advantage\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m             )[:mask_size]\n\u001b[1;32m     74\u001b[0m         )\n\u001b[0;32m---> 76\u001b[0m \u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokens_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/tmp/tokens.bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43madvantages_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/tmp/advantages.bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogprobs_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/tmp/logprobs.bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseqlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8192\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[157], line 44\u001b[0m, in \u001b[0;36mhandle_request\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     selected_trajectories\u001b[38;5;241m.\u001b[39mappend(trajectories\u001b[38;5;241m.\u001b[39mpop(i))\n\u001b[0;32m---> 44\u001b[0m tokens[row] \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_message_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mselected_trajectories\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseqlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseqlen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m replacement_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<|reserved_special_token_250|>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m mask \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(\n\u001b[1;32m     54\u001b[0m     [trajectory\u001b[38;5;241m.\u001b[39mterminus\u001b[38;5;241m.\u001b[39mall_message_params(replacement_token\u001b[38;5;241m=\u001b[39mreplacement_token) \u001b[38;5;28;01mfor\u001b[39;00m trajectory \u001b[38;5;129;01min\u001b[39;00m selected_trajectories],  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     concatenate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     56\u001b[0m     seqlen\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mseqlen,\n\u001b[1;32m     57\u001b[0m ) \u001b[38;5;241m==\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mget_token_id(replacement_token)\n",
      "File \u001b[0;32m~/atreides/experiments/lib/tokenizer.py:50\u001b[0m, in \u001b[0;36mTokenizer.encode\u001b[0;34m(self, messages, add_generation_prompt, continue_final_message, concatenate, seqlen)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate \u001b[38;5;241m=\u001b[39m generate  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     49\u001b[0m pad_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(tokenizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad_token_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39meos_token_id\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(token_ids[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m concatenate:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "class Request(BaseModel):\n",
    "    tokens_filename: str\n",
    "    advantages_filename: str\n",
    "    logprobs_filename: str\n",
    "    rows: int\n",
    "    seqlen: int\n",
    "    start: int\n",
    "    stop: int\n",
    "\n",
    "\n",
    "def handle_request(request: Request) -> None:\n",
    "    tokens = torch.from_file(\n",
    "        request.tokens_filename,\n",
    "        shared=True,\n",
    "        size=request.rows * request.seqlen,\n",
    "        dtype=torch.int64,\n",
    "    ).view(-1, request.seqlen)\n",
    "    advantages = torch.from_file(\n",
    "        request.advantages_filename,\n",
    "        shared=True,\n",
    "        size=request.rows * request.seqlen,\n",
    "        dtype=torch.float32,\n",
    "    ).view(-1, request.seqlen)\n",
    "    logprobs = torch.from_file(\n",
    "        request.logprobs_filename,\n",
    "        shared=True,\n",
    "        size=request.rows * request.seqlen,\n",
    "        dtype=torch.float32,\n",
    "    ).view(-1, request.seqlen)\n",
    "    trajectories = sorted(\n",
    "        (best_trajectory(episode) for episode in buffer),\n",
    "        key=lambda t: t.score(),\n",
    "    )\n",
    "    for row in range(request.start, request.stop):\n",
    "        selected_trajectories: list[Trajectory] = []\n",
    "        for i in range(0, len(trajectories), -1):\n",
    "            if (\n",
    "                trajectories[i].token_count\n",
    "                + sum(t.token_count for t in selected_trajectories)\n",
    "                > request.seqlen\n",
    "            ):\n",
    "                continue\n",
    "            selected_trajectories.append(trajectories.pop(i))\n",
    "        tokens[row] = tokenizer.encode(\n",
    "            [\n",
    "                trajectory.terminus.all_message_params()\n",
    "                for trajectory in selected_trajectories\n",
    "            ],  # type: ignore\n",
    "            concatenate=True,\n",
    "            seqlen=request.seqlen,\n",
    "        )\n",
    "        replacement_token = \"<|reserved_special_token_250|>\"\n",
    "        mask = tokenizer.encode(\n",
    "            [trajectory.terminus.all_message_params(replacement_token=replacement_token) for trajectory in selected_trajectories],  # type: ignore\n",
    "            concatenate=True,\n",
    "            seqlen=request.seqlen,\n",
    "        ) == tokenizer.get_token_id(replacement_token)\n",
    "        mask_size = mask.sum()\n",
    "        advantages[row] = torch.full_like(mask, fill_value=torch.nan, dtype=torch.float32)\n",
    "        advantages[row][mask] = torch.tensor(\n",
    "            list(\n",
    "                advantage\n",
    "                for trajectory in selected_trajectories\n",
    "                for advantage in trajectory.terminus.all_token_advantages()\n",
    "            )[:mask_size]\n",
    "        )\n",
    "        logprobs[row] = torch.full_like(mask, fill_value=torch.nan, dtype=torch.float32)\n",
    "        logprobs[row][mask] = torch.tensor(\n",
    "            list(\n",
    "                advantage\n",
    "                for trajectory in selected_trajectories\n",
    "                for advantage in trajectory.terminus.all_logprobs()\n",
    "            )[:mask_size]\n",
    "        )\n",
    "\n",
    "handle_request(\n",
    "    Request(\n",
    "        tokens_filename=\"/tmp/tokens.bin\",\n",
    "        advantages_filename=\"/tmp/advantages.bin\",\n",
    "        logprobs_filename=\"/tmp/logprobs.bin\",\n",
    "        rows=64,\n",
    "        seqlen=8192,\n",
    "        start=0,\n",
    "        stop=1,\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
