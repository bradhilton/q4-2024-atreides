{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-13 21:25:12 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='NousResearch/Hermes-2-Theta-Llama-3-8B', speculative_config=None, tokenizer='NousResearch/Hermes-2-Theta-Llama-3-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=NousResearch/Hermes-2-Theta-Llama-3-8B, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbradhilton\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/atreides/experiments/wandb/run-20241213_212513-rl31</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bradhilton/atreides-experiments/runs/rl31' target=\"_blank\">rl31</a></strong> to <a href='https://wandb.ai/bradhilton/atreides-experiments' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bradhilton/atreides-experiments' target=\"_blank\">https://wandb.ai/bradhilton/atreides-experiments</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bradhilton/atreides-experiments/runs/rl31' target=\"_blank\">https://wandb.ai/bradhilton/atreides-experiments/runs/rl31</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from lib.clue import Clue, DeductiveSolver\n",
    "from lib.rl.episode import Episode, EpisodeCompletion\n",
    "from lib.rl.ppo import PPOLoss\n",
    "from lib.rl.recipe import ComponentConfig, TuneRecipeConfig\n",
    "from lib.rl.trainer import ExploreOptions, Trainer, vLLMConfig\n",
    "from lib.utils import return_exception\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "from torchtune.models.llama3_1 import llama3_1_8b\n",
    "from typing import Literal, Optional\n",
    "\n",
    "with open(\"./data/chain-of-thought-examples.json\") as f:\n",
    "    chain_of_thought_examples: list[dict[str, str]] = json.load(f)\n",
    "\n",
    "\n",
    "def get_variable_difficulty_game(\n",
    "    return_first_solver_as_winner: Optional[bool] = None,\n",
    ") -> Clue:\n",
    "    num_players = random.randint(3, 6)\n",
    "    num_weapons = max(\n",
    "        3,\n",
    "        min(\n",
    "            num_players + random.randint(-1, 5),\n",
    "            len(Clue.weapons),\n",
    "        ),\n",
    "    )\n",
    "    num_suspects = min(\n",
    "        num_weapons + random.randint(0, num_weapons - 1), len(Clue.suspects)\n",
    "    )\n",
    "    num_rooms = min(num_suspects + random.randint(0, num_suspects - 2), len(Clue.rooms))\n",
    "    elements = {\n",
    "        \"suspect\": random.sample(Clue.suspects, k=num_suspects),\n",
    "        \"weapon\": random.sample(Clue.weapons, k=num_weapons),\n",
    "        \"room\": random.sample(Clue.rooms, k=num_rooms),\n",
    "    }\n",
    "    if random.random() < 0.1:\n",
    "        elements[\"motive\"] = random.sample(\n",
    "            Clue.motives,\n",
    "            k=max(3, min(num_weapons + random.randint(-1, 3), len(Clue.motives))),\n",
    "        )\n",
    "    if random.random() < 0.1:\n",
    "        frequency = random.choice([0.25, 0.5, 1.0])\n",
    "        start = 24.0 - frequency\n",
    "        end = 0.0\n",
    "        for _ in range(random.randint(1, num_weapons + 1)):\n",
    "            if random.randint(0, 1):\n",
    "                end += frequency\n",
    "            else:\n",
    "                start -= frequency\n",
    "\n",
    "        def format_time(time: float) -> str:\n",
    "            return f\"{int(time):02d}:{int(60 * (time - int(time))):02d}\"\n",
    "\n",
    "        elements[\"time\"] = Clue.get_times(\n",
    "            format_time(start), format_time(end), f\"{int(frequency * 60)}min\"\n",
    "        )\n",
    "    game = Clue(\n",
    "        num_players=num_players,\n",
    "        elements=elements,\n",
    "    )\n",
    "    difficulty_level = num_players + random.randint(-2, 3)\n",
    "    # print(f\"Players: {num_players}\")\n",
    "    # for element in elements:\n",
    "    #     print(f\"{element.capitalize()}: {len(elements[element])}\")\n",
    "    # print(f\"Difficulty level: {difficulty_level}\")\n",
    "    return game.play(\n",
    "        deductive_solver=DeductiveSolver(\n",
    "            # note_cards_in_hand=False,\n",
    "            # note_responses_to_suggestions=False,\n",
    "            # note_cards_that_players_do_not_have=False,\n",
    "            # check_unique_card_placement_constraints=False,\n",
    "            # check_player_hand_size_constraints=False,\n",
    "            check_solution_has_one_and_only_one_card_per_element=difficulty_level > 1,\n",
    "            check_one_of_constraints=difficulty_level > 2,\n",
    "            check_inverse_one_of_constraints=difficulty_level > 3,\n",
    "            merge_and_check_disjoint_inverse_one_of_constraints=difficulty_level > 4,\n",
    "            exhaustively_test_possible_assignments=False,\n",
    "        ),\n",
    "        cp_solver_max_solve_time_per_turn=0.01,\n",
    "        check_cp_solver_grid=False,\n",
    "        check_if_deductive_solver_and_cp_solver_grids_match=False,\n",
    "        return_first_solver_as_winner=(\n",
    "            bool(random.randint(0, 1))\n",
    "            if return_first_solver_as_winner is None\n",
    "            else return_first_solver_as_winner\n",
    "        ),\n",
    "        print_playthrough=False,\n",
    "        max_turns=100,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_easy_game(return_first_solver_as_winner: Optional[bool] = None) -> Clue:\n",
    "    game = Clue(\n",
    "        num_players=3,\n",
    "        elements={\n",
    "            \"suspect\": random.sample(Clue.suspects, k=3),\n",
    "            \"weapon\": random.sample(Clue.weapons, k=3),\n",
    "            \"room\": random.sample(Clue.rooms, k=3),\n",
    "            # \"motive\": random.sample(Clue.motives, k=3),\n",
    "            # \"time\": Clue.get_times(\"21:00\", \"03:00\", \"1h\"),\n",
    "        },\n",
    "    )\n",
    "    game.play(\n",
    "        deductive_solver=DeductiveSolver(\n",
    "            # note_cards_in_hand=False,\n",
    "            # note_responses_to_suggestions=False,\n",
    "            # note_cards_that_players_do_not_have=False,\n",
    "            # check_unique_card_placement_constraints=False,\n",
    "            # check_player_hand_size_constraints=False,\n",
    "            check_solution_has_one_and_only_one_card_per_element=False,\n",
    "            check_one_of_constraints=False,\n",
    "            check_inverse_one_of_constraints=False,\n",
    "            merge_and_check_disjoint_inverse_one_of_constraints=False,\n",
    "            exhaustively_test_possible_assignments=False,\n",
    "        ),\n",
    "        cp_solver_max_solve_time_per_turn=0.01,\n",
    "        check_cp_solver_grid=False,\n",
    "        check_if_deductive_solver_and_cp_solver_grids_match=False,\n",
    "        return_first_solver_as_winner=return_first_solver_as_winner or False,\n",
    "        print_playthrough=False,\n",
    "        max_turns=100,\n",
    "    )\n",
    "    return game\n",
    "\n",
    "\n",
    "@return_exception\n",
    "def sample_random_episode(\n",
    "    difficulty: Literal[\"easy\", \"variable\"] = \"variable\",\n",
    "    example_probability: float = 0.0,\n",
    "    max_prompt_characters: int = 8192,\n",
    "    reward_follow_up_completion: bool = True,\n",
    "    return_first_solver_as_winner: Optional[bool] = None,\n",
    ") -> Episode:\n",
    "    while True:\n",
    "        try:\n",
    "            game = (\n",
    "                get_easy_game if difficulty == \"easy\" else get_variable_difficulty_game\n",
    "            )(return_first_solver_as_winner=return_first_solver_as_winner)\n",
    "            prompt, follow_up, solution = game.get_prompt_and_follow_up_and_solution()\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if len(prompt) <= max_prompt_characters:\n",
    "            break\n",
    "\n",
    "    async def reward_completion(completion: EpisodeCompletion) -> EpisodeCompletion:\n",
    "        if len(completion.messages) == 2:\n",
    "            follow_up_completion = await completion.follow_up(\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": follow_up},\n",
    "                ],\n",
    "                max_tokens=10\n",
    "                + len(\"\\n\".join(f\"{key}: {value}\" for key, value in solution.items()))\n",
    "                // 2,\n",
    "            )\n",
    "        else:\n",
    "            follow_up_completion = completion\n",
    "        answer = follow_up_completion.last_assistant_message.get(\"content\")\n",
    "        assert isinstance(answer, str)\n",
    "        if reward_follow_up_completion:\n",
    "            completion = follow_up_completion\n",
    "        completion.reward = sum(\n",
    "            [\n",
    "                bool(\n",
    "                    # Find first match of key followed by colon and capture following text\n",
    "                    (\n",
    "                        match := re.search(\n",
    "                            rf\"{key}: ([A-Za-z \\.:-]+)\",\n",
    "                            answer,\n",
    "                            re.IGNORECASE,\n",
    "                        )\n",
    "                    )\n",
    "                    # Check if captured group matches expected value\n",
    "                    and match.group(1).strip().lower() == value.strip().lower()\n",
    "                )\n",
    "                for key, value in solution.items()\n",
    "            ]\n",
    "        ) / len(solution)\n",
    "        completion.reward -= (\n",
    "            completion.all_absent_stop_tokens\n",
    "            / (3 if reward_follow_up_completion else 2)\n",
    "            / len(solution)\n",
    "        )\n",
    "        return completion\n",
    "\n",
    "    async def on_sample(completions: list[EpisodeCompletion]) -> None:\n",
    "        for completion in await asyncio.gather(\n",
    "            *[reward_completion(completion) for completion in completions]\n",
    "        ):\n",
    "            completion.commit()\n",
    "\n",
    "    example = random.choice(chain_of_thought_examples)\n",
    "\n",
    "    return Episode(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        examples=lambda: (\n",
    "            [\n",
    "                {\"role\": \"user\", \"content\": example[\"prompt\"]},\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": example[\"chain_of_thought\"]\n",
    "                    + (example[\"answer\"] and f\"\\n\\n---\\n\\n{example['answer']}\"),\n",
    "                },\n",
    "            ]\n",
    "            if random.random() < example_probability\n",
    "            else []\n",
    "        ),\n",
    "        on_sample=on_sample,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_episodes():\n",
    "    while True:\n",
    "        yield sample_random_episode()\n",
    "\n",
    "\n",
    "model_name = \"rl31\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    base_model=\"NousResearch/Hermes-2-Theta-Llama-3-8B\",\n",
    "    output_dir=f\"./models/{model_name}\",\n",
    "    explore_options=ExploreOptions(\n",
    "        iterations=8,\n",
    "        num_parents=6,\n",
    "        branch_factor=4,\n",
    "        patience=5,\n",
    "        sample_probability_power=None,\n",
    "        sampling_kwargs={\"max_tokens\": 1024},\n",
    "    ),\n",
    "    train_episodes=train_episodes(),\n",
    "    episodes_per_iteration=64 * torch.cuda.device_count(),\n",
    "    max_mask_sequence_batch_size=1,\n",
    "    val_episodes=(\n",
    "        sample_random_episode() for _ in range(64 * torch.cuda.device_count())\n",
    "    ),\n",
    "    val_patience=15,\n",
    "    val_samples_per_episode=3,\n",
    "    val_sampling_kwargs={\"max_tokens\": 1024},\n",
    "    tune_model=llama3_1_8b,\n",
    "    tune_model_type=\"LLAMA3\",\n",
    "    tune_recipe_config=TuneRecipeConfig(\n",
    "        seed=42,\n",
    "        shuffle=False,\n",
    "        num_output_chunks=4,\n",
    "        resume_from_checkpoint=False,\n",
    "        batch_size=1,\n",
    "        epochs=1,\n",
    "        optimizer=ComponentConfig(\n",
    "            \"torch.optim.AdamW\",\n",
    "            # \"bitsandbytes.optim.PagedAdamW8bit\",\n",
    "            # \"bitsandbytes.optim.AdamW\",\n",
    "            # params=PLACEHOLDER,\n",
    "            lr=3e-6,\n",
    "            fused=True,\n",
    "        ),\n",
    "        loss=ComponentConfig(\n",
    "            PPOLoss,\n",
    "            policy_coef=0.0,\n",
    "            clip_epsilon=0.2,\n",
    "            unclipped_policy_coef=0.0,\n",
    "            tanh_log_policy_coef=0.8,\n",
    "            value_coef=0.0,\n",
    "            entropy_coef=0.0,\n",
    "            entropy_target=0.75,\n",
    "            entropy_target_coef=0.15,\n",
    "            kl_coef=0.5,\n",
    "            weighted_entropy_coef=0.1,\n",
    "            weighted_kl_coef=0.0,\n",
    "            weighted_ce_coef=0.0,\n",
    "            normalize_values=False,\n",
    "            normalize_advantages=False,\n",
    "        ),\n",
    "        compile=False,\n",
    "        optimizer_in_bwd=False,\n",
    "        gradient_accumulation_steps=1,\n",
    "        enable_activation_checkpointing=True,\n",
    "        enable_activation_offloading=False,\n",
    "        custom_sharded_layers=[\"tok_embeddings\", \"output\"],\n",
    "        log_every_n_steps=1,\n",
    "        log_peak_memory_stats=True,\n",
    "    ),\n",
    "    # tune_run=False,\n",
    "    tune_sequence_length=16384,\n",
    "    vllm_config=vLLMConfig(\n",
    "        env={\"VLLM_ALLOW_LONG_MAX_MODEL_LEN\": \"1\"},\n",
    "        kwargs=dict(\n",
    "            block_size=32,\n",
    "            disable_log_requests=True,\n",
    "            enable_prefix_caching=True,\n",
    "            enforce_eager=True,\n",
    "            gpu_memory_utilization=0.9,\n",
    "            max_model_len=16384,\n",
    "            max_num_seqs=512,\n",
    "            max_num_batched_tokens=16384 * 4,\n",
    "            preemption_mode=\"swap\",\n",
    "            return_tokens_as_token_ids=True,\n",
    "            swap_space=32,\n",
    "        ),\n",
    "        max_concurrent_samples=512,\n",
    "        timeout=120 + 15 * torch.cuda.device_count(),\n",
    "    ),\n",
    "    wandb_kwargs=dict(\n",
    "        name=model_name,\n",
    "        id=model_name,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 vLLM servers...\n",
      "$ vllm serve NousResearch/Hermes-2-Theta-Llama-3-8B --port=8002 --block-size=32 --disable-log-requests --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=65536 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=32 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf4101d5e1f4e218649ffceaeee76b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val: 0episode [00:00, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd63cbf4ed9c4ea1a8db4f20232704e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl31/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1|86|Loss: 0.0713: 100%|██████████| 86/86 [17:21<00:00, 12.03s/it, entropy=0.8314, entropy_target=0.0814, kl_div=0.1110, policy=0.0005, tanh_log_policy=0.0025, unclipped_policy=-0.0046, value=1.2127, weighted_ce=0.0088, weighted_entropy=-0.0162, weighted_kl_div=-0.0023]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iteration 1 model files to /home/ubuntu/atreides/experiments/models/rl31/0001\n",
      "Starting 1 vLLM servers...\n",
      "$ vllm serve /home/ubuntu/atreides/experiments/models/rl31/0001 --port=8002 --block-size=32 --disable-log-requests --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=65536 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=32 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2021e245d41c46ecbde47f681889f669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc78b412ce47476b8a538c2494d716b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl31/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1|65|Loss: 0.0666: 100%|██████████| 65/65 [19:22<00:00, 17.61s/it, entropy=0.5909, entropy_target=0.1591, kl_div=0.0931, policy=0.0398, tanh_log_policy=-0.0019, unclipped_policy=0.0381, value=2.4093, weighted_ce=-0.0074, weighted_entropy=0.0229, weighted_kl_div=0.0028]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iteration 2 model files to /home/ubuntu/atreides/experiments/models/rl31/0002\n",
      "Starting 1 vLLM servers...\n",
      "$ vllm serve /home/ubuntu/atreides/experiments/models/rl31/0002 --port=8002 --block-size=32 --disable-log-requests --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.9 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=65536 --preemption-mode=swap --return-tokens-as-token-ids --swap-space=32 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c70e9783d5a4ec983d6fc459da3d580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d0405d2a304777877e66a4a66cf838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await trainer.train(iterations=10, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl23/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1|127|Loss: 0.0196: 100%|██████████| 127/127 [37:31<00:00, 17.58s/it, entropy=0.7883, entropy_target=0.0383, kl_div=0.1517, policy=-0.0037, tanh_log_policy=0.0003, unclipped_policy=-0.0066, value=0.9517, weighted_ce=0.0017, weighted_entropy=-0.0032, weighted_kl_div=-0.0006]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved iteration 10 model files to /home/ubuntu/atreides/experiments/models/rl23/0010\n"
     ]
    }
   ],
   "source": [
    "await trainer.tune(trainer.explore_results[-1], verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 vLLM servers...\n",
      "$ vllm serve /home/ubuntu/atreides/experiments/models/rl23/0010 --port=8000 --block-size=32 --disable-log-requests --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.85 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=65536 --return-tokens-as-token-ids --swap-space=32 --preemption-mode=swap --api-key=default\n",
      "INFO 12-13 01:40:32 api_server.py:528] vLLM API server version 0.6.3.post1\n",
      "INFO 12-13 01:40:32 api_server.py:529] args: Namespace(subparser='serve', model_tag='/home/ubuntu/atreides/experiments/models/rl23/0010', config='', host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key='default', lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=True, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='/home/ubuntu/atreides/experiments/models/rl23/0010', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=16384, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=32, enable_prefix_caching=True, disable_sliding_window=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=0, swap_space=32.0, cpu_offload_gb=0, gpu_memory_utilization=0.85, num_gpu_blocks_override=None, max_num_batched_tokens=65536, max_num_seqs=512, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, enforce_eager=True, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode='swap', served_model_name=None, qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, scheduling_policy='fcfs', disable_log_requests=True, max_log_len=None, disable_fastapi_docs=False, dispatch_function=<function serve at 0x7bf7d00b0fe0>)\n",
      "INFO 12-13 01:40:32 api_server.py:166] Multiprocessing frontend to use ipc:///tmp/50d18425-f6a4-428a-98ac-bd18e6b5699a for IPC Path.\n",
      "INFO 12-13 01:40:32 api_server.py:179] Started engine process with PID 63932\n",
      "WARNING 12-13 01:40:32 config.py:1786] User-specified max_model_len (16384) is greater than the derived max_model_len (max_position_embeddings=8192 or model_max_length=None in model's config.json). This may lead to incorrect model outputs or CUDA errors. Make sure the value is correct and within the model context size.\n",
      "WARNING 12-13 01:40:37 config.py:1786] User-specified max_model_len (16384) is greater than the derived max_model_len (max_position_embeddings=8192 or model_max_length=None in model's config.json). This may lead to incorrect model outputs or CUDA errors. Make sure the value is correct and within the model context size.\n",
      "WARNING 12-13 01:40:37 arg_utils.py:1019] [DEPRECATED] Block manager v1 has been removed, and setting --use-v2-block-manager to True or False has no effect on vLLM behavior. Please remove --use-v2-block-manager in your engine argument. If your use case is not supported by SelfAttnBlockSpaceManager (i.e. block manager v2), please file an issue with detailed information.\n",
      "WARNING 12-13 01:40:37 config.py:395] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "WARNING 12-13 01:40:42 arg_utils.py:1019] [DEPRECATED] Block manager v1 has been removed, and setting --use-v2-block-manager to True or False has no effect on vLLM behavior. Please remove --use-v2-block-manager in your engine argument. If your use case is not supported by SelfAttnBlockSpaceManager (i.e. block manager v2), please file an issue with detailed information.\n",
      "WARNING 12-13 01:40:42 config.py:395] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 12-13 01:40:42 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='/home/ubuntu/atreides/experiments/models/rl23/0010', speculative_config=None, tokenizer='/home/ubuntu/atreides/experiments/models/rl23/0010', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=16384, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/ubuntu/atreides/experiments/models/rl23/0010, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=True, use_async_output_proc=False, use_cached_outputs=True, mm_processor_kwargs=None)\n",
      "INFO 12-13 01:40:44 model_runner.py:1056] Starting to load model /home/ubuntu/atreides/experiments/models/rl23/0010...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pt checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/vllm/model_executor/model_loader/weight_utils.py:425: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(bin_file, map_location=\"cpu\")\n",
      "Loading pt checkpoint shards:  25% Completed | 1/4 [00:03<00:11,  3.97s/it]\n",
      "Loading pt checkpoint shards:  50% Completed | 2/4 [00:04<00:04,  2.05s/it]\n",
      "Loading pt checkpoint shards:  75% Completed | 3/4 [00:07<00:02,  2.47s/it]\n",
      "Loading pt checkpoint shards: 100% Completed | 4/4 [00:10<00:00,  2.65s/it]\n",
      "Loading pt checkpoint shards: 100% Completed | 4/4 [00:10<00:00,  2.64s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-13 01:40:55 model_runner.py:1067] Loading model weights took 14.9595 GB\n",
      "INFO 12-13 01:40:57 gpu_executor.py:122] # GPU blocks: 11284, # CPU blocks: 8192\n",
      "INFO 12-13 01:40:57 gpu_executor.py:126] Maximum concurrency for 16384 tokens per request: 22.04x\n",
      "INFO 12-13 01:41:12 api_server.py:232] vLLM to use /tmp/tmpdvtq55fw as PROMETHEUS_MULTIPROC_DIR\n",
      "WARNING 12-13 01:41:12 serving_embedding.py:199] embedding_mode is False. Embedding API will not work.\n",
      "INFO 12-13 01:41:12 launcher.py:19] Available routes are:\n",
      "INFO 12-13 01:41:12 launcher.py:27] Route: /openapi.json, Methods: HEAD, GET\n",
      "INFO 12-13 01:41:12 launcher.py:27] Route: /docs, Methods: HEAD, GET\n",
      "INFO 12-13 01:41:12 launcher.py:27] Route: /docs/oauth2-redirect, Methods: HEAD, GET\n",
      "INFO 12-13 01:41:12 launcher.py:27] Route: /redoc, Methods: HEAD, GET\n",
      "INFO 12-13 01:41:12 launcher.py:27] Route: /health, Methods: GET\n",
      "INFO 12-13 01:41:12 launcher.py:27] Route: /tokenize, Methods: POST\n",
      "INFO 12-13 01:41:12 launcher.py:27] Route: /detokenize, Methods: POST\n",
      "INFO 12-13 01:41:12 launcher.py:27] Route: /v1/models, Methods: GET\n",
      "INFO 12-13 01:41:12 launcher.py:27] Route: /version, Methods: GET\n",
      "INFO 12-13 01:41:12 launcher.py:27] Route: /v1/chat/completions, Methods: POST\n",
      "INFO 12-13 01:41:12 launcher.py:27] Route: /v1/completions, Methods: POST\n",
      "INFO 12-13 01:41:12 launcher.py:27] Route: /v1/embeddings, Methods: POST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [63856]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on socket ('0.0.0.0', 8000) (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:40800 - \"POST /v1/chat/completions HTTP/1.1\" 200 OK\n",
      "vLLM server started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1488a28058d2484cb51eb3dc0cee9b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val: 0episode [00:00, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping val evaluation due to expired patience (0 remaining episodes x 15 patience per episode = 0 seconds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.44525732761148284, [])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await trainer.eval(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': \"On a warm autumn day Maxwell, Angelica, Mark, and Ella sat down to play a friendly deduction game.\\n\\nThey assembled 4 decks of cards, each for a separate type of data composed of the following:\\n\\nSuspect:\\n- Madame Rose\\n- Mrs. Peacock\\n- Monsieur Brunette\\n- Professor Plum\\n- Mrs. White\\n- Sgt. Gray\\n- Colonel Mustard\\n- Miss Scarlet\\n- Mr. Green\\n\\nWeapon:\\n- Lead Pipe\\n- Horseshoe\\n- Poison\\n- Knife\\n- Candlestick\\n- Revolver\\n- Wrench\\n- Rope\\n\\nRoom:\\n- Trophy Room\\n- Conservatory\\n- Lounge\\n- Kitchen\\n- Library\\n- Hall\\n- Carriage House\\n- Cloak Room\\n- Fountain\\n- Dining Room\\n\\nTime:\\n- 09:00 PM\\n- 10:00 PM\\n- 11:00 PM\\n- 12:00 AM\\n\\nAfter randomly (and blindly) choosing one card from each deck and placing them in the center of the table facedown, they shuffled the remaining cards and dealt out the following to each player:\\n\\n- Maxwell: 6 cards\\n- Angelica: 7 cards\\n- Mark: 7 cards (Mr. Green, Hall, Revolver, Mrs. White, 09:00 PM, Wrench, and Trophy Room)\\n- Ella: 7 cards\\n\\nThe game proceeded as follows:\\n\\n1. On their turn, a player asked about a set of exactly 4 cards, one from each of the game's categories. (Note: Players could ask about any cards, including those in their own hand.)\\n2. The player directed this question to the other players in clockwise order, starting with the player to their left.\\n3. If a player had one or more of the asked-about cards, they had to show one of those cards (of their choice) to the asking player privately. The turn then ended, and play passed to the next player.\\n4. If a player did not have any of the asked-about cards, they said so, and the question passed to the next player in clockwise order.\\n5. This continued until either:\\na) A player showed a card to the asking player, or\\nb) All the queried players had stated they didn't have any of the asked-about cards.\\n6. After a player's turn ended (either by being shown a card or having all queried players pass), play moved to the next player in clockwise order.\\n\\nHere is how the game played out:\\n\\nMaxwell asked if anyone had Mr. Green or the Poison or the Trophy Room or 12:00 AM:\\n- Angelica did not have any of the cards\\n- Mark showed Maxwell Mr. Green\\n\\nAngelica asked if anyone had Colonel Mustard or the Horseshoe or the Trophy Room or 10:00 PM:\\n- Mark showed Angelica the Trophy Room\\n\\nMark asked if anyone had Mrs. Peacock or the Knife or the Trophy Room or 12:00 AM:\\n- Ella showed Mark Mrs. Peacock\\n\\nElla asked if anyone had Mrs. Peacock or the Lead Pipe or the Cloak Room or 09:00 PM:\\n- Maxwell showed Ella a card\\n\\nMaxwell asked if anyone had Miss Scarlet or the Wrench or the Dining Room or 12:00 AM:\\n- Angelica showed Maxwell a card\\n\\nAngelica asked if anyone had Colonel Mustard or the Horseshoe or the Library or 10:00 PM:\\n- Mark did not have any of the cards\\n- Ella showed Angelica a card\\n\\nMark asked if anyone had Professor Plum or the Wrench or the Hall or 12:00 AM:\\n- Ella did not have any of the cards\\n- Maxwell did not have any of the cards\\n- Angelica showed Mark Professor Plum\\n\\nElla asked if anyone had Mrs. Peacock or the Revolver or the Dining Room or 12:00 AM:\\n- Maxwell did not have any of the cards\\n- Angelica did not have any of the cards\\n- Mark showed Ella the Revolver\\n\\nMaxwell asked if anyone had Professor Plum or the Lead Pipe or the Cloak Room or 12:00 AM:\\n- Angelica showed Maxwell a card\\n\\nAngelica asked if anyone had Professor Plum or the Rope or the Fountain or 09:00 PM:\\n- Mark showed Angelica 09:00 PM\\n\\nMark asked if anyone had Madame Rose or the Knife or the Trophy Room or 12:00 AM:\\n- Ella did not have any of the cards\\n- Maxwell did not have any of the cards\\n- Angelica showed Mark Madame Rose\\n\\nElla asked if anyone had Professor Plum or the Poison or the Lounge or 09:00 PM:\\n- Maxwell did not have any of the cards\\n- Angelica showed Ella a card\\n\\nMaxwell asked if anyone had Monsieur Brunette or the Wrench or the Library or 12:00 AM:\\n- Angelica did not have any of the cards\\n- Mark showed Maxwell the Wrench\\n\\nAngelica asked if anyone had Mrs. White or the Candlestick or the Library or 12:00 AM:\\n- Mark showed Angelica Mrs. White\\n\\nMark asked if anyone had Colonel Mustard or the Lead Pipe or the Lounge or 11:00 PM:\\n- Ella showed Mark 11:00 PM\\n\\nElla asked if anyone had Madame Rose or the Revolver or the Library or 12:00 AM:\\n- Maxwell did not have any of the cards\\n- Angelica showed Ella a card\\n\\nMaxwell asked if anyone had Colonel Mustard or the Horseshoe or the Fountain or 10:00 PM:\\n- Angelica showed Maxwell a card\\n\\nAngelica asked if anyone had Sgt. Gray or the Revolver or the Lounge or 12:00 AM:\\n- Mark showed Angelica the Revolver\\n\\nMark asked if anyone had Mrs. White or the Horseshoe or the Fountain or 12:00 AM:\\n- Ella did not have any of the cards\\n- Maxwell did not have any of the cards\\n- Angelica showed Mark the Fountain\\n\\nElla asked if anyone had Mrs. Peacock or the Rope or the Lounge or 12:00 AM:\\n- Maxwell did not have any of the cards\\n- Angelica showed Ella a card\\n\\nMaxwell asked if anyone had Sgt. Gray or the Knife or the Dining Room or 11:00 PM:\\n- Angelica showed Maxwell a card\\n\\nAngelica asked if anyone had Monsieur Brunette or the Revolver or the Fountain or 11:00 PM:\\n- Mark showed Angelica the Revolver\\n\\nMark asked if anyone had Monsieur Brunette or the Candlestick or the Trophy Room or 12:00 AM:\\n- Ella showed Mark the Candlestick\\n\\nElla asked if anyone had Colonel Mustard or the Poison or the Library or 12:00 AM:\\n- Maxwell did not have any of the cards\\n- Angelica did not have any of the cards\\n- Mark did not have any of the cards\\n\\nMaxwell asked if anyone had Colonel Mustard or the Lead Pipe or the Kitchen or 12:00 AM:\\n- Angelica did not have any of the cards\\n- Mark did not have any of the cards\\n- Ella showed Maxwell a card\\n\\nAngelica asked if anyone had Monsieur Brunette or the Poison or the Fountain or 11:00 PM:\\n- Mark did not have any of the cards\\n- Ella showed Angelica a card\\n\\nMark asked if anyone had Mrs. White or the Revolver or the Fountain or 10:00 PM:\\n- Ella showed Mark 10:00 PM\\n\\nElla asked if anyone had Monsieur Brunette or the Poison or the Library or 12:00 AM:\\n- Maxwell did not have any of the cards\\n- Angelica did not have any of the cards\\n- Mark did not have any of the cards\\n\\nMaxwell asked if anyone had Sgt. Gray or the Poison or the Library or 10:00 PM:\\n- Angelica did not have any of the cards\\n- Mark did not have any of the cards\\n- Ella showed Maxwell a card\\n\\nAngelica asked if anyone had Colonel Mustard or the Knife or the Fountain or 12:00 AM:\\n- Mark did not have any of the cards\\n- Ella showed Angelica a card\\n\\nMark asked if anyone had Mrs. White or the Revolver or the Lounge or 09:00 PM:\\n- Ella showed Mark the Lounge\\n\\nElla asked if anyone had Mr. Green or the Poison or the Cloak Room or 12:00 AM:\\n- Maxwell showed Ella a card\\n\\nMaxwell asked if anyone had Mrs. White or the Rope or the Kitchen or 12:00 AM:\\n- Angelica showed Maxwell a card\\n\\nAngelica asked if anyone had Professor Plum or the Knife or the Fountain or 12:00 AM:\\n- Mark did not have any of the cards\\n- Ella did not have any of the cards\\n- Maxwell did not have any of the cards\\n\\nMark asked if anyone had Mr. Green or the Revolver or the Dining Room or 09:00 PM:\\n- Ella did not have any of the cards\\n- Maxwell did not have any of the cards\\n- Angelica did not have any of the cards\\n\\nAt this point Mark was able to correctly infer the solution and win the game.\\n\\nWhat were the facedown cards in the center of the table?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': \"Based on Mark's deductions, the facedown cards in the center of the table were:\\n\\nSuspect: Colonel Mustard\\nWeapon: Poison\\nRoom: Fountain\\nTime: 12:00 AM\\n\\nThese cards allowed Mark to deduce that Colonel Mustard committed the murder in the Fountain with the Poison at midnight. Congratulations to Mark for winning the game! :) \\n\\nTo summarize the game-winning situation:\\n\\nColonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\n\\nMark was able to deduce that Colonel Mustard committed the murder in the Fountain with the Poison at midnight due to the accumulation of these facedown cards in the center of the table. :) \\n\\nGreat game, everyone! Would you like to play again? :) \\n\\nNote: If you would like to play again, we can shuffle the cards and start a new game with the same rules. Let me know! :) \\n\\nHave a great day! :) \\n\\nAnswer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) \\n\\nExplanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :)  Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Fill out your answer like this:\\nSuspect: <#SUSPECT#>\\nWeapon: <#WEAPON#>\\nRoom: <#ROOM#>\\nTime: <#TIME#>'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Suspect: Colonel Mustard\\nWeapon: Poison\\nRoom: Fountain\\nTime: 12:00 AM\\n\\nAnswer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) \\n\\nGreat game, everyone! Would you like to play again? :) \\n\\nNote: If you would like to play again, we can shuffle the cards and start a new game with the same rules. Let me know! :) \\n\\nHave a great day! :) \\n\\nAnswer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Explanation: Colonel Mustard was present in the game throughout,\\nPoison was asked about multiple times but never shown,\\nFountain was asked about multiple times but never shown,\\nand\\n12:00 AM was asked about multiple times but never shown.\\nTherefore, Colonel Mustard committed the murder in the Fountain with the Poison at midnight. :) Answer: Colonel Mustard committed the murder in the Fountain with the'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(\n",
    "    (\n",
    "        leaf\n",
    "        for episode in trainer.explore_results[-1].episodes\n",
    "        for leaf in episode.completion.leaves()\n",
    "    ),\n",
    "    key=lambda x: x.all_token_count(trainer.tokenizer, cache=True),\n",
    ").all_message_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 1 vLLM servers...\n",
      "$ vllm serve /home/ubuntu/atreides/experiments/models/rl23/0010 --port=8000 --block-size=32 --disable-log-requests --enable-prefix-caching --enforce-eager --gpu-memory-utilization=0.85 --max-model-len=16384 --max-num-seqs=512 --max-num-batched-tokens=65536 --return-tokens-as-token-ids --swap-space=32 --api-key=default\n",
      "vLLM servers started succesfully. Logs can be found at ./logs/vllm.log\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74257d1cae534dcbbebd61d6dcb315dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val: 0episode [00:00, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b1797edd2346878423ec291567e079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "explore:   0%|          | 0/64 [00:00<?, ?episode/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ProcessLookupError'> \n",
      "$ tune run lib.rl.recipe.TuneRecipe --config /home/ubuntu/atreides/experiments/models/rl23/config.yaml\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtrain(iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/atreides/experiments/lib/rl/trainer.py:280\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, iterations, test, verbosity)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m    276\u001b[0m     _, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m, return_exceptions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbosity\u001b[38;5;241m=\u001b[39mverbosity),\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplore(\u001b[38;5;241m1\u001b[39m, return_exceptions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbosity\u001b[38;5;241m=\u001b[39mverbosity),\n\u001b[1;32m    279\u001b[0m     )\n\u001b[0;32m--> 280\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtune(result, verbosity\u001b[38;5;241m=\u001b[39mverbosity)\n\u001b[1;32m    281\u001b[0m _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m, return_exceptions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbosity\u001b[38;5;241m=\u001b[39mverbosity),\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m, verbosity\u001b[38;5;241m=\u001b[39mverbosity) \u001b[38;5;28;01mif\u001b[39;00m test \u001b[38;5;28;01melse\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    284\u001b[0m )\n",
      "File \u001b[0;32m~/atreides/experiments/lib/rl/trainer.py:677\u001b[0m, in \u001b[0;36mTrainer.tune\u001b[0;34m(self, result, verbosity)\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtune_recipe_config\u001b[38;5;241m.\u001b[39mreference_checkpointer \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_checkpointer_config(\n\u001b[1;32m    672\u001b[0m             \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_checkpoint_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_model),\n\u001b[1;32m    673\u001b[0m             checkpoint_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreference_model_checkpoint_files,\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m     )\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtune_run:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tune_run(verbosity)\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     cleanup_before_training()\n",
      "File \u001b[0;32m~/atreides/experiments/lib/rl/trainer.py:738\u001b[0m, in \u001b[0;36mTrainer._tune_run\u001b[0;34m(self, verbosity)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m process\u001b[38;5;241m.\u001b[39mstderr:\n\u001b[1;32m    737\u001b[0m     tasks\u001b[38;5;241m.\u001b[39mappend(asyncio\u001b[38;5;241m.\u001b[39mcreate_task(log_output(process\u001b[38;5;241m.\u001b[39mstderr, sys\u001b[38;5;241m.\u001b[39mstderr)))\n\u001b[0;32m--> 738\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n",
      "File \u001b[0;32m~/atreides/experiments/lib/rl/trainer.py:713\u001b[0m, in \u001b[0;36mTrainer._tune_run.<locals>.log_output\u001b[0;34m(stream, io)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 713\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m4096\u001b[39m)\n\u001b[1;32m    714\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[1;32m    715\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.12.8-linux-x86_64-gnu/lib/python3.12/asyncio/streams.py:713\u001b[0m, in \u001b[0;36mStreamReader.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(blocks)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[0;32m--> 713\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# This will work right even if buffer is less than n bytes\u001b[39;00m\n\u001b[1;32m    716\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytes\u001b[39m(\u001b[38;5;28mmemoryview\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)[:n])\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.12.8-linux-x86_64-gnu/lib/python3.12/asyncio/streams.py:545\u001b[0m, in \u001b[0;36mStreamReader._wait_for_data\u001b[0;34m(self, func_name)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mcreate_future()\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 545\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "await trainer.train(iterations=1, verbosity=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
