{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/atreides/.venv/lib/python3.12/site-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:\n",
      "No module named 'vllm._version'\n",
      "  from vllm.version import __version__ as VLLM_VERSION\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-23 22:47:54 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='NousResearch/Hermes-2-Theta-Llama-3-8B', speculative_config=None, tokenizer='NousResearch/Hermes-2-Theta-Llama-3-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=NousResearch/Hermes-2-Theta-Llama-3-8B, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "INFO 10-23 22:47:55 model_runner.py:1060] Starting to load model NousResearch/Hermes-2-Theta-Llama-3-8B...\n",
      "INFO 10-23 22:47:56 weight_utils.py:243] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739e4d75d72242f6becce4603858fda3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-23 22:47:59 model_runner.py:1071] Loading model weights took 14.9595 GB\n",
      "INFO 10-23 22:48:00 gpu_executor.py:122] # GPU blocks: 9604, # CPU blocks: 2048\n",
      "INFO 10-23 22:48:00 gpu_executor.py:126] Maximum concurrency for 8192 tokens per request: 18.76x\n",
      "INFO 10-23 22:48:03 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 10-23 22:48:03 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 10-23 22:48:15 model_runner.py:1530] Graph capturing finished in 11 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"NousResearch/Hermes-2-Theta-Llama-3-8B\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm.sampling_params import SamplingParams\n",
    "\n",
    "prompt = \"\"\"\n",
    "On a warm spring day Summer, Giselle and Connor sat down to play a casual mystery game.\n",
    "\n",
    "They assembled 3 decks of cards, each for a separate type of information composed of the following:\n",
    "\n",
    "Suspect:\n",
    "- Miss Scarlet\n",
    "- Mr. Green\n",
    "- Mrs. White\n",
    "\n",
    "Weapon:\n",
    "- Candlestick\n",
    "- Knife\n",
    "- Lead Pipe\n",
    "\n",
    "Room:\n",
    "- Hall\n",
    "- Lounge\n",
    "- Dining Room\n",
    "\n",
    "After randomly (and blindly) choosing one card from each group and placing them in the middle of the table facedown, they shuffled the remaining cards and dealt out the following to each player:\n",
    "\n",
    "- Summer: 2 cards\n",
    "- Giselle: 2 cards ('Lounge', 'Miss Scarlet')\n",
    "- Connor: 2 cards\n",
    "\n",
    "The game proceeded as follows:\n",
    "\n",
    "1. On their turn, a player asked about a set of exactly 3 cards, one from each of the game's categories. (Note: Players could ask about any cards, including those in their own hand.)\n",
    "2. The player directed this question to the other players in clockwise order, starting with the player to their left.\n",
    "3. If a player had one or more of the asked-about cards, they had to show one of those cards (of their choice) to the asking player privately. The turn then ended, and play passed to the next player.\n",
    "4. If a player did not have any of the asked-about cards, they said so, and the question passed to the next player in clockwise order.\n",
    "5. This continued until either:\n",
    "    a) A player showed a card to the asking player, or\n",
    "    b) All the queried players had stated they didn't have any of the asked-about cards.\n",
    "6. After a player's turn ended (either by being shown a card or having all queried players pass), play moved to the next player in clockwise order.\n",
    "\n",
    "Here is how the game played out:\n",
    "\n",
    "Summer asked if anyone had 'Mrs. White' or 'Knife' or 'Dining Room':\n",
    "- Giselle did not have any of the cards\n",
    "- Connor showed Summer a card\n",
    "\n",
    "Giselle asked if anyone had 'Mrs. White' or 'Knife' or 'Lounge':\n",
    "- Connor did not have any of the cards\n",
    "- Summer did not have any of the cards\n",
    "\n",
    "Connor asked if anyone had 'Miss Scarlet' or 'Candlestick' or 'Hall':\n",
    "- Summer did not have any of the cards\n",
    "- Giselle showed Connor 'Miss Scarlet'\n",
    "\n",
    "Summer asked if anyone had 'Mr. Green' or 'Knife' or 'Hall':\n",
    "- Giselle did not have any of the cards\n",
    "- Connor did not have any of the cards\n",
    "\n",
    "At this point, Giselle was able to correctly infer the solution and win the game.\n",
    "\n",
    "What were the facedown cards in the middle of the table?\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtune.models.llama3_1 import llama3_1_8b\n",
    "\n",
    "model = llama3_1_8b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/huggingface/hub/models--NousResearch--Hermes-2-Theta-Llama-3-8B/snapshots/57a73110702e7b05ba3f39fef36297454c680725\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import subprocess\n",
    "\n",
    "model_dir = subprocess.run(\n",
    "    \"HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download NousResearch/Hermes-2-Theta-Llama-3-8B\",\n",
    "    shell=True,\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    ").stdout.strip()\n",
    "\n",
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtune.training.checkpointing import FullModelHFCheckpointer\n",
    "\n",
    "checkpointer = FullModelHFCheckpointer(\n",
    "    checkpoint_dir=model_dir,\n",
    "    checkpoint_files=glob.glob(f\"{model_dir}/*.safetensors\"),\n",
    "    output_dir=model_dir,\n",
    "    model_type='LLAMA3' # type: ignore\n",
    ")\n",
    "state_dict = checkpointer.load_checkpoint()\n",
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128000,\n",
       " 128000,\n",
       " 128002,\n",
       " 882,\n",
       " 198,\n",
       " 1966,\n",
       " 264,\n",
       " 8369,\n",
       " 10683,\n",
       " 1938,\n",
       " 19367,\n",
       " 11,\n",
       " 480,\n",
       " 285,\n",
       " 6853,\n",
       " 323,\n",
       " 58280,\n",
       " 7731,\n",
       " 1523,\n",
       " 311,\n",
       " 1514,\n",
       " 264,\n",
       " 16736,\n",
       " 23347,\n",
       " 1847,\n",
       " 382,\n",
       " 7009,\n",
       " 35105,\n",
       " 220,\n",
       " 18,\n",
       " 30881,\n",
       " 315,\n",
       " 7563,\n",
       " 11,\n",
       " 1855,\n",
       " 369,\n",
       " 264,\n",
       " 8821,\n",
       " 955,\n",
       " 315,\n",
       " 2038,\n",
       " 24306,\n",
       " 315,\n",
       " 279,\n",
       " 2768,\n",
       " 1473,\n",
       " 78524,\n",
       " 1002,\n",
       " 512,\n",
       " 12,\n",
       " 9083,\n",
       " 81818,\n",
       " 198,\n",
       " 12,\n",
       " 4491,\n",
       " 13,\n",
       " 7997,\n",
       " 198,\n",
       " 12,\n",
       " 18083,\n",
       " 13,\n",
       " 5929,\n",
       " 271,\n",
       " 29314,\n",
       " 512,\n",
       " 12,\n",
       " 73997,\n",
       " 30133,\n",
       " 198,\n",
       " 12,\n",
       " 62302,\n",
       " 198,\n",
       " 12,\n",
       " 30982,\n",
       " 28905,\n",
       " 271,\n",
       " 14330,\n",
       " 512,\n",
       " 12,\n",
       " 11166,\n",
       " 198,\n",
       " 12,\n",
       " 50767,\n",
       " 198,\n",
       " 12,\n",
       " 39190,\n",
       " 10637,\n",
       " 271,\n",
       " 6153,\n",
       " 27716,\n",
       " 320,\n",
       " 438,\n",
       " 89447,\n",
       " 8,\n",
       " 19301,\n",
       " 832,\n",
       " 3786,\n",
       " 505,\n",
       " 1855,\n",
       " 1912,\n",
       " 323,\n",
       " 25012,\n",
       " 1124,\n",
       " 304,\n",
       " 279,\n",
       " 6278,\n",
       " 315,\n",
       " 279,\n",
       " 2007,\n",
       " 17011,\n",
       " 785,\n",
       " 11,\n",
       " 814,\n",
       " 75371,\n",
       " 279,\n",
       " 9861,\n",
       " 7563,\n",
       " 323,\n",
       " 27023,\n",
       " 704,\n",
       " 279,\n",
       " 2768,\n",
       " 311,\n",
       " 1855,\n",
       " 2851,\n",
       " 1473,\n",
       " 12,\n",
       " 19367,\n",
       " 25,\n",
       " 220,\n",
       " 17,\n",
       " 7563,\n",
       " 198,\n",
       " 12,\n",
       " 480,\n",
       " 285,\n",
       " 6853,\n",
       " 25,\n",
       " 220,\n",
       " 17,\n",
       " 7563,\n",
       " 4417,\n",
       " 43,\n",
       " 26645,\n",
       " 518,\n",
       " 364,\n",
       " 36412,\n",
       " 81818,\n",
       " 1329,\n",
       " 12,\n",
       " 58280,\n",
       " 25,\n",
       " 220,\n",
       " 17,\n",
       " 7563,\n",
       " 271,\n",
       " 791,\n",
       " 1847,\n",
       " 45374,\n",
       " 439,\n",
       " 11263,\n",
       " 1473,\n",
       " 16,\n",
       " 13,\n",
       " 1952,\n",
       " 872,\n",
       " 2543,\n",
       " 11,\n",
       " 264,\n",
       " 2851,\n",
       " 4691,\n",
       " 922,\n",
       " 264,\n",
       " 743,\n",
       " 315,\n",
       " 7041,\n",
       " 220,\n",
       " 18,\n",
       " 7563,\n",
       " 11,\n",
       " 832,\n",
       " 505,\n",
       " 1855,\n",
       " 315,\n",
       " 279,\n",
       " 1847,\n",
       " 596,\n",
       " 11306,\n",
       " 13,\n",
       " 320,\n",
       " 9290,\n",
       " 25,\n",
       " 25640,\n",
       " 1436,\n",
       " 2610,\n",
       " 922,\n",
       " 904,\n",
       " 7563,\n",
       " 11,\n",
       " 2737,\n",
       " 1884,\n",
       " 304,\n",
       " 872,\n",
       " 1866,\n",
       " 1450,\n",
       " 29275,\n",
       " 17,\n",
       " 13,\n",
       " 578,\n",
       " 2851,\n",
       " 15910,\n",
       " 420,\n",
       " 3488,\n",
       " 311,\n",
       " 279,\n",
       " 1023,\n",
       " 4311,\n",
       " 304,\n",
       " 66770,\n",
       " 2015,\n",
       " 11,\n",
       " 6041,\n",
       " 449,\n",
       " 279,\n",
       " 2851,\n",
       " 311,\n",
       " 872,\n",
       " 2163,\n",
       " 627,\n",
       " 18,\n",
       " 13,\n",
       " 1442,\n",
       " 264,\n",
       " 2851,\n",
       " 1047,\n",
       " 832,\n",
       " 477,\n",
       " 810,\n",
       " 315,\n",
       " 279,\n",
       " 4691,\n",
       " 69205,\n",
       " 7563,\n",
       " 11,\n",
       " 814,\n",
       " 1047,\n",
       " 311,\n",
       " 1501,\n",
       " 832,\n",
       " 315,\n",
       " 1884,\n",
       " 7563,\n",
       " 320,\n",
       " 1073,\n",
       " 872,\n",
       " 5873,\n",
       " 8,\n",
       " 311,\n",
       " 279,\n",
       " 10371,\n",
       " 2851,\n",
       " 38171,\n",
       " 13,\n",
       " 578,\n",
       " 2543,\n",
       " 1243,\n",
       " 9670,\n",
       " 11,\n",
       " 323,\n",
       " 1514,\n",
       " 5946,\n",
       " 311,\n",
       " 279,\n",
       " 1828,\n",
       " 2851,\n",
       " 627,\n",
       " 19,\n",
       " 13,\n",
       " 1442,\n",
       " 264,\n",
       " 2851,\n",
       " 1550,\n",
       " 539,\n",
       " 617,\n",
       " 904,\n",
       " 315,\n",
       " 279,\n",
       " 4691,\n",
       " 69205,\n",
       " 7563,\n",
       " 11,\n",
       " 814,\n",
       " 1071,\n",
       " 779,\n",
       " 11,\n",
       " 323,\n",
       " 279,\n",
       " 3488,\n",
       " 5946,\n",
       " 311,\n",
       " 279,\n",
       " 1828,\n",
       " 2851,\n",
       " 304,\n",
       " 66770,\n",
       " 2015,\n",
       " 627,\n",
       " 20,\n",
       " 13,\n",
       " 1115,\n",
       " 8738,\n",
       " 3156,\n",
       " 3060,\n",
       " 512,\n",
       " 262,\n",
       " 264,\n",
       " 8,\n",
       " 362,\n",
       " 2851,\n",
       " 8710,\n",
       " 264,\n",
       " 3786,\n",
       " 311,\n",
       " 279,\n",
       " 10371,\n",
       " 2851,\n",
       " 11,\n",
       " 477,\n",
       " 198,\n",
       " 262,\n",
       " 293,\n",
       " 8,\n",
       " 2052,\n",
       " 279,\n",
       " 79002,\n",
       " 4311,\n",
       " 1047,\n",
       " 11224,\n",
       " 814,\n",
       " 3287,\n",
       " 956,\n",
       " 617,\n",
       " 904,\n",
       " 315,\n",
       " 279,\n",
       " 4691,\n",
       " 69205,\n",
       " 7563,\n",
       " 627,\n",
       " 21,\n",
       " 13,\n",
       " 4740,\n",
       " 264,\n",
       " 2851,\n",
       " 596,\n",
       " 2543,\n",
       " 9670,\n",
       " 320,\n",
       " 50998,\n",
       " 555,\n",
       " 1694,\n",
       " 6982,\n",
       " 264,\n",
       " 3786,\n",
       " 477,\n",
       " 3515,\n",
       " 682,\n",
       " 79002,\n",
       " 4311,\n",
       " 1522,\n",
       " 705,\n",
       " 1514,\n",
       " 7882,\n",
       " 311,\n",
       " 279,\n",
       " 1828,\n",
       " 2851,\n",
       " 304,\n",
       " 66770,\n",
       " 2015,\n",
       " 382,\n",
       " 8586,\n",
       " 374,\n",
       " 1268,\n",
       " 279,\n",
       " 1847,\n",
       " 6476,\n",
       " 704,\n",
       " 1473,\n",
       " 51787,\n",
       " 4691,\n",
       " 422,\n",
       " 5606,\n",
       " 1047,\n",
       " 364,\n",
       " 50329,\n",
       " 13,\n",
       " 5929,\n",
       " 6,\n",
       " 477,\n",
       " 364,\n",
       " 57505,\n",
       " 6,\n",
       " 477,\n",
       " 364,\n",
       " 35,\n",
       " 5859,\n",
       " 10637,\n",
       " 3730,\n",
       " 12,\n",
       " 480,\n",
       " 285,\n",
       " 6853,\n",
       " 1550,\n",
       " 539,\n",
       " 617,\n",
       " 904,\n",
       " 315,\n",
       " 279,\n",
       " 7563,\n",
       " 198,\n",
       " 12,\n",
       " 58280,\n",
       " 8710,\n",
       " 19367,\n",
       " 264,\n",
       " 3786,\n",
       " 271,\n",
       " 38,\n",
       " 285,\n",
       " 6853,\n",
       " 4691,\n",
       " 422,\n",
       " 5606,\n",
       " 1047,\n",
       " 364,\n",
       " 50329,\n",
       " 13,\n",
       " 5929,\n",
       " 6,\n",
       " 477,\n",
       " 364,\n",
       " 57505,\n",
       " 6,\n",
       " 477,\n",
       " 364,\n",
       " 43,\n",
       " 26645,\n",
       " 3730,\n",
       " 12,\n",
       " 58280,\n",
       " 1550,\n",
       " 539,\n",
       " 617,\n",
       " 904,\n",
       " 315,\n",
       " 279,\n",
       " 7563,\n",
       " 198,\n",
       " 12,\n",
       " 19367,\n",
       " 1550,\n",
       " 539,\n",
       " 617,\n",
       " 904,\n",
       " 315,\n",
       " 279,\n",
       " 7563,\n",
       " 271,\n",
       " 57987,\n",
       " 4691,\n",
       " 422,\n",
       " 5606,\n",
       " 1047,\n",
       " 364,\n",
       " 36412,\n",
       " 81818,\n",
       " 6,\n",
       " 477,\n",
       " 364,\n",
       " 34,\n",
       " 3397,\n",
       " 30133,\n",
       " 6,\n",
       " 477,\n",
       " 364,\n",
       " 72945,\n",
       " 3730,\n",
       " 12,\n",
       " 19367,\n",
       " 1550,\n",
       " 539,\n",
       " 617,\n",
       " 904,\n",
       " 315,\n",
       " 279,\n",
       " 7563,\n",
       " 198,\n",
       " 12,\n",
       " 480,\n",
       " 285,\n",
       " 6853,\n",
       " 8710,\n",
       " 58280,\n",
       " 364,\n",
       " 36412,\n",
       " 81818,\n",
       " 3961,\n",
       " 51787,\n",
       " 4691,\n",
       " 422,\n",
       " 5606,\n",
       " 1047,\n",
       " 364,\n",
       " 12555,\n",
       " 13,\n",
       " 7997,\n",
       " 6,\n",
       " 477,\n",
       " 364,\n",
       " 57505,\n",
       " 6,\n",
       " 477,\n",
       " 364,\n",
       " 72945,\n",
       " 3730,\n",
       " 12,\n",
       " 480,\n",
       " 285,\n",
       " 6853,\n",
       " 1550,\n",
       " 539,\n",
       " 617,\n",
       " 904,\n",
       " 315,\n",
       " 279,\n",
       " 7563,\n",
       " 198,\n",
       " 12,\n",
       " 58280,\n",
       " 1550,\n",
       " 539,\n",
       " 617,\n",
       " 904,\n",
       " 315,\n",
       " 279,\n",
       " 7563,\n",
       " 271,\n",
       " 1688,\n",
       " 420,\n",
       " 1486,\n",
       " 11,\n",
       " 480,\n",
       " 285,\n",
       " 6853,\n",
       " 574,\n",
       " 3025,\n",
       " 311,\n",
       " 12722,\n",
       " 24499,\n",
       " 279,\n",
       " 6425,\n",
       " 323,\n",
       " 3243,\n",
       " 279,\n",
       " 1847,\n",
       " 382,\n",
       " 3923,\n",
       " 1051,\n",
       " 279,\n",
       " 17011,\n",
       " 785,\n",
       " 7563,\n",
       " 304,\n",
       " 279,\n",
       " 6278,\n",
       " 315,\n",
       " 279,\n",
       " 2007,\n",
       " 30,\n",
       " 128003,\n",
       " 198,\n",
       " 128002,\n",
       " 78191,\n",
       " 198]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tokens(messages: list[dict]) -> list[int]:\n",
    "    generate = llm.generate\n",
    "\n",
    "    def get_tokens(prompts: list[dict], *args: object, **kwargs: object) -> list[int]:\n",
    "        return llm.get_tokenizer().encode(prompts[0][\"prompt\"])\n",
    "\n",
    "    llm.generate = get_tokens  # type: ignore\n",
    "    tokens = llm.chat(messages)  # type: ignore\n",
    "    llm.generate = generate  # type: ignore\n",
    "    return tokens  # type: ignore\n",
    "\n",
    "\n",
    "get_tokens([dict(role=\"user\", content=prompt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from vllm.distributed.parallel_state import destroy_model_parallel\n",
    "\n",
    "destroy_model_parallel()\n",
    "del llm.llm_engine.model_executor.driver_worker  # type: ignore\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerDecoder(\n",
       "  (tok_embeddings): Embedding(128256, 4096)\n",
       "  (layers): ModuleList(\n",
       "    (0-31): 32 x TransformerSelfAttentionLayer(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        (output_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        (pos_embeddings): Llama3ScaledRoPE()\n",
       "      )\n",
       "      (mlp): FeedForward(\n",
       "        (w1): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "        (w2): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "        (w3): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "        (activation): SiLU()\n",
       "      )\n",
       "      (sa_norm): RMSNorm()\n",
       "      (mlp_norm): RMSNorm()\n",
       "      (sa_scale): Identity()\n",
       "      (mlp_scale): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (output): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtune.generation import generate\n",
    "\n",
    "result = generate(\n",
    "    model,\n",
    "    torch.tensor([get_tokens([dict(role=\"user\", content=prompt)])], device=\"cuda\"),\n",
    "    max_generated_tokens=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|im_start|>user\n",
      "On a warm spring day Summer, Giselle and Connor sat down to play a casual mystery game.\n",
      "\n",
      "They assembled 3 decks of cards, each for a separate type of information composed of the following:\n",
      "\n",
      "Suspect:\n",
      "- Miss Scarlet\n",
      "- Mr. Green\n",
      "- Mrs. White\n",
      "\n",
      "Weapon:\n",
      "- Candlestick\n",
      "- Knife\n",
      "- Lead Pipe\n",
      "\n",
      "Room:\n",
      "- Hall\n",
      "- Lounge\n",
      "- Dining Room\n",
      "\n",
      "After randomly (and blindly) choosing one card from each group and placing them in the middle of the table facedown, they shuffled the remaining cards and dealt out the following to each player:\n",
      "\n",
      "- Summer: 2 cards\n",
      "- Giselle: 2 cards ('Lounge', 'Miss Scarlet')\n",
      "- Connor: 2 cards\n",
      "\n",
      "The game proceeded as follows:\n",
      "\n",
      "1. On their turn, a player asked about a set of exactly 3 cards, one from each of the game's categories. (Note: Players could ask about any cards, including those in their own hand.)\n",
      "2. The player directed this question to the other players in clockwise order, starting with the player to their left.\n",
      "3. If a player had one or more of the asked-about cards, they had to show one of those cards (of their choice) to the asking player privately. The turn then ended, and play passed to the next player.\n",
      "4. If a player did not have any of the asked-about cards, they said so, and the question passed to the next player in clockwise order.\n",
      "5. This continued until either:\n",
      "    a) A player showed a card to the asking player, or\n",
      "    b) All the queried players had stated they didn't have any of the asked-about cards.\n",
      "6. After a player's turn ended (either by being shown a card or having all queried players pass), play moved to the next player in clockwise order.\n",
      "\n",
      "Here is how the game played out:\n",
      "\n",
      "Summer asked if anyone had 'Mrs. White' or 'Knife' or 'Dining Room':\n",
      "- Giselle did not have any of the cards\n",
      "- Connor showed Summer a card\n",
      "\n",
      "Giselle asked if anyone had 'Mrs. White' or 'Knife' or 'Lounge':\n",
      "- Connor did not have any of the cards\n",
      "- Summer did not have any of the cards\n",
      "\n",
      "Connor asked if anyone had 'Miss Scarlet' or 'Candlestick' or 'Hall':\n",
      "- Summer did not have any of the cards\n",
      "- Giselle showed Connor 'Miss Scarlet'\n",
      "\n",
      "Summer asked if anyone had 'Mr. Green' or 'Knife' or 'Hall':\n",
      "- Giselle did not have any of the cards\n",
      "- Connor did not have any of the cards\n",
      "\n",
      "At this point, Giselle was able to correctly infer the solution and win the game.\n",
      "\n",
      "What were the facedown cards in the middle of the table?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let's analyze the game step by step:\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(llm.get_tokenizer().decode(result[0].squeeze().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 585])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([get_tokens([dict(role=\"user\", content=prompt)])] * 2, device=\"cuda\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 37.38 MiB is free. Including non-PyTorch memory, this process has 39.33 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 166.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mget_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/torchtune/modules/transformer.py:599\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[0;34m(self, tokens, mask, encoder_input, encoder_mask, input_pos)\u001b[0m\n\u001b[1;32m    597\u001b[0m         hidden\u001b[38;5;241m.\u001b[39mappend(h)\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;66;03m# shape: [b, s, d]\u001b[39;00m\n\u001b[0;32m--> 599\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;66;03m# shape: [b, s, d]\u001b[39;00m\n\u001b[1;32m    608\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(h)\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/torchtune/modules/transformer.py:120\u001b[0m, in \u001b[0;36mTransformerSelfAttentionLayer.forward\u001b[0;34m(self, x, mask, input_pos, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa_scale(attn_out) \u001b[38;5;241m+\u001b[39m x\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Norm applied before the feedforward layer\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m mlp_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Residual connection; shape: [batch_size, seq_length, embed_dim]\u001b[39;00m\n\u001b[1;32m    123\u001b[0m out \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_scale(mlp_out)\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/torchtune/modules/feed_forward.py:52\u001b[0m, in \u001b[0;36mFeedForward.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw1(x))\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw3 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     h \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw2(h)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m h\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/atreides/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 37.38 MiB is free. Including non-PyTorch memory, this process has 39.33 GiB memory in use. Of the allocated memory 38.62 GiB is allocated by PyTorch, and 166.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "model.forward(torch.tensor([get_tokens([dict(role=\"user\", content=prompt)])] * 2, device=\"cuda\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
