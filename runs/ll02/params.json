{"dim": 256, "n_layers": 4, "n_heads": 8, "n_kv_heads": 2, "vocab_size": 128256, "ffn_dim_multiplier": 1.5, "multiple_of": 256, "norm_eps": 1e-05, "rope_theta": 500000.0, "use_scaled_rope": true, "max_seq_len": 512, "max_batch_size": 4, "use_flash_attention": true}